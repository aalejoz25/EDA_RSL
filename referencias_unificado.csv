fuente|authors|author_full_names|Author_ID|title|year|source_title|volume|issue|art|page_start|page_end|page_count|cited_by|DOI|link|abstract|author_Keywords|index_keywords|document_type|publication_stage|open_access|source|EID
scopus||||Future of Information and Communication Conference, FICC 2025|2025|Lecture Notes in Networks and Systems|1283 LNNS|||||2265|0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000643403&partnerID=40&md5=f731da4dbd030d96147c0de7329df1c6|The proceedings contain 138 papers. The special focus in this conference is on Future of Information and Communication. The topics include: Robots in Healthcare: Measuring Acceptance of Professional Caregivers Towards Finding Key Requirements for System Design; a Human-Centric Architecture for Natural Interaction with Organizational Systems; industrial Metaverse for Smart Manufacturing: Ecosystem Architecture and Applications; centralised Graph-Based Collision-Free Air Traffic Management Approach for Autonomous Aerial Vehicle Navigation; phytoNode Upgraded: Energy-Efficient Long-Term Environmental Monitoring Using Phytosensing; evaluating the Socio-Economic Impacts of Hyperloop Technology Through the Lens of Labour Market: A Focus on Intelligent Transportation, Case of Latvia; Human-In-The-Loop Reasoning for Traffic Sign Detection: Collaborative Approach YOLO with Video-LLaVA; Reasoning with Generative AI; “Model Cards for Model Reporting” in 2024: Reclassifying Category of Ethical Considerations in Terms of Trustworthiness and Risk Management; robotic Process Automation in Software Testing: Challenges and Open Research Directions; chatbot Personas as a Gateway to Enhanced Learning Experiences; is It Time to Start Taking the Concept of a Holodeck Seriously?; agent for Machine Learning: A Text-to-Model (T2M) Approach; The Theory of Cybernetics for Managing Human-AI Interactions: A Framework for AI Management; steering Toward Trustworthiness: A Speech-Act Theory Perspective on Building Trust in Language Models for Autonomous Vehicle Applications; fingerprint Synthesis from Diffusion Models and Generative Adversarial Networks; Easy Problems that LLMs Get Wrong; socratic Dialogue with Generative Artificial Intelligence: Where is the Future?; Vectoring Languages: A High-Dimensional Perspective of Language to Bridge the Gap Between Philosophy and AI Science; The Elephant in the Room: Why AI Safety Demands Diverse Teams; exploring Foundation Model Fusion Effectiveness and Explainability for Stylistic Analysis of Emotional Podcast Data; machine Learning Enabled Earthquake Classification with Real Time Monitoring and Alert System.|||Conference review|Final||Scopus|2-s2.0-105000643403
scopus|Adline Freeda R.; Sudha K.|Adline Freeda, R. (57191618601); Sudha, K. (59978506500)|57191618601; 59978506500|Top AI-powered tools for software test automation|2025|Artificial Intelligence for Cloud-Native Software Engineering||||263|282|19|0|10.4018/979-8-3693-9356-7.ch010|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105009879839&doi=10.4018%2f979-8-3693-9356-7.ch010&partnerID=40&md5=fa5450c30d35dfed9337edaba11b722b|As software systems become more complex, there is also an acute need for efficient, accurate, and scalable testing solutions. While traditional test automation is indeed quite powerful, it very often has to struggle against the demands of more advanced development environments that rely on continuous integration and delivery pipelines. We will compare these tools with a number of real-world case studies, underlining the improvements in how these tools enhance software quality and reduce the time-to-market along with the ability to perform continuous testing.Of course, we also touch upon the related issues when adopting AI-driven testing solutions-the challenges of data privacy and the integration complexity of new tools into existing workflows. By the end of this chapter, you will understand in clear-cut terms the main benefits and limitations and the scope of AI-powered tools, thus making them better decision-makers when it comes to choosing and applying such technology to their software testing processes. © 2025, IGI Global Scientific Publishing. All rights reserved.||Automation; Computer software selection and evaluation; Integration testing; Software quality; Case-studies; Continuous integrations; Continuous testing; Development environment; Real-world; Software Quality; Software test automation; Software-systems; Test Automation; Time to market; Ability testing|Book chapter|Final||Scopus|2-s2.0-105009879839
scopus|Karlsson A.; Lindmaa E.; Sun S.; Staron M.|Karlsson, Albin (59233098900); Lindmaa, Erik (59461382000); Sun, Simin (59398905000); Staron, Miroslaw (6505767603)|59233098900; 59461382000; 59398905000; 6505767603|AI-Based Automotive Test Case Generation: An Action Research Study on Integration of Generative AI into Test Automation Frameworks|2025|Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) |15453 LNCS|||50|66|16|0|10.1007/978-3-031-78392-0_4|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211222986&doi=10.1007%2f978-3-031-78392-0_4&partnerID=40&md5=d4d4bfc3a2216fd6002168a0549b418a|Generative AI is transforming software development, particularly in unit and regression testing. However, it’s rarely used in Hardware-in-the-Loop (HIL) testing due to hardware-specific environments. This paper examines integrating GitHub Copilot into automotive test automation frameworks, focusing on Volvo’s Test Automation Framework (TAF). It explores how Copilot can automate test case generation and compares AI-generated test cases with manually written ones in terms of reliability and robustness. Using an iterative action research methodology, the study evaluates the functional suitability of AI-generated test cases and the challenges of integration. Results show that in the first iteration, 23% of AI-generated test cases passed in Jenkins and received high functionality scores. In the second iteration, this increased to 36%. These findings highlight the potential of Generative AI to enhance HIL testing. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.|Generative AI; Hardware-in-the-Loop (HIL) Testing; Test Automation Framework (TAF); Testcase Generation|Automatic test pattern generation; Automobile testing; Generative adversarial networks; Hardware-in-the-loop simulation; Integration testing; Action research; Automotive tests; Generative AI; Hardware-in-the-loop testing; Research studies; Test automation framework; Test automation frameworks; Test case; Test case generation; Unit testing; Software design|Conference paper|Final||Scopus|2-s2.0-85211222986
scopus|Liu Y.; Wang Q.|Liu, Yin (60004970000); Wang, Quanxin (60005280400)|60004970000; 60005280400|Exploration of experimental teaching mode of software testing course based on OBE concept and deep learning|2025|Discover Artificial Intelligence|5|1|154||||0|10.1007/s44163-025-00403-9|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105011032883&doi=10.1007%2fs44163-025-00403-9&partnerID=40&md5=61846b1ed860fed00271fcfb0b17ddf3|Software testing education is closely related to science and technology. The emerging technological innovation and the development of educational theory require curriculum design and implementation methods to keep pace with the times. This study explores the experimental teaching mode of applying the concept of output-oriented education (OBE) and deep learning technology to the software testing course. Through a detailed literature review, this paper clarifies the challenges faced by the current software testing education and the existing teaching gaps. Then, it puts forward an innovative teaching model design. This study adopts a series of research designs and methods to experiment and verify the effectiveness of teaching mode based on the OBE concept and deep learning in improving the learning effect of software testing courses. Through the rigorous analysis of experimental data, the research results reveal the obvious advantages of this teaching mode in enhancing students' learning motivation, understanding and practical operation ability and suggesting future educational practice and research direction. © The Author(s) 2025.|Deep learning technology; Model of instruction; Output-oriented education (OBE); Software testing education|Curricula; Deep learning; Design; Educational technology; Engineering education; Learning systems; Teaching; Deep learning technology; Experimental teaching modes; Learning technology; Model of instruction; Output-oriented education (OBE); Science and Technology; Software testing education; Software testings; Teaching modes; Technological innovation; Software testing|Article|Final||Scopus|2-s2.0-105011032883
scopus|Ardic B.; Brandt C.; Khatami A.; Swillus M.; Zaidman A.|Ardic, Baris (57220805933); Brandt, Carolin (57219536571); Khatami, Ali (58475870200); Swillus, Mark (58106336100); Zaidman, Andy (18435685400)|57220805933; 57219536571; 58475870200; 58106336100; 18435685400|The qualitative factor in software testing: A systematic mapping study of qualitative methods|2025|Journal of Systems and Software|227||112447||||0|10.1016/j.jss.2025.112447|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002843686&doi=10.1016%2fj.jss.2025.112447&partnerID=40&md5=3a0d99dd7d0df324862a1632b59733c7|Software testing research has provided metrics on efficiency, error rates, and insights into the effectiveness of testing methodologies and tools. However, these tell only a part of the story. The qualitative dimension, which studies experiences, perceptions, and decision-making processes is crucial, but less prevalent in literature. This study aims to systematically map qualitative research in software testing to consolidate and categorize the methodologies used in qualitative testing research, highlight their importance, and identify patterns, gaps, and future directions. We conducted a systematic mapping study, identifying and analyzing 102 primary studies from 2003 to 2023. We categorized the studies according to research strategies, data collection, and data analysis methods. We identified case studies and grounded theory as the most prevalent research strategies. Researchers primarily used semi-structured interviews and thematic analysis to understand how practitioners work and gather stakeholder perspectives. The subject areas most covered by qualitative studies included software testing processes and risks, and test automation. Areas such as test oracles, and machine learning were underrepresented. We also assessed the quality of reporting and the methodological rigor, emphasizing the challenges and limitations identified during the process. Through this study, we provide a comprehensive overview of qualitative research practices in software testing, revealing trends, gaps, and methodological insights. © 2025 The Authors|Human factors; Qualitative analysis; Qualitative methodology; Software testing; Systematic mapping|Mapping; Software testing; Error rate; Qualitative analysis; Qualitative factors; Qualitative method; Qualitative methodologies; Qualitative research; Research strategy; Software testings; Systematic mapping; Systematic mapping studies; Adversarial machine learning|Article|Final|All Open Access; Hybrid Gold Open Access|Scopus|2-s2.0-105002843686
scopus|Banala S.; Panyaram S.; Selvakumar P.|Banala, Subash (59665598500); Panyaram, Sudheer (59664368200); Selvakumar, P. (57201867763)|59665598500; 59664368200; 57201867763|Artificial intelligence in software testing|2025|Artificial Intelligence for Cloud-Native Software Engineering||||237|262|25|0|10.4018/979-8-3693-9356-7.ch009|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105009873694&doi=10.4018%2f979-8-3693-9356-7.ch009&partnerID=40&md5=0893fcc8bcb09bcdf5a5c84ce3e4370c|AI which is reshaping the landscape of quality assurance (QA) by enhancing efficiency, accuracy, and coverage. Traditionally, software testing has relied heavily on manual and semi-automated processes, often leading to time-consuming and error-prone tasks. AI introduces a new paradigm in software testing, offering advanced methodologies and tools that significantly improve the effectiveness and efficiency of QA practices. Additionally, AI enhances test maintenance and evolution. Traditional test suites require manual updates as software evolves, which can be labor-intensive and prone to oversight. AI-powered tools can automatically adjust test cases and scripts to accommodate changes in the software, reducing the manual effort required to maintain and update tests. By leveraging AI to detect changes in the software and adjust tests accordingly, organizations can ensure that their test suites remain relevant and effective throughout the development lifecycle.Another significant advancement brought about by AI is the optimization of test execution. © 2025, IGI Global Scientific Publishing. All rights reserved.||Automation; Life cycle; Quality assurance; Automated process; Effectiveness and efficiencies; Error prone tasks; Labour-intensive; Optimisations; Quality assurance practices; Software testings; Test case; Test maintenances; Test scripts; Software testing|Book chapter|Final||Scopus|2-s2.0-105009873694
scopus|Poth A.; Rrjolli O.; Arcuri A.|Poth, Alexander (57207597845); Rrjolli, Olsi (57889770900); Arcuri, Andrea (23097099900)|57207597845; 57889770900; 23097099900|Technology adoption performance evaluation applied to testing industrial REST APIs|2025|Automated Software Engineering|32|1|5||||4|10.1007/s10515-024-00477-2|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211119965&doi=10.1007%2fs10515-024-00477-2&partnerID=40&md5=2e90ff188de38cd38412eceacc5bc71f|Testing is an important task within software development. To write test cases and integrate them into an automated test suite requires a significant amount of work. Given a set of requirements and specifications of a software, testing is needed to verify its correctness. When done manually, it is an expensive and error prone task. To facilitate such work, automated test-case generation via tools could be useful. Test-case generation can be facilitated by deterministic algorithm-driven approaches or non-deterministic approaches such as with AI (e.g., evolutionary and LLM). The different approaches come with their strengths and weaknesses, which must be considered when integrating these approaches into a product test procedure in industry. Several novel testing techniques and tools have been developed in academia and industry, but how effective they are and how to integrate them in real-world large industrial scenarios is still unclear. In this paper, a systematic approach is presented to evaluate test-case generation methodologies and integrate them into a scalable enterprise setup. The specific context is black-box testing of REST APIs, based on their OpenAPI schemas. The aim is to facilitate IT product development and service delivery. The proposed Technology Adoption Performance Evaluation (TAPE) approach is evaluated by a case study within the Group IT of Volkswagen AG. We evaluated existing tools such as OpenAPI Generator, EvoMaster and StarCoder which are built on different technologies. Our results show that these tools are of benefit for test engineers to facilitate test-case specification and design within the Group IT of Volkswagen AG. © The Author(s) 2024.|API validation; Benchmarking; LLM; Quality engineering; Requirements-based testing; SBST; Test automation; Test-case generation|Automatic test pattern generation; Benchmarking; Black-box testing; Computer software selection and evaluation; Failure analysis; Integration testing; Requirements engineering; API validation; LLM; Performances evaluation; Quality engineering; Requirement-based testing; SBST; Technology adoption; Test Automation; Test case generation; Volkswagen AG; Software design|Article|Final|All Open Access; Hybrid Gold Open Access|Scopus|2-s2.0-85211119965
scopus|Withunsapphasiri J.; Phannachitta P.; Doungsa-Ard C.|Withunsapphasiri, Jiramed (59789660300); Phannachitta, Passakorn (54917592600); Doungsa-Ard, Chartchai (6507087471)|59789660300; 54917592600; 6507087471|Predicting Test Smell Categories based on Issue Descriptions using Information Retrieval and Machine Learning Techniques|2025|10th International Conference on Digital Arts, Media and Technology, DAMT 2025 and 8th ECTI Northern Section Conference on Electrical, Electronics, Computer and Telecommunications Engineering, NCON 2025||||125|130|5|0|10.1109/ECTIDAMTNCON64748.2025.10961982|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105004552037&doi=10.1109%2fECTIDAMTNCON64748.2025.10961982&partnerID=40&md5=b0b2a3beecbfd13722f2450f1382a6bb|Effective software testing is essential for achieving high-quality software products. Various strategies and methods are used to ensure the software meets requirements and functionality, but test smell is one of the challenges to achieving effective software testing. These smells contain various issues, such as execution behavior, semantic inconsistencies, dependency management, inefficiencies, and code-related problems. This study investigates applying information retrieval (IR) and machine learning techniques to predict test smell categories by analyzing natural language issue descriptions and shifting from code-based to issue-based approaches. The result reveals that preprocessing techniques impact model performance. Techniques such as Spacy demonstrated better performance due to their sophisticated language models, while TF-IDF proved effective in distinguishing semantic inconsistencies in textual issue descriptions. Oversampling appeared as a crucial method for handling data imbalance and enhancing model performance across all test smell categories. However, N-gram requires further investigation to capture the relationship in issue descriptions. These findings show the possibility of combining natural language processing with machine learning to predict and address test smell categories, contributing to more reliable software testing practices and reducing the mistakes that will happen. This study can potentially explore additional preprocessing strategies, oversampling techniques, and machine learning models to optimize predictive performance. © 2025 IEEE.|Information Retrieval; Machine Learning; Mining Software Repositories; Software Engineering; Software Testing; Test smells|Application programs; Computer aided software engineering; Computer operating systems; Computer program listings; Computer software maintenance; Computer software selection and evaluation; Integration testing; Program processors; Search engines; Software design; Software packages; Software prototyping; Software quality; Utility programs; Machine learning techniques; Machine-learning; Mining software; Mining software repository; Modeling performance; Natural languages; Semantic inconsistencies; Software repositories; Software testings; Test smell; Model checking|Conference paper|Final||Scopus|2-s2.0-105004552037
scopus|Rao G.; Nandal D.|Rao, Gajender (59759916500); Nandal, Deepak (57192575801)|59759916500; 57192575801|Test Case Optimization using Machine Learning based Hybrid Meta-Heuristic Approach|2025|Journal of Electronic Testing: Theory and Applications (JETTA)|41|2||173|192|19|0|10.1007/s10836-025-06165-7|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003864871&doi=10.1007%2fs10836-025-06165-7&partnerID=40&md5=7f9408a717daa94ecdd174bde7a7e8bd|Software testing is a critical task that can be used to ensure the quality of the end product. Different types of applications process the input data with respect to a specific operation and its outcomes are generated accordingly. It is essential to test each application as per the supported functionality, and it is also necessary to optimize the test cases for applications to reduce the computational cost. To achieve this goal, there is a need to design different test cases as well as an intelligent solution is required to select and optimize the test cases according to the requirements. Particle swarm optimization (PSO) and Genetic Algorithm (GA) both are capable enough to produce the optimal solutions for software testing. However, there is no provision to perform the classification over their outcomes with respect to test case optimization using machine learning support. This paper presents a hybrid meta-heuristic method that selects the test cases on behalf of their attributes as well as it also performs classification over the test cases under the constraints of the test case’s attributes. For experiments, different classifiers are used (i.e. k-nearest neighbour (KNN), Decision Tree (DT), Logistic Regression (LOG), Support Vector Machine (SVM), Gaussian Naive Bayes (GNB), Stochastic gradient descent (SGD) and Random Forest (RDF) etc.) and analysis shows that GNB and SGD classifiers both have optimal accuracy, precision & recall values. As compared to existing algorithms, i.e. traditional PSO and Genetic algorithm, it outperforms in terms of optimal number of detected errors (1821), error rate (91.05) and coverage rate (90.86363636). The Proposed scheme can be extended to optimize the test cases for other software types, along with real-time interaction and dataset updation support for software testers. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2025.|Meta-heuristics approaches; Software Testing; Test case generation|Enterprise software; Logistic regression; Software quality; Testbeds; Hybrid metaheuristics; Machine-learning; Meta-heuristic approach; Optimisations; Optimization and genetic algorithms; Particle swarm genetic algorithms; Particle swarm optimization algorithm; Software testings; Test case; Test case generation; Random forests|Article|Final||Scopus|2-s2.0-105003864871
scopus|Niu T.; Lee R.; Lam S.; Hafen J.; Lukow S.; Li N.; Hosemann P.; Gigax J.|Niu, Tongjun (57193006801); Lee, Ross (58781248200); Lam, Sebastian (57899509000); Hafen, Joseph (57219309900); Lukow, Steven (57221818479); Li, Nan (55677088186); Hosemann, Peter (23099630500); Gigax, Jonathan (56066484800)|57193006801; 58781248200; 57899509000; 57219309900; 57221818479; 55677088186; 23099630500; 56066484800|A Novel Machine Learning-Driven Approach to High Throughput Mechanical Testing|2025|JOM|77|4|138632|2121|2133|12|0|10.1007/s11837-024-07063-7|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217198428&doi=10.1007%2fs11837-024-07063-7&partnerID=40&md5=f9ac2ecdccc1c58ec7c99e66025ed38b|Mechanical testing is a critical but often protracted process for evaluating materials. This study demonstrates a novel high-throughput approach that integrates femtosecond laser machining for rapid sample preparation, automated tensile testing of specimen arrays, and machine learning techniques for efficient data analysis. 316L stainless steel and additively manufactured grade 91 steel were used to fashion miniature tensile specimens. The mechanical properties were automatically extracted from the ensuing stress-strain curves using both a supervised deep learning segmentation model (U-Net) and unsupervised clustering methods (k-means, DBSCAN). While all techniques performed acceptably on the more homogeneous 316L samples, the trained U-Net showed superior robustness and accuracy when analyzing the highly heterogeneous grade 91 specimens, with errors 2–3 times lower than the unsupervised approaches compared to manual analysis. The initial expense incurred generating training data for the U-Net was offset by significantly decreased analysis time and improved consistency. This unified methodology, combining machining, automated testing, and machine learning, provides an accelerated workflow for investigating mechanical properties of both additively manufactured and conventional alloys. © The Minerals, Metals & Materials Society 2025.||Deep learning; K-means clustering; Laser beam cutting; Laser materials processing; Network security; Self-supervised learning; Steel testing; Stress-strain curves; Supervised learning; Tensile strength; Tensile testing; Unsupervised learning; 316 L stainless steel; Femtosecond laser machining; Grade 91 steel; High-throughput; High-throughput approaches; Machine learning techniques; Machine-learning; Mechanical; Property; Sample preparation; Femtosecond lasers|Article|Final||Scopus|2-s2.0-85217198428
scopus|Choi C.; Kwon Y.; Kang D.; Kim C.; Jung S.|Choi, Cheolu (59558766500); Kwon, Yongwan (57377507200); Kang, Dongjoong (55455030300); Kim, Changseop (59558766600); Jung, Sabum (59558766700)|59558766500; 57377507200; 55455030300; 59558766600; 59558766700|Development of Washing Machine Dehydration Unbalance Control Specifications Through Bayesian Optimization|2025|Applied Sciences (Switzerland)|15|3|1632||||0|10.3390/app15031632|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217846345&doi=10.3390%2fapp15031632&partnerID=40&md5=e432931dbd95f612a13d88e85a87bc76|Featured Application: Optimization of control parameters for home appliances. Optimizing control specifications to prevent unbalance during the dehydration process in washing machine development is a complex task that consumes significant time and resources. Traditional methods involve expert engineers conducting various experiments and data analyses to develop optimal control specifications. However, these approaches are time-consuming and struggle to optimize diverse performance factors simultaneously. Additionally, the quality of the results heavily depends on the engineers’ experience and capabilities, making it challenging to maintain consistent quality. To overcome these limitations, a new data-driven approach is proposed. This study proposes a methodology that uses Bayesian Optimization to predict the unbalance during the dehydration process and derive optimal control specifications to minimize it. Bayesian Optimization builds a predictive model based on collected data and uses an acquisition function for efficient exploration to find the optimal solution. Through this method, we automated the optimization of unbalance prevention control specifications. Applying the proposed methodology to an actual washing machine model achieved performance equivalent to that derived by expert engineers. Specifically, we succeeded in maintaining the maximum vibration during the dehydration process below the target level and reducing the time to reach high-speed rotation (RPM) ranges. The main contribution of this study is the rapid derivation of machine learning-based optimized control specifications with minimal human intervention and small-scale experiments by building a test automation system within the home appliance development process. This approach shortened the development period and improved quality consistency. © 2025 by the authors.|Bayesian Optimization; control; dehydration; spinning process; tuning; washing machine|Domestic appliances; Model predictive control; Optimal control systems; Washers; Bayesian optimization; Control parameters; Control specifications; Dehydration process; Machine development; Optimal controls; Optimisations; Optimizing control; Spinning process; Tuning; Washing machines|Article|Final|All Open Access; Gold Open Access|Scopus|2-s2.0-85217846345
scopus|Govinda S.; Prasanthi B.G.; Vincent A.N.|Govinda, Sangeetha (57219413559); Prasanthi, B.G. (57225932333); Vincent, Agnes Nalini (58882555100)|57219413559; 57225932333; 58882555100|Novel preemptive intelligent artificial intelligence-model for detecting inconsistency during software testing|2025|IAES International Journal of Artificial Intelligence|14|3||1781|1789|8|0|10.11591/ijai.v14.i3.pp1781-1789|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105008110548&doi=10.11591%2fijai.v14.i3.pp1781-1789&partnerID=40&md5=a62c2acf339ae2e1c316a933f75560bb|The contribution of artificial intelligence (AI)-based modelling is highly significant in automating the software testing process; thereby enhancing the cost, resources, and productivity while performing testing. Review of existing AI-models towards software testing showcases yet an open-scope for further improvement as yet the conventional AI-model suffers from various challenges especially in perspective of test case generation. Therefore, the proposed scheme presents a novel preemptive intelligent computational framework that harnesses a unique ensembled AI-model for generating and executing highly precise and optimized test-cases resulting in an outcome of adversary or inconsistencies associated with test cases. The ensembled AI-model uses both unsupervised and supervised learning approaches on publicly available outlier dataset. The benchmarked outcome exhibits supervised learning-based AI-model to offer 21% of reduced error and 1.6% of reduced processing time in contrast to unsupervised scheme while performing software testing. © 2025, Institute of Advanced Engineering and Science. All rights reserved.|Artificial intelligence; Automation; Error; Inconsistency; Software testing||Article|Final||Scopus|2-s2.0-105008110548
scopus|Gupta A.K.; Govindankutty S.; Nandyala A.R.; Maria Thason J.R.; Pippal S.; Gupta G.K.|Gupta, Ankit Kumar (59694056900); Govindankutty, Sreeprasad (59693674500); Nandyala, Avinash Reddy (59738630800); Maria Thason, Justin Rajakumar (59738610500); Pippal, Sanjeev (54279333400); Gupta, Gopal Kumar (59259332000)|59694056900; 59693674500; 59738630800; 59738610500; 54279333400; 59259332000|AI-Driven Test Automation for Big Data Systems in Cloud Environments|2025|1st International Conference on Advances in Computer Science, Electrical, Electronics, and Communication Technologies, CE2CT 2025||||1354|1359|5|0|10.1109/CE2CT64011.2025.10941644|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002700669&doi=10.1109%2fCE2CT64011.2025.10941644&partnerID=40&md5=aafd02de1e9cb2eedadd60ec64e52e95|AI-based Test Automation for Cloud-Based Big Advanced Data Systems this method used AI and other new data science methods such as big data, cloud computing, etc. Current testing methodologies do not suit the environments of modern big data systems in a cloud-based environment. AI based test automation approaches: Automated test scenario preparation, examination of test events to identify defects and generation of testing issues. Big data systems, on the other hand, can periodically scan for maximum performance with an all-AI approach, carry out A/B testing, and fine-tune performance. This is particularly important for cloud environments when the architecture of the system and data processing continually changes at a high rate. Additionally, AI in test automation is capable of detecting anomalies and predicting possible system breakdown, providing early warning of issues to ensure mitigation and thereby avoiding costly downtime. This way various scenarios and data sets can be tested and covered to ensure that the best results are covered. © 2025 IEEE.|Ensuring; Environment; Mitigation; Vulnerabilities Covered|Cloud environments; Cloud-based; Data systems; Ensuring; Environment; Mitigation; Performance; Science methods; Test Automation; Vulnerability covered; Data centers|Conference paper|Final||Scopus|2-s2.0-105002700669
scopus|Sisomboon W.; Kaewyotha J.; Dansakulcharoenkit P.; Songpan W.|Sisomboon, Wantana (57212476437); Kaewyotha, Jakkrit (56688577200); Dansakulcharoenkit, Prathan (59416176000); Songpan, Wararat (56688578200)|57212476437; 56688577200; 59416176000; 56688578200|AI-Driven Prompt Templates for User Acceptance Test Case Generation|2025|Communications in Computer and Information Science|2318 CCIS|||78|92|14|0|10.1007/978-981-97-9793-6_6|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209588387&doi=10.1007%2f978-981-97-9793-6_6&partnerID=40&md5=0b26487ec755fda741e74078aecd35d6|This study investigates the application of artificial intelligence to optimize the creation of user acceptance test (UAT) cases using large language models (LLMs) such as advanced AI text generators (e.g., ChatGPT, Claude AI, Gemini, and Copilot). These AI-driven tools, powered by LLMs, efficiently produce test cases, enhancing the reliability and efficiency of the testing process. The research rigorously evaluates these AI-driven approaches through empirical tests and their integration into real-world software testing settings. The performance evaluation focuses on precision, recall, F-score, accuracy, test coverage, average generation time, language proficiency, ease of use, and real-world applicability. The goal is to seamlessly integrate these tools into the standard testing workflows of a software testing and quality assurance company, reducing the workload on human testers by automating test case generation. This automation aims to enhance both the breadth and accuracy of tests and facilitate the creation of complex test scenarios. Experimental results indicate significant advancements in software testing methodologies compared to traditional methods such as Boundary Value Analysis (BVA), Equivalence Partitioning (EP), complex BVA, use case, and state transition testing. AI tools notably improve the formulation and implementation of UATs, saving time and ensuring software solutions align more effectively with user requirements and expectations. Overall, AI-powered text generators, particularly ChatGPT models (versions 4.0 and 3.5), demonstrated strong performance and high user satisfaction in generating UAT test cases, marking a significant step forward in automated software testing. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2025.|ChatGPT; Claude ai; CoPilot; Gemini; LLMs; User Acceptance Test Case|Application programs; Computer software selection and evaluation; Integration testing; Software quality; Software reliability; ChatGPT; Claude ai; Copilot; Geminus; Language model; Large language model; Software testings; Test case; User acceptance test case; Users' acceptance; Acceptance tests|Conference paper|Final||Scopus|2-s2.0-85209588387
scopus|Velasco A.; Garryyeva A.; Palacio D.N.; Mastropaolo A.; Poshyvanyk D.|Velasco, Alejandro (58548501800); Garryyeva, Aya (59565816800); Palacio, David N. (57215358958); Mastropaolo, Antonio (54784859600); Poshyvanyk, Denys (13613571900)|58548501800; 59565816800; 57215358958; 54784859600; 13613571900|Toward Neurosymbolic Program Comprehension|2025|IEEE International Conference on Program Comprehension||||377|381|4|0|10.1109/ICPC66645.2025.00047|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105009062479&doi=10.1109%2fICPC66645.2025.00047&partnerID=40&md5=270776a4f6dcb39ceff8f39854f59249|Recent advancements in Large Language Models (LLMs) have paved the way for Large Code Models (LCMs), enabling automation in complex software engineering tasks, such as code generation, software testing, and program comprehension, among others. Tools like GitHub Copilot and ChatGPT have shown substantial benefits in supporting developers across various practices. However, the ambition to scale these models to trillion-parameter sizes, exemplified by GPT-4, poses significant challenges that limit the usage of Artificial Intelligence (AI)-based systems powered by large Deep Learning (DL) models. These include rising computational demands for training and deployment and issues related to trustworthiness, bias, and interpretability. Such factors can make managing these models impractical for many organizations, while their 'black-box' nature undermines key aspects, including transparency and accountability. In this paper, we question the prevailing assumption that increasing model parameters is always the optimal path forward, provided there is sufficient new data to learn additional patterns. In particular, we advocate for a Neurosymbolic research direction that combines the strengths of existing DL techniques (e.g., LLMs) with traditional symbolic methods-renowned for their reliability, speed, and determinism. To this end, we outline the core features and present preliminary results for our envisioned approach, aimed at establishing the first Neurosymbolic Program Comprehension (NsPC) framework to aid in identifying defective code components. © 2025 IEEE.|Interpretability; Neuro-Symbolic AI; Program Comprehension; Vulnerability Detection|Computer systems programming; Deep learning; Learning systems; Optimal systems; Software testing; Codegeneration; Complex software; Engineering tasks; Interpretability; Language model; Neuro-symbolic artificial intelligence; Program comprehension; Software project; Software testings; Vulnerability detection; Codes (symbols)|Conference paper|Final||Scopus|2-s2.0-105009062479
scopus|Rawson J.; Reddivari S.|Rawson, Jessica (59932360100); Reddivari, Sandeep (49663771900)|59932360100; 49663771900|A ChatGPT-powered Prompt Engineering Framework for Generating Software Acceptance Criteria|2025|ACMSE 2025 - Proceedings of the 2025 ACM Southeast Conference||||282|287|5|0|10.1145/3696673.3723078|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007440286&doi=10.1145%2f3696673.3723078&partnerID=40&md5=f1f41bfdcc6a129b05cd4af3d19cdb76|There has been a growing interest in using Natural Language Processing (NLP), such as OpenAI's ChatGPT for software engineering tasks, including requirements engineering, software design and software testing. This paper introduces a novel prompt engineering framework that aims to utilize ChatGPT for the generation of high-quality acceptance criteria in the software development process, particularly in the implementation and maintenance stages, by using curated prompts and inputs. The paper describes the development and possible implementation of the proposed framework. © 2025 Copyright held by the owner/author(s). Publication rights licensed to ACM.|Acceptance Criteria; ChatGPT; Prompt Engineering; Requirements Engineering|Acceptance tests; Application programs; Computer aided software engineering; Computer software maintenance; Computer software selection and evaluation; Open source software; Software design; Software packages; Software prototyping; Software quality; Software testing; Utility programs; Verification; Acceptance criteria; ChatGPT; Engineering frameworks; Engineering software; Engineering tasks; Language processing; Natural languages; Prompt engineering; Requirement engineering; Software testings; Requirements engineering|Conference paper|Final||Scopus|2-s2.0-105007440286
scopus|Shi J.; Xiao Z.; Shi H.; Jiang Y.; Li X.|Shi, Jinjing (36728676800); Xiao, Zimeng (58910884600); Shi, Heyuan (57192187933); Jiang, Yu (56193157500); Li, Xuelong (55936260100)|36728676800; 58910884600; 57192187933; 56193157500; 55936260100|QuanTest: Entanglement-Guided Testing of Quantum Neural Network Systems|2025|ACM Transactions on Software Engineering and Methodology|34|2|48||||2|10.1145/3688840|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218341187&doi=10.1145%2f3688840&partnerID=40&md5=15293b72488d1c708686f02439faa9ed|Quantum Neural Network (QNN) combines the deep learning (DL) principle with the fundamental theory of quantum mechanics to achieve machine learning tasks with quantum acceleration. Recently, QNN systems have been found to manifest robustness issues similar to classical DL systems. There is an urgent need for ways to test their correctness and security. However, QNN systems differ significantly from traditional quantum software and classical DL systems, posing critical challenges for QNN testing. These challenges include the inapplicability of traditional quantum software testing methods to QNN systems due to differences in programming paradigms and decision logic representations, the dependence of quantum test sample generation on perturbation operators, and the absence of effective information in quantum neurons. In this article, we propose QuanTest, a quantum entanglement-guided adversarial testing framework to uncover potential erroneous behaviors in QNN systems. We design a quantum entanglement adequacy criterion to quantify the entanglement acquired by the input quantum states from the QNN system, along with two similarity metrics to measure the proximity of generated quantum adversarial examples to the original inputs. Subsequently, QuanTest formulates the problem of generating test inputs that maximize the quantum entanglement adequacy and capture incorrect behaviors of the QNN system as a joint optimization problem and solves it in a gradient-based manner to generate quantum adversarial examples. Experimental results demonstrate that QuanTest possesses the capability to capture erroneous behaviors in QNN systems (generating 67.48-96.05% more high-quality test samples than the random noise under the same perturbation size constraints). The entanglement-guided approach proves effective in adversarial testing, generating more adversarial examples (maximum increase reached 21.32%).  Copyright © 2025 held by the owner/author(s). Publication rights licensed to ACM.|adversarial testing; deep neural network; quantum entanglement; Quantum neural network|Adversarial machine learning; Deep neural networks; Quantum electronics; Quantum noise; Quantum optics; Software testing; Adversarial testing; Critical challenges; Fundamental theory; Learning tasks; Machine-learning; Neural network systems; Neural-networks; Quantum neural networks; Robustness issues; Test samples; Quantum entanglement|Article|Final|All Open Access; Bronze Open Access; Green Open Access|Scopus|2-s2.0-85218341187
scopus|Gokulakannan S.; Ashokkumar M.; Bhuvaneswari R.; Sakthi R.B.L.|Gokulakannan, S. (59219640600); Ashokkumar, M. (59697862700); Bhuvaneswari, R. (59699122600); Sakthi, R.B. Lakshmipathi (59697862800)|59219640600; 59697862700; 59699122600; 59697862800|Enhancing Paper Quality through Artificial Intelligence (AI)|2025|IPPTA: Quarterly Journal of Indian Pulp and Paper Technical Association|37|1||134|138|4|0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000262524&partnerID=40&md5=e2e6e530f753076eb154930d9022ba4d|The Integration of Artificial Intelligence (AI) and automation into manufacturing processes is transforming industries worldwide and the paper industry is no exception. It is challenging and need of the hour to maintain consistent product quality to sustain as a market leader globally for any industry. The Automated Paper Lab in TNPL, a state-of-the-art automated testing system, represents a leap towards Industry 4.0, provides a comprehensive suite of capabilities, including precise measurement of tensile strength, porosity, smoothness, basis weight, and caliper. A standout feature of this lab is its roll-specific identification system, which assigns unique roll numbers to track quality parameters across the production process, ensuring traceability and targeted quality improvements. While the automated Paper Lab has revolutionized automated quality control with its precise measurements, there remains significant potential for enhancement through integration with Artificial Intelligence (AI). This study proposes utilizing AI to analyse the lab’s data for real-time process optimization. By correlating roll-specific quality results with production variables such as chemical dosing and process settings, manufacturers can achieve dynamic adjustments that minimize defects and ensure consistent product quality. The Integration of AI with the Paper testing Equipment would enable predictive insights, allowing manufacturers to proactively address deviations in quality metrics before they impact production. This closed-loop system would enhance operational efficiency, reduce non-conforming products, and promote sustainable practices by optimizing resource utilization. The proposed framework showcases the transformative potential of combining automated testing with advanced analytics, setting the stage for smarter, more adaptive paper manufacturing processes. This paper outlines the current capabilities of the Automated Paper Lab, explores its applications in quality assurance, and presents a forward-looking vision for integrating AI to achieve unparalleled levels of efficiency and sustainability in the paper industry which saves time, human resources and reduces non-conformity products. © 2025 Indian Pulp and Paper Technical Association. All rights reserved.|Artificial Intelligence; Automated Paper Lab; Non-Conformity; Sustainability|Artificial Intelligence; Integration; Paper Industry; Processes; Product Quality; Production; Rolls; Test Equipment|Article|Final||Scopus|2-s2.0-105000262524
scopus|Zhang Q.; Li D.|Zhang, Qian (59978540900); Li, Dongcheng (57210431957)|59978540900; 57210431957|Fusion Mutation-Based Test Generation and XGBoost-Driven Prioritization for Image Classification DNNs|2025|International Journal of Performability Engineering|21|5||235|248|13|0|10.23940/ijpe.25.05.p1.235248|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105009952910&doi=10.23940%2fijpe.25.05.p1.235248&partnerID=40&md5=1e3bbfa082ca5892cc415c9a02cec546|With deep learning increasingly employed in safety-critical domains, ensuring the reliability of deep neural networks has become paramount. Although traditional software testing can detect model errors, the substantial costs of assembling large, manually annotated test sets remain a key challenge. To address this, we propose: (1) a fusion mutation-based test case generation technique and (2) a test case prioritization algorithm based on feature analysis. The fusion mutation method enriches test diversity through both data mutation and model mutation. By designing a hyperparameter optimization space for image distortion and employing an improved Bayesian optimization algorithm, our approach rapidly identifies optimal mutation parameters and adaptively generates test sets from minimal data. These mutated images simulate various distortion scenarios, forming the basis for priority ranking. The priority sorting algorithm leverages differential, rule, and effectiveness features, combined with an XGBoost-based strategy that prioritizes the most error-prone test cases and restricts ineffective mutations. This ensures expedited identification of potential DNN defects, improving testing efficiency. Experiments using popular image classification networks on multiple datasets demonstrate that our method outperforms other state-of-the-art approaches in 50% of tested scenarios, achieving a 2%–9.2% performance gain. These findings validate our method’s effectiveness in uncovering diverse error types in DNNs and generating high-quality test sets while maintaining a balance between test data efficiency and diversity. © 2025 Totem Publisher, Inc. All rights reserved.|deep neural network; fusion mutation; image classification; test generation; test prioritization||Article|Final||Scopus|2-s2.0-105009952910
scopus|Liu Z.; Wang H.; Xu T.; Wang B.|Liu, Zhuang (58739320100); Wang, Hailong (59198945200); Xu, Tongtong (57210911094); Wang, Bei (59148536800)|58739320100; 59198945200; 57210911094; 59148536800|RAG-Driven multiple assertions generation with large language models|2025|Empirical Software Engineering|30|3|105||||0|10.1007/s10664-025-10641-1|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003665539&doi=10.1007%2fs10664-025-10641-1&partnerID=40&md5=e264b6f07063190d1f7d6d0793415739|Software testing is one of the most crucial parts of the software development life cycle. Developers spend substantial amount of time and effort on software testing. Recently, there has been a growing scholarly interest in the automation of software testing. However, recent studies have revealed significant limitations in the quality and efficacy of the generated assert statements. These limitations primarily arise due to: (i) the inherent complexity involved in generating assert statements that are both meaningful and effective; (ii) the challenge of capturing the relationship between multiple assertions in a single test case. In recent research, deep learning techniques have been employed to generate meaningful assertions. However, it is typical for a single assertion to be generated for each test case, which contradicts the current situation where over 40% of test cases contain multiple assertions. Compared with deep learning techniques, the advantages of large language models (LLMs) in test generation tasks have been proven. This paper proposes a new approach named ALLMAssert (Augmented Large Language Model Assertion Generation) to automatically generate multiple assertions for test methods. ALLMAssert exploits two LLMs to collaboratively generate test assertions for developers. ALLMAssert first fine-tune the codellama-34B-instruct model to obtain a specialized model for multi-assert generation. We then mine more contextual information in the Java project. Through a series of information augmentation steps, we prompt the base LLM to correct the assert statements generated by the fine-tuned LLM. To evaluate the effectiveness of our approach, we conduct extensive experiments on the dataset built on the top of Methods2Test dataset. Experimental results show that ALLMAssert achieves scores of 56.61%, 20.43%, and 15.07% in terms of CodeBLEU, accuracy and perfect prediction and substantially outperforms the baselines. Furthermore, we evaluate the effectiveness of ALLMAssert on the task of bug detection and the result indicates that the assert sequences generated by ALLMAssert can assist in exposing 76 real-world bugs extracting from Defects4J, outperforming the SOTA approaches by a large margin as well. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2025.|Assert statement generation; Large language model; Software testing|Computer operating systems; Software design; Software quality; Testbeds; Assert statement generation; Assertion generations; Inherent complexity; Language model; Large language model; Learning techniques; Recent researches; Software development life-cycle; Software testings; Test case; Model checking|Article|Final||Scopus|2-s2.0-105003665539
scopus|Spahiu C.S.; Stanescu L.; Spahiu D.S.|Spahiu, Cosmin Stoica (15926573000); Stanescu, Liana (15926500500); Spahiu, David Stoica (59960777200)|15926573000; 15926500500; 59960777200|Transformation of the Software Testing: From Manual Efforts to AI Driven Efficiency|2025|Proceedings of the 2025 26th International Carpathian Control Conference, ICCC 2025|||||||0|10.1109/ICCC65605.2025.11022921|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105008941007&doi=10.1109%2fICCC65605.2025.11022921&partnerID=40&md5=57b3e04bba85156a6b77793a0dd84608|The Artificial Intelligence models developed in the last years have highly optimized many domains, including the software testing activity. Software testing was a manual task involving high-effort for testers to write test-cases specifications and write code to automate the defined scenarios. With the advent of artificial intelligence (AI), software testing has become more efficient and accurate. AI can automate many of the repetitive and time-consuming tasks, such as generating test cases, executing tests, and analyzing results. The current paper will consider a standard AI model and use it in a real project, analyzing the maturity of the generated content, together with the time improvements obtained. © 2025 IEEE.|AI tests generation; tests generation; tests maturity; verification and validation|Artificial intelligence; Verification; Artificial intelligence test generation; Intelligence models; Intelligence software; Intelligence tests; Software testings; Test case specifications; Test generations; Test maturity; Verification-and-validation; Software testing|Conference paper|Final||Scopus|2-s2.0-105008941007
scopus|Jabu M.A.; Alugongo A.A.; Nkomo N.Z.|Jabu, Mbatha Abednigo (57296536700); Alugongo, A.A. (9333959300); Nkomo, N.Z. (57211191782)|57296536700; 9333959300; 57211191782|A Critical Review on the Use of Artificial Intelligence in the Automotive Industry|2025|International Journal of Engineering Trends and Technology|73|6||450|456|6|0|10.14445/22315381/IJETT-V73I6P136|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105009814777&doi=10.14445%2f22315381%2fIJETT-V73I6P136&partnerID=40&md5=0eb62046a66534cafcbfca614be1fa31|Artificial Intelligence has been used as an effective approach to processing data because of the growing volume of data and calls to speed up its processing. Artificial Intelligence has the potential to transform the automotive industry like no other technology, and it is gaining an increasingly important role in the current automotive industry. Due to this, automobil es have an increasing number of sensors installed in them, turning them into machines that can gather, process, and display data in real-time. The convenience that automobiles provide for individuals on their trips, the designs of the vehicles themselves, and, most importantly these days, the technology they offer have made the automotive business one of the most well-liked sectors in our society. Additionally, as technology advances, technical malfunctions become more common. As a result, testing has become a crucial step in the production of any vehicle. As a result, businesses have begun investing in automated testing to cut down on both labor costs and long-term expenses. This paper reviews the use of artificial intelligence in the automotive industry and its application, limitations, and potential use. Furthermore, this paper discusses machine learning and deep learning technology used. There is a need to create efficient ways to process data. Further research is still needed to make artificial intelligence as advanced as the human mind and solve complex problems. © 2025 Seventh Sense Research Group®.|Artificial Intelligence; Automotive industry; Deep Learning; Industry 4.0; Machine learning||Review|Final||Scopus|2-s2.0-105009814777
scopus|Villoth J.P.; Villoth S.J.; Jovanovic L.; Zivkovic M.; Mani J.; Antonijevic M.; Kaljevic J.; Milovanovic M.; Bacanin N.|Villoth, John Philipose (59560083700); Villoth, Saramma John (59702908900); Jovanovic, Luka (57208164323); Zivkovic, Miodrag (57208755936); Mani, Joseph (57220460804); Antonijevic, Milos (57207255354); Kaljevic, Jelena (57203352028); Milovanovic, Marina (36992347600); Bacanin, Nebojsa (37028223900)|59560083700; 59702908900; 57208164323; 57208755936; 57220460804; 57207255354; 57203352028; 36992347600; 37028223900|Detecting Software Defects in Generated Python Code with Applied Natural Language Processing Optimized by Modified Metaheuristic|2025|Lecture Notes in Networks and Systems|1254|||575|588|13|0|10.1007/978-981-96-1744-9_47|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007984626&doi=10.1007%2f978-981-96-1744-9_47&partnerID=40&md5=970d471e2d9caaeedf61b6f00f9f271c|The rapid progress in technology and information sciences, along with the increasing demand for automation, has created a growing need for code that defines operations and tasks. Software projects typically depend on dedicated testing teams and extensive procedures to prepare and implement processes into a product. Although crucial, software testing is often underestimated in developing reliable software. Additionally, developers are increasingly adopting code generators to reduce development time. This study investigates the potential of combining natural language processing (NLP) with classifier algorithms to detect software defects in Python source code. A semi-synthetic dataset is employed, and a classifier is used for fault detection. Due to the high dependency of classifiers on parameter selection, optimizers are necessary to achieve optimal performance. This research introduces a modified version of the VNS algorithm to address optimization requirements. Findings suggest that NLP for code error detection is a promising approach, with the top models reaching an accuracy of over 99.7%. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2025.|Metaheuristics; Natural language processing; Python; Software defect; Source code; XGBoost|Codes (symbols); Defects; Fault detection; High level languages; Learning algorithms; Python; Software testing; Language processing; Metaheuristic; Natural language processing; Natural languages; Python code; Software defects; Software project; Source codes; Testing teams; Xgboost; Natural language processing systems|Conference paper|Final||Scopus|2-s2.0-105007984626
scopus|Zhang Y.; Chen T.Y.; Pike M.; Towey D.; Ying Z.; Zhou Z.Q.|Zhang, Yifan (57246702400); Chen, Tsong Yueh (59958388800); Pike, Matthew (55995007900); Towey, Dave (8362064600); Ying, Zhihao (57246938800); Zhou, Zhi Quan (59958597700)|57246702400; 59958388800; 55995007900; 8362064600; 57246938800; 59958597700|Enhancing autonomous driving simulations: A hybrid metamorphic testing framework with metamorphic relations generated by GPT|2025|Information and Software Technology|187||107828||||0|10.1016/j.infsof.2025.107828|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105010562785&doi=10.1016%2fj.infsof.2025.107828&partnerID=40&md5=a498af0b5ed57f792c93e33a6248fa4a|Context: Autonomous Driving Systems (ADSs) have rapidly developed over the past decade. Given the complexity and cost of testing ADSs, advanced simulation tools like the CARLA simulator are essential for efficient algorithm development and validation. However, the intricacies of autonomous driving (AD) simulations pose challenges for software testing, particularly the oracle problem, which relates to the difficulty in determining the correctness of outputs within reasonable timeframes. While many studies validate ADS algorithms using simulations, few address the validity of the simulated data, a fundamental premise for ADS testing. Objective: This study addresses the oracle problem in AD simulations by employing Metamorphic Testing (MT) and Metamorphic Relations (MRs) to detect software defects in the CARLA simulator. Additionally, we explore AI-driven approaches, specifically integrating ChatGPT's customizable features to enhance MR generation and refinement. Method: We propose a human-AI hybrid MT framework that combines human inputs with AI-driven automation to generate and refine MRs. The framework uses the GPT-MR generator, a customized large language model (LLM) based on Metamorphic Relation Patterns (MRPs) and ChatGPT, to produce MRs according to user specifications. These MRs are then refined by MT experts and fed into a test harness, automating test-case creation and execution while supporting diverse parameter inputs. Results: The GPT-MR generator produced effective MRs, leading to the discovery of four significant defects in the CARLA simulator, demonstrating their effectiveness in identifying software flaws. The test harness enabled efficient, automated testing across multiple modules and vehicle-control approaches, which enhanced the robustness and efficiency of our methods. Conclusions: Our study highlights the effectiveness of MT and MRPs in addressing the oracle problem for AD simulations, enhancing software reliability, and ensuring robust validation processes. The combination of AI-driven tools and human knowledge offers a structured methodology for validating simulated data and ADS performance, contributing to more reliable ADS development and testing. © 2025 Elsevier B.V.|Autonomous driving (AD); ChatGPT; Large language models (LLMs); Metamorphic relation (MR); Metamorphic relation pattern (MRP); Metamorphic testing (MT); Oracle problem; Simulation; Test harness|Autonomous vehicles; Computer simulation languages; Defects; Integration testing; Autonomous driving; ChatGPT; Language model; Large language model; Metamorphic relation; Metamorphic relation pattern; Metamorphic relations; Metamorphic testing; Oracle problem; Simulation; Test harness; Software reliability|Article|Final||Scopus|2-s2.0-105010562785
scopus|Phung K.; Ogunshile E.; Aydin M.E.|Phung, Khoa (57222057373); Ogunshile, Emmanuel (55845562500); Aydin, Mehmet E. (7102765275)|57222057373; 55845562500; 7102765275|Domain-specific implications of error-type metrics in risk-based software fault prediction|2025|Software Quality Journal|33|1|7||||3|10.1007/s11219-024-09704-1|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214561050&doi=10.1007%2fs11219-024-09704-1&partnerID=40&md5=83753076e5a2ad9e06f05f16bbf42561|In software development, Software Fault Prediction (SFP) is essential for optimising resource allocation and improving testing efficiency. Traditional SFP methods typically use binary-class models, which can provide a limited perspective on the varying risk levels associated with individual software modules. This study explores the impacts of Error-type Metrics on the fault-proneness of software modules in domain-specific software projects. Also, it aims to enhance SFP methods by introducing a risk-based approach using Error-type Metrics. This method categorises software modules into High, Medium, and Low-Risk categories, offering a more granular and informative fault prediction framework. This approach aims to refine the fault prediction process and contribute to more effective resource allocation and project management in software development. We explore the domain-specific impact of Error-type Metrics through Principal Component Analysis (PCA), aiming to fill a gap in the existing literature by offering insights into how these metrics affect machine learning models across different software domains. We employ three machine learning models - Support Vector Machine (SVM), Random Forest (RF), and Extreme Gradient Boosting (XGB) - to test our approach. The Synthetic Minority Over-sampling Technique (SMOTE) is used to address class imbalance. Our methodology is validated on fault data from four open-source software projects, aiming to confirm the robustness and generalisability of our approach. The PCA findings provide evidence of the varied impacts of Error-type Metrics in different software environments. Comparative analysis indicates a strong performance by the XGB model, achieving an accuracy of 97.4%, a Matthews Correlation Coefficient of 96.1%, and an F1-score of 97.4% across the datasets. These results suggest the potential of the proposed method to contribute to software testing and quality assurance practices. Our risk-based SFP approach introduces a new perspective to risk assessment in software development. The study’s findings contribute insights into the domain-specific applicability of Error-type Metrics, expanding their potential utility in SFP. Future research directions include refining our fault-counting methodology and exploring broader applications of Error-type Metrics and our proposed risk-based approach. © The Author(s) 2025.|Domain-specific analysis; Error-type metrics; Extreme gradient boosting model; Principal component analysis; Risk categorisation; Software fault prediction; Software quality assurance|Adaptive boosting; Application programs; Computer software selection and evaluation; Open source software; Project management; Resource allocation; Risk analysis; Risk assessment; Support vector machines; Utility programs; Domain specific; Domain-specific analyze; Error types; Error-type metric; Extreme gradient boosting model; Gradient boosting; Principal-component analysis; Risk categorization; Software fault prediction; Software quality assurance; Software testing|Article|Final|All Open Access; Hybrid Gold Open Access|Scopus|2-s2.0-85214561050
scopus|Li N.; Xu Y.; Luo J.; Fang J.|Li, Na (57224588686); Xu, Yimei (57402824000); Luo, Jiafan (58995688000); Fang, Jiaxin (60019323300)|57224588686; 57402824000; 58995688000; 60019323300|AI-Driven Test Case Generation Based on DeepSeek-Chat Large-Language Model|2025|2025 5th International Symposium on Computer Technology and Information Science, ISCTIS 2025||||1|4|3|0|10.1109/ISCTIS65944.2025.11065082|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105011943408&doi=10.1109%2fISCTIS65944.2025.11065082&partnerID=40&md5=bc90b2898de1ae4e5ff00ba742d8f888|With the increasing complexity of software systems, traditional test case generation methods have become inadequate to meet the demands for efficient and high-quality software testing[1]. This paper proposes an AI-driven test case generation technology based on the DeepSeek-Chat large model, aiming to streamline the process from requirements to automated test case generation and enhance the automation level and efficiency of software testing in the industry. Leveraging natural language processing (NLP) and machine learning (ML) techniques[2], DeepSeek-Chat is capable of automatically generating high-quality test cases, significantly improving test coverage and defect detection rates. Experimental results demonstrate that, compared to traditional methods, this technology achieves a 30% improvement in test coverage and a 25% increase in defect detection rate. This study provides a novel and efficient test case generation approach for the software testing industry, offering significant practical application value. © 2025 IEEE.|AI-Driven Test Case Generation; DeepSeek-Chat; Defect Detection Rate; Machine Learning; Natural Language Processing; Software Test Automation; Test Coverage|Application programs; Automatic test pattern generation; Automation; Computer software selection and evaluation; Defects; Learning algorithms; Learning systems; Machine learning; Model checking; Software quality; Software testing; AI-driven test case generation; Deepseek-chat; Defect detection; Defect detection rate; Detection rates; Language processing; Machine-learning; Natural language processing; Natural languages; Software test automation; Test case generation; Test-coverage; Natural language processing systems|Conference paper|Final||Scopus|2-s2.0-105011943408
scopus||||Future of Information and Communication Conference, FICC 2025|2025|Lecture Notes in Networks and Systems|1285 LNNS|||||2265|0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-105006408966&partnerID=40&md5=35cf2258f93e2fc95a548566acc97dad|The proceedings contain 138 papers. The special focus in this conference is on Future of Information and Communication. The topics include: Robots in Healthcare: Measuring Acceptance of Professional Caregivers Towards Finding Key Requirements for System Design; a Human-Centric Architecture for Natural Interaction with Organizational Systems; industrial Metaverse for Smart Manufacturing: Ecosystem Architecture and Applications; centralised Graph-Based Collision-Free Air Traffic Management Approach for Autonomous Aerial Vehicle Navigation; phytoNode Upgraded: Energy-Efficient Long-Term Environmental Monitoring Using Phytosensing; evaluating the Socio-Economic Impacts of Hyperloop Technology Through the Lens of Labour Market: A Focus on Intelligent Transportation, Case of Latvia; Human-In-The-Loop Reasoning for Traffic Sign Detection: Collaborative Approach YOLO with Video-LLaVA; Reasoning with Generative AI; “Model Cards for Model Reporting” in 2024: Reclassifying Category of Ethical Considerations in Terms of Trustworthiness and Risk Management; robotic Process Automation in Software Testing: Challenges and Open Research Directions; chatbot Personas as a Gateway to Enhanced Learning Experiences; is It Time to Start Taking the Concept of a Holodeck Seriously?; agent for Machine Learning: A Text-to-Model (T2M) Approach; The Theory of Cybernetics for Managing Human-AI Interactions: A Framework for AI Management; steering Toward Trustworthiness: A Speech-Act Theory Perspective on Building Trust in Language Models for Autonomous Vehicle Applications; fingerprint Synthesis from Diffusion Models and Generative Adversarial Networks; Easy Problems that LLMs Get Wrong; socratic Dialogue with Generative Artificial Intelligence: Where is the Future?; Vectoring Languages: A High-Dimensional Perspective of Language to Bridge the Gap Between Philosophy and AI Science; The Elephant in the Room: Why AI Safety Demands Diverse Teams; exploring Foundation Model Fusion Effectiveness and Explainability for Stylistic Analysis of Emotional Podcast Data; machine Learning Enabled Earthquake Classification with Real Time Monitoring and Alert System.|||Conference review|Final||Scopus|2-s2.0-105006408966
scopus|Ricca F.; Marchetto A.; Stocco A.|Ricca, Filippo (24822686600); Marchetto, Alessandro (23971457800); Stocco, Andrea (36882807000)|24822686600; 23971457800; 36882807000|A multi-year grey literature review on AI-assisted test automation|2025|Information and Software Technology|186||107799||||0|10.1016/j.infsof.2025.107799|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105008195369&doi=10.1016%2fj.infsof.2025.107799&partnerID=40&md5=0c903806d793f0c5253415ea4ed892c8|Context: Test Automation (TA) techniques are crucial for quality assurance in software engineering but face limitations such as high test suite maintenance costs and the need for extensive programming skills. Artificial Intelligence (AI) offers new opportunities to address these issues through automation and improved practices. Objective: Given the prevalent usage of AI in industry, sources of truth are held in grey literature as well as the minds of professionals, stakeholders, developers, and end-users. To this aim, our study surveys grey literature to explore how AI is adopted in TA, focusing on the problems it solves, its solutions, and the available tools. Additionally, the study is complemented by expert insights. Methods: Over five years, we reviewed over 3,600 grey literature sources, including blogs, white papers, and user manuals, and finally filtered 342 documents to develop taxonomies of TA problems and AI solutions. We also cataloged 100 AI-driven TA tools and interviewed five expert software testers to gain insights into AI's current and future role in TA. Results: The study found that manual test code development and maintenance are the main challenges in TA. In contrast, automated test generation and self-healing test scripts are the most common AI solutions. We identified 100 AI-based TA tools, with Applitools, Testim, Functionize, AccelQ, and Mabl being the most adopted in practice. Conclusion: This paper offers a detailed overview of AI's impact on TA through grey literature analysis and expert interviews. It presents new taxonomies of TA problems and AI solutions, provides a catalog of AI-driven tools, and relates solutions to problems and tools to solutions. Interview insights further revealed the state and future potential of AI in TA. Our findings support practitioners in selecting TA tools and guide future research. © 2025 Elsevier B.V.|AI-assisted test automation; Artificial intelligence; Automated test generation; Grey literature; Self-healing test scripts; Test automation|Automatic test pattern generation; Computer aided software engineering; Quality assurance; Self-healing materials; Software testing; Artificial intelligence-assisted test automation; Automated test generations; Grey literature; Healing tests; Self-healing; Self-healing test script; Test Automation; Test automation tool; Test scripts; Automation|Article|Final||Scopus|2-s2.0-105008195369
scopus|Raju S.S.; Leong W.Y.|Raju, S.S. (59982435800); Leong, W.Y. (56185056100)|59982435800; 56185056100|Identifying Research Gaps in AI-Driven Software Testing: A Review of Automation Tools and Challenges in SMEs|2025|ASM Science Journal|20|1|||||0|10.32802/asmscj.2025.2006|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105009996085&doi=10.32802%2fasmscj.2025.2006&partnerID=40&md5=3fe3c0e41e99b03450ea9b9830d3b19d|AI-driven (Artificial Intelligence) software testing frameworks have become crucial in today's fast-paced digital environment to guarantee the timely delivery of high-quality systems. Software testing is undergoing a revolution because of the incorporation of AI-driven frameworks, which automate intricate test scenarios, improve accuracy, and drastically cut down on time-to-market. However, a lack of defined frameworks, cost concerns, and ambiguity over performance hinder the adoption of advanced AI-powered testing solutions by many SMEs (Small and Medium-Sized Enterprises). Researchers and industry professionals will use the review's conclusions as a starting point to close the gap between innovation and real-world application, guaranteeing the smooth incorporation of AI-driven testing frameworks into contemporary software engineering procedures. Initially, 3998 research papers were extracted and at the third filtering, 20 research papers were chosen for the final review. This study offers a comprehensive analysis of the commonly used automation tools in various stages of software testing. The findings of this literature review study suggest there are no experience-based testing approaches for SMEs. There is a need to conduct surveys with practitioners to identify the benefits and limitations they are experiencing from using these automation tools for testing and ultimately to provide a comprehensive framework for automation software testing. © 2025 Akademi Sains Malaysia. All rights reserved.|Artificial Intelligence (AI); Innovation; Small and Medium-Sized Enterprise (SMEs); Software Testing; Testing Framework||Review|Final||Scopus|2-s2.0-105009996085
scopus|Ma J.|Ma, Junbang (58187456600)|58187456600|AI-Driven Web Application Automated Testing and Code Optimization|2025|2025 IEEE 6th International Seminar on Artificial Intelligence, Networking and Information Technology, AINIT 2025||||1739|1742|3|0|10.1109/AINIT65432.2025.11035018|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105010206572&doi=10.1109%2fAINIT65432.2025.11035018&partnerID=40&md5=6ee313ca20bbb067d281c226e33a1bbc|-Deep learning has revolutionized web application testing and code optimization. Our innovative model combines automatic test generation with code quality evaluation, showing remarkable improvements. Testing efficiency increased 5.2-fold with 93.2% code coverage, while system efficiency improved by 42.3%. Validation across 1000 projects demonstrated 47.2% faster response times and 35.8% better resource utilization. The solution features adaptive testing and intelligent refactoring, particularly benefiting large-scale applications. This comprehensive approach enhances development efficiency and reduces maintenance costs, providing practical value for software teams. ©2025 IEEE.|Code Optimization; Deep Learning; Performance Evaluation; Web Application Testing|Artificial intelligence; Automatic programming; Automatic testing; Efficiency; Optimal systems; Optimization; Application codes; Automated code; Automated testing; Code optimization; Deep learning; Innovative models; Performances evaluation; WEB application; Web application testing; Web applications; Codes (symbols)|Conference paper|Final||Scopus|2-s2.0-105010206572
scopus|Bhimavarapu U.|Bhimavarapu, Usharani (57468593600)|57468593600|AI-enabled learning environments evaluating literacy outcomes through machine learning|2025|Rethinking Literacy in the Era of Sustainability and Artificial Intelligence||||133|160|27|0|10.4018/979-8-3373-0725-1.ch005|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105009994065&doi=10.4018%2f979-8-3373-0725-1.ch005&partnerID=40&md5=9a358a4c84e36702fcca84c546416051|AI for literacy improvement has been widely popular for providing personalized learning, automated testing, and experience-based learning. The present research examines the effect of AI intervention on improving literacy using logistic regression modeling. Systematic data was obtained by conducting surveys with follow-up data cleaning, feature engineering using Principal Component Analysis (PCA), and model training. The logistic regression model estimated the probability of literacy acquisition against AI-based learning materials and population variables. Model performance measures such as accuracy, precision, recall, and the ROC curve reflected the efficacy of AI interventions. The findings highlight the potential of AI to facilitate literacy development and guide education policies for maximizing AIbased learning strategies. © 2025, IGI Global Scientific Publishing. All rights reserved.||Computer aided instruction; Data accuracy; Learning systems; Logistic regression; Personnel training; Automated testing; Data cleaning; Experience-based learning; Feature engineerings; Follow up; Learning environments; Logistic Regression modeling; Machine-learning; Personalized learning; Principal-component analysis; Principal component analysis|Book chapter|Final||Scopus|2-s2.0-105009994065
scopus|Abdullayev V.; Faizal A.; Seyidova I.; Mikayilov S.; Mammadova R.; Pirverdiyeva L.; Guliyev E.|Abdullayev, Vugar (57190337076); Faizal, Ajesh (59650161600); Seyidova, Irada (58991610100); Mikayilov, Seymur (57213149373); Mammadova, Rubaba (59650673700); Pirverdiyeva, Lala (59651175400); Guliyev, Etibar (57216502762)|57190337076; 59650161600; 58991610100; 57213149373; 59650673700; 59651175400; 57216502762|Integration of Artificial Intelligence and Robotics into the industrial sector; [Integración de Inteligencia Artificial y Robótica en el sector industrial]|2025|Data and Metadata|4||209||||1|10.56294/dm2025209|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218747746&doi=10.56294%2fdm2025209&partnerID=40&md5=123b5eb392d38155a1c65e46bf97a757|The 4th industrial revolution is driven by the implementation of automated robots and artificial intelligence (AI) to enhance efficiency, accuracy, and safety. This integration encompasses several vital domains like optimizing the supply chain, interaction between human and robots on the shop floor, predictive maintenance, automation of repetitive tasks, customisation, behaviour design, and safety management, data analysis, etc. AI-enabled robots perform repetitive tasks at very high precision, reducing the chances of human error and allowing workers to focus on more complex tasks. Automated upkeep utilizes AI to determine the time machinery will likely fail, which minimizes downtime and maintenance costs. Automated testing and AI-driven vision systems support quality control by ensuring a balanced quality of the product. AI improves supply chain processes, optimizing logistics and inventory management. Collaboration between humans and collaborative robot’s results in safer and more productive environments with people working alongside each other. Artificial Intelligence plays an important role in making smarter decisions, analysing data more effectively, and providing valuable information that can be used to improve operations. Manufacturing customization and flexibility are reliant on adaptive systems and the ability to manufacture personalized products by means of productivity. Safe and Risk Management is consolidated because robots work in dangerous scenarios and artificial intelligence models assess potential dangers. Despite challenges including labour displacement, cybersecurity, ethics, and data integration stemming from this technology, these are all potentially available on your terms. This article reviews the broader impacts that robots and artificial Intelligence have had on the industrial sector, placing emphasis on the revolution it could lead towards as well as the key elements to consider before implementing it. © 2024; Los autores.|Artificial Intelligence (AI); Big Data Analytics; Cobots; Decision-Making; Human-Robot Collaboration; Industrial Automation; Maintenance; Predictive; Robotics; Safety Management||Article|Final||Scopus|2-s2.0-85218747746
scopus|Bandi A.; Nukala H.S.T.; Tatavarthi B.; Boggavarapu A.|Bandi, Ajay (55386327700); Nukala, Harsha Sai Teja (59980633100); Tatavarthi, Bhavya (59981293800); Boggavarapu, Amulya (59980475700)|55386327700; 59980633100; 59981293800; 59980475700|Automated Test Case Generation for Software Testing Using Generative AI|2025|Communications in Computer and Information Science|2435 CCIS|||78|87|9|0|10.1007/978-3-031-92178-0_7|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105010114947&doi=10.1007%2f978-3-031-92178-0_7&partnerID=40&md5=d89b9ffadcd730d0b90cd5536c789ee5|Software testing is a critical phase in the development lifecycle, ensuring the reliability and correctness of software systems. Traditional test case generation can be time-consuming and labor-intensive, often requiring significant manual effort. With the rapid advancement of generative AI, tools like ChatGPT and Gemini offer new possibilities for automating this process. This paper investigates the application of these AI-driven tools for test case generation, evaluating their effectiveness in achieving comprehensive code coverage across diverse programming problems. This paper investigates the application of generative AI tools, specifically ChatGPT and Gemini, for automating test case generation in software testing. By analyzing source code from 30 programming problems across various topics, including loops, conditionals, arrays, strings, and recursion, the study evaluates the tools’ effectiveness in achieving comprehensive code coverage. The research addresses key questions regarding the quality, coverage, and efficiency of AI-generated test cases compared to manual efforts. The findings reveal that ChatGPT consistently outperforms Gemini in accuracy, adaptability, and handling of complex constructs, such as recursive algorithms and nested structures. While both tools reduce the manual effort required for test case generation, Gemini shows limitations in achieving full coverage for advanced scenarios. These results underscore the potential of generative AI to streamline software testing workflows, freeing developers to focus on higher-order problem-solving. However, the study also highlights the need for further refinement of these tools to enhance their reliability and robustness. This work provides a foundational step toward leveraging generative AI to transform software development and testing practices. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.|AI-Driven Test Case Generation; AI-Powered Test Automation; Automated Test Case Generation; Generative AI for Testing; Machine Learning in Software Testing; Software Testing with AI|Application programs; Automatic test pattern generation; Codes (symbols); Computer systems programming; Learning systems; Life cycle; Problem solving; Software design; Software reliability; Software testing; AI-driven test case generation; AI-powered test automation; Automated test-case generations; Generative AI for testing; Machine learning in software testing; Machine-learning; Software testing with AI; Software testings; Test Automation; Test case generation; Automation|Conference paper|Final||Scopus|2-s2.0-105010114947
scopus|Smith N.M.; Bánsághi S.; Chen N.; Neal T.B.; McNulty J.J.; Haidegger T.P.; Arbogast J.W.|Smith, Nicole M. (59665471500); Bánsághi, Száva (19638679300); Chen, Nanshan (57734626600); Neal, Travis B. (59665667800); McNulty, John J. (59664867600); Haidegger, Tamás P. (16315516400); Arbogast, James W. (7003739374)|59665471500; 19638679300; 57734626600; 59665667800; 59664867600; 16315516400; 7003739374|Importance of dosing: Analysis of touch-free hand hygiene dispensers for consistency|2025|American Journal of Infection Control|53|6||696|700|4|0|10.1016/j.ajic.2025.02.007|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85219564032&doi=10.1016%2fj.ajic.2025.02.007&partnerID=40&md5=85ce7cabcd1f9fa2268bcd25aa472b63|Background: We investigated 5 touch-free automatic foam alcohol-based handrub (ABHR) hand hygiene dispensers common in US hospitals. Output dosing was evaluated for consistency to comply with the Leapfrog 2022 guidance requirement of ≥ 1.0 mL per ABHR dispense. Methods: Fifteen dispensers and 32 distinct refills were tested, with > 10,000 dispenses analyzed for 5 different dispensing systems. Automated testing used computer programming and mechatronics to activate the dispensers and capture output weights at predetermined delay patterns. Low, medium, and high usage patterns per day were set with dispense delay patterns. In another laboratory, dispensers were activated manually for measurements; 50 doses were collected and weighed within an hour for each refill. Results: Three of the dispenser systems had mean output > 1.0 mL, and 2 were < 1.0 mL. Two dispensers have significantly greater variability, which is driven by the foam pump design. Conclusions: It was discovered that usage/testing patterns impact dosing performance. The dispenser design and engineering cause significant differences in volume dispensed and consistency across dispenses. Using sufficient ABHR to cover hands completely and keeping hands wet long enough to significantly reduce pathogens is an important requirement. Facilities should assess ABHR dispenser outputs and consider consistent dosing as an essential performance criterion for effective hand hygiene policies and practices. © 2025 Association for Professionals in Infection Control and Epidemiology, Inc.|Alcohol-based handrubs; Dispenser quality|Hand Disinfection; Hand Hygiene; Hospitals; Humans; United States; Article; controlled study; drug dose regimen; hand washing; human; touch; devices; hand disinfection; hospital; procedures; United States|Article|Final|All Open Access; Hybrid Gold Open Access|Scopus|2-s2.0-85219564032
scopus|Saxena A.|Saxena, Anurag (59915717700)|59915717700|Rethinking Software Testing for Modern Development|2025|Computer|58|6||49|58|9|0|10.1109/MC.2025.3554094|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105006547641&doi=10.1109%2fMC.2025.3554094&partnerID=40&md5=fe53f7f35814df6e466a024e4faf024f|This article explores the shift from manual to automated testing, emphasizing the role of artificial intelligence and machine learning in enhancing efficiency and quality assurance in the software development lifecycle, highlighting innovative security testing for open source software and examining artificial intelligence’s impact on testing frameworks. © 1970-2012 IEEE.||Reliability theory; Software design; Software prototyping; Software quality; Software testing; Artificial intelligence learning; Automated testing; Machine-learning; Modern development; Open-source softwares; Security testing; Software development life-cycle; Software testings; Testing framework; Open source software|Article|Final||Scopus|2-s2.0-105006547641
scopus|Bevara R.V.K.; Mannuru N.R.; Karedla S.P.; Lund B.; Xiao T.; Pasem H.; Dronavalli S.C.; Rupeshkumar S.|Bevara, Ravi Varma Kumar (58920425200); Mannuru, Nishith Reddy (58149819400); Karedla, Sai Pranathi (59074465500); Lund, Brady (57202058854); Xiao, Ting (57202463025); Pasem, Harshitha (59655443000); Dronavalli, Sri Chandra (58889980400); Rupeshkumar, Siddhanth (59655710300)|58920425200; 58149819400; 59074465500; 57202058854; 57202463025; 59655443000; 58889980400; 59655710300|Resume2Vec: Transforming Applicant Tracking Systems with Intelligent Resume Embeddings for Precise Candidate Matching|2025|Electronics (Switzerland)|14|4|794||||1|10.3390/electronics14040794|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218913856&doi=10.3390%2felectronics14040794&partnerID=40&md5=032e5263e938e81667e52133133e376b|Conventional Applicant Tracking Systems (ATSs) encounter considerable constraints in accurately aligning resumes with job descriptions (JD), especially in handling unstructured data and intricate qualifications. We provide Resume2Vec, an innovative method that utilizes transformer-based deep learning models, including encoders (BERT, RoBERTa, and DistilBERT) and decoders (GPT, Gemini, and Llama), to create embeddings for resumes and job descriptions, employing cosine similarity for evaluation. Our methodology integrates quantitative analysis via embedding-based evaluation with qualitative human assessment across several professional fields. Experimental findings indicate that Resume2Vec outperformed conventional ATS systems, achieving enhancements of up to 15.85% in Normalized Discounted Cumulative Gain (nDCG) and 15.94% in Ranked Biased Overlap (RBO) scores, especially within the mechanical engineering and health and fitness domains. Although conventional the ATS exhibited slightly superior nDCG scores in operations management and software testing, Resume2Vec consistently displayed a more robust alignment with human preferences across the majority of domains, as indicated by the RBO metrics. This research demonstrates that Resume2Vec is a powerful and scalable method for matching resumes to job descriptions, effectively overcoming the shortcomings of traditional systems, while preserving a high alignment with human evaluation criteria. The results indicate considerable promise for transformer-based methodologies in enhancing recruiting technology, facilitating more efficient and precise candidate selection procedures. © 2025 by the authors.|applicant tracking system (ATS); BERT; embeddings; GPT; job description; large language models (LLMs); Llama; recruitment; resume screening; transformer models||Article|Final|All Open Access; Gold Open Access|Scopus|2-s2.0-85218913856
scopus|Kiran S.; Emre I.E.; Tasdelen S.|Kiran, Selcuk (58805644000); Emre, Ilkim Ecem (57205351669); Tasdelen, Selen (59680912700)|58805644000; 57205351669; 59680912700|Prioritization of Regression Test Cases Based on Machine Learning Methods|2025|Gazi University Journal of Science|38|1||131|144|13|0|10.35378/gujs.1446469|https://www.scopus.com/inward/record.uri?eid=2-s2.0-86000722918&doi=10.35378%2fgujs.1446469&partnerID=40&md5=f3d9b4fb9df27a23f4947729077489b3|Due to resource and time constraints involved in the software testing process, it is not possible to implement all test scenarios for each release. Test scenarios can be prioritized according to certain criteria defined by the developers to ensure effective execution of the testing process and detection of errors. This study investigated whether machine learning based models could be used to prioritize test scenarios created in regression testing. It is attempted to determine which tests can be prioritized for execution based on different independent variables. In total, each of the 964 test scenarios in the dataset was labelled as minor (482) and major (482) by two experts. In the models, the number of related requirements, the number of related errors, and the age of the scenario were used as independent variables, and the scenario classes labelled as minor-major were taken as the target variable. The scenarios were pre-processed using natural language processing techniques and different machine learning algorithms were used for model development. In the classification based on test scenarios, the random forest algorithm showed the best performance with a F1-score of 81%. In the classification based on the number of related requirements, the number of interrelated errors, and the age of the test scenarios, the random forest model once again demonstrated the highest success rate at 79%. This study demonstrates that machine learning techniques offer a variety of models for test case prioritization. © 2025, Gazi Universitesi. All rights reserved.|Machine learning; Natural language processing; Regression testing; Software testing; Test case prioritization|Contrastive Learning; Decision trees; Natural language processing systems; Random errors; Random forests; Software testing; Independent variables; Language processing; Machine-learning; Natural language processing; Natural languages; Regression testing; Software testings; Test case prioritization; Test scenario; Testing process; Adversarial machine learning|Article|Final|All Open Access; Gold Open Access|Scopus|2-s2.0-86000722918
scopus|Stefani T.; Christensen J.M.; Girija A.A.; Gupta S.; Durak U.; Köster F.; Krüger T.; Hallerbach S.|Stefani, Thomas (57194066251); Christensen, Johann Maximilian (59407461900); Girija, Akshay Anilkumar (59407077500); Gupta, Siddhartha (57219358086); Durak, Umut (24334630800); Köster, Frank (56370770200); Krüger, Thomas (58746798300); Hallerbach, Sven (57201647334)|57194066251; 59407461900; 59407077500; 57219358086; 24334630800; 56370770200; 58746798300; 57201647334|Automated scenario generation from Operational Design Domain model for testing AI-based systems in aviation|2025|CEAS Aeronautical Journal|16|1|12021|197|212|15|1|10.1007/s13272-024-00772-4|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001089551&doi=10.1007%2fs13272-024-00772-4&partnerID=40&md5=80352f9bdbc84204cc0c948b7b03adc2|Applications based on artificial intelligence (AI) promise benefits, ranging from improved performance to increased capabilities in many industries. In the aviation domain, one example is the new Airborne Collision Avoidance System (ACAS X). The current investigation aims at combining ACAS X and AI to maintain its performance while decreasing the memory footprint. However, the anticipation of AI being increasingly used confronts regulators with challenges in terms of safety assurance and certification. Consequently, the European Union Aviation Safety Agency (EASA) published a concept paper for machine learning applications in aviation. Both, the Concept of Operation (ConOps) in combination with an Operational Design Domain (ODD), are listed as objectives to be met for the safety analysis. From a developer’s perspective, this raises questions on how to effectively derive the ODD from ConOps and test the given system based on the ODD description. Based on an exemplary use case of a Near Mid-Air Collision avoidance between two aircraft through the advisories of ACAS X, a highly automated framework for generating and testing synthetic data is proposed. Using this framework, 1800 Near Mid-Air Collision scenario files are created and automatically executed in the simulation environment FlightGear. Scenario-based testing is used for the logging of ACAS X advisory data and evaluating it against predefined requirements. By this approach, an efficient way of verifying system requirements and conducting automated testing based on the ODD definition is demonstrated. Throughout this process, Model-Based Systems Engineering (MBSE) is used to reduce and manage complexity. The framework in this paper enables a systematic and highly automated approach for scenario generation based on the ODD. © The Author(s) 2024.|AI; Model-Based Systems Engineering; Operational Design Domain; Scenario-based testing|Civil aviation; Flight simulators; Flight testing; Model checking; Requirements engineering; Aviation domain; Design domains; Domain model; Mid-air collisions; Model-based system engineerings; Operational design; Operational design domain; Performance; Scenario-based testing; Scenarios generation; Aircraft accidents|Article|Final|All Open Access; Hybrid Gold Open Access|Scopus|2-s2.0-105001089551
scopus|Jain A.; Tiwari R.|Jain, Amit (59972453700); Tiwari, Rohit (59972922700)|59972453700; 59972922700|AI for Productivity: Transforming Enterprise Software Development|2025|Computer|58|7||40|52|12|0|10.1109/MC.2025.3543181|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105009588756&doi=10.1109%2fMC.2025.3543181&partnerID=40&md5=5215c7d8c8a02dd9a6268f25f274d70b|Through a survey study and real-world examples, this study explores how artificial intelligence (AI)-powered project management, code generation, automated testing, and AI-enhanced DevOps are revolutionizing development workflows. The article also highlights best practices for implementing AI effectively and the key considerations and challenges involved, along with an analysis of the emerging trends and the potential of AI in driving continuous improvement in enterprise environments. © 1970-2012 IEEE.||Artificial intelligence; Enterprise software; Project management; Automated testing; Best practices; Codegeneration; Continuous improvements; Development workflow; Emerging trends; Enterprise environment; Enterprise software development; Real-world; Software design|Article|Final||Scopus|2-s2.0-105009588756
scopus|Li Y.; Liu P.; Wang H.; Chu J.; Wong W.E.|Li, Yihao (55367133500); Liu, Pan (57195976524); Wang, Haiyang (57226344322); Chu, Jie (59414679200); Wong, W. Eric (7403972316)|55367133500; 57195976524; 57226344322; 59414679200; 7403972316|Evaluating large language models for software testing|2025|Computer Standards and Interfaces|93||103942||||4|10.1016/j.csi.2024.103942|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209364741&doi=10.1016%2fj.csi.2024.103942&partnerID=40&md5=9f962b856ec7a2ca32fcddea612191b2|Large language models (LLMs) have demonstrated significant prowess in code analysis and natural language processing, making them highly valuable for software testing. This paper conducts a comprehensive evaluation of LLMs applied to software testing, with a particular emphasis on test case generation, error tracing, and bug localization across twelve open-source projects. The advantages and limitations, as well as recommendations associated with utilizing LLMs for these tasks, are delineated. Furthermore, we delve into the phenomenon of hallucination in LLMs, examining its impact on software testing processes and presenting solutions to mitigate its effects. The findings of this work contribute to a deeper understanding of integrating LLMs into software testing, providing insights that pave the way for enhanced effectiveness in the field. © 2024 Elsevier B.V.|Evaluation; Hallucination; Large language models; LLM-driven testing|Computer software selection and evaluation; Code analysis; Evaluation; Hallucination; Language model; Large language model; Large language model-driven testing; Model-driven testing; Natural languages; Software testings; Integration testing|Article|Final||Scopus|2-s2.0-85209364741
scopus|Yadavali V.V.|Yadavali, Vinaysimha Varma (59987278700)|59987278700|AI and Machine Learning in Software Testing: Bridging the Gap Between Defect Prediction, Test Automation, and Continuous Integration|2025|International Conference on Trends in Engineering Systems and Technologies, ICTEST 2025 - Proceedings|||||||0|10.1109/ICTEST64710.2025.11042797|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105010509615&doi=10.1109%2fICTEST64710.2025.11042797&partnerID=40&md5=86a00e1b82700143caeacf80fa9e699d|Software testing is an essential process in software engineering that assures the reliability and functionality of software applications by recognising defects early in the development cycle. Bugs, often known as software defects are challenges that cause software to function improperly or fail to meet its desired specifications. Traditional defect detection techniques include static analysis and manual testing, which are laborious and prone to human errors, which could miss defects pertaining to runtime behavior. In recent years, test automation has become an increasingly common method to enhance the testing process. It integrates with Continuous Integration (CI) pipelines to ensure that errors are continuously detected when new code is released. By employing the PROMISE dataset and a gradient boosting technique, Light GBM, the proposed research improves the accuracy of software defect prediction (SDP). The model employs gradually larger and more varied datasets to increase the model efficiency through a model retraining procedure. Retraining increased precision from 0.93 to 0.98, recall from 0.91 to 0.97, and F1-score from 0.92 to 0.97, according to measures that were assessed before and after retraining. The findings show that the LightGBM model greatly improves problem identification and yields more accurate predictions when used in conjunction with automated test cycles. This optimizes testing procedures and shortens the time-to-market for software releases. © 2025 IEEE.|continuous integration; software defect prediction; software quality; Software testing; test automation|Application programs; Automation; Computer software selection and evaluation; Defects; Errors; Forecasting; Integration; Software quality; Software reliability; Automation integration; Continuous integrations; Defect prediction; Machine-learning; Prediction tests; Software applications; Software defect prediction; Software Quality; Software testings; Test Automation; Integration testing|Conference paper|Final||Scopus|2-s2.0-105010509615
scopus|Paduraru C.; Zavelca M.; Stefanescu A.|Paduraru, Ciprian (55637207200); Zavelca, Miruna (59148629500); Stefanescu, Alin (57188811190)|55637207200; 59148629500; 57188811190|Agentic AI for Behavior-Driven Development Testing Using Large Language Models|2025|International Conference on Agents and Artificial Intelligence|2|||805|815|10|0|10.5220/0013374400003890|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001687420&doi=10.5220%2f0013374400003890&partnerID=40&md5=d0653130d0b523d4009db4a93502fe54|Behavior-driven development (BDD) testing significantly improves communication and collaboration between developers, testers and business stakeholders, and ensures that software functionality meets business requirements. However, the benefits of BDD are often overshadowed by the complexity of writing test cases, making it difficult for non-technical stakeholders. To address this challenge, we propose BDDTestAIGen, a framework that uses Large Language Models (LLMs), Natural Language Processing (NLP) techniques, human-in-theloop and Agentic AI methods to automate BDD test creation. This approach aims to reduce manual effort and effectively involve all project stakeholders. By fine-tuning an open-source LLM, we improve domain-specific customization, data privacy and cost efficiency. Our research shows that small models provide a balance between computational efficiency and ease of use. Contributions include the innovative integration of NLP and LLMs into BDD test automation, an adaptable open-source framework, evaluation against industry-relevant scenarios, and a discussion of the limitations, challenges and future directions in this area. © 2025 by SCITEPRESS – Science and Technology Publications, Lda.|Agentic AI; Behavior-Driven Development (BDD); Human-in-the-Loop; Large Language Models (LLMs); Natural Language Processing (NLP); Software Testing Frameworks; Test Automation||Conference paper|Final||Scopus|2-s2.0-105001687420
scopus|Aarifeen H.; Wickramaarachchi D.|Aarifeen, Hafsa (59786075500); Wickramaarachchi, Dilani (55787377800)|59786075500; 55787377800|Evaluating AI-Based Unit Testing Tools: A Focus on Usability, Reliability, and Integration|2025|2025 5th International Conference on Advanced Research in Computing: Converging Horizons: Uniting Disciplines in Computing Research through AI Innovation, ICARC 2025 - Proceedings|||||||0|10.1109/ICARC64760.2025.10963099|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105004553959&doi=10.1109%2fICARC64760.2025.10963099&partnerID=40&md5=4920ea613dd98c6e2de0db4a06226cec|This study presents an empirical comparison of Artificial Intelligence (AI)-based unit testing tools, focusing on their usability, reliability, and the challenges of integrating them into existing software testing frameworks. As AI-driven testing tools emerge as solutions to the limitations of traditional manual testing, particularly within agile methodologies and continuous integration/continuous deployment (CI/CD) pipelines, their effectiveness remains an area of active research. The research evaluates the potential of these tools to automate test generation and execution, thereby improving test coverage and bug detection while minimizing manual intervention. However, significant usability challenges persist, as developers often find these tools difficult to configure and deploy, especially in projects with varying complexities. Additionally, concerns about the reliability of AI-generated tests, particularly regarding consistent bug detection across different environments, are addressed. Integration into legacy systems poses further obstacles, as many organizations hesitate to overhaul established testing frameworks. The findings of this study offer insights into the current state of AI-based unit testing tools and provide recommendations for overcoming barriers to their widespread adoption in real-world development environments.  © 2025 IEEE.|artificial intelligence; integration; reliability; unit testing tools; usability|Software reliability; Software testing; Agile Methodologies; Bug detection; Empirical comparison; Manual testing; Software testings; Testing framework; Testing tools; Unit testing; Unit testing tool; Usability; Usability engineering|Conference paper|Final||Scopus|2-s2.0-105004553959
scopus|Prabu G.; Sujatha C.; Shine J.E.; Arulkumar T.|Prabu, G. (57192652059); Sujatha, C. (55813765700); Shine, J. Erin (59928400200); Arulkumar, T. (57896866000)|57192652059; 55813765700; 59928400200; 57896866000|SFFHO: Development of Statistical Fitness-based Fire Hawk Optimizer for Software Testing and Maintenance Approach using Adaptive Deep Learning Method|2025|Journal of Electronic Testing: Theory and Applications (JETTA)|41|3||313|338|25|0|10.1007/s10836-025-06177-3|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007230934&doi=10.1007%2fs10836-025-06177-3&partnerID=40&md5=5c6d551d6f3ebc5f4e137ce32735e17a|Software maintenance is the trendsetting activity of modifying, fixing and enhancing the software code deliverables once it is turned over to the client. Evolving with large-scale data available in the system, the software system indulges in deriving the software maintenance. Though software testing and maintenance are critical, it is costly and time-consuming operations in the software development lifecycle. Moreover, the conventional approaches struggle to keep pace with the quick evolution of software systems, resulting in inaccurate or incomplete testing, security vulnerabilities, and undetected bugs. The conventional approaches such as existing testing models, code reviews, and manual testing, often struggle to keep pace with the quick updates and changes to software models, resulting in an important increase in maintenance and testing costs, effort, and time. In addition, the traditional models mostly depend on simplistic assumptions about software behaviour, ignoring the complex relationships among the environmental factors, user interactions, and software components. This oversimplification can result in inaccurate or incomplete testing, leading to unidentified bugs, security concerns, and performance problems that can have serious problems in critical software systems. Therefore, there is an urgent requirement for innovative models that can efficiently maintain and test the software systems, guaranteeing their performance, security, and reliability. This work develops a novel Adaptive Ensemble Deep Learning (AEDL) and Statistical Fitness-based Fire Hawk Optimizer (SFFHO) for revolutionizing software testing and maintenance. This work presents a new software testing and maintenance approach utilizing a deep learning approach. At first, the significant data is fetched from available data resources. Further, the collected data is subjected to the Adaptive Ensemble Deep Learning (AEDL) model. Here, the AEDL model is built with the combination of the Variational Autoencoder (VAE), Attention-based Convolutional Neural Network (ACNN) and Dilated Recurrent Neural Network (DRNN). The developed model helps maintain and test the software based on the client's requirements. Moreover, to enhance the system, the hyper-parameter of AEDL is tuned by the Statistical Fitness-based Fire Hawk Optimizer (SFFHO). Finally, the designed system is contrasted with other traditional approaches that prove better efficiency. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2025.|Attention-based convolution neural network; Dilated recurrent neural network; Software testing and maintenance; Statistical fitness-based fire hawk optimizer; Variational autoencoder|Computer software maintenance; Computer software selection and evaluation; Integration testing; Open source software; Software reliability; Testbeds; UNIX; Attention-based convolution neural network; Auto encoders; Convolution neural network; Dilated recurrent neural network; Neural-networks; Optimizers; Software testings; Statistical fitness-based fire hawk optimizer; Testing and maintenance; Variational autoencoder; Model checking|Article|Final||Scopus|2-s2.0-105007230934
scopus|Kumar S.; Napte K.; Rani R.; Pippal S.K.|Kumar, Sumit (57190867920); Napte, Kiran (57222042420); Rani, Ruchi (56321161900); Pippal, Sanjeev Kumar (54279333400)|57190867920; 57222042420; 56321161900; 54279333400|A method for IoT devices test case generation using language models|2025|MethodsX|14||103340||||0|10.1016/j.mex.2025.103340|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105004210451&doi=10.1016%2fj.mex.2025.103340&partnerID=40&md5=968df81ca6a3284e74cd2408515c9df7|The rapid growth of IoT and electronic systems has led to complex real-time data processing and management solutions. However, these systems present significant software and hardware testing challenges, often requiring manual, time-consuming testing efforts. To address this, an automated end-to-end testing framework is essential for improving efficiency and reliability in IoT system development. With advancements in Natural Language Processing (NLP) and language models, automated test case generation systems can now create structured test cases in programming languages while ensuring code integrity and style. Applying these techniques to IoT projects streamlines testing, enhances accuracy, and reduces workload. This paper introduces TCG-IoT (Test Case Generation for IoT Systems), an automated testing framework designed to generate comprehensive test cases and actionable event lists based on technical and data specifications. Unlike existing frameworks that depend on model-based testing or simulation environments, TCG-IoT uniquely integrates a Retrieval-Augmented Generation (RAG) mechanism, a vector knowledge base of IoT standards, and code generation via Code-Llama to directly produce structured, executable C-code scripts for software and manual steps for hardware components. The results demonstrate that TCG-IoT delivers high-quality, context-aware test cases and scripts with maximum system coverage, ensuring secure, efficient, and scalable IoT development. • Automates test case generation for IoT hardware and software components. • Enhances test coverage and reliability using language models. • Evaluates performance through case studies on smart home automation. © 2025 The Author(s)|IoT; Language models; NLP techniques; Test Case Generation; Testing|Article; computer language; data processing; home automation; human; internet of things; knowledge base; language model; methodology; natural language processing; reliability; retrieval augmented generation; simulation; smart home; software; validation study; workload|Article|Final||Scopus|2-s2.0-105004210451
scopus|Kura S.R.; Bommala H.; Marri S.R.; Bhukya M.; Swaraja K.; Joshi S.K.|Kura, Swapna Rani (59409514000); Bommala, Harikrishna (57206858420); Marri, Sarojini Rani (59760287300); Bhukya, Madhu (59760203200); Swaraja, Kuraparthi (55006028100); Joshi, Sanjeev Kumar (58070510300)|59409514000; 57206858420; 59760287300; 59760203200; 55006028100; 58070510300|Machine Learning-Based Mutation Testing Framework|2025|AIP Conference Proceedings|3157|1|80015||||0|10.1063/5.0261650|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003882370&doi=10.1063%2f5.0261650&partnerID=40&md5=f21bd95c20cfa3db37b53499d31b3b31|Mutation testing is a critical technique in software testing to assess the effectiveness of test suites by introducing artificial code mutations and evaluating if the tests can detect these mutations. Traditional mutation testing is often computationally expensive, time-consuming, and limited in its mutation scope. This paper presents a novel Machine Learning-based Mutation Testing Framework (MLMTF) that leverages machine learning algorithms to automate and enhance mutation testing processes. MLMTF utilizes a combination of automated code mutation generation and machine learning models to predict the likelihood of a mutation being killed by a given test suite. By learning from historical mutation results and software code characteristics, MLMTF effectively reduces the number of mutants that need to be executed, thereby significantly decreasing computational overhead. The framework provides substantial advantages in terms of efficiency, scalability, and accuracy compared to conventional mutation testing techniques. This paper outlines the architecture of MLMTF, its key components, and its integration into existing software testing workflows. We present experimental results on real-world codebases to demonstrate the framework's performance and effectiveness. MLMTF is a promising approach to revolutionize mutation testing, making it more accessible and practical for software development and quality assurance teams. © 2025 Author(s).|Automated Code Mutation; Code Analysis; Computational Efficiency; Machine Learning; Mutation Testing; Software Quality Assurance; Software Testing; Test Automation; Test Effectiveness; Test Suite Evaluation||Conference paper|Final||Scopus|2-s2.0-105003882370
scopus|Pathirana W.P.P.M.; Jayatissa Y.|Pathirana, W.P.P.M. (57211264242); Jayatissa, Yehemini (59185623100)|57211264242; 59185623100|Towards Sustainable Software Testing Practices in IT Firms|2025|2025 5th International Conference on Advanced Research in Computing: Converging Horizons: Uniting Disciplines in Computing Research through AI Innovation, ICARC 2025 - Proceedings|||||||0|10.1109/ICARC64760.2025.10963141|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105004554649&doi=10.1109%2fICARC64760.2025.10963141&partnerID=40&md5=c105fecde095cc9acb80549d816eb752|As the demand for environmentally responsible and cost-efficient software development grows, sustainable software testing practices have become a critical focus. This study examines the role of automation, optimization techniques, AI/ML integration, and efficient test environments in achieving sustainability goals within software testing processes. Using a mixed-method research approach, the findings reveal that efficient test environments leveraging virtualization have the greatest impact, significantly reducing idle resource usage and energy consumption. Automation and optimization techniques enhance workflow efficiency, minimize resource wastage, and ensure timely, high-quality outputs. While AI/ML technologies show transformative potential in predictive analytics and selfhealing processes, their adoption is constrained by high implementation costs and limited organizational expertise. Testing Process Maturity (PRM) emerged as a key moderating factor, amplifying the benefits of automation but requiring balance to avoid rigid, inflexible workflows. Barriers such as high initial costs, resistance to change, and limited awareness highlight the need for organizational cultural shifts, scalable implementation strategies, and collaborative industry standards. This study provides actionable recommendations for aligning software testing with environmental, economic, and social sustainability objectives, offering a roadmap for organizations to achieve eco-efficient and resilient software development.  © 2025 IEEE.|Environmental Impact; Resource Utilization; Software Testing; Sustainability of Software Development|Computer operating systems; Computer software selection and evaluation; Effluents; Model checking; Open source software; Particulate emissions; Software design; Soot; Waste utilization; IT firms; Optimization techniques; Organisational; Resources utilizations; Software testings; Sustainability of software development; Sustainable softwares; Test Environment; Testing process; Work-flows; Integration testing|Conference paper|Final||Scopus|2-s2.0-105004554649
scopus|Hao J.; Li B.; Zhao X.; Chen J.; Zheng B.; Qu J.|Hao, Junhong (58186975200); Li, Baifeng (60016995500); Zhao, Xinyuan (60017139800); Chen, Jiawei (60016995600); Zheng, Binxian (60017570400); Qu, Jingkang (60017283600)|58186975200; 60016995500; 60017139800; 60016995600; 60017570400; 60017283600|Design and Implementation of an Automated Functional Testing System for NV11 Massage Seat Controller With Performance Optimization|2025|Applied Research|4|4|e70029||||0|10.1002/appl.70029|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105011861308&doi=10.1002%2fappl.70029&partnerID=40&md5=b58f08b957613c3864d8579415299bae|This paper addresses the growing need for efficient and precise automated testing of automotive electronic control units (ECUs), specifically focusing on the NIO NV11 massage seat controller. Traditional manual testing methods suffer from significant inefficiencies and accuracy limitations, while existing automated systems lack specialized load modeling and seamless integration with manufacturing execution systems (MES). The proposed solution aims to bridge these gaps through a comprehensive testing framework. The system integrates hardware and software components to enable end-to-end automation. The hardware core consists of an industrial computer (IPC) interfacing via the local interconnect network (LIN) bus, complemented by a Flash burning module, LIN communication interface, and programmable power supply. A custom test fixture facilitates uninterrupted transitions from functional verification to data uploading, while digital instrumentation ensures fine-grained testing precision. The software architecture leverages intelligent algorithms for adaptive parameter adjustment and real-time data analysis. Experimental results demonstrate notable performance improvements: testing time is reduced by ~30% compared to traditional methods, while error rates decrease by around 20%, ensuring high repeatability and accuracy. The system's modular design enables straightforward adaptation to other automotive ECUs, such as anti-lock braking systems (ABS) and electronic stability programs (ESP), with minimal modifications. Industrial deployment has validated its ability to enhance testing efficiency, reliability, and flexibility in meeting evolving automotive quality control demands. This study contributes a robust automated testing framework that combines hardware-software integration with intelligent algorithms, addressing critical gaps in existing solutions. The system's scalability and adaptability position it as a valuable asset for advancing ECU testing in the automotive industry, with future developments targeting AI-driven predictive maintenance and expanded application scenarios. The abbreviations are shown in the “Abbreviations” section. © 2025 Wiley-VCH GmbH.|automated test system; automotive electronics; electronic control unit testing; industrial computer; local interconnect network bus; manufacturing execution system|Automatic testing; Automation; Automobile electronic equipment; Automobile hardware; Computer control systems; Computer hardware; Computer testing; Fixtures (tooling); Industrial electronics; Interfaces (computer); Physical therapy; Predictive maintenance; Automated test systems; Automotives; Electronic control unit testing; Electronics control unit; Industrial computers; Local interconnect network bus; Local interconnect networks; Manufacturing Execution System; Network bus; Unit testing; Ability testing; Automotive industry; Integration testing|Article|Final||Scopus|2-s2.0-105011861308
scopus||||Computing Conference, CompCom 2025|2025|Lecture Notes in Networks and Systems|1424 LNNS|||||691|0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-105009401395&partnerID=40&md5=93fe6073327cbd642cdbaa163948af14|The proceedings contain 41 papers. The special focus in this conference is on Computing. The topics include: Enhanced Liver and Tumor Segmentation in Multi-modal Medical Images Using Deep Learning Techniques; Advanced AI and Temporal Analysis for Accurate Cricket Shot Classification; Prompt-Driven Approach for Cattle Image Segmentation Based on SAM; vision Transformer Based Photometric Stellar Classification; design and Implementation of a Novel and Robust Automated Attendance System; transforming Classic E-Learning into Immersive Learning: Innovative Strategies for the Metaverse; Enhancing Mobile Learning with Meta-mobile Technology: User Experience Insights from Malaysia and the USA; integrating Artificial and Human Intelligence Within a Constructionism Framework: A Case Study in Syllabus Design; A Dynamic Query Framework for Research Accessibility Using OpenAI and Langchain; how Do Large Language Models Perform on the Question Answering Tasks?; Modelling Protest Related Topics by Combining GPT-4 with State-of-the-Art Approaches; Simplifying Formal Proof-Generating Models with ChatGPT and Basic Searching Techniques; NL2EQ: Generating Elasticsearch Query DSL from Natural Language Text Using Large Language Models; Validation of Practicality for CSI Sensing Utilizing Machine Learning; synthesis of Optimal Stabilization System by Supervised Machine Learning of Symbolic Regression; The Future of Software Testing: AI–Powered Test Case Generation and Validation; Impact of AI-Generated Phishing Attacks: A New Cybersecurity Threat; comparing Traditional Machine Learning with Deep Learning: Finding the Optimal Tool for Precipitation Intensity Forecasting; glucoPredict: An Ensemble Machine Learning Method Using Lifestyle, Health, and Socioeconomic Factors to Predict and Prevent Diabetes Risk; enhancing Cybersecurity with Advanced Dataset Features: Improving Machine Learning Algorithms and Intrusion Detection Systems; Subject-Specific Temporal Analysis of Cognitive Load Using fNIRS: A Machine Learning Approach; data-Driven Machine Learning Approaches for Predicting In-Hospital Sepsis Mortality.|||Conference review|Final||Scopus|2-s2.0-105009401395
scopus|Muththamizh Selvi S.I.; Senthamarai T.; Kumar S.K.; Sheik Hameed N.; Vijayakumar S.; Raj I.I.|Muththamizh Selvi, S.I. (59898470800); Senthamarai, T. (59898856900); Kumar, S. Karthik (59900288700); Sheik Hameed, N. (58705942300); Vijayakumar, S. (57211912860); Raj, I Infant (57202985713)|59898470800; 59898856900; 59900288700; 58705942300; 57211912860; 57202985713|Artificial Intelligence in Mobile Computing for English Language Testing: Redefining Automated Language Assessment|2025|Proceedings of 2025 3rd International Conference on Intelligent Systems, Advanced Computing, and Communication, ISACC 2025||||417|421|4|0|10.1109/ISACC65211.2025.10969303|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105005193147&doi=10.1109%2fISACC65211.2025.10969303&partnerID=40&md5=ea888e503990bfc35420207c2b74ca7b|"Artificial intelligence's (AI) quick development has created new opportunities in a number of domains, including education. Language evaluation is one such field that has experienced a great deal of innovation. The utilization of auto encoders to redefine automated language assessment is the focus of this work, which investigates the integration of artificial intelligence (AI) in mobile computing for English language evaluation. Traditional language assessment approaches are being challenged by AI's capability to offer real-time, scalable, and personalized evaluations. By leveraging autoencoders deep learning models optimized for unsupervised learning and feature extraction - the proposed system evaluates diverse linguistic attributes such as grammar, spelling, pronunciation, fluency, and comprehension. Autoencoders transform high-dimensional input data into low-dimensional latent spaces, enabling efficient assessment of nuanced language patterns. The methodology incorporates the LibriSpeech ASR Corpus for data preprocessing, feature extraction, and training. Key innovations include robust handling of diverse input types (text and audio), accurate reconstruction of linguistic features, and scalable evaluation of proficiency. Performance metrics such as accuracy, reconstruction error, and fluency scores demonstrate the model's superior learning and assessment capabilities. Compared to other deep learning methods like LSTMs, CNNs, and Transformers, the autoencoder-based approach excels in accuracy and adaptability, offering impartial and precise assessments. The study ""concludes""with a discussion of the benefits and challenges of AI-driven automated testing, providing insights into its potential to revolutionize educational assessment and reduce the burden on instructors by automating routine evaluations © 2025 IEEE."|Artificial Intelligenc(AI); Autoencoders; Automated Testing; Deep Learning Models; Language Assessment|Automatic test pattern generation; Context free grammars; Context sensitive grammars; Personnel training; Semantics; Syntactics; Teaching; Unsupervised learning; Artificial intelligenc; Auto encoders; Automated testing; Deep learning model; English languages; Features extraction; Language assessment; Language evaluations; Learning models; Mobile-computing; Deep learning|Conference paper|Final||Scopus|2-s2.0-105005193147
scopus||||ICSIE 2024 - 2024 13th International Conference on Software and Information Engineering|2025|ICSIE 2024 - 2024 13th International Conference on Software and Information Engineering||||||147|0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-105008289224&partnerID=40&md5=0264d054f766719605014d17d05c0243|The proceedings contain 19 papers. The topics discussed include: exploring gamification risks and implications in agile software development enterprises: an empirical study; enabling ai-driven customer experiences in fashion e-commerce through an end-to-end ML software development framework; PM4Flower: a scriptable parametric modeling interface for procedural flower generation using PM4VR; a review of practices suitable for ethics-aware software engineering; streamlining test execution: a case study on the use of automated testing to enhance productivity; and privacy by design: a systematic literature review of European and British regulatory perspectives for software and information engineering.|||Conference review|Final||Scopus|2-s2.0-105008289224
scopus|Li X.-P.; Yan M.; Fan X.-Y.; Tang Z.-T.; Kai S.-X.; Hao J.-Y.; Yuan M.-X.; Chen J.-J.|Li, Xiao-Peng (58413482000); Yan, Ming (56307496100); Fan, Xing-Yu (58532465100); Tang, Zhen-Tao (58491516800); Kai, Shi-Xiong (57204760558); Hao, Jian-Ye (36809586800); Yuan, Ming-Xuan (19640750600); Chen, Jun-Jie (57145642900)|58413482000; 56307496100; 58532465100; 58491516800; 57204760558; 36809586800; 19640750600; 57145642900|Survey on Testing of Intelligent Chip Design Program; [智能化芯片设计程序测试研究综述]|2025|Ruan Jian Xue Bao/Journal of Software|36|6||2453|2476|23|0|10.13328/j.cnki.jos.007328|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105005954048&doi=10.13328%2fj.cnki.jos.007328&partnerID=40&md5=d7da5c1d4b776944ba74b6ad785c42a1|In the current intelligent era, chips, serving as the core components of intelligent electronic devices, play a critical role in multiple fields such as artificial intelligence, the Internet of Things, and 5G communication. It is of great significance to ensure the correctness, security, and reliability of chips. During the chip development process, developers first need to implement the chip design into a software form (i.e., chip design programs) by using hardware description languages, and then conduct physical design and finally tape-out (i.e., production and manufacturing). As the basis of chip design and manufacturing, the quality of the chip design program directly impacts the quality of the chips. Therefore, the testing of chip design programs is of important research significance. The early testing methods for chip design programs mainly depend on the test cases manually designed by developers to test the chip design programs, often requiring a large amount of manual cost and time. With the increasing complexity of chip design programs, various simulation-based automated testing methods have been proposed, improving the efficiency and effectiveness of chip design program testing. In recent years, more and more researchers have been committed to applying intelligent methods such as machine learning, deep learning, and large language models (LLMs) to the field of chip design program testing. This study surveys 88 academic papers related to intelligent chip design program testing, and sorts and summarizes the existing achievements in intelligent chip design program testing from three perspectives: test input generation, test oracle construction, and test execution optimization. It focuses on the evolution of chip design program testing methods from the machine learning stage to the deep learning stage and then to the large language model stage, exploring the potential of different stages’ methods in improving testing efficiency and coverage, as well as reducing testing costs. Additionally, it introduces research datasets and tools in the field of chip design program testing and envisions future development directions and challenges. ©中国科学院软件研究所版权所有|large language model (LLM); test case generation; testing of chip design program|Automatic test pattern generation; Computer debugging; Computer software selection and evaluation; Hardware-software codesign; Integrated circuit layout; Intellectual property core; Testbeds; 'current; Chip design; Design programs; Language model; Large language model; Machine-learning; Program testing; Test case generation; Testing method; Testing of chip design program; Printed circuit design|Article|Final||Scopus|2-s2.0-105005954048
scopus|Yu H.; Zhang Y.; Li Q.; Jiang L.; Shang Y.|Yu, Hao (59147037500); Zhang, Ying (59671490200); Li, Qian (59671325900); Jiang, Libiao (7403475970); Shang, Yunpeng (59163066700)|59147037500; 59671490200; 59671325900; 7403475970; 59163066700|Research on software defect prediction based on machine learning; [基 于 机 器 学 习 的 软 件 缺 陷 预 测 研 究]|2025|Chongqing Daxue Xuebao/Journal of Chongqing University|48|2||10|21|11|0|10.11835/j.issn.1000-582X.2025.02.002|https://www.scopus.com/inward/record.uri?eid=2-s2.0-86000145588&doi=10.11835%2fj.issn.1000-582X.2025.02.002&partnerID=40&md5=eac5d52068ab1500983871c5c6fe4bd1|With the gradual penetration of machine learning technology into various fields, software testing in the software development process is very important. Software defect prediction faces class imbalance problem and accuracy issue. This paper proposes a supervised learning-based software prediction method for solving these two core problems. The method adopts sample balancing technique, combined with synthetic minority over-sampling technique(SMOTE) and edited nearest neighbor(ENN) algorithm, to test local weight learning(LWL), J48, C4.8, random forest, Bayes net(BN), multilayer feedforward neural network(MFNN), supported vector machine(SVM), and naive Bayes key(NB-K). These algorithms are applied to three different datasets (KK1, KK3 and PK2) in the NASA database and their effects are compared and analyzed in detail. The results show that the random forest model combining SMOTE and ENN exhibits high efficiency and avoiding overfitting in dealing with class imbalance problems, which provides an effective way to solve the problem in software defect prediction. © 2025 Chongqing University. All rights reserved.|class imbalance; machine learning; random forest; software defect prediction; XGBoost||Article|Final||Scopus|2-s2.0-86000145588
scopus|Haldar S.; Pierce M.; Fernando Capretz L.|Haldar, Susmita (58419715100); Pierce, Mary (59195600700); Fernando Capretz, Luiz (59453425400)|58419715100; 59195600700; 59453425400|Exploring the Integration of Generative AI Tools in Software Testing Education: A Case Study on ChatGPT and Copilot for Preparatory Testing Artifacts in Postgraduate Learning|2025|IEEE Access|13|||46070|46090|20|1|10.1109/ACCESS.2025.3545882|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001239332&doi=10.1109%2fACCESS.2025.3545882&partnerID=40&md5=86a933c4b170caf390243024326fe224|Software testing education is important for building qualified testing professionals. To ensure that software testing graduates are ready for real-world challenges, it is necessary to integrate modern tools and technologies into the curriculum. With the emergence of Large Language Models (LLMs), their potential use in software engineering has become a focus, but their application in software testing education remains largely unexplored. This study, conducted in the Capstone Project course of a postgraduate software testing program, was carried out over two semesters with two distinct groups of students. A custom-built Travel Application limited to a web platform was used in the first semester. In the second semester, a new set of students worked with an open-source application, offering a larger-scale, multi-platform experience across web, desktop, and mobile platforms. Students initially created preparatory testing artifacts manually as a group deliverable. Following this, they were assigned an individual assignment to generate the same artifacts using LLM tools such as ChatGPT 3.5 in the first semester and Microsoft Copilot in the second. This process directly compared manually created artifacts and those generated using LLMs, leveraging AI for faster outputs. After completion, they responded to a set of assigned questions. The students’ responses were assessed using an integrated methodology, including quantitative and qualitative assessments, sentiment analysis to understand emotions, and a thematic approach to extract deeper insights. The findings revealed that while LLMs can assist and augment manual testing efforts, they cannot entirely replace the need for manual testing. By incorporating innovative technology into the curriculum, this study highlights how Generative AI can support active learning, connect theoretical concepts with practical applications, and align educational practices with industry needs. © 2013 IEEE.|Capstone project; ChatGPT; generative AI; Microsoft Copilot; sentiment analysis; software testing education|Application programs; Curricula; Engineering education; Integration testing; Open source software; Teaching; Windows operating system; Capstone projects; ChatGPT; Generative AI; Language model; Manual testing; MicroSoft; Microsoft copilot; Sentiment analysis; Software testing education; Software testings; Students|Article|Final|All Open Access; Gold Open Access|Scopus|2-s2.0-105001239332
scopus|Ozer E.; Akcayol M.A.|Ozer, Edipcan (59949279000); Akcayol, Muhammet Ali (55662828600)|59949279000; 55662828600|Automated Test Case Output Generation Using Seq2Seq Models|2025|ICSIE 2024 - 2024 13th International Conference on Software and Information Engineering||||46|53|7|0|10.1145/3708635.3708644|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105008323127&doi=10.1145%2f3708635.3708644&partnerID=40&md5=337b520e30806fbcc2ae85e35ed0c987|The aim of this paper is to present a creative approach to generate test case outputs for a given input automatically for software testing. Sequence-to-sequence (seq2seq) model is applied. Our approach aims to address the challenge of creating meaningful test case outputs for input variations in software testing, improving efficiency and accuracy in test automation. With the help of natural language processing techniques, the model is trained on an original dataset of test inputs and their corresponding outputs, predicting the output for a given test case input. We employ evaluation metrics including BLEU, ROUGE, and JACCARD similarity scores to assess the quality of generated outputs, comparing them against reference outputs. Our initial results show that the seq2seq model has a huge potential of producing accurate test case outputs, significantly reducing manual effort in test case generation. This work demonstrates the potential for integrating Recurrent Neural Network techniques into software testing and providing a scalable solution for automated test case output generation. © 2024 Copyright held by the owner/author(s).|Automated test generation; machine learning; natural language processing; recurrent neural networks; seq2seq model; software testing; test automation|Automatic test pattern generation; Automation; Computer software selection and evaluation; Integration testing; Learning algorithms; Learning systems; Model checking; Natural language processing systems; Quality control; Statistical tests; Automated test generations; Language processing; Machine-learning; Natural language processing; Natural languages; Neural-networks; Seq2seq model; Software testings; Test Automation; Test case; Recurrent neural networks|Conference paper|Final||Scopus|2-s2.0-105008323127
scopus|Villa L.; Zanini Brusamarello C.|Villa, Lucas (59310837600); Zanini Brusamarello, Claiton (24436435100)|59310837600; 24436435100|Application of machine learning in monitoring fouling in heat exchangers in chemical engineering: A systematic review|2025|Canadian Journal of Chemical Engineering|103|4||1786|1801|15|2|10.1002/cjce.25480|https://www.scopus.com/inward/record.uri?eid=2-s2.0-86000434060&doi=10.1002%2fcjce.25480&partnerID=40&md5=ce46d0919b46a6d22f3867a996d398ce|The present work consists of a systematic literature review that examines studies on using machine learning to monitor fouling in heat exchangers in the chemical engineering area. The research was conducted in four renowned databases: SCOPUS, Science Direct, IEEE, and Web of Science. The main objective of the investigation was to identify the most prevalent machine learning methods, evaluate their performance, and analyze the challenges associated with their implementation and prospects. Using the StArt software, seven relevant scientific papers from the established review protocol. The most frequently identified methods were support vector machine (SVM) and k-nearest neighbours (k-NN), followed by decision tree. However, long-term and short-term predictors and long short-term memory (LSTM) and non-linear autoregressive with exogenous inputs (NARX) algorithms were the most successful, followed by Gaussian process regression (GPR), SVM, k-NN, and improved grey wolf optimization–support vector regression (IGWO-SVR) algorithms. Although these methods inspire confidence, it is important to highlight that they are still in the software testing phase. Key gaps identified include the need for further studies on real industrial applications and the integration of advanced sensors and measurement systems. Future directions point to developing more robust and generalized algorithms capable of dealing with the complexity of real systems. © 2024 Canadian Society for Chemical Engineering.|algorithms; detection; dirty; equipment|Bioreactors; Cooling towers; Surveying instruments; Detection; Dirty;; Machine learning methods; Machine-learning; Nearest-neighbour; Performance; Scientific papers; Systematic literature review; Systematic Review; Web of Science|Short survey|Final||Scopus|2-s2.0-86000434060
scopus|Schmidt D.C.; Laplante P.|Schmidt, Douglas C. (57203331566); Laplante, Phil (7005498946)|57203331566; 7005498946|Software Testing in the Generative AI Era: A Practitioner’s Playbook|2025|Computer|58|7||147|152|5|0|10.1109/MC.2025.3562940|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105009589213&doi=10.1109%2fMC.2025.3562940&partnerID=40&md5=499b8f2c9b51b951d7bbeab9441ea8e5|This article presents a practitioner-focused playbook on how generative artificial intelligence is transforming software testing by automating tasks like test generation, simulation, and anomaly detection, while also introducing new challenges like hallucinations, bias, and nondeterminism. © 1970-2012 IEEE.||Anomaly detection; Artificial intelligence; Anomaly detection; Non Determinism; Software testings; Test generations; Software testing|Article|Final||Scopus|2-s2.0-105009589213
scopus|Chakraborty A.K.; Majumder A.; Kundu V.|Chakraborty, Ashis Kumar (55440444100); Majumder, Anuran (59260576400); Kundu, Vivek (59260576500)|55440444100; 59260576400; 59260576500|Size-biased Hybrid Model for Software Defect Prediction|2025|OPSEARCH|62|2||706|724|18|0|10.1007/s12597-024-00832-7|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201256540&doi=10.1007%2fs12597-024-00832-7&partnerID=40&md5=8b02b86b984e9f0d7a3ddbd5520ea392|Overall software management generally includes software testing as an important aspect. Defect prediction in software is an important activity for testing a software. Hybrid models which include statistical and machine learning techniques have become very popular in recent days for predicting existence of errors in a software. Till recently software reliability models were developed based on the number of undetected bugs. However, some recent works on software reliability drastically changed the idea of estimating software reliability. The newly developed concept of “bug size” in a software is used in this article along with a proven hybrid method to predict software reliability. We have used this new method on several NASA data sets. Several standard criteria have been used to examine the efficacy of the proposed method and we obtained much better results compared to the earlier results on similar data sets. © The Author(s), under exclusive licence to Operational Research Society of India 2024.|Hybrid model; Imbalanced data; Machine learning; Size of a bug; Software defect prediction (SDP)||Article|Final||Scopus|2-s2.0-85201256540
scopus|Wang Y.; Guo S.; Tan C.W.|Wang, Yuchen (57911974700); Guo, Shangxin (58421050300); Tan, Chee Wei (15072338600)|57911974700; 58421050300; 15072338600|From Code Generation to Software Testing: AI Copilot With Context-Based Retrieval-Augmented Generation|2025|IEEE Software|42|4||34|42|8|2|10.1109/MS.2025.3549628|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000040423&doi=10.1109%2fMS.2025.3549628&partnerID=40&md5=0036eb2cfa1b567a0e8476b9a42966fb|The rapid pace of large-scale software development places increasing demands on traditional testing methodologies. We propose a novel perspective on software testing, highlighting the transformative potential of AI-driven technologies in modern software development practices. © 1984-2012 IEEE.||Acceptance tests; Coding errors; Program debugging; Software design; Auto completion; Automated testing; Bug detection; Chatbots; Codegeneration; Context based retrieval; Large-scales; Software testings; Testing methodology; Testing systems; Software testing|Article|Final||Scopus|2-s2.0-105000040423
scopus|Ghafoor Hussain R.; Yow K.-C.; Gori M.|Ghafoor Hussain, Rida (59561256300); Yow, Kin-Choong (57217739971); Gori, Marco (7005254436)|59561256300; 57217739971; 7005254436|Leveraging an Enhanced CodeBERT-Based Model for Multiclass Software Defect Prediction via Defect Classification|2025|IEEE Access|13|||24383|24397|14|4|10.1109/ACCESS.2024.3525069|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215851908&doi=10.1109%2fACCESS.2024.3525069&partnerID=40&md5=75c5bdc3b0ec769032c9828c08e484cb|Ensuring software reliability through early-stage defect prevention and prediction is crucial, particularly as software systems become increasingly complex. Automated testing has emerged as the most practical approach to achieving bug-free and efficient code. In this context, machine learning-driven methods, especially those leveraging natural language models, have gained significant traction for developing effective techniques. This paper introduces a novel framework for automating software defect prediction, focusing on eight specific defects: SIGFPE, NZEC, LOGICAL, SYNTAX, SIGSEGV, SIGABRT, SEMANTIC, and LINKER. Our research involves a specialized dataset comprising nine classes, including eight common programming errors and one error-free class. The goal is to enhance software testing and development processes by identifying defects within code snippets. The proposed framework utilizes a CodeBERT-based algorithm for defect prediction, optimizing model hyperparameters to achieve superior accuracy. Comparative analysis against established models such as RoBERTa, Microsoft CodeBERT, and GPT-2 demonstrates that our approach yields significant improvements in prediction performance, with accuracy gains of up to 20% and 7% respectively in binary and multi class experimentation. Empirical studies validate the effectiveness of neural language models like CodeBERT for software defect prediction, highlighting substantial advancements in software testing and development techniques. These findings underscore the potential benefits of incorporating advanced machine learning models into the software development lifecycle.  © 2025 The Authors.|code snippets; CodeBERT; defects; GPT; Software defect prediction; software reliability|Adversarial machine learning; Semantics; Software testing; Automated testing; Code snippet; CodeBERT; Defect classification; Defect prediction; Defect prevention; GPT; Software defect prediction; Software-Reliability; Software-systems; Prediction models|Article|Final|All Open Access; Gold Open Access|Scopus|2-s2.0-85215851908
scopus||||15th International Conference on e-Infrastructure and e-Services for Developing Countries, AFRICOMM 2023|2025|Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering, LNICST|588 LNICST|||||249|0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85219177256&partnerID=40&md5=c105603bb3f1d12d9ef878d392a01521|The proceedings contain 44 papers. The special focus in this conference is on e-Infrastructure and e-Services for Developing Countries. The topics include: Digital Forensics Investigations: Major Challenges in Mobile and Cloud Forensics; a Cloud-Based Drones’ Model for Detection and Tracking of Stationary and Motion-Based Snakes in Farms in Marginalized Rural Areas: A Preliminary Study; A Domain Specific Language (DSL) for Agroecosystems Modelling and Simulation; Leveraging Conversational AI for Accelerating User-Driven Software Testing; integration of Artificial Intelligence with Diabetic Data for Increasingly Personalized Medicine; Question Design Using NLP; Edge- AI and Internet of Things for Intelligent Systems: Architectures, Applications and Future Perspectives; comparative Study of Name Entity Recognition Models in Burkina Faso Context; PLAVIDA, an Annotation Tool for Audio and Video in African Languages; towards a Framework for the Preparation of High Quality Data for Use by Machine Learning Algorithms; CAOGen: An Automatic Ontology Constructor Based on Data Mining Techniques; artificial Intelligence for the Analysis of the Security Situation in Burkina Faso; analysis, Design and Implementation of a Ripe Mango Detection Program in Burkina Faso; financial Fraud Detection Using Rich Mobile Money Transaction Datasets; culture Ontology to Enhance Social Cohesion; new Zero Watermarking Scheme Based on Hyper-catadioptric System Model and Hyperbolic Geometry; Cotton Disease Detection on UAV Images: A Deep Learning-Based Approach with YOLOv7.|||Conference review|Final||Scopus|2-s2.0-85219177256
scopus|Hadzhikoleva S.; Rachovski T.; Hadzhikolev E.; Ivanov I.|Hadzhikoleva, Stanka (57191359477); Rachovski, Todor (57197831783); Hadzhikolev, Emil (57191364629); Ivanov, Ivan (57214064487)|57191359477; 57197831783; 57191364629; 57214064487|The Role of Generative Artificial Intelligence in Programmer Training: Opportunities and Challenges|2025|Environment Technology Resources - Proceedings of the 16th International Scientific and Practical Conference|2|||151|156|5|0|10.17770/etr2025vol2.8608|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105011715993&doi=10.17770%2fetr2025vol2.8608&partnerID=40&md5=97408ef5f3d41e32a829e920059f9451|Artificial intelligence has rapidly entered people's daily lives and has innovated many traditional models by integrating AI technologies. The need for changes in educational practices has come to the forefront. This article outlines various possibilities for using generative artificial intelligence in programming education. Different examples are presented, including code generation, debugging and optimization, documentation and commenting, automated testing, conversion between different programming languages, and more. Additionally, some risks and limitations are discussed. © 2025 The Author(s). Published by RTU PRESS.|AI in education; AI in programmer training; generative AI in programming education; programming with AI|Education computing; AI in education; AI in programmer training; AI Technologies; Code optimization; Codegeneration; Daily lives; Generative AI in programming education; Programming education; Programming with AI; Traditional models; Artificial intelligence|Conference paper|Final||Scopus|2-s2.0-105011715993
scopus||||15th International Conference on e-Infrastructure and e-Services for Developing Countries, AFRICOMM 2023|2025|Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering, LNICST|587 LNICST|||||249|0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85219198177&partnerID=40&md5=54cfc6d11bec28bd46573ed0a17fa933|The proceedings contain 44 papers. The special focus in this conference is on e-Infrastructure and e-Services for Developing Countries. The topics include: Digital Forensics Investigations: Major Challenges in Mobile and Cloud Forensics; a Cloud-Based Drones’ Model for Detection and Tracking of Stationary and Motion-Based Snakes in Farms in Marginalized Rural Areas: A Preliminary Study; A Domain Specific Language (DSL) for Agroecosystems Modelling and Simulation; Leveraging Conversational AI for Accelerating User-Driven Software Testing; integration of Artificial Intelligence with Diabetic Data for Increasingly Personalized Medicine; Question Design Using NLP; Edge- AI and Internet of Things for Intelligent Systems: Architectures, Applications and Future Perspectives; comparative Study of Name Entity Recognition Models in Burkina Faso Context; PLAVIDA, an Annotation Tool for Audio and Video in African Languages; towards a Framework for the Preparation of High Quality Data for Use by Machine Learning Algorithms; CAOGen: An Automatic Ontology Constructor Based on Data Mining Techniques; artificial Intelligence for the Analysis of the Security Situation in Burkina Faso; analysis, Design and Implementation of a Ripe Mango Detection Program in Burkina Faso; financial Fraud Detection Using Rich Mobile Money Transaction Datasets; culture Ontology to Enhance Social Cohesion; new Zero Watermarking Scheme Based on Hyper-catadioptric System Model and Hyperbolic Geometry; Cotton Disease Detection on UAV Images: A Deep Learning-Based Approach with YOLOv7.|||Conference review|Final||Scopus|2-s2.0-85219198177
scopus|Ranapana R.M.S.; Wijayanayake W.M.J.I.|Ranapana, R.M.S. (59789557200); Wijayanayake, W.M.J.I. (6507962345)|59789557200; 6507962345|The Role of AI in Software Test Automation|2025|2025 5th International Conference on Advanced Research in Computing: Converging Horizons: Uniting Disciplines in Computing Research through AI Innovation, ICARC 2025 - Proceedings|||||||0|10.1109/ICARC64760.2025.10962814|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105004559152&doi=10.1109%2fICARC64760.2025.10962814&partnerID=40&md5=655db55e28bd7e10680ebdd6bf4ef73f|Artificial Intelligence (AI) has emerged as a transformative force in software test automation, significantly enhancing the efficiency, accuracy, and reliability of testing processes. This research will investigates the role of AI in software test automation, focusing on key methodologies, applications, and challenges encountered during implementation. The review identifies and analyzes various AI-driven techniques, including Machine Learning (ML), Neural Networks, and Genetic Algorithms, which are utilized to optimize testing activities such as test case generation, defect detection, and test execution. Findings indicate that AI can substantially improve the software testing lifecycle by automating repetitive tasks, reducing human error, and increasing test coverage. By leveraging AI algorithms, organizations can achieve faster turnaround times and enhance the overall quality of software products. Additionally, AI facilitates predictive analytics, enabling teams to identify potential defects early in the development process, thereby minimizing costs and time associated with late-stage bug fixes. However, the resaerch also highlights several challenges that hinder the widespread adoption of AI in software testing. Issues such as data quality, model overfitting, and the complexities of integrating AI solutions with existing testing frameworks present significant barriers. Furthermore, many AI applications remain largely theoretical or limited to academic research, lacking real-world implementation.The insights gained from this review are invaluable for both researchers and practitioners aiming to harness AI's capabilities to revolutionize software testing practices. By addressing the identified challenges and fostering collaboration between academia and industry, stakeholders can develop more robust frameworks and models that leverage AI's potential, ultimately creating a more efficient and effective software testing environment.  © 2025 IEEE.|Artificial Intelligence; Efficiency; Machine Learning; Software Testing; Test Automation|Computer software selection and evaluation; Enterprise software; Model checking; Software quality; Software reliability; Testbeds; Defect detection; Learning neural networks; Machine-learning; Neural networks and genetic algorithms; Software test automation; Software testings; Test Automation; Test case generation; Test execution; Testing process; Integration testing|Conference paper|Final||Scopus|2-s2.0-105004559152
scopus|Kaur A.|Kaur, Ashmeet (59951797100)|59951797100|Automating XPath Query Generation Using NLP for Streamlined Web Crawling and GUI Testing|2025|International Conference on Trends in Engineering Systems and Technologies, ICTEST 2025 - Proceedings|||||||0|10.1109/ICTEST64710.2025.11042798|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105010476199&doi=10.1109%2fICTEST64710.2025.11042798&partnerID=40&md5=6af6a4167d44dda39151da8455a42354|Efficient web data extraction and automated testing often require precise XPath queries, but generating these queries manually is both time-consuming and prone to errors. This work presents an advanced approach to automate the creation of XPath queries by leveraging natural language processing (NLP). Through a novel two-stage pipeline, the method first identifies relevant content from web pages and then uses an enhanced model to generate robust and reusable XPath queries. By reducing the complexity of web page structures and focusing on task-specific elements, this technique minimizes computational costs and improves processing speed. Benchmark results show that this NLP-powered solution significantly enhances both accuracy and efficiency in web crawling and GUI testing tasks, offering a scalable, user-friendly alternative to traditional methods. The solution is easily integrated into existing workflows, saving valuable time and effort in web scraping applications. © 2025 IEEE.|automated information extraction; GUI testing; natural language processing; web scraping; XPath query generation|Benchmarking; Computer software reusability; Data mining; Extraction; Graphical user interfaces; Information retrieval; Learning algorithms; Query processing; Web crawler; Websites; Automated information; Automated information extraction; GUI testing; Language processing; Natural language processing; Natural languages; Query generation; Web scrapings; Xpath queries; Xpath query generation; Natural language processing systems|Conference paper|Final||Scopus|2-s2.0-105010476199
scopus|Sorokin L.; Safin D.; Nejati S.|Sorokin, Lev (57916395300); Safin, Damir (58303334500); Nejati, Shiva (18038340600)|57916395300; 58303334500; 18038340600|Can search-based testing with pareto optimization effectively cover failure-revealing test inputs?|2025|Empirical Software Engineering|30|1|26||||2|10.1007/s10664-024-10564-3|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209354680&doi=10.1007%2fs10664-024-10564-3&partnerID=40&md5=de24ba3c4a9f2fbc3fed3d316efaec4a|Search-based software testing (SBST) is a widely-adopted technique for testing complex systems with large input spaces, such as Deep Learning-enabled (DL-enabled) systems. Many SBST techniques focus on Pareto-based optimization where multiple objectives are optimized in parallel to reveal failures. However, it is important to ensure that identified failures are spread throughout the entire failure-inducing area of a search domain, and not clustered in a sub-region. This ensures that identified failures are semantically diverse and reveal a wide range of underlying causes. In this paper, we present a theoretical argument explaining why testing based on Pareto optimization is inadequate for covering failure-inducing areas within a search domain. We support our argument with empirical results obtained by applying two widely used types of Pareto-based optimization techniques, namely NSGA-II (an evolutionary algorithm) and OMOPSO (a swarm-based algorithm), to two DL-enabled systems: an industrial Automated Valet Parking (AVP) system and a system for classifying handwritten digits. We measure the coverage of failure-revealing test inputs in the input space using a metric, that we refer to as the Coverage Inverted Distance (CID) quality indicator. Our results show that NSGA-II and OMOPSO are not more effective than a naïve random search baseline in covering test inputs that reveal failures. We show that this comparison remains valid for failure-inducing regions of various sizes of these two case studies. Further, we show that incorporating a diversity-focused fitness function as well as a repopulation operator in NSGA-II improves, on average, the coverage difference between NSGA-II and random search by 52.1%. However, even after diversification, NSGA-II still does not outperform random testing in covering test inputs that reveal failures. The replication package for this study is available in a GitHub repository (Replication package. https://github.com/ast-fortiss-tum/coverage-emse-24 2024. © The Author(s) 2024.|Autonomous driving; Coverage; Metaheuristics; Quality indicators; Random testing; Scenario-based testing; Search-based software testing; Testing deep learning systems|Failure analysis; Input output programs; Outages; Autonomous driving; Coverage; Metaheuristic; NSGA-II; Quality indicators; Random testing; Scenario-based testing; Search-based software testing; Test inputs; Testing deep learning system; Pareto principle|Article|Final|All Open Access; Hybrid Gold Open Access|Scopus|2-s2.0-85209354680
scopus|Wang Q.; Wang J.; Li M.; Wang Y.; Liu Z.|Wang, Qing (55698296000); Wang, Junjie (55976866600); Li, Mingyang (57207884211); Wang, Yawen (59654253100); Liu, Zhe (57221434139)|55698296000; 55976866600; 57207884211; 59654253100; 57221434139|A Roadmap for Software Testing in Open-Collaborative and AI-Powered Era|2025|ACM Transactions on Software Engineering and Methodology|34|5|148||||1|10.1145/3709355|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007503062&doi=10.1145%2f3709355&partnerID=40&md5=d34a2deb0b23e5e980d79b50f16ef55f|Internet technology has given rise to an open-collaborative software development paradigm, necessitating the open-collaborative schema to software testing. It enables diverse and globally distributed contributions, but also presents significant challenges to efficient testing processes, coordination among personnel, and management of testing artifacts. At the same time, advancements in AI have enhanced testing capabilities and enabling automation, while also introducing new testing needs and unique challenges for AI-based systems. In this context, this article explores software testing in the open-collaborative and AI-powered era, focusing on the interrelated dimensions of process, personnel, and technology. Among them, process involves managing testing workflows and artifacts to improve efficiency, personnel emphasizes the role of individuals in ensuring testing quality through collaboration and contributions, while technology refers to AI methods that enhance testing capabilities and address challenges in AI-based systems. Furthermore, we delve into the challenges and opportunities arising from emerging technologies such as Large Language Models (LLMs) and the AI model-centric development paradigm. © 2025 Association for Computing Machinery. All rights reserved.|AI; Artificial Intelligence; Large Language Model; LLM; Open Collaborative; Open Source; Software Testing|Ability testing; Empowerment of personnel; Human resource management; Open source software; Subjective testing; Collaborative software development; Internet technology; Language model; Large language model; Open collaborative; Open-source; Roadmap; Software testings; Software testing|Article|Final||Scopus|2-s2.0-105007503062
scopus|Hanim N.M.; Ahmad J.; Ismail M.A.; Sabri N.A.M.; Azmi S.|Hanim, Nadiah Mohd (59898979600); Ahmad, Johanna (57193720009); Ismail, Mohd Arfian (56275344400); Sabri, Nor Amalina Mohd (57076176400); Azmi, Shahdatunnaim (57040872000)|59898979600; 57193720009; 56275344400; 57076176400; 57040872000|Application of Reinforcement Learning Techniques in Software Testing of Android Applications: A Systematic Literature Review|2025|International Journal on Advanced Science, Engineering and Information Technology|15|2||647|653|6|0|10.18517/ijaseit.15.2.12521|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105005201116&doi=10.18517%2fijaseit.15.2.12521&partnerID=40&md5=7fd8d42dcbdf92f9a35c3f129f37cb5d|Software testing is a critical process in ensuring the quality and reliability of applications before they are deployed to production. However, it is resource-intensive and often tedious, particularly in the context of Android applications, which pose unique challenges due to their vast state space, diverse user interactions, and variable behaviors. Reinforcement learning (RL), a machine learning framework where agents interact with environments to improve decision-making policies, has gained attention for its potential in software testing. This systematic literature review examines the application of reinforcement learning in software testing of Android applications, focusing on widely researched areas, prevalent techniques, and emerging trends. The review analyzes 22 selected studies from an initial pool of over 30,000 articles published between 2020 and 2024. The findings highlight that automated testing is the primary focus in this domain, with Q-learning emerging as the dominant RL technique. Actor-critic methods, deep Q-networks (DQN), and policy gradient approaches are also explored in several studies, aiming to improve the adaptability and efficiency of testing processes. Most research emphasizes fault detection and coverage maximization, often targeting event-driven interactions and GUI-based behaviors. Despite significant advancements, the study identifies underexplored areas, such as test case prioritization and the integration of user behavior or user interaction data, as promising directions for future research. This review contributes to understanding the current landscape and offers guidance for future RL-based Android application testing investigations. © (2025), (Insight Society). All rights reserved.|Android application; machine learning; reinforcement learning; software testing; systematic literature review||Article|Final||Scopus|2-s2.0-105005201116
scopus|Villoth J.P.; Zivkovic M.; Zivkovic T.; Abdel-salam M.; Hammad M.; Jovanovic L.; Simic V.; Bacanin N.|Villoth, John Philipose (59560083700); Zivkovic, Miodrag (57208755936); Zivkovic, Tamara (6701358907); Abdel-salam, Mahmoud (58138730800); Hammad, Mohamed (57194656523); Jovanovic, Luka (57208164323); Simic, Vladimir (7005545253); Bacanin, Nebojsa (37028223900)|59560083700; 57208755936; 6701358907; 58138730800; 57194656523; 57208164323; 7005545253; 37028223900|Two-tier deep and machine learning approach optimized by adaptive multi-population firefly algorithm for software defects prediction|2025|Neurocomputing|630||129695||||6|10.1016/j.neucom.2025.129695|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217956359&doi=10.1016%2fj.neucom.2025.129695&partnerID=40&md5=1c2072363603da382403d47b91422c43|Software plays a progressively crucial role, where automated software systems control essential operations. Since development needs also progressively expand, manual code reviews become increasingly difficult, frequently resulting in testing lasting longer than development itself. An encouraging option for enhancing defect identification within the source code involves combining artificial intelligence and natural language processing (NLP). Analyzing source code offers an efficient approach to enhance defect detection and prevent errors in the code. This study investigates source code analysis using NLP and machine learning, where traditional and contemporary techniques of error detection are evaluated. Metaheuristics algorithms are utilized to tune machine learning classifiers, and an altered variant of the well-known firefly algorithm is proposed as part of this research. A two-tier framework is suggested, consisting of a convolutional neural network (CNN), which handles complex feature spaces, while eXtreme gradient boosting (XGBoost), adaptive boosting (AdaBoost), and categorical boosting (CatBoost) classifiers are employed within the second-tier for improving defect detection. Supplementary simulations employing custom term frequency inverse document frequency encoding are also executed to showcase the capabilities of the suggested framework. In total, seven experiments are carried out with publicly accessible datasets. The accuracy of CNN is 80.6% for the defect prediction task, which is enhanced with the second layer using XGBoost, AdaBoost, and CatBoost to nearly 81.5%. The experiments with the NLP approach exhibit superior outcomes, where XGBoost, AdaBoost, and CatBoost achieve accuracies of 99.6%, 99.7%, and 99.8%, indicating the large potential of the suggested approach in the software testing domain. © 2025 Elsevier B.V.|Convolutional neural network; Explainable artificial intelligence; Metaheuristics optimization; Natural language processing; Software defect prediction|Ada (programming language); Adaptive boosting; Adversarial machine learning; Coding errors; Convolutional neural networks; Deep neural networks; Multilayer neural networks; Convolutional neural network; Explainable artificial intelligence; Firefly algorithms; Language processing; Metaheuristic optimization; Natural language processing; Natural languages; Software defect prediction; Source codes; Two tiers; algorithm; article; artificial intelligence; classifier; convolutional neural network; diagnosis; encoding; explainable artificial intelligence; firefly algorithm; human; machine learning; metaheuristics; natural language processing; prediction; simulation; software; Software testing|Article|Final||Scopus|2-s2.0-85217956359
scopus|Kanagaraj K.; Nithiyanandam P.; Sekar S.; Shanmugam S.|Kanagaraj, Kamaraj (57224496191); Nithiyanandam, Prasath (55994125400); Sekar, Saradha (58519739400); Shanmugam, Sangeetha (59539316800)|57224496191; 55994125400; 58519739400; 59539316800|Combinatorial test case prioritization using hybrid Energy Valley Dwarf Mongoose Optimization approach|2025|Expert Systems with Applications|271||126634||||0|10.1016/j.eswa.2025.126634|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216795339&doi=10.1016%2fj.eswa.2025.126634&partnerID=40&md5=cef9ce656a6121d98c2f0bf60e2a2b66|Combinatorial Test Case Prioritization is a technique used in software testing to improve the efficiency and effectiveness of test suites. It involves selecting and ordering test cases based on their ability to detect faults, especially those caused by interactions between multiple parameters. Artificial Intelligence (AI) has made significant contributions to Combinatorial Test Case Prioritization (TCP) by introducing advanced techniques to enhance the efficiency of the testing process. However, managing dependencies between test cases and adjusting the prioritization accordingly can be complex and time-consuming in most of the previous techniques. Therefore, an Energy Valley Dwarf Mongoose Optimization Algorithm (EVDMOA) is devised for Combinatorial TCP. Initially, the software programs are collected from the dataset. Then, test case generation is performed to create the test suites. Next, the combinatorial TCP is performed. Here, the fitness parameters such as Average Percentage of Fault Detected (APFD), Average Percentage of Branch Coverage (APBC), and weight are considered for fitness evaluation. Moreover, the weights in the fitness function are computed by the Deep Q Net (DQN), which is trained by the proposed EVDMOA. At last, the prioritized test cases are obtained. The EVDMOA achieves the AFPD, APBC, and fitness values of 0.907, 0.914, and 0.926. Moreover, the EVDMOA helps in maintaining the overall quality and reliability of the software. © 2025 Elsevier Ltd|Deep Q Net (DQN); Dwarf Mongoose Optimization Algorithm (DMOA); Energy Valley Optimization (EVO); Regression Testing; Test Case Prioritization (TCP)|Deep Q net; Dwarf mongoose optimization algorithm; Energy; Energy valley optimization; Optimisations; Optimization algorithms; Regression testing; Test case; Test case prioritization; Software reliability|Article|Final||Scopus|2-s2.0-85216795339
scopus|Nagila A.; Trivedi N.; Nagila R.; Trivedi K.; Bhardwaj S.; Rani J.|Nagila, Ashish (57983883100); Trivedi, Neelu (57560506300); Nagila, Ritu (59134445200); Trivedi, Kanishk (59983591400); Bhardwaj, Sanjeev (57742983900); Rani, Jeetu (59984029800)|57983883100; 57560506300; 59134445200; 59983591400; 57742983900; 59984029800|A Framework for Automated Software Testing using Machine Learning and Artificial Intelligence|2025|Proceedings of 3rd IEEE International Conference on Knowledge Engineering and Communication Systems, ICKECS 2025|||||||0|10.1109/ICKECS65700.2025.11034863|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105010215504&doi=10.1109%2fICKECS65700.2025.11034863&partnerID=40&md5=1d15319226303a0a2ef905b07d980381|In order to produce high-quality applications while decreasing human labor and speeding up application development, automatic software testing is a crucial development methodology. This paper presents a novel framework that uses machine learning and artificial intelligence to improve automated software testing through intelligent solutions. Through machine learning techniques that perform test case selection and bug prediction with programming code base change monitoring, the framework achieves its optimization. Testing processes benefit from automated learning features that boost testing performance in real-time and artificial intelligence-based models that enhance error detection capabilities. When findings from contemporary methodologies surpass those from traditional testing methods, there are improvements in test coverage as well as fault detection capabilities and overall efficiency. This framework proposes a potential approach to the testing of AI and machine learning that takes into account adaption constraints as well as test scalability issues and automation dependability.  © 2025 IEEE.|Artificial Intelligence; Automated Testing; Defect Detection; Intelligent Testing; Machine Learning; Software Quality Assurance; Test Case Optimization|Application programs; Automatic programming; Automatic testing; Automation; Computer software selection and evaluation; Learning algorithms; Learning systems; Machine learning; Model checking; Software quality; Software testing; Well testing; Automated software testing; Automated testing; Defect detection; Detection capability; Intelligent testing; Machine-learning; Optimisations; Software quality assurance; Test case; Test case optimization; Quality assurance|Conference paper|Final||Scopus|2-s2.0-105010215504
scopus|Li J.; Yin Z.; Zong G.; Sang H.|Li, Junru (60006661900); Yin, Zhongxu (57204174724); Zong, Guoxiao (57217050952); Sang, Haiya (60006798600)|60006661900; 57204174724; 57217050952; 60006798600|GDFuzz: An efficient directed fuzzing method based on XAI|2025|Journal of Systems and Software|230||112568||||0|10.1016/j.jss.2025.112568|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105011146323&doi=10.1016%2fj.jss.2025.112568&partnerID=40&md5=a9e0b66d6bf49815acecf2b15799c7eb|As software systems grow increasingly complex, traditional fuzz testing struggles with inefficiencies, limited coverage, and poor adaptability to large-scale codebases with intricate input formats. These challenges are exacerbated in directed fuzz testing, where a lack of explainability often hampers effective user intervention and fine-grained input control, limiting both manageability and precision. To address these limitations, this paper introduces GDFuzz, an innovative fuzz testing framework that enhances directed testing by integrating explainable deep learning and interactive controllability. At its core, GDFuzz leverages the Local Interpretable Model-Agnostic Explanations (LIME) technique to identify and protect critical input bytes that influence the execution path to target locations. This mechanism, termed Sample Masks, guides mutation strategies toward more effective and targeted exploration. Furthermore, GDFuzz provides a real-time visual intervention interface, enabling users to dynamically adjust strategies based on neural network outputs, bridging the gap between automated testing and human expertise. Additionally, GDFuzz integrates a Dual-Queue Cyclic Simulated Annealing (DQCSA) algorithm and adaptive incremental learning to adapt to our explanation mechanism. We validate GDFuzz through comparative experiments on five real-world applications against four state-of-the-art fuzzers: AFL, AFL++, SelectFuzz, FormatFuzzer and AFLGo. Results demonstrate that GDFuzz improves effective execution rates by an average of 185% across all benchmarks, highlighting the impact of its interpretability-driven enhancements. Notably, GDFuzz uncovered eight previously undisclosed vulnerabilities (0-days) in widely used open-source libraries, with four assigned CVE identifiers and four pending review. These achievements underline the value of explainable and controllable testing in advancing directed fuzzing methodologies. © 2025|Explainable deep learning; Fuzzing; Open source software; Vulnerability detection|Arts computing; Benchmarking; Deep learning; Human computer interaction; Integration testing; Learning algorithms; Open systems; Explainable deep learning; Fine grained; Fuzz Testing; Fuzzing; Input format; Large-scales; Open-source softwares; Software-systems; User intervention; Vulnerability detection; Open source software|Article|Final||Scopus|2-s2.0-105011146323
scopus|Nourry O.; Kashiwa Y.; Shang W.; Shu H.; Kamei Y.|Nourry, Olivier (57195999834); Kashiwa, Yutaro (56685200200); Shang, Weiyi (35093168200); Shu, Honglin (59300219400); Kamei, Yasutaka (24476112100)|57195999834; 56685200200; 35093168200; 59300219400; 24476112100|My Fuzzers Won't Build: An Empirical Study of Fuzzing Build Failures|2025|ACM Transactions on Software Engineering and Methodology|34|2|29||||1|10.1145/3688842|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218351629&doi=10.1145%2f3688842&partnerID=40&md5=cb36a84b31ca8e29dcd7b69ced47b245|Fuzzing is an automated software testing technique used to find software vulnerabilities that works by sending large amounts of inputs to a software system to trigger bad behaviors. In recent years, the open source software ecosystem has seen a significant increase in the adoption of fuzzing to avoid spreading vulnerabilities throughout the ecosystem. While fuzzing can uncover vulnerabilities, there is currently a lack of knowledge regarding the challenges of conducting fuzzing activities over time. Specifically, fuzzers are very complex tools to set up and build before they can be used. We set out to empirically find out how challenging is build maintenance in the context of fuzzing. We mine over 1.2 million build logs from Google's OSS-Fuzz service to investigate fuzzing build failures. We first conduct a quantitative analysis to quantify the prevalence of fuzzing build failures. We then manually investigate 677 failing fuzzing builds logs and establish a taxonomy of 25 root causes of build failures. We finally train a machine learning model to recognize common failure patterns in failing build logs. Our taxonomy can serve as a reference for practitioners conducting fuzzing build maintenance. Our modeling experiment shows the potential of using automation to simplify the process of fuzzing.  © 2025 Copyright held by the owner/author(s). Publication rights licensed to ACM.|Build Maintenance; Empirical Study; Fuzzing|Open source software; Program debugging; Program diagnostics; Software testing; Automated software testing; Build maintenance; Empirical studies; Fuzzing; Large amounts; Open-source softwares; Software ecosystems; Software testing techniques; Software vulnerabilities; Software-systems; Taxonomies|Article|Final|All Open Access; Bronze Open Access|Scopus|2-s2.0-85218351629
scopus|Rehan S.; Al-Bander B.; Al-Said Ahmad A.|Rehan, Shaheer (59731531400); Al-Bander, Baidaa (57194549815); Al-Said Ahmad, Amro (57204835491)|59731531400; 57194549815; 57204835491|Harnessing Large Language Models for Automated Software Testing: A Leap Towards Scalable Test Case Generation|2025|Electronics (Switzerland)|14|7|1463||||0|10.3390/electronics14071463|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002315925&doi=10.3390%2felectronics14071463&partnerID=40&md5=aab1c5c05027a3e02182a49aa0872b9f|Software testing is critical for ensuring software reliability, with test case generation often being resource-intensive and time-consuming. This study leverages the Llama-2 large language model (LLM) to automate unit test generation for Java focal methods, demonstrating the potential of AI-driven approaches to optimize software testing workflows. Our work leverages focal methods to prioritize critical components of the code to produce more context-sensitive and scalable test cases. The dataset, comprising 25,000 curated records, underwent tokenization and QLoRA quantization to facilitate training. The model was fine-tuned, achieving a training loss of 0.046. These results show the promise of AI-driven test case generation and underscore the feasibility of using fine-tuned LLMs for test case generation, highlighting opportunities for improvement through larger datasets, advanced hyperparameter optimization, and enhanced computational resources. We conducted a human-in-the-loop validation on a subset of unit tests generated by our fined-tuned LLM. This confirms that these tests effectively leverage focal methods, demonstrating the model’s capability to generate more contextually accurate unit tests. The work suggests the need to develop novel validation objective metrics specifically tailored for the automation of test cases generated by utilizing large language models. This work establishes a foundation for scalable and efficient software testing solutions driven by artificial intelligence. The data and code are publicly available on GitHub. © 2025 by the authors.|focal methods; Llama-2; LLM; QLoRA; software testing; test case generation; unit testing||Article|Final||Scopus|2-s2.0-105002315925
scopus|Zhang M.; Arcuri A.; Li Y.; Liu Y.; Xue K.; Wang Z.; Huo J.; Huang W.|Zhang, Man (56990520700); Arcuri, Andrea (23097099900); Li, Yonggang (57846861100); Liu, Yang (57874427300); Xue, Kaiming (57846418700); Wang, Zhao (59359419200); Huo, Jian (59359522300); Huang, Weiwei (59359028800)|56990520700; 23097099900; 57846861100; 57874427300; 57846418700; 59359419200; 59359522300; 59359028800|Fuzzing microservices: A series of user studies in industry on industrial systems with EvoMaster|2025|Science of Computer Programming|246||103322||||0|10.1016/j.scico.2025.103322|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105006736856&doi=10.1016%2fj.scico.2025.103322&partnerID=40&md5=63dfb34841e482e6951b6b7ff96c4e92|With several microservice architectures comprising thousands of web services in total, used to serve 630 million customers, companies like Meituan face several challenges in the verification and validation of their software. The use of automated techniques, especially advanced AI-based ones, could bring significant benefits here. EVOMASTER is an open-source test case generation tool for web services, that exploits the latest advances in the field of Search-Based Software Testing research. This paper reports on our experience of integrating the EVOMASTER tool in the testing processes at Meituan over almost 2 years (i.e., between October 2021 and July 2023). Two user studies were carried out in 2021 (with two industrial APIs) and in 2023 (with three industrial APIs) to evaluate two versions of EVOMASTER (i.e., v1.3.0 and v1.6.1), respectively, in tackling the test generation for industrial web services which are parts of a large e-commerce microservice system. The two user studies involve in total 321,131 lines of code from these five APIs and 27 industrial participants at Meituan. Questionnaires and interviews were carried out in both user studies with the engineers and managers at Meituan. The two user studies demonstrate clear advantages of EVOMASTER (in terms of code coverage and fault detection) and the urgent need to have such a fuzzer in industrial microservices testing. Given its clear advantages, EVOMASTER now has been integrated into the industrial testing pipelines at Meituan. To study how these results could generalize, a follow up user study was done in 2024 (with EVOMASTER v2.0.0) with five engineers in the five different companies. Our results show that, besides their clear usefulness, there are still many critical challenges that the research community needs to investigate to improve performance further. © 2025 The Author(s)|Automated test generation; Empirical industrial study; Fuzzing; Microservices; SBST|Verification; Automated techniques; Automated test generations; Empirical industrial study; Fuzzing; Industrial systems; Microservice; SBST; User study; Verification-and-validation; Webs services; Automatic test pattern generation|Article|Final||Scopus|2-s2.0-105006736856
scopus|Baqar M.; Khanda R.|Baqar, Mohammad (59314559300); Khanda, Rajat (36634122800)|59314559300; 36634122800|The Future of Software Testing: AI–Powered Test Case Generation and Validation|2025|Lecture Notes in Networks and Systems|1424 LNNS|||276|300|24|0|10.1007/978-3-031-92605-1_18|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105009404321&doi=10.1007%2f978-3-031-92605-1_18&partnerID=40&md5=4de688f42e8960069c979f40baa9ce84|Software testing is a crucial phase in the software development lifecycle (SDLC), ensuring that products meet necessary functional, performance, and quality benchmarks before release. Despite advancements in automation, traditional methods of generating and validating test cases still face significant challenges, including prolonged timelines, human error, incomplete test coverage, and high costs of manual intervention. These limitations often lead to delayed product launches and undetected defects that compromise software quality and user satisfaction. The integration of AI in software testing has emerged as a transformative approach, addressing long-standing challenges in test case generation and validation. This paper explores AI-driven methods that leverage machine learning, natural language processing, and other advanced techniques to automate and enhance test case creation, optimize test coverage, and adapt to evolving software landscapes. Real-world examples illustrate how AI improves efficiency, accuracy, and scalability in testing workflows. However, the study acknowledges limitations, such as potential biases in AI algorithms, the need for substantial training data, and integration challenges with existing workflows. Additionally, areas for future research, including refining AI models to handle domain-specific testing scenarios and integrating AI testing with edge computing, are proposed. By presenting a comprehensive analysis of current tools, frameworks, and case studies, the paper aims to advance the understanding of AI’s role in modern software testing and inspire further innovations. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.|AI in software development; AI in software testing; AI-driven testing tools; Anomaly detection in testing; Automated test case generation; Continuous integration and deployment (CI/CD); Machine learning in testing; Natural Language Processing (NLP) for testing; Predictive models in testing; Self-healing test cases; Software quality assurance; Test automation; Test case optimization; Test case validation; Test coverage optimization|Anomaly detection; Automation; Benchmarking; Computer software selection and evaluation; Human computer interaction; Integration; Integration testing; Learning algorithms; Learning systems; Life cycle; Machine learning; Natural language processing systems; Software design; Software quality; AI in software development; AI in software testing; AI-driven testing tool; Anomaly detection; Anomaly detection in testing; Automated test-case generations; Continuous integration and deployment (CI/CD); Continuous integrations; Coverage optimizations; Healing tests; Language processing; Machine learning in testing; Machine-learning; Natural language processing  for testing; Natural languages; Optimisations; Predictive model in testing; Predictive models; Self-healing; Self-healing test case; Software quality assurance; Software testings; Test Automation; Test case; Test case optimization; Test case validation; Test coverage optimization; Test-coverage; Testing tools; Quality assurance|Conference paper|Final||Scopus|2-s2.0-105009404321
scopus|Najmi A.; El-Dosuky M.|Najmi, Alaa (59931404000); El-Dosuky, Mohamed (55797083000)|59931404000; 55797083000|Intelligent Software Testing for Test Case Analysis Framework Using ChatGPT with Natural Language Processing and Deep Learning Integration|2025|Journal of Computer Science|21|5||1140|1155|15|0|10.3844/jcssp.2025.1140.1155|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007455741&doi=10.3844%2fjcssp.2025.1140.1155&partnerID=40&md5=e5bd46682efe7b7550898ef9a99f1281|Effective testing scenarios are necessary to guarantee the dependability and Caliber of software. Conventional techniques for creating these scenarios frequently involve a great deal of manual labor and might not fully cover all software requirements. In order to improve the automation and Caliber of software testing scenario development, this study investigates the combination of Natural Language Processing (NLP) and Deep Learning (DL) approaches with ChatGPT, an advanced language model by OpenAI. The suggested method automatically creates a variety of thorough test cases by utilizing ChatGPT's sophisticated natural language processing capabilities. To evaluate the model's capacity to comprehend intricate software requirements and generate pertinent situations, a comparison between conventional scenario-generation techniques and those improved by ChatGPT is carried out. The process is divided into four stages: Requirement parsing, in which natural language software requirements are analyzed and interpreted using NLP models; scenario generation, in which a transformer-based model is used to generate testing scenarios that are logical and appropriate for the environment. an automation pipeline that uses Hugging Face Transformers and Python to speed up the scenario generating process and evaluation metrics that evaluate the created scenarios according to requirement coverage and relevance coherence. The effectiveness of this method is illustrated through a case study on evaluating an Optical Character Recognition (OCR) system for private documents. The results show that integrating ChatGPT with NLP and DL greatly enhances the depth of testing scenarios, speeds up the generation process, and lowers manual labor. The potential of ChatGPT to automate and optimize software testing is demonstrated in this study, providing a more effective and flexible solution for a variety of testing scenarios. © 2025 Alaa Najmi and Mohamed El-Dosuky. This open-access article is distributed under a Creative Commons Attribution (CC-BY) 4.0 license.|Deep Learning; Intelligent Test Case ChatGPT; NLP; Software Testing||Article|Final||Scopus|2-s2.0-105007455741
scopus|Boukhlif M.; Kharmoum N.; Hanine M.; Lagmiri S.N.|Boukhlif, Mohamed (58247381400); Kharmoum, Nassim (57210745538); Hanine, Mohamed (57219370936); Lagmiri, Souad Najoua (56748167600)|58247381400; 57210745538; 57219370936; 56748167600|Using LLMs to Analyze Software Requirements for Software Testing: A Comparative Study|2025|Lecture Notes in Networks and Systems|1330 LNNS|||413|421|8|0|10.1007/978-3-031-86698-2_37|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002714647&doi=10.1007%2f978-3-031-86698-2_37&partnerID=40&md5=f020e36cc399815bc08510db2531f5a5|The precision and clarity of Software Requirements (SR) are crucial for effective software testing and successful project delivery. Traditional methods of SR analysis, while effective, often demand substantial manual effort and are susceptible to human error. Recent advancements in Natural Language Processing (NLP), particularly with the development of Large Language Models (LLMs), present new opportunities for automating and enhancing the analysis of SRS documents. This paper presents a comparative study on the application of LLMs in analyzing SR for the purpose of improving software testing processes. Our research investigates the capabilities of LLMs in identifying ambiguities, inconsistencies, and gaps in SR documents, which are critical factors influencing the efficacy of software testing. We compare the performance of LLMs against conventional SRS analysis techniques, focusing on key metrics such as precision, recall, and the ability to generate actionable insights. The results of our study indicate that LLMs significantly enhance the accuracy and efficiency of SR analysis. LLMs demonstrated a high precision rate in detecting ambiguous terms and phrases, often suggesting clarifications that align closely with expert recommendations. Moreover, LLMs effectively identified inconsistencies within and across requirement documents, uncovering potential conflicts and redundancies that might be overlooked by traditional methods. These capabilities are particularly beneficial for improving the quality of test cases derived from SR, thereby enhancing the overall software testing process. In addition to performance metrics, the study explores the practical implications of integrating LLM-based analysis into existing software testing workflows. Factors such as scalability, cost-effectiveness, and the learning curve for practitioners are examined. However, the study also acknowledges the challenges and limitations associated with LLM adoption, including issues related to the interpretability of LLM outputs and the necessity for extensive domain-specific training data. Potential solutions and directions for future research are discussed to address these challenges. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.|Large Language Models (LLMs); Software Requirements; Software Requirements Analysis; Software Testing|Application programs; Computer software selection and evaluation; Integration testing; Modeling languages; Natural language processing systems; Requirements engineering; Analysis softwares; Comparatives studies; Human errors; Language model; Large language model; Project delivery; Software requirements; Software requirements analysis; Software testings; Testing process; Software quality|Conference paper|Final||Scopus|2-s2.0-105002714647
scopus|Mcshane J.; Celik L.; Aideyan I.; Brooks R.; Pesé M.D.|Mcshane, John (59126106700); Celik, Levent (59125256200); Aideyan, Iwinosa (59126106800); Brooks, Richard (24608979900); Pesé, Mert D. (57194029260)|59126106700; 59125256200; 59126106800; 24608979900; 57194029260|LLM-Powered Fuzz Testing of Automotive Diagnostic Protocols|2025|SAE Technical Papers|||||||0|10.4271/2025-01-8091|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105008181831&doi=10.4271%2f2025-01-8091&partnerID=40&md5=1b18ca2a882ee8bf5d4b1eb81af4d96f|"Modern vehicles contain tens of different Electronic Control Units (ECUs) from several vendors. These small computers are connected through several networking busses and protocols, potentially through gateways and converters. In addition, vehicle-to-vehicle and internet connectivity are now considered requirements, adding additional complexity to an already complex electronic system. Due to this complexity and the safety-critical nature of vehicles, automotive cyber-security is a difficult undertaking. One critical aspect of cyber-security is the robust software testing for potential bugs and vulnerabilities. Fuzz testing is an automated software testing method injecting large input sets into a system. It is an invaluable technique across many industries and has become increasingly popular since its conception. Its success relies highly on the ""quality""of inputs injected. One shortcoming associated with fuzz testing is the expertise required in developing ""smart""fuzz testing tools (fuzzers). Developing a fuzzer requires expertise on various topics, from input types and underlying networks to potential system configurations. Moreover, fuzzers are generally not transferable between different systems, limiting their reuse. This study investigates whether Generative AI technologies can meaningfully assist in their development by comparing an AI-generated fuzzer against a commercial one. An automotive fuzzer focusing on Unified Diagnostic Services (UDS) was developed by exclusively querying an AI model. First, the pre-trained AI is taught the underlying structure and constraints of UDS and is then used to generate semantically valid test cases. The effectiveness of test cases for vulnerability and fault detection is evaluated. The impact of specific queries and the underlying protocol network configurations on the generated test cases is then investigated through comparison with a commercial fuzzer. © 2025 SAE International. All Rights Reserved."||Automobile electronic equipment; Complex networks; Control systems; Internet protocols; Network security; Query processing; Safety engineering; Software testing; Automotives; Complex electronic systems; Cyber security; Diagnostic protocols; Diagnostic services; Electronics control unit; Fuzz Testing; Internet connectivity; Test case; Vehicle to vehicles; Fault detection|Conference paper|Final||Scopus|2-s2.0-105008181831
scopus|Zaki M.H.; Mazen S.A.; Helal I.M.A.|Zaki, Marwa Hussein (57194770645); Mazen, Sherif A. (24760794300); Helal, Iman M. A. (36099094600)|57194770645; 24760794300; 36099094600|Robotic Process Automation in Software Testing: Challenges and Open Research Directions|2025|Lecture Notes in Networks and Systems|1283 LNNS|||197|207|10|0|10.1007/978-3-031-84457-7_12|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000696482&doi=10.1007%2f978-3-031-84457-7_12&partnerID=40&md5=2d3ba7f6f0d6f05d0e8fcb36f549fd82|Robotic Process Automation (RPA) is an automation technology for business processes that has gained more interest over the years. It is a software solution that automates repetitive and structured business processes. Its usage can improve task productivity and deduct costs measurably. It is considered a powerful technology, but its applications are directed toward rule-based tasks and miss the cognitive capabilities of the decision-making process. One of the recent research directions is emerging intelligent automation (IA), which integrates artificial intelligence solutions and machine learning techniques with robotic process automation. This can automate decision-making processes, increase traditional robotic process automation capabilities, enhance the robots’ performance, and add value to the automation process. On the other hand, software testing is a very important stage in the software lifecycle development process. It focuses on checking the software quality and ensuring its smooth running without major errors. In this paper, we identify the relationship between RPA and software testing. Also, we discuss how RPA can contribute to the software testing process.  © The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.|Automation testing; Intelligent automation; RPA; Software testing|Adversarial machine learning; Application programs; Computer software selection and evaluation; Intelligent robots; Robot learning; Software testing; Automation technology; Automation testing; Business Process; Decision-making process; Intelligent automation; ITS applications; Process automation; Robotic process automation; Software solution; Software testings; Decision making|Conference paper|Final||Scopus|2-s2.0-105000696482
scopus|Elasri C.; Kharmoum N.; Saoiabi F.; Lagmiri S.N.; Ziti S.|Elasri, Chaimae (59124893400); Kharmoum, Nassim (57210745538); Saoiabi, Fadwa (59124037800); Lagmiri, Souad Najoua (56748167600); Ziti, Soumia (55999104600)|59124893400; 57210745538; 59124037800; 56748167600; 55999104600|Analyzing Generative AI’s Impact on Graph Theory and Software Testing: A Comparative Study|2025|Lecture Notes in Networks and Systems|1330 LNNS|||305|314|9|0|10.1007/978-3-031-86698-2_27|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002729334&doi=10.1007%2f978-3-031-86698-2_27&partnerID=40&md5=486481d19c93359d92a2bd850b93e4f8|Generative AI has been considered to fit Science and Technology especially in Graph Theory and Software Testing and as such the subject has attracted some attention. Based on the literature, this paper reviews previous works concerning the effect of Generative AI in these fields owing to the call to build more knowledge, address challenges, and improve practices. Graph theory which is a branch of discrete mathematics is vital in computer science and operation research. For this field, generative AI would help in the discovery of graphs, algorithms as well as solutions. With this proposal, this study examines how the existing GANs and VAEs are applied to graph generation, node prediction, and anomaly detection before pointing out the existing research gaps and future research avenues. Likewise, Software Testing essential in system development is evolving with Generative AI. The conventional ways are thus more cumbersome and very often inaccurate. In terms of testing, generative AI can come up with test cases, predict failures, and generate smart data therefore changing the test techniques. This paper discusses and analyze models of AI used for test automation and identification of defects for test automation. Consequently, comparing the literature, the paper elucidates that Generative AI transforms Graph Theory and Software Testing while promoting interdisciplinary cooperation. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.|Anomaly Detection; Comparative Study; GANs (Generative Adversarial Networks); Generative AI; Graph Theory; Software Testing; Test Automation; VAEs (Variational Autoencoders)|Adversarial machine learning; Graph theory; Program debugging; Software testing; Adversarial networks; Anomaly detection; Auto encoders; Comparatives studies; Generative adversarial network; Generative AI; Software testings; Test Automation; Theory testing; Variational autoencoder; Generative adversarial networks|Conference paper|Final||Scopus|2-s2.0-105002729334
scopus|Liu H.; Li Z.; Han B.; Chen X.; Paul D.; Liu Y.|Liu, Hengyuan (57331229600); Li, Zheng (57015803000); Han, Baolong (58814826300); Chen, Xiang (57189091783); Paul, Doyle (57196759117); Liu, Yong (57191420792)|57331229600; 57015803000; 58814826300; 57189091783; 57196759117; 57191420792|Integrating neural mutation into mutation-based fault localization: A hybrid approach|2025|Journal of Systems and Software|221||112281||||0|10.1016/j.jss.2024.112281|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210042295&doi=10.1016%2fj.jss.2024.112281&partnerID=40&md5=e8b75ec39e05a4c8bfe3242c495ece63|Fault localization is an important part of software testing and debugging, helping improve the process of fixing faults. Mutation-Based Fault Localization (MBFL) is widely used, but the reliance of Traditional-MBFL on syntactical mutants often limits its accuracy. To address this, we propose Neural-MBFL, which introduces neural mutation to generate semantically richer mutants using deep learning to better mimic real faults. Additionally, we present NeuraIntegra-MBFL, which combines neural and traditional mutation strategies through mutant combination and suspiciousness aggregation. Experiments on 835 faulty programs from the Defects4J benchmark show that Neural-MBFL improves fault localization compared to Traditional-MBFL, with a 35.50% relative improvement in MAP and 127 more faults localized at TOP-5, while maintaining acceptable computational cost. Compared to Neural-MBFL, NeuraIntegra-MBFL further enhances performance, particularly with suspiciousness aggregation, achieving an additional 11.96% MAP improvement and localizes 45 more faults at TOP-5, demonstrating the effectiveness of integrating suspiciousness scores. Using overlap and correlation analyses, we confirmed the complementarity between Neural-MBFL and Traditional-MBFL. Neural-MBFL is more effective at localizing faults that require understanding deep code semantics, while Traditional-MBFL performs better at handling rule-based modifications. NeuraIntegra-MBFL successfully integrates the strengths of both methods, offering better performance than either approach alone. © 2024 Elsevier Inc.|Fault localization; Mutation-based fault localization; Neural mutation; Neural mutation integration strategy|Fault localization; Hybrid approach; Integration strategy; Mutation strategy; Mutation-based fault localization; Neural mutation; Neural mutation integration strategy; Performance; Software Testing and Debugging|Article|Final||Scopus|2-s2.0-85210042295
scopus|Hajar Z.; Kharmoum N.; Ziti S.|Hajar, Zraiate (60018697100); Kharmoum, Nassim (57210745538); Ziti, Soumia (55999104600)|60018697100; 57210745538; 55999104600|Comparative Study of Software Testing: Traditional Approaches vs. Artificial Intelligence Techniques|2025|Lecture Notes in Networks and Systems|1402 LNNS|||872|881|9|0|10.1007/978-3-031-91334-1_79|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105011976103&doi=10.1007%2f978-3-031-91334-1_79&partnerID=40&md5=a4f187f12d614d70f2a2a25d5b7cfe5c|Artificial intelligence is growing fast in many domains, like software testing. This raises questions about how it could improve or even replace traditional methods. This study looks at both traditional and AI-based software testing, showing their advantages and problems. Traditional software testing uses manual processes and automated scripts. It takes a lot of time and human effort to design tests, run them, and analyze the results. These methods are familiar and dependable, but they are not very flexible and require a lot of time and resources. On the other hand, AI-based methods, like machine learning, can create and execute tests on their own. These techniques can find small problems and patterns that traditional methods might miss. They also save time and reduce costs because they can do a lot of the work automatically. Moreover, AI tools can check the results more quickly and find useful information by working with a lot of data and finding patterns. But using AI for software testing also has some problems. For example, AI needs a diverse data to learn correctly. Also, the results it gives can sometimes be hard to understand because it’s not always clear how it works. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.|AI; AI-Based Methods; Artificial Intelligence; Automated Scripts; Machine learning; Manual Processes; Software testing; Traditional Methods|Information use; Learning systems; Machine learning; AI-based method; Artificial intelligence techniques; Automated scripts; Comparatives studies; Machine-learning; Manual process; Software testings; Traditional approaches; Traditional approachs; Traditional method; Software testing|Conference paper|Final||Scopus|2-s2.0-105011976103
scopus|Yadav K.; Sircar A.; Bist N.|Yadav, Kriti (57210190147); Sircar, Anirbid (7004457839); Bist, Namrata (57218219319)|57210190147; 7004457839; 57218219319|A comprehensive review on role of information technology in city gas distribution industry|2025|Unconventional Resources|7||100202||||0|10.1016/j.uncres.2025.100202|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007803666&doi=10.1016%2fj.uncres.2025.100202&partnerID=40&md5=ea88d616f9aed9fb8d93439f9346ccf0|India is quickly transitioning towards a gas-based society by expanding the proportion of natural gas in the nation's energy blend from 6 % to 15 % by 2030. India is investing around INR 1.2 trillion in the natural gas distribution of the city gas sector. The most recent developments in distribution include intelligent (acoustic and mechanical) methods for identification of leaks in pipelines, robotic examination, automated testing with ultrasound, thermal mass circulation detectors, geographical information systems, and intelligent carriers and cascade units. The role of the Internet of Things comes into the picture to bind all these digitalisation techniques into a smart technique. This infrastructure eliminates the need for human involvement by integrating different tools and technologies. It allows for the development of smarter cities across the world. This work reveals the possible uses of several internet techniques in the city gas distribution industry. The study introduces readers to the smart technologies used for Smart Gas Distribution, such as Geographical Information Systems, Supervisory Control and Data Acquisition Systems, Applications and Products in Data Processing, etc. The work also highlights the key challenges in the adaptation of these technologies in the gas distribution sector. The paper offers a thorough overview of the topic and motivates academicians and investors to employ a variety of internet solutions. The application of big data, artificial intelligence, and machine learning can contribute to several levels of city gas distribution. The potential risk factors and upkeep expenses might be eliminated with the presence of this intelligent network, with the help of artificial intelligence and machine learning. The distinctiveness that this study presents its ability to bring light on many technologies used in places such as North America, China, South Korea, and Europe, such as DecisionSpace365 and Birdz, and Silent Soft SA's for the gas industry. © 2025 The Authors|City gas distribution; Internet of things; Machine learning; Neural network; Smart gas distribution|China; Europe; India; North America; South Korea; artificial intelligence; artificial neural network; information technology; Internet; machine learning; natural gas; spatiotemporal analysis; urban area|Review|Final||Scopus|2-s2.0-105007803666
scopus|Treshcheva E.; Itkin I.; Yavorskiy R.; Dorofeev N.|Treshcheva, Elena (57209506427); Itkin, Iosif (56940477500); Yavorskiy, Rostislav (55974150100); Dorofeev, Nikolai (58807106900)|57209506427; 56940477500; 55974150100; 58807106900|Test2Text: AI-Based Mapping between Autogenerated Tests and Atomic Requirements|2025|2025 IEEE International Conference on Software Testing, Verification and Validation Workshops, ICSTW 2025||||17|20|3|0|10.1109/ICSTW64639.2025.10962519|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105004740527&doi=10.1109%2fICSTW64639.2025.10962519&partnerID=40&md5=3a6c3ff6de752288bb74d732f022eb17|Artificial intelligence is transforming software testing by scaling up test data generation and analysis, creating new possibilities, but also introducing new challenges. One of the common problems with large-scale test data is the lack of traceability between test scenarios and system requirements. The paper addresses this challenge by proposing a traceability solution tailored to an industrial setting employing a data-driven approach. Building on an existing model-based testing framework, the design extends its annotation capabilities through a multilayer taxonomy. The suggested architecture leverages AI techniques for bidirectional mapping: linking requirements to test scripts for coverage analysis and tracing test scripts back to requirements to understand the tested functionality.  © 2025 IEEE.|natural language processing; requirements traceability; test coverage; test report|Mapping; Software testing; Language processing; Natural language processing; Natural languages; Requirements traceability; Scaling-up; Software testings; Test data generation; Test reports; Test scripts; Test-coverage; Natural language processing systems|Conference paper|Final||Scopus|2-s2.0-105004740527
scopus|Arasteh B.; Arasteh K.; Ghaffari A.|Arasteh, Bahman (39861139000); Arasteh, Keyvan (57220034945); Ghaffari, Ali (57197223215)|39861139000; 57220034945; 57197223215|An automatic software test-generation method to discover the faults using fusion of machine learning and horse herd algorithm|2025|Journal of Supercomputing|81|5|741||||0|10.1007/s11227-025-07219-5|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002970731&doi=10.1007%2fs11227-025-07219-5&partnerID=40&md5=35bda87d470647d1a1135fc37f691432|One of the time-consuming and expensive phases in software development is software testing, which is used to improve the quality of software systems. Therefore, Software test automation is a helpful technique that can alleviate testing time. Several techniques based on evolutionary and heuristic algorithms have been put forth to produce maximum coverage test sets. The primary shortcomings of earlier methods are inconsistent outcomes, insufficient branch coverage, and low fault-detection rates. Increasing branch coverage rate, defect detection rate, success rate, and stability are the primary goals of this research. A time- and cost-effective method has been suggested in this research to produce test data automatically by utilizing machine learning and horse herd optimization algorithms. In the first stage of the proposed method, the suggested machine learning classification model identifies the non-error-propagating instructions of the input program using machine learning algorithms. In the second stage, a test generator was suggested to cover only the program's fault-propagating instructions. The main characteristics of produced test data are avoiding the coverage of non-error-propagating instructions, maximizing the coverage of error-propagating instructions, maximizing success rate, and the fault discovery capability. Several experiments have been performed using nine standard benchmark programs. In the first stage, the suggested instruction classifier provides 90% accuracy and 82% precision. In the second stage, according to the results, the produced test data by the suggested method cover 99.93% of the error-prone instructions. The average success percentage with this method was 98.93%. The suggested method identifies roughly 89.40% of the injected faults by mutation testing tools. © The Author(s) 2025.|Branch coverage; Fault-detection score; Horse herd optimization algorithms; Machine learning; Sensitive-instructions classification; Software testing|Computer software selection and evaluation; FORTH (programming language); Branch-coverage; Error propagating; Fault-detection score; Faults detection; Horse herd optimization algorithm; Machine-learning; Optimization algorithms; Sensitive-instruction classification; Software testings; Test data; Software testing|Article|Final||Scopus|2-s2.0-105002970731
scopus||||Future of Information and Communication Conference, FICC 2025|2025|Lecture Notes in Networks and Systems|1284 LNNS|||||2265|0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000957449&partnerID=40&md5=95ba6cc01069bd0f1c5ede797af3c5e3|The proceedings contain 138 papers. The special focus in this conference is on Future of Information and Communication. The topics include: Robots in Healthcare: Measuring Acceptance of Professional Caregivers Towards Finding Key Requirements for System Design; a Human-Centric Architecture for Natural Interaction with Organizational Systems; industrial Metaverse for Smart Manufacturing: Ecosystem Architecture and Applications; centralised Graph-Based Collision-Free Air Traffic Management Approach for Autonomous Aerial Vehicle Navigation; phytoNode Upgraded: Energy-Efficient Long-Term Environmental Monitoring Using Phytosensing; evaluating the Socio-Economic Impacts of Hyperloop Technology Through the Lens of Labour Market: A Focus on Intelligent Transportation, Case of Latvia; Human-In-The-Loop Reasoning for Traffic Sign Detection: Collaborative Approach YOLO with Video-LLaVA; Reasoning with Generative AI; “Model Cards for Model Reporting” in 2024: Reclassifying Category of Ethical Considerations in Terms of Trustworthiness and Risk Management; robotic Process Automation in Software Testing: Challenges and Open Research Directions; chatbot Personas as a Gateway to Enhanced Learning Experiences; is It Time to Start Taking the Concept of a Holodeck Seriously?; agent for Machine Learning: A Text-to-Model (T2M) Approach; The Theory of Cybernetics for Managing Human-AI Interactions: A Framework for AI Management; steering Toward Trustworthiness: A Speech-Act Theory Perspective on Building Trust in Language Models for Autonomous Vehicle Applications; fingerprint Synthesis from Diffusion Models and Generative Adversarial Networks; Easy Problems that LLMs Get Wrong; socratic Dialogue with Generative Artificial Intelligence: Where is the Future?; Vectoring Languages: A High-Dimensional Perspective of Language to Bridge the Gap Between Philosophy and AI Science; The Elephant in the Room: Why AI Safety Demands Diverse Teams; exploring Foundation Model Fusion Effectiveness and Explainability for Stylistic Analysis of Emotional Podcast Data; machine Learning Enabled Earthquake Classification with Real Time Monitoring and Alert System.|||Conference review|Final||Scopus|2-s2.0-105000957449
scopus|Kumar N.H.; Rodda S.|Kumar, Nammi Hemanth (59649753900); Rodda, Sireesha (23986052300)|59649753900; 23986052300|Comparative Review on Automated Test Failure Detection and Healing Tools|2025|SSRG International Journal of Electrical and Electronics Engineering|12|2||113|123|10|0|10.14445/23488379/IJEEE-V12I2P113|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218785534&doi=10.14445%2f23488379%2fIJEEE-V12I2P113&partnerID=40&md5=e01da9b4cef445b4ff33692a0f1dc379|The main aim of this paper was to evaluate automated test failure detection and healing tools in software test automation. Although Artificial Intelligence and Machine Learning involve creating separate and individual algorithms for accessing data and making sense of it by identifying patterns to form conclusions, these predictions should be used to their full benefit for software testing. Automated test failure detection and healing tools are one approach that makes more of these predictions become a reality under software testing. This paper reviews the existing literature regarding healing tools specifically created for test failure detection and healing, particularly their performance in recognizing User Interface changes and healing the test scripts automatically. The review presents the key characteristics, features, functionalities, and technologies used in the tools, such as Artificial Intelligence, machine learning, visual testing, and integration with popular test automation frameworks. By juxtaposing the sources reviewed above, the review outlines the pros and cons and promising application areas of each and provides suggestions for appropriate uses in highly diverse testing conditions and contexts. Moreover, the review also starts with the gaps and the challenges that the current cutting-edge approaches have faced and gives a future outlook on what directions future research and development have in terms of automated test failure detection and healing. Somewhere It seems like there is no distinctive technique framework or tool available that could support the automated test failure detection and healing and can fulfill all the requirements. Finally, this paper ends with a discussion of the most popular tools available, along with the expressed thought process about the present and forthcoming artificial intelligence for test automation. © 2025 Seventh Sense Research Group.|Artificial Intelligence; Machine Learning; Self-healing tools; Test automation||Review|Final||Scopus|2-s2.0-85218785534
scopus|Flores J.G.F.; Solomon J.; Nasseraddin C.; Yerebakan T.; Matsko A.B.; Wong C.W.|Flores, Jaime Gonzalo Flor (57193083964); Solomon, Jim (57985255100); Nasseraddin, Connor (57984722200); Yerebakan, Talha (57194156435); Matsko, Andrey B (7005181399); Wong, Chee Wei (7404953947)|57193083964; 57985255100; 57984722200; 57194156435; 7005181399; 7404953947|AtOMICS: a deep learning-based automated optomechanical intelligent coupling system for testing and characterization of silicon photonics chiplets|2025|Machine Learning: Science and Technology|6|1|15018||||0|10.1088/2632-2153/adaa4d|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217056476&doi=10.1088%2f2632-2153%2fadaa4d&partnerID=40&md5=d0d48c9fa6a379315a0d5d29c726d435|Recent advances in silicon photonics promise to revolutionize modern technology by improving the performance of everyday devices in multiple fields (Thomson et al 2016 J. Opt. 18 073003). However, as the industry moves into a mass fabrication phase, the problem of adequate testing of integrated silicon photonics devices remains to be solved. A cost-efficient manner that reduces schedule risk needs to involve automated testing of multiple devices that share common characteristics such as input-output coupling mechanisms, but at the same time needs to be generalizable to various types of devices and scenarios. This paper presents a neural network-based automated system designed for in-plane fiber-chip-fiber testing, characterization, and active alignment of silicon photonic devices that use process-design-kit library edge couplers. The presented approach combines state-of-the-art computer vision techniques with time-series analysis, to control a testing setup that can process multiple devices and be quickly tuned to incorporate additional hardware. The system can operate at vacuum or atmospheric pressures and maintains stability for fairly long time periods in excess of a month. © 2025 The Author(s). Published by IOP Publishing Ltd.|active alignment; automatic coupling; cavity optomechanics; neural networks; optomechanical accelerometer; silicon photonics; testing|Accelerometers; Computer testing; Couplings; Integrated circuit design; Integrated circuit testing; Photonic devices; Photonic integrated circuits; Photonic integration technology; Thermal blooming; Vacuum applications; Active alignment; Automatic coupling; Cavity optomechanics; Coupling systems; Multiple devices; Neural-networks; Optomechanical; Optomechanical accelerometer; Silicon photonic devices; Silicon photonics; Silicon photonics|Article|Final|All Open Access; Gold Open Access|Scopus|2-s2.0-85217056476
scopus|Lanus E.; Lee B.; Chandrasekaran J.; Freeman L.J.; Raunak M.S.; Kacker R.N.; Richard Kuhn D.|Lanus, Erin (57194342964); Lee, Brian (59361247500); Chandrasekaran, Jaganmohan (56704897000); Freeman, Laura J. (36494460500); Raunak, M.S. (6507667067); Kacker, Raghu N. (6603751138); Richard Kuhn, D. (55666229700)|57194342964; 59361247500; 56704897000; 36494460500; 6507667067; 6603751138; 55666229700|Data Frequency Coverage Impact on AI Performance|2025|2025 IEEE International Conference on Software Testing, Verification and Validation Workshops, ICSTW 2025||||258|267|9|0|10.1109/ICSTW64639.2025.10962464|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105004724395&doi=10.1109%2fICSTW64639.2025.10962464&partnerID=40&md5=693d05f19d84c14d0dc762b82e35b41c|Artificial Intelligence (AI) models use statistical learning over data to solve complex problems for which straightforward rules or algorithms may be difficult or impossible to design; however, a side effect is that models that are complex enough to sufficiently represent the function may be uninterpretable. Combinatorial testing, a black-box approach arising from software testing, has been applied to test AI models. A key differentiator between traditional software and AI is that many traditional software faults are deterministic, requiring a failureinducing combination of inputs to appear only once in the test set for it to be discovered. On the other hand, AI models learn statistically by reinforcing weights through repeated appearances in the training dataset, and the frequency of input combinations plays a significant role in influencing the model's behavior. Thus, a single occurrence of a combination of feature values may not be sufficient to influence the model's behavior. Consequently, measures like simple combinatorial coverage that are applicable to software testing do not capture the frequency with which interactions are covered in the AI model's input space. This work develops methods to characterize the data frequency coverage of feature interactions in training datasets and analyze the impact of imbalance, or skew, in the combinatorial frequency coverage of the training data on model performance. We demonstrate our methods with experiments on an open-source dataset using several classical machine learning algorithms. This pilot study makes three observations: performance may increase or decrease with data skew, feature importance methods do not predict skew impact, and adding more data may not mitigate skew effects.  © 2025 IEEE.|Combinatorial Coverage; Combinatorial Frequency; Testing AI|Computer software selection and evaluation; Model checking; Open source software; Combinatorial coverage; Combinatorial frequency; Intelligence models; Model use; Modeling behaviour; Performance; Software testings; Statistical learning; Testing artificial intelligence; Training dataset; Software testing|Conference paper|Final||Scopus|2-s2.0-105004724395
scopus|Sabané A.; Plein L.; Bissyandé T.F.|Sabané, Aminata (59759840500); Plein, Laura (57219508910); Bissyandé, Tegawendé F. (36080354200)|59759840500; 57219508910; 36080354200|Leveraging Conversational AI for Accelerating User-Driven Software Testing|2025|Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering, LNICST|588 LNICST|||81|88|7|0|10.1007/978-3-031-81573-7_6|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85219193014&doi=10.1007%2f978-3-031-81573-7_6&partnerID=40&md5=75c955bfb572a40817a910c014c91881|This work addresses a research challenge in automating the translation of natural language inputs into programming language specifications. We consider the case of bug reports, which are informally written by users, and that must be specifying into executable test cases for reproducing the bug on the target software. Software bugs are indeed largely reported in natural language by users. Yet, we lack reliable tools to automatically address reported bugs (i.e., enabling their analysis, reproduction, and bug fixing). We therefore build on the recent promises brought by ChatGPT for various tasks, including in software engineering, and establish the following research question: What if Conversational Artificial Intelligence (AI) models could be used to explore the semantics of bug reports as well as to automate their reproduction? We evaluate the capabilities of ChatGPT, a state-of-the-art conversational AI, i.e., chatbot, using the popular Defects4J benchmark with its associated bug reports. The results reveal that ChatGPT can generate executable test cases that could trigger 50% of the bugs reported in natural language. These results are promising not only for the research community, but also for practitioners. © ICST Institute for Computer Sciences, Social Informatics and Telecommunications Engineering 2025.|Bug reports; ChatGPT; Debugging; Test cases; Translation|Computer aided language translation; Computer debugging; Program debugging; Program translators; Software testing; Specification languages; Bug reports; ChatGPT; Debugging; Executables; Natural languages; Research challenges; Software testings; Test case; Translation; User driven; Semantics|Conference paper|Final||Scopus|2-s2.0-85219193014
scopus|Brandt C.; Ramirez A.|Brandt, Carolin (57219536571); Ramirez, Aurora (56179745300)|57219536571; 56179745300|Towards Refined Code Coverage: A New Predictive Problem in Software Testing|2025|2025 IEEE Conference on Software Testing, Verification and Validation, ICST 2025||||613|617|4|0|10.1109/ICST62969.2025.10989028|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007550430&doi=10.1109%2fICST62969.2025.10989028&partnerID=40&md5=f77757c4a0712af6d988ffa49280a905|To measure and improve the strength of test suites, software projects and their developers commonly use code coverage and aim for a threshold of around 80%. But what is the 80 % of the source code that should be covered? To prepare for the development of new, more refined code coverage criteria, we introduce a novel predictive problem in software testing: whether a code line is, or should be, covered by the test suite. In this short paper, we propose the collection of coverage information, source code metrics, and abstract syntax tree data and explore whether they are relevant to predict whether a code line is exercised by the test suite or not. We present a preliminary experiment using four machine learning (ML) algorithms and an open source Java project. We observe that ML classifiers can achieve high accuracy (up to 90%) on this novel predictive problem. We also apply an explainable method to better understand the characteristics of code lines that make them more 'appealing' to be covered. Our work opens a research line worth to investigate further, where the focus of the prediction is the code to be tested. Our innovative approach contrasts with most predictive problems in software testing, which aim to predict the test case failure probability. © 2025 IEEE.|Code Coverage; Explainable Artificial Intelligence; Machine Learning; Software Testing; Test Adequacy|Computer aided software engineering; Open source software; Software packages; Verification; Code coverage; Code line; Coverage criteria; Explainable artificial intelligence; Information sources; Machine-learning; Software project; Software testings; Source codes; Test adequacies; Testbeds|Conference paper|Final||Scopus|2-s2.0-105007550430
scopus|Shiri Harzevili N.; Mohajer M.M.; Wei M.; Pham H.V.; Wang S.|Shiri Harzevili, Nima (57221044093); Mohajer, Mohammad Mahdi (58510034600); Wei, Moshi (57225202710); Pham, Hung Viet (57188848389); Wang, Song (56995463200)|57221044093; 58510034600; 57225202710; 57188848389; 56995463200|History-Driven Fuzzing for Deep Learning Libraries|2025|ACM Transactions on Software Engineering and Methodology|34|1|19||||0|10.1145/3688838|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218133176&doi=10.1145%2f3688838&partnerID=40&md5=8211605921ef202d0c03f71caf0e898f|Recently, many Deep Learning (DL) fuzzers have been proposed for API-level testing of DL libraries. However, they either perform unguided input generation (e.g., not considering the relationship between API arguments when generating inputs) or only support a limited set of corner-case test inputs. Furthermore, many developer APIs crucial for library development remain untested, as they are typically not well documented and lack clear usage guidelines, unlike end-user APIs. This makes them a more challenging target for automated testing. To fill this gap, we propose a novel fuzzer named Orion, which combines guided test input generation and corner-case test input generation based on a set of fuzzing heuristic rules constructed from historical data known to trigger critical issues in the underlying implementation of DL APIs. To extract the fuzzing heuristic rules, we first conduct an empirical study on the root cause analysis of 376 vulnerabilities in two of the most popular DL libraries, PyTorch and TensorFlow. We then construct the fuzzing heuristic rules based on the root causes of the extracted historical vulnerabilities. Using these fuzzing heuristic rules, Orion generates corner-case test inputs for API-level fuzzing. In addition, we extend the seed collection of existing studies to include test inputs for developer APIs. Our evaluation shows that Orion reports 135 vulnerabilities in the latest releases of TensorFlow and PyTorch, 76 of which were confirmed by the library developers. Among the 76 confirmed vulnerabilities, 69 were previously unknown, and 7 have already been fixed. The rest are awaiting further confirmation. For end-user APIs, Orion detected 45.58% and 90% more vulnerabilities in TensorFlow and PyTorch, respectively, compared to the state-of-the-art conventional fuzzer, DeepRel. When compared to the state-of-the-art LLM-based DL fuzzer, AtlasFuz, and Orion detected 13.63% more vulnerabilities in TensorFlow and 18.42% more vulnerabilities in PyTorch. Regarding developer APIs, Orion stands out by detecting 117% more vulnerabilities in TensorFlow and 100% more vulnerabilities in PyTorch compared to the most relevant fuzzer designed for developer APIs, such as FreeFuzz.  © 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.|deep learning; Fuzz testing; test generation|Automated testing; Corner case; Deep learning; End-users; Fuzz Testing; Heuristic rules; Historical data; State of the art; Test generations; Test inputs; Deep learning|Article|Final|All Open Access; Bronze Open Access|Scopus|2-s2.0-85218133176
scopus|Arab I.; Magel K.; Akour M.|Arab, Issar (57202832385); Magel, Kenneth (7801503070); Akour, Mohammed (57750775000)|57202832385; 7801503070; 57750775000|Evaluating the Predictive Power of Software Metrics for Fault Localization|2025|Computers|14|6|222||||0|10.3390/computers14060222|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105008887081&doi=10.3390%2fcomputers14060222&partnerID=40&md5=2fbd6cf608406823c99b900b82a65728|Fault localization remains a critical challenge in software engineering, directly impacting debugging efficiency and software quality. This study investigates the predictive power of various software metrics for fault localization by framing the task as a multi-class classification problem and evaluating it using the Defects4J dataset. We fitted thousands of models and benchmarked different algorithms—including deep learning, Random Forest, XGBoost, and LightGBM—to choose the best-performing model. To enhance model transparency, we applied explainable AI techniques to analyze feature importance. The results revealed that test suite metrics consistently outperform static and dynamic metrics, making them the most effective predictors for identifying faulty classes. These findings underscore the critical role of test quality and coverage in automated fault localization. By combining machine learning with transparent feature analysis, this work delivers practical insights to support more efficient debugging workflows. It lays the groundwork for an iterative process that integrates metric-based predictive models with large language models (LLMs), enabling future systems to automatically generate targeted test cases for the most fault-prone components, which further enhances the automation and precision of software testing. © 2025 by the authors.|automated debugging; fault localization; machine learning; software metrics; software quality assurance; test coverage|Automatic test pattern generation; Automation; Computer debugging; Computer software selection and evaluation; Deep learning; Iterative methods; Learning algorithms; Learning systems; Program debugging; Software quality; Software testing; Automated debugging; Critical challenges; Fault localization; Machine-learning; Multiclass classification problems; Predictive power; Software metrics; Software Quality; Software quality assurance; Test-coverage; Quality assurance|Article|Final||Scopus|2-s2.0-105008887081
scopus|Gao S.; Liao W.; Shu T.; Zhao Z.; Wang Y.|Gao, Shuanliang (58493030200); Liao, Wei (59368976200); Shu, Tao (57532461100); Zhao, Zhuoning (58772206300); Wang, Yaqiang (36769515100)|58493030200; 59368976200; 57532461100; 58772206300; 36769515100|Research on Hybrid Collaborative Development Model Based on Multi-Dimensional Behavioral Information|2025|Applied Sciences (Switzerland)|15|9|4907||||0|10.3390/app15094907|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105004796181&doi=10.3390%2fapp15094907&partnerID=40&md5=c66ade03198bba5c9aaae1e3416b63d4|This paper aims to propose a hybrid collaborative development model based on multi-dimensional behavioral information (HCDMB) to deal with systemic problems in modern software engineering, such as the low efficiency of cross-stage collaboration, the fragmentation of the intelligent tool chain, and the imperfect human–machine collaboration mechanism. This paper focuses on the stages of requirements analysis, software development, software testing and software operation and maintenance in the process of software development. By integrating the multi-dimensional characteristics of the development behavior track, collaboration interaction record and product application data in the process of project promotion, the mixture of experts (MoE) model is introduced to break through the rigid constraints of the traditional tool chain. Reinforcement learning combined with human feedback is used to optimize the MoE dynamic routing mechanism. At the same time, the few-shot context learning method is used to build different expert models, which further improve the reasoning efficiency and knowledge transfer ability of the system in different scenarios. The HCDMB model proposed in this paper can be viewed as an important breakthrough in the software engineering collaboration paradigm, so as to provide innovative solutions to the many problems faced by dynamic requirements and diverse scenarios based on artificial intelligence technology in the field of software engineering involving different project personnel. © 2025 by the authors.|large language models; mixture of experts; multi-dimensional behavioral information; software engineering|Application programs; Behavioral research; Computer operating systems; Computer software maintenance; Computer software selection and evaluation; Expert systems; Integration testing; Model checking; Personnel testing; Project management; Reinforcement learning; Search engines; Software packages; Software prototyping; Software quality; Transfer learning; Collaborative development; Development model; Human-machine collaboration; Intelligent tools; Language model; Large language model; Mixture of experts; Model-based OPC; Multi dimensional; Multi-dimensional behavioral information; Software design|Article|Final||Scopus|2-s2.0-105004796181
scopus|Tahvili S.; Hatvani L.; Felderer M.; de Oliveira Neto F.; Afzal W.; Feldt R.|Tahvili, Sahar (37093975500); Hatvani, Leo (36696277600); Felderer, Michael (24832720900); de Oliveira Neto, Francisco Gomes (35247739300); Afzal, Wasif (24832739300); Feldt, Robert (24476388300)|37093975500; 36696277600; 24832720900; 35247739300; 24832739300; 24476388300|Comparative analysis of text mining and clustering techniques for assessing functional dependency between manual test cases|2025|Software Quality Journal|33|2|24||||0|10.1007/s11219-025-09722-7|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105005412458&doi=10.1007%2fs11219-025-09722-7&partnerID=40&md5=6528cd9245c5bab3a245002cde3bfee8|Text mining techniques, particularly those leveraging machine learning for natural language processing, have gained significant attention for qualitative data analysis in software testing. However, their complexity and lack of transparency can pose challenges, especially in safety-critical domains where simpler, interpretable solutions are often preferred unless accuracy is heavily compromised. This study investigates the trade-offs between complexity, effort, accuracy, and utility in text mining and clustering techniques, focusing on their application for detecting functional dependencies among manual integration test cases in safety-critical systems. Using empirical data from an industrial testing project at ALSTOM Sweden, we evaluate various string distance methods, NCD compressors, and machine learning approaches. The results highlight the impact of preprocessing techniques, such as tokenization, and intrinsic factors, such as text length, on algorithm performance. Findings demonstrate how text mining and clustering can be optimized for safety-critical contexts, offering actionable insights for researchers and practitioners aiming to balance simplicity and effectiveness in their testing workflows. © The Author(s) 2025.|Artificial intelligence; Clustering; Natural language processing; Software testing; Text mining|Cluster analysis; Natural language processing systems; Verification; Clustering techniques; Clusterings; Functional dependency; Language processing; Natural language processing; Natural languages; Software testings; Text Clustering; Text mining techniques; Text-mining; Integration testing|Article|Final||Scopus|2-s2.0-105005412458
scopus|Barakat S.; Martin-Lopez A.; Müller C.; Segura S.; Ruiz-Cortés A.|Barakat, Saman (58160957000); Martin-Lopez, Alberto (57212275741); Müller, Carlos (55728096900); Segura, Sergio (25629936300); Ruiz-Cortés, Antonio (15120180100)|58160957000; 57212275741; 55728096900; 25629936300; 15120180100|The IDL tool suite: Specifying and analyzing inter-parameter dependencies in web APIs|2025|SoftwareX|29||101998||||1|10.1016/j.softx.2024.101998|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211194918&doi=10.1016%2fj.softx.2024.101998&partnerID=40&md5=ebcb0929f434aaf5398e33eeb591abb0|Web APIs may include inter-parameter dependencies that limit how input parameters can be combined to call services correctly. These dependencies are extremely common, appearing in 4 out of every 5 APIs. This paper presents the IDL tool suite, a set of software tools for managing inter-parameter dependencies in web APIs. The suite includes a specification language (IDL), an OpenAPI Specification extension (IDL4OAS), an analysis engine (IDLReasoner), a web API, a playground, an AI chatbot, and a website. We also highlight several contributions by different groups of authors where the IDL tool suite has proven useful in the domains of automated testing, code generation, and API gateways. To date, the IDL tool suite has contributed to the detection of more than 200 bugs in industrial APIs, including GitHub, Spotify, and YouTube, among others. Also, IDL has been used to boost automated code generation, generating up to 10 times more code than state-of-the-art generators for web APIs. © 2024 The Authors|IDL; OpenAPI specification; REST; Web API|Application programming interfaces (API); Automatic test pattern generation; EXAPT (programming language); Gateways (computer networks); Websites; Automated testing; Chatbots; IDL; Input parameter; OpenAPI specification; Parameter dependency; REST; Software-tools; Toolsuite; Web API; Specification languages|Article|Final||Scopus|2-s2.0-85211194918
scopus|Shi Y.; Yin B.; Shi J.-A.|Shi, Ying (58062890400); Yin, Beibei (16242881200); Shi, Jing-Ao (59419024500)|58062890400; 16242881200; 59419024500|Markov model based coverage testing of deep learning software systems|2025|Information and Software Technology|179||107628||||0|10.1016/j.infsof.2024.107628|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210129407&doi=10.1016%2fj.infsof.2024.107628&partnerID=40&md5=7925f765c9368df5efb5be5445fd3b85|Context: Deep Learning (DL) software systems have been widely deployed in safety and security-critical domains, which calls for systematic testing to guarantee their accuracy and reliability. Objective measurement of test quality is one of the key issues in software testing. Recently, many coverage criteria have been proposed to measure the testing adequacy of Deep Neural Networks (DNNs). Objective: Recent research demonstrates that existing criteria have some limitations on interpreting the increasingly diverse behaviors of DNNs or clarifying the relationship between the coverage and the decision logic of DNNs. Moreover, some evaluations argue against the correlation between coverage and defect detection. In this paper, a novel coverage approach is proposed to interpret the internal information of programs. Methods: The process of coverage testing is formalized and quantified by constructing Markov models based on critical neurons extracted using Layer-wise Relevance Propagation in the structure of DNNs. The difference in the transition matrix of Markov chains between training and testing data is measured by KL divergence, and it is developed as a coverage criterion. Results: The values of the proposed coverage increase as the number of classes increases. The values are different for various test suites, and they become higher with the addition of new samples. Higher coverage values are observed to correlate with an increased fault detection capability. Conclusion: The experimental results illustrate that the proposed approach can effectively measure actual diversity and exhibit more adaptability to additional test cases. Furthermore, there is a positive correlation between the proposed coverage and fault detection, which provides support for test case selection guided by coverage. © 2024 Elsevier B.V.|Coverage criteria; Deep learning software systems; Deep learning testing; Information theory; Markov chains|Software testing; Coverage criteria; Coverage testing; Deep learning software system; Deep learning testing; Faults detection; Learning software; Markov modeling; Model-based OPC; Neural-networks; Software-systems; Markov chains|Article|Final||Scopus|2-s2.0-85210129407
scopus|Touqir A.; Iradat F.; Iqbal W.; Rakib A.; Taskin N.; Jadidbonab H.; Haas O.|Touqir, Asma (59377666500); Iradat, Faisal (36662225400); Iqbal, Waseem (56102434000); Rakib, Abdur (25825507800); Taskin, Nazim (36522004100); Jadidbonab, Hesam (57197821944); Haas, Olivier (7103157877)|59377666500; 36662225400; 56102434000; 25825507800; 36522004100; 57197821944; 7103157877|Systematic exploration of fuzzing in IoT: techniques, vulnerabilities, and open challenges|2025|Journal of Supercomputing|81|8|877||||0|10.1007/s11227-025-07371-y|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105005805745&doi=10.1007%2fs11227-025-07371-y&partnerID=40&md5=043a780496e40ab98616e88f197b50de|As our dependence on the internet and digital platforms grows, the risk of cyber threats rises, making it essential to implement effective measures to safeguard sensitive information through cybersecurity, ensure system integrity, and prevent unauthorized data access. Fuzz testing, commonly known as fuzzing, is a valuable technique for software testing as it uncovers vulnerabilities and defects in systems by introducing random data inputs, often leading to system crashes. In the Internet of Things (IoT) domain, fuzzing is crucial for identifying vulnerabilities in networks, devices, and applications through automated tools that systematically inject malformed inputs into IoT systems. However, despite its importance, existing research on fuzzing techniques in IoT contexts remains limited by the absence of standardized benchmarks, inefficiencies in re-hosting strategies, and difficulties in detecting complex, condition-dependent vulnerabilities. The primary objective of this study is to comprehensively evaluate current fuzzing practices, emphasizing adaptive techniques designed for IoT systems. Using the PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) model, a systematic literature review was conducted across 32 academic articles published between 2020 and 2024. The analysis revealed that although fuzzing enhances IoT security, its effectiveness is hindered by device heterogeneity, limited system resources, and evolving cyber threat landscapes. The findings suggest that to overcome these limitations, future research should focus on AI-driven fuzzing methods, robust multi-architecture support, and the development of standardized evaluation frameworks to strengthen IoT cybersecurity. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2025.|Advanced adaptive fuzzing techniques; Effective cybersecurity measures; Unauthorized data access; Valuable software testing technique|Computer software selection and evaluation; Cyber attacks; Integration testing; Malware; Sensitive data; Testbeds; Advanced adaptive fuzzing technique; Cyber security; Cyber threats; Data access; Digital platforms; Effective cybersecurity measure; Software testing techniques; Systematic exploration; Unauthorized data access; Valuable software testing technique; Model checking|Article|Final||Scopus|2-s2.0-105005805745
scopus|Kofroň J.; Margaria T.; Seceleanu C.|Kofroň, Jan (14056327100); Margaria, Tiziana (36704777800); Seceleanu, Cristina (55884138900)|14056327100; 36704777800; 55884138900|Preface to the special issue on engineering of computer-based systems|2025|International Journal on Software Tools for Technology Transfer|27|1||1|3|2|0|10.1007/s10009-025-00807-z|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105005269510&doi=10.1007%2fs10009-025-00807-z&partnerID=40&md5=23885ae4e582996336205d8b8f5483e5|This special issue contains nine extended and rigorously peer-reviewed papers selected from those originally presented at ECBS 2023, the 8th International Conference on Engineering of Computer-Based Systems, held at Mälardalen University, Sweden, October 16-18, 2023, under the theme “Engineering for Responsible AI”. The included papers represent innovative contributions addressing critical aspects of responsible artificial intelligence and integrated engineering practices. These contributions span from formal verification and security analyses of IoT protocols and federated learning frameworks to machine learning-based simulations and predictions in hardware and software systems. The selection also includes work on automata learning techniques for protocol compliance, continuous integration approaches for neural network-based autonomous systems, assertion usage in software testing, language-driven engineering for code generation, and the integration of IoT backends in digital twin infrastructures. Together, these papers showcase recent advances, offering valuable insights into the rigorous integration of modern technologies within complex, computer-based systems. © The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature 2025.|Automata learning; Digital twins; Machine learning; Security of IoT; Testing|Computer hardware description languages; Computer software selection and evaluation; Formal verification; Model checking; Program processors; Search engines; UNIX; Automaton learning; Engineering of Computer Based Systems; Engineering practices; Hardware and software; Hardware system; Integrated engineering; Learning frameworks; Machine-learning; Security analysis; Security of IoT; Integration testing|Article|Final||Scopus|2-s2.0-105005269510
scopus|Cotroneo D.; De Rosa G.; Liguori P.|Cotroneo, Domenico (6603263234); De Rosa, Giuseppe (60009500300); Liguori, Pietro (57205390161)|6603263234; 60009500300; 57205390161|PyResBugs: A Dataset of Residual Python Bugs for Natural Language-Driven Fault Injection|2025|Proceedings - 2025 IEEE/ACM 2nd International Conference on AI Foundation Models and Software Engineering, FORGE 2025||||146|150|4|0|10.1109/Forge66646.2025.00024|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105011360853&doi=10.1109%2fForge66646.2025.00024&partnerID=40&md5=bfd428af9c1c3fbdd4d5f259dc98634f|This paper presents PyResBugs, a curated dataset of residual bugs, i.e., defects that persist undetected during traditional testing but later surface in production - collected from major Python frameworks. Each bug in the dataset is paired with its corresponding fault-free (fixed) version and annotated with multi-level natural language (NL) descriptions. These NL descriptions enable natural language-driven fault injection, offering a novel approach to simulating real-world faults in software systems. By bridging the gap between Software Fault Injection techniques and real-world representativeness, PyResBugs provides researchers with a high-quality resource for advancing AI-driven automated testing in Python systems.  © 2025 IEEE.|Dataset; Fault Injection; Natural Language; Python; Residual Bugs|Automation; High level languages; Python; Software testing; Statistical tests; Surface defects; Dataset; Fault injection; Fault Injection techniques; Language description; Multilevels; Natural languages; Real-world; Residual bug; Software fault; Software-systems; Natural language processing systems|Conference paper|Final||Scopus|2-s2.0-105011360853
scopus||||2025 IEEE International Conference on Consumer Electronics, ICCE 2025|2025|Digest of Technical Papers - IEEE International Conference on Consumer Electronics||||||2346|0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-105006479776&partnerID=40&md5=d7a46a9f05fa5e8b348d70b60a306ab8|The proceedings contain 427 papers. The topics discussed include: UMAP and tree physiology optimization for effective water quality management in consumer electronics; using transfer learning on deep learning networks to predict channel operating margin; an architecture for configuring html applications that run on consumer electronics products; a plugin-based testing tool in an adaptive automated testing infrastructure for consumer electronics devices; eye image and EOG signal conversion via autoencoders for human-machine interaction; efficient task scheduling using constrains programming; hardware-friendly quantization via outlier scaling in convolution-attention-based hybrid networks; jitter modeling for high-speed interconnects using segment-based statistical analysis for pam4 signaling scheme; feature alignment in vision mamba to resolve domain shift of mobile medical devices; cognitive radio sensor networks for visually impaired individuals for smart healthcare applications; energy-conscious image enhancement for dimmed displays: balancing visual quality and power efficiency for consumer devices; and enabling next-generation consumer experience with feature coding for machines.|||Conference review|Final||Scopus|2-s2.0-105006479776
scopus|Amalfitano D.; Faralli S.; Hauck J.C.R.; Matalonga S.; Distante D.|Amalfitano, Domenico (25926238800); Faralli, Stefano (57193656573); Hauck, Jean Carlo Rossa (14045055000); Matalonga, Santiago (55247434200); Distante, Damiano (14008871000)|25926238800; 57193656573; 14045055000; 55247434200; 14008871000|Artificial Intelligence Applied to Software Testing: A Tertiary Study|2024|ACM Computing Surveys|56|3|58||||22|10.1145/3616372|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176768820&doi=10.1145%2f3616372&partnerID=40&md5=c9dfb5d6c6d2d99c777d457e6d4d7c54|Context: Artificial intelligence (AI) methods and models have extensively been applied to support different phases of the software development lifecycle, including software testing (ST). Several secondary studies investigated the interplay between AI and ST but restricted the scope of the research to specific domains or sub-domains within either area.Objective: This research aims to explore the overall contribution of AI to ST, while identifying the most popular applications and potential paths for future research directions.Method: We executed a tertiary study following well-established guidelines for conducting systematic literature mappings in software engineering and for answering nine research questions.Results: We identified and analyzed 20 relevant secondary studies. The analysis was performed by drawing from well-recognized AI and ST taxonomies and mapping the selected studies according to them. The resulting mapping and discussions provide extensive and detailed information on the interplay between AI and ST.Conclusion: The application of AI to support ST is a well-consolidated and growing interest research topic. The mapping resulting from our study can be used by researchers to identify opportunities for future research, and by practitioners looking for evidence-based information on which AI-supported technology to possibly adopt in their testing processes. © 2023 Copyright held by the owner/author(s).|Artificial intelligence; Software testing; Systematic literature review; Systematic mapping study; Taxonomy; Tertiary study|Artificial intelligence; Life cycle; Mapping; Software design; Software testing; Artificial intelligence methods; Future research directions; Research questions; Research topics; Software development life-cycle; Software testings; Subdomain; Systematic literature review; Systematic mapping studies; Tertiary study; Taxonomies|Article|Final|All Open Access; Green Open Access; Hybrid Gold Open Access|Scopus|2-s2.0-85176768820
scopus|Silva L.A.D.L.; MacHado L.R.F.; Emmendorfer L.|Silva, Luis Alvaro De Lima (23096402400); MacHado, Lori R. F. (59151522400); Emmendorfer, Leonardo (15845452000)|23096402400; 59151522400; 15845452000|A Case and Cluster-Based Framework for Reuse and Prioritization in Software Testing|2024|ACM International Conference Proceeding Series|||41||||0|10.1145/3658271.3658312|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194888496&doi=10.1145%2f3658271.3658312&partnerID=40&md5=049ff94a72b618ba8cb953f3c5c09bfa|Context: Machine Learning (ML) based reuse and prioritization software testing techniques allow test analysts to generate and select test artifacts so that cases with a higher priority are selected and executed earlier than those with a lower priority. Problem: Even though test cases are broadly used in developing regression tests, the problem is that these software artifacts are still underused when structuring reusable software testing experiences. Solution: This work presents a Case-Based Reasoning and Clustering framework in which augmented test case representations maintain the data and knowledge from concrete instances of testing problem-solving. Then, similarity-based query answering is explored in selecting and prioritizing test cases for given testing problems. Query results' clustering is also developed, permitting the examination of the possible cluster structures in the formed test suites and the consequent use of the identified clusters in the run-time re-prioritization of the test case executions. IS theory: Within the General Systems Theory, we investigate ML techniques with recognized explanatory capabilities to resolve software testing problems. Methods: Experiments in a real-world software project were developed. The overall goal was to assess the case and cluster methods' effectiveness in retesting the implemented functionalities of a new target system version. Summary of results: Results with the presented techniques show improved fault detection rates positively contributing to performing regression tests in software projects. Contributions and impact in the IS area: The C2Test framework allows test analysts to better decide which items should be retested in each new version of a target system.  © 2024 ACM.|case-based reasoning; clustering.; Software testing; test case prioritization; test case reuse|Case based reasoning; Computer software reusability; Fault detection; Casebased reasonings (CBR); Clustering.; Clusterings; Prioritization; Regression tests; Reuse; Software testings; Test case; Test case prioritization; Test case reuse; Software testing|Conference paper|Final||Scopus|2-s2.0-85194888496
scopus|Lavingia K.; Purohit P.; Dutta V.; Lavingia A.|Lavingia, Kruti (57210109637); Purohit, Palak (59004737700); Dutta, Vikram (59004737800); Lavingia, Ami (58141849600)|57210109637; 59004737700; 59004737800; 58141849600|Advancements in automated testing tools for Android set-top boxes: a comprehensive evaluation and integration approach|2024|International Journal of System Assurance Engineering and Management|15|7||2808|2817|9|1|10.1007/s13198-024-02335-6|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191433913&doi=10.1007%2fs13198-024-02335-6&partnerID=40&md5=fbd77d90153785745efec460ffb98118|Android set-top boxes, often known as STBs, have emerged as a popular option for streaming and viewing digital content. Testing Android STBs, however, can be extremely difficult due to the complicated hardware and software configurations they require. In addition to being time-consuming and error-prone, manual testing can be exceedingly costly. Because of this, automation testing has emerged as a possible solution to the problems that have been identified. This article presents an overview of the current state of the art in automation testing for Android STBs from a technical perspective. This article highlights the difficulties typically connected with testing Android STBs, the advantages of automation testing, and the various tools and methods utilised for automation testing. Integrating AI and machine learning approaches are explored to demonstrate the potential for increasing efficiency and adaptability in Android STB automation testing. The findings contribute to the evolution of testing techniques for Android STBs by providing insights into tool selection, performance optimisation, and future approaches for intelligent automation. In addition, the article provides an overview of recent research conducted in this area and an analysis of the current and future directions that automation testing for Android STBs will take. © The Author(s) under exclusive licence to The Society for Reliability Engineering, Quality and Operations Management (SREQOM), India and The Division of Operation and Maintenance, Lulea University of Technology, Sweden 2024.|Android; Artificial intelligent; Automation; Behave framework; Behavior-driven development; Machine learning; Manual testing; Set-top box; Testing; Tools|Android (operating system); Integration testing; Machine learning; 'current; Android; Artificial intelligent; Automated testing tools; Automation testing; Behave framework; Behavior-driven development; Machine-learning; Manual testing; Set top box; Automation|Review|Final||Scopus|2-s2.0-85191433913
scopus|Olsen M.; Raunak M.S.; Richard Kuhn D.; Van Lierop H.; Badorf F.; Durso F.|Olsen, Megan (24923113900); Raunak, M.S. (6507667067); Richard Kuhn, D. (55666229700); Van Lierop, Hans (59832858100); Badorf, Fenrir (59832858200); Durso, Francis (57994442000)|24923113900; 6507667067; 55666229700; 59832858100; 59832858200; 57994442000|A Combinatorial Approach to Reduce Machine Learning Dataset Size|2025|2025 IEEE International Conference on Software Testing, Verification and Validation Workshops, ICSTW 2025||||248|257|9|0|10.1109/ICSTW64639.2025.10962533|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105004725507&doi=10.1109%2fICSTW64639.2025.10962533&partnerID=40&md5=21f34ea0407adfdbae263f49cb883898|Although large datasets may seem to be the best choice for machine learning, a smaller dataset that better represents the important parts of the problem will be faster to train and potentially more effective. Although dimensionality reduction focuses on reducing features (columns) of data, dataset reduction focuses on removing data points (rows). Typical approaches for reducing dataset size include random sampling, or using machine learning to understand the data. We propose using combinatorial coverage and frequency difference (CFD) techniques from software testing to choose the most effective rows of data to generate a smaller training dataset. We explore the effectiveness of four approaches to reduce a dataset using CFD, and a case study showing that we can produce a significantly smaller dataset that is more effective in training a Support Vector Machine than the original dataset or datasets generated by other approaches.  © 2025 IEEE.|combinatorial frequency differencing; instance selection; machine learning|Best choice; Combinatorial approach; Combinatorial frequency differencing; Data set size; Frequency differences; Instance selection; Large datasets; Learning dataset; Machine-learning; Small data set; Software testing|Conference paper|Final||Scopus|2-s2.0-105004725507
scopus|Roberts P.|Roberts, Paul (57205056019)|57205056019|Game AI Uncovered: Volume Three|2025|Game AI Uncovered: Volume Three||||1|232|231|0|10.1201/9781003411130|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213177591&doi=10.1201%2f9781003411130&partnerID=40&md5=71bd89e5fdc22c17a8e956ccacf11d72|Game Al Uncovered: Volume Three continues the series with another collection of chapters from 18 of the top game Al professionals and researchers, from around the world. Each chapter includes wisdom, ideas, tips, and tricks that were used in the development of video games. The techniques discussed in these pages cover the underlying development of a wide array of published titles, including Watch Dogs: Legion, City of Gangsters, Eve: Valkyrie, Firefall, The Persistence. Advance Soccer, Alpha Beto Gunner, and Luna Abyss. Contained within this volume are insights that cover a host of different areas within game Al, including vehicle Al, simulating social norms, Al spawning fundamentals, pathfinding, creation of characters using components, animation-driven behaviour, tactical positioning in football, automated testing, abstract pattern matching, and machine learning for games. Beginners in the area of game Al, along with professional developers, will find a wealth of knowledge that will not only help in the development of their own games but also spark ideas for new approaches. This volume includes chapters written by Dr Allan Bruce, Anubha Banerjee, Bruno Rebaque, Dale Green, David Wooldridge, Eric S. Le Saux, Greg Irwin, Jason Lok Heng Chin, Johan Holthausen, John Reynolds, Mathias Siemonsmeier, Michele Condò, Dr Nic Melder, Paul Roberts, Phil Carlisle, Richard Bull, Robert Zubek, and Tobias Karlsson. © 2025 Paul Roberts.||Animation; Artificial intelligence; Football; Human computer interaction; Interactive computer graphics; Learning systems; Machine components; Automated testing; Game AI; Machine-learning; Path finding; Pattern-matching; Roberts; Social norm; Spawnings; Tacticals; Video-games; Pattern matching|Book|Final||Scopus|2-s2.0-85213177591
scopus|Ruiz K.G.P.; Delbem A.C.B.; de Souza P.S.L.|Ruiz, Kevin Gerardo Polo (59995963900); Delbem, Alexandre Claudio Botazzo (8575424400); de Souza, Paulo Sergio Lopes (56053047500)|59995963900; 8575424400; 56053047500|Impact of Distances in an Anomaly Detection Context for Time Series in Software Testing|2025|Lecture Notes in Computer Science|15649 LNCS|||18|34|16|0|10.1007/978-3-031-96997-3_2|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105010611937&doi=10.1007%2f978-3-031-96997-3_2&partnerID=40&md5=87b36a682e5a30192e7de9a187da2c8e|Software Testing is a critical stage in Software Development projects, which increases their quality at the cost of an increasing budget. This cost grows as the System Under Test (SUT) has poor testability. Data streaming systems or web servers usually present poor testability because they have constant input rates that often hide faults during testing. For such systems, it is costly to build test cases and verify whether the output is correct for each particular input. Tricorder proposes a methodology for anomaly detection without system requirements, taking into account the unsupervised learning provided by Damicore’s methodology. This paper evaluates the behavior of distance measures for time series data within the frameworks of unsupervised machine learning carried out by Damicore, which is applied to software anomaly detection. The study systematically assesses the impact of each distance measure on the resulting accuracy within Damicore by conducting experiments across multiple benchmarks. Our findings reveal that the Levenshtein distance significantly outperforms DTW, NCD, FFT, and Hamming. Conversely, Hamming distance demonstrates the poorest performance. Levenshtein distance, on the other hand, offers an excellent balance between execution time and accuracy, providing an optimal trade-off for efficient and effective fault detection. The findings provide valuable insights into the effectiveness of these measures in enhancing fault detection accuracy, which could be extended to other domains involving anomaly detection of time-series data. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.|Agglomerative Clustering; Anomaly Detection; Fault Detection; Software Testing; Time Series|Anomaly detection; Budget control; Correlation detectors; Fault detection; Hamming distance; Learning systems; Software design; Unsupervised learning; Agglomerative clustering; Anomaly detection; Distance measure; Faults detection; Levenshtein distance; Software development projects; Software testings; Testability; Time-series data; Times series; Economic and social effects; Software testing; Time series|Conference paper|Final||Scopus|2-s2.0-105010611937
scopus|Guo A.; Gao X.; Chen Z.; Xiao Y.; Liu J.; Ge X.; Sun W.; Fang C.|Guo, An (57221804932); Gao, Xinyu (57218364257); Chen, Zhenyu (55579848600); Xiao, Yuan (57991857500); Liu, Jiakai (59325580100); Ge, Xiuting (57215320224); Sun, Weisong (57208225070); Fang, Chunrong (55321130800)|57221804932; 57218364257; 55579848600; 57991857500; 59325580100; 57215320224; 57208225070; 55321130800|CooTest: An Automated Testing Approach for V2X Communication Systems|2024|ISSTA 2024 - Proceedings of the 33rd ACM SIGSOFT International Symposium on Software Testing and Analysis||||1453|1465|12|0|10.1145/3650212.3680373|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205563037&doi=10.1145%2f3650212.3680373&partnerID=40&md5=2714b11e95e8bd37663066b34080df3a|Perceiving the complex driving environment precisely is crucial to the safe operation of autonomous vehicles. With the tremendous advancement of deep learning and communication technology, Vehicle-to-Everything (V2X) collaboration has the potential to address limitations in sensing distant objects and occlusion for a single-agent perception system. However, despite spectacular progress, several communication challenges can undermine the effectiveness of multi-vehicle cooperative perception. The low interpretability of Deep Neural Networks (DNNs) and the high complexity of communication mechanisms make conventional testing techniques inapplicable for the cooperative perception of autonomous driving systems (ADS). Besides, the existing testing techniques, depending on manual data collection and labeling, become time-consuming and prohibitively expensive. In this paper, we design and implement CooTest, the first automated testing tool of the V2X-oriented cooperative perception module. CooTest devises the V2X-specific metamorphic relation and equips communication and weather transformation operators that can reflect the impact of the various cooperative driving factors to produce transformed scenes. Furthermore, we adopt a V2X-oriented guidance strategy for the transformed scene generation process and improve testing efficiency. We experiment CooTest with multiple cooperative perception models with different fusion schemes to evaluate its performance on different tasks. The experiment results show that CooTest can effectively detect erroneous behaviors under various V2X-oriented driving conditions. Also, the results confirm that CooTest can improve detection average precision and decrease misleading cooperation errors by retraining with the generated scenes.  © 2024 Copyright is held by the owner/author(s). Publication rights licensed to ACM.|Autonomous driving system; Cooperative perception; Metamorphic testing; Software testing|Automobile testing; Autonomous agents; Magnetic levitation vehicles; Automated testing; Autonomous driving; Autonomous driving system; Communications systems; Cooperative perception; Driving environment; Driving systems; Metamorphic testing; Software testings; Testing technique; Autonomous vehicles|Conference paper|Final|All Open Access; Green Open Access|Scopus|2-s2.0-85205563037
scopus|Suman; Khan R.A.|Suman (58826839800); Khan, Raees Ahmad (25724398200)|58826839800; 25724398200|Survey on identification and prediction of security threats using various deep learning models on software testing|2024|Multimedia Tools and Applications|83|27||69863|69874|11|2|10.1007/s11042-024-18323-8|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184194206&doi=10.1007%2fs11042-024-18323-8&partnerID=40&md5=d97c8bfa3e8b8f7cf139b0fe9d2f304c|In this research, authors give a literature analysis of the methods used to detect and anticipate security risks in software testing by using a number of deep learning models. The purpose of this study is to conduct a literature review on the use of deep learning models in software testing for the purpose of detecting and predicting security issues. Moreover, the motive of this work is to analyze the exiting techniques related as software testing model and its application oriented performance. A thorough search of the available literature across several databases and resources forms the basis of this evaluation. There are a total of 69 publications found via the search, 34 of which are original research. Convolutional neural networks, long short-term memory networks, generative adversarial networks, and capsule networks are only some of the state-of-the-art methods for identifying and predicting security risks that are the topic of this research study. Datasets, performance indicators, and assessment criteria are all dissected for this examination. Finally, the benefits and drawbacks of using deep learning models to detect and anticipate software security flaws during testing are outlined in this article. Software testing experts and academics will benefit from this study since it will shed light on the present state of the art in the area and provide direction for the creation of innovative approaches to the detection and forecasting of security risks in software testing. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.|Deep learning; Identification; Prediction; Security threats; Software testing|Application programs; Deep learning; Learning systems; Risk assessment; Security systems; Software testing; Deep learning; Identification; Learning models; Literature analysis; Literature reviews; Security issues; Security risks; Security threats; Software testings; Testing models; Forecasting|Article|Final||Scopus|2-s2.0-85184194206
scopus|Shankar S.P.; Chaudhari S.S.|Shankar, Sahana P. (57216108507); Chaudhari, Shilpa Shashikant (56177436200)|57216108507; 56177436200|Analysis of Bio Inspired Based Hybrid Learning Model for Software Defect Prediction|2024|SN Computer Science|5|7|825||||3|10.1007/s42979-024-03171-y|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202167071&doi=10.1007%2fs42979-024-03171-y&partnerID=40&md5=9e7cada5157547056f03d93371fcf8eb|The software’s quality can be ensured through software testing, which is one of the critical methods. However, it was found that testing consumes more than half of the project's total expenses. Effective and efficient software testing utilizes minimal software resources to find as many flaws in the software system as possible. This paper presents research on software defect prediction using hybrid machine learning algorithm. The algorithm incorporates the benefits of supervised as well as unsupervised learning methodology that improves the accuracy of defect prediction. The study uses publicly available datasets from the open source PROMISE repository provided by NASA MDP to perform machine learning analysis and maximize accuracy. In particular, the study suggested a hybrid learning model and conducted a comparative analysis among Naïve Bayes, Multilayer Perceptron, Random Forest, CNN, Adaboost, and KNN on four different datasets namely CM1, KC1, KC2 and PC1. With respect to F1-score, accuracy, precision, and recall, the results show that the hybrid method performed better than the other methods. The study achieved an accuracy of 93.67% (BAT + CNN) on PC1 dataset, 92% on (Bat + CNN) for CM1 and KC1 respectively. This indicates that the hybrid learning technique of (BAT + CNN) is more potent than other methodologies in prediction of defects. The research can help software development teams identify potential bugs early on, leading to efficient and effective software creation. One useful approach for predicting software defects is the hybrid machine learning method, which can lead to improved software quality and lower maintenance costs. This aids the software testing phase by predicting the faulty modules with better accuracy thereby reducing the testing effort. The main objectives of the research include applying different machine learning algorithms and methods to the given datasets and determine the most effective ones. © The Author(s), under exclusive licence to Springer Nature Singapore Pte Ltd. 2024.|Bat; CNN; PROMISE; Sparrow Search; Squirrel Search; Testing||Article|Final||Scopus|2-s2.0-85202167071
scopus|Wan C.; Liu S.; Xie S.; Liu Y.; Hoffmann H.; Maire M.; Lu S.|Wan, Chengcheng (57190807234); Liu, Shicheng (57271349000); Xie, Sophie (57471495500); Liu, Yuhan (58248884400); Hoffmann, Henry (7401864015); Maire, Michael (7003906267); Lu, Shan (35199803400)|57190807234; 57271349000; 57471495500; 58248884400; 7401864015; 7003906267; 35199803400|Keeper: Automated Testing and Fixing of Machine Learning Software|2024|ACM Transactions on Software Engineering and Methodology|33|7|167||||0|10.1145/3672451|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206219501&doi=10.1145%2f3672451&partnerID=40&md5=cbf74053930b0a3b7d9391e76ba2beb2|The increasing number of software applications incorporating machine learning (ML) solutions has led to the need for testing techniques. However, testing ML software requires tremendous human effort to design realistic and relevant test inputs and to judge software output correctness according to human common sense. Even when misbehavior is exposed, it is often unclear whether the defect is inside ML API or the surrounding code and how to fix the implementation. This article tackles these challenges by proposing Keeper, an automated testing and fixing tool for ML software. The core idea of Keeper is designing pseudo-inverse functions that semantically reverse the corresponding ML task in an empirical way and proxy common human judgment of real-world data. It incorporates these functions into a symbolic execution engine to generate tests. Keeper also detects code smells that degrade software performance. Once misbehavior is exposed, Keeper attempts to change how ML APIs are used to alleviate the misbehavior. Our evaluation on a variety of applications shows that Keeper greatly improves branch coverage, while identifying 74 previously unknown failures and 19 code smells from 56 out of 104 applications. Our user studies show that 78% of end-users and 95% of developers agree with Keeper’s detection and fixing results. © 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.|machine learning; machine learning API; Software testing|Application programs; Contrastive Learning; Input output programs; Software testing; Automated testing; Code smell; Machine learning API; Machine learning software; Machine-learning; Misbehaviour; Software applications; Software testings; Testing technique; Adversarial machine learning|Article|Final|All Open Access; Bronze Open Access|Scopus|2-s2.0-85206219501
scopus|Kapse R.; Harsoor B.|Kapse, Rahul (59337314500); Harsoor, Bharati (36537035900)|59337314500; 36537035900|Source Code Pre-processing and Analysis to Extricate Features Using Abstract Syntax Tree|2025|Lecture Notes in Networks and Systems|1172 LNNS|||261|269|8|0|10.1007/978-981-97-8631-2_15|https://www.scopus.com/inward/record.uri?eid=2-s2.0-86000459493&doi=10.1007%2f978-981-97-8631-2_15&partnerID=40&md5=4fbc2c656b025e634b85d3d3a925eaf9|The software is a collection of single files or many files which contain source code. The advances in Machine Learning algorithms and methods have inspired investigators to use these technical advancements for software program code assessment for software development work like software testing or defect prediction. This paper aims to pre-process the source code and apply machine learning strategies to do software program code analysis to extricate software program code features using AST and use these features of software program code for software engineering work. In the analysis, we analyse the Cyclomatic complexity of software program code and Halsted measures. Extricated sampled features are Max_cc: Maximum McCabe’s cyclomatic complexity, Moa: Measure, of Aggregation, Dam: Data Access Metric, Loc: Lines of Code, Lcom: Lack of cohesion in methods, Npm: Number of Public Methods, Cc: McCabe’s cyclomatic complexity, Ce: Efferent Couplings, Noc: Number of Children, Ca: Afferent couplings, Rfc: Response for a Class. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2025.|Abstract syntax tree; Code analysis; Code pre-processing; Defect prediction; Feature extrication|Computer software selection and evaluation; Couplings; EXAPT (programming language); Program debugging; Software design; Syntactics; Abstract Syntax Trees; Code analysis; Code pre-processing; Cyclomatic complexity; Defect prediction; Feature extrication; Pre-processing; Program code; Software project; Source codes; Software testing|Conference paper|Final||Scopus|2-s2.0-86000459493
scopus|Kapoor S.|Kapoor, Saurabh (59481672800)|59481672800|AI-Assisted Test Script Generation for GUI Applications|2025|2025 5th International Conference on Advances in Electrical, Computing, Communication and Sustainable Technologies, ICAECT 2025|||||||0|10.1109/ICAECT63952.2025.10958949|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105004558773&doi=10.1109%2fICAECT63952.2025.10958949&partnerID=40&md5=5ad8f28db974e5ef58570778f7173923|Automated testing is crucial for ensuring the quality and reliability of modern software applications, especially those with complex graphical user interfaces (GUIs). However, traditional approaches to GUI testing, such as record-and-replay and manual script generation, are often labor-intensive and fail to capture the dynamic nature of user interactions. This paper presents a novel AI-assisted framework for automatically generating test scripts for GUI applications. By leveraging advancements in computer vision and reinforcement learning, the framework accurately detects GUI elements, models user interactions, and generates effective test sequences to validate expected application behavior. The system is evaluated on a diverse set of GUI applications, demonstrating superiority over existing testing methods in terms of test coverage, script generation efficiency, and fault detection capabilities. The results highlight the potential of AI-powered techniques to transform GUI testing, enabling more robust and scalable software development processes.  © 2025 IEEE.|AI Assisted Testing; Automated Test Script Generation; Computer Vision; GUI Testing; Reinforcement Learning|Computer graphics; Computer vision; Enterprise software; Software design; Software quality; AI assisted testing; Automated test; Automated test script generation; Graphical user interface testing; Interface applications; Interface testings; Reinforcement learnings; Script generation; Test scripts; User interaction; Automatic test pattern generation|Conference paper|Final||Scopus|2-s2.0-105004558773
scopus|Gao L.; Qiu J.; Chen G.|Gao, Li (58927197200); Qiu, Junlin (51665930600); Chen, Guanhua (57203121185)|58927197200; 51665930600; 57203121185|Software Test Data Management Based on Knowledge Graph|2024|Informatica (Slovenia)|48|16||27|36|9|1|10.31449/inf.v48i16.6461|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207472860&doi=10.31449%2finf.v48i16.6461&partnerID=40&md5=4c549cf639e945624c4983bb8ee7f4f3|As software development models and methods mature, large-scale software systems emerge. However, a critical challenge remains: the lack of a comprehensive software test data management model that integrates basic data management with advanced knowledge reasoning. To address this issue, we developed a software test data management model based on knowledge graphs, enabling intelligent management and reasoning of software test data. The model incorporates an entity extraction model based on a feed-forward neural network, a knowledge graph integration method based on graph databases, and a knowledge reasoning submodule based on deep learning. To validate the effectiveness of our model, we evaluated the performance of each component individually. Our deep learning-based entity extraction model achieved an accuracy of 0.92, a recall of 0.88, and an F1 score of 0.90, significantly outperforming traditional methods such as regular expressions and dictionary-based approaches. Utilizing Cypher for graph database querying, our system provides accurate answers with a response time of 0.12 seconds, outperforming SQL and SPARQL-based querying methods. Furthermore, our approach excels in knowledge-based reasoning with an accuracy of 0.89 and site coverage of 0.81, surpassing both ontology-based and graph-based reasoning methods. These results highlight the enhanced construction, querying, and reasoning capabilities of our knowledge graph-based approach for managing software testing data. © 2024 Slovene Society Informatika. All rights reserved.|data management; knowledge graph; software testing|Data accuracy; Structured Query Language; Entity extractions; Extraction modeling; Graph database; Knowledge graphs; Knowledge reasoning; Management Model; Model-based OPC; Software development models; Software testings; Test data management; Knowledge graph|Article|Final||Scopus|2-s2.0-85207472860
scopus|Alencar R.C.; Fernandes B.J.T.; Lima P.H.E.S.; da Silva C.M.R.|Alencar, Reno C. (59483101300); Fernandes, Bruno J. T. (25633734000); Lima, Paulo H. E. S. (59482724600); da Silva, Carlo M. R. (56204480800)|59483101300; 25633734000; 59482724600; 56204480800|AI techniques for automated penetration testing in MQTT networks: a literature investigation|2025|International Journal of Computers and Applications|47|1||106|121|15|1|10.1080/1206212X.2024.2443504|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212783480&doi=10.1080%2f1206212X.2024.2443504&partnerID=40&md5=646cc86977010db685a2aae67553876a|The proliferation of IoT has made MQTT systems frequent targets of cyberattacks. While existing literature predominantly focuses on intrusion detection systems, this research aims to explore how machine learning algorithms can be leveraged to automate penetration testing in MQTT environments. A review of the literature reveals a significant gap in the field of automated testing, with few studies utilizing specific brokers and realistic datasets. This study contributes to the security of MQTT networks through: (a) a survey of widely used MQTT brokers, detailing their features, vulnerabilities, and mitigation measures; (b) an analysis of common attacks against brokers, including the identification of attack vectors, intrusion techniques, and defense mechanisms; (c) a mapping of machine learning models, such as Decision Trees (DT), Generative Adversarial Networks (GANs), and Boosting Algorithms, for detecting malicious activities and automating penetration testing in MQTT environments; and (d) the proposal of metrics to evaluate the effectiveness of the proposed models, considering both their ability to detect attacks and to successfully exploit vulnerabilities. © 2024 Informa UK Limited, trading as Taylor & Francis Group.|internet of things; IoT Vulnerabilities; machine learning; MQTT; network attacks; Penetration testing|Ability testing; Adaptive boosting; Decision trees; Generative adversarial networks; Intrusion detection; Network intrusion; Random forests; AI techniques; Automated testing; Cyber-attacks; Intrusion Detection Systems; IoT vulnerability; Machine learning algorithms; Machine-learning; MQTT; Network attack; Penetration testing; Adversarial machine learning|Review|Final||Scopus|2-s2.0-85212783480
scopus|Hamad M.; Kühr M.; Mouratidis H.; Kalogeraki E.-M.; Gizelis C.; Papanikas D.; Bountioukos-Spinaris A.; Skandylas C.; Raptis E.; Alexopoulos A.; Chrysos G.; Marmpena M.; Politi S.; Lieros K.; Nikolaos P.; Xanthopoulos I.; Papastergiou S.; Ioannidis S.; Asplund M.; Pahl M.-O.; Steinhorst S.|Hamad, Mohammad (56767753100); Kühr, Michael (58811632000); Mouratidis, Haralambos (35512143700); Kalogeraki, Eleni-Maria (56341990300); Gizelis, Christos (6505905358); Papanikas, Dimitris (6602469624); Bountioukos-Spinaris, Athanasios (59921879300); Skandylas, Charilaos (57203553264); Raptis, Evangelos (59920915800); Alexopoulos, Andreas (57951582700); Chrysos, Grigorios (15076541700); Marmpena, Mina (57213418631); Politi, Sevasti (58539610500); Lieros, Konstantinos (59920719500); Nikolaos, Papagiannopoulos (59921685400); Xanthopoulos, Iordanis (57193558346); Papastergiou, Spyros (16199942300); Ioannidis, Sotiris (24767420100); Asplund, Mikael (22978610300); Pahl, Marc-Oliver (36070040900); Steinhorst, Sebastian (24588286900)|56767753100; 58811632000; 35512143700; 56341990300; 6505905358; 6602469624; 59921879300; 57203553264; 59920915800; 57951582700; 15076541700; 57213418631; 58539610500; 59920719500; 59921685400; 57193558346; 16199942300; 24767420100; 22978610300; 36070040900; 24588286900|Multi-Partner Project: CyberSecDome - Framework for Secure, Collaborative, and Privacy-Aware Incident Handling for Digital Infrastructure|2025|Proceedings -Design, Automation and Test in Europe, DATE|||||||0|10.23919/DATE64628.2025.10992768|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105006910342&doi=10.23919%2fDATE64628.2025.10992768&partnerID=40&md5=dd4e129ff017409e6fe00816a60c517a|Digital infrastructure is vital for the economy, democracy, and everyday life, yet it is becoming increasingly vulnerable to strategic cyber-attacks. These attacks can lead to significant disruptions, resulting in widespread service outages, financial losses, and a decline in public trust. Ensuring resilience is difficult due to the infrastructure's complexity, the large volume of data involved, and the growing need for quick, coordinated responses. In the EU Horizon project CyberSecDome, we propose a multi-layered framework that provides AI-driven solutions for incident prediction and detection, automated testing, risk assessment, and rapid incident response, supporting continuity amid complex, large-scale cyber threats. Additionally, Cyber-SecDome introduces a virtual reality interface to enhance AI model explainability and provide real-time contextual awareness of ongoing attacks and defense mechanisms. It also enables privacy-aware model sharing across AI systems, fostering secure collaboration among different domes. © 2025 EDAA.|AI; Incident handling; Intrusion detection; Security|Artificial life; Cyber attacks; Intelligent computing; Intelligent systems; Malware; Multi agent systems; Network intrusion; Network security; Problem solving; Sensitive data; Cyber-attacks; Digital infrastructures; Financial loss; Incident handling; Intrusion-Detection; Large volumes; Privacy aware; Public trust; Security; Service outage; Intrusion detection|Conference paper|Final||Scopus|2-s2.0-105006910342
scopus|Brabbs J.; Jones B.C.|Brabbs, John (6506564502); Jones, B. Colby (59343060400)|6506564502; 59343060400|How the Cloud is a Mission Enabler for Embedded System Development|2024|SAE Technical Papers|||||||0|10.4271/2024-01-4101|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204934928&doi=10.4271%2f2024-01-4101&partnerID=40&md5=0cc9fdf72fbb3e9c9c94c8c556e3d4fb|The Army can increase its software modernization effort for Embedded System software development by leveraging the Cloud to expand the capability of the DevSecOps environment to include automated testing at scale. The Cloud will support the integration of current and new off-the-shelf technologies; and merging next generation technologies from industry partners into a coherent DevSecOps Cloud ecosystem. The following areas are critical to meeting mission requirements and applications: virtual simulation, trade study analytics, technology adoption, DevSecOps capabilities, artificial intelligence applications and infrastructure, and collaborative single vehicle Systems Integration Laboratory (SIL). These areas are all essential to shortening the vehicle product lifecycle and time to deliver mission essential capabilities to the field to support warfighter needs.  © Rights reserved by the National Defense Industrial Association (NDIA) Michigan Chapter, authors and their respected organizations.||Cloud platforms; Integration testing; Modernization; 'current; Automated testing; Embedded system development; Embedded systems software; Generation technologies; Mission requirements; Off-the-shelf technologies; Software modernization; Trade-study; Virtual simulations; Artificial intelligence|Conference paper|Final||Scopus|2-s2.0-85204934928
scopus|Kharchenko K.; Beznosyk O.; Bulakh B.; Kyriusha B.; Yaremenko V.|Kharchenko, Kostyantyn (6504722716); Beznosyk, Oleksandr (24830332300); Bulakh, Bogdan (55817517600); Kyriusha, Bogdan (57194412445); Yaremenko, Vadym (57222082342)|6504722716; 24830332300; 55817517600; 57194412445; 57222082342|FORECASTING SOFTWARE DEVELOPMENT COSTS IN SCRUM ITERATIONS USING ORDINARY LEAST SQUARES METHOD|2024|Technology Audit and Production Reserves|4|2||30|33|3|1|10.15587/2706-5448.2024.310411|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105011840920&doi=10.15587%2f2706-5448.2024.310411&partnerID=40&md5=90fd441e253962eb5fb76005ddde45fa|During scrum iterations, it is possible to apply cost forecasting for software testing and operation, if the data from previous iterations are known. Since the data for estimating the scope of work and the deadline within one sprint are accumulated during the project execution, it is possible to use such data to build a forecasting algorithm for the estimated parameters of the subsequent sprints. The approach is based on refining the assessment provided by the development team and the scrum master in a specific metric. The main parameters for evaluation are the execution time and the amount of work performed. As a result of forecasting, it is possible to obtain clarifications for the team’s assessment regarding the scope of work for the next sprint. This estimate is based on planned and actual data from the previous sprints. The article discusses the method of least squares and the proposed code for a machine learning model based on this method. An example and graphs for iterations in scrum and corresponding forecasting for the next sprints are presented. The use of the least squares method allows creating a mathematical model that can be adapted to different project conditions, providing flexibility and accuracy in forecasting. For example, the study uses the real data from the previous sprints, which includes the team’s resource assessment and actual expenditures. Based on these data, a model was built that demonstrates a high correlation between predicted and actual costs, confirming the effective-ness of using the least squares method. So, the least squares method is an effective tool for forecasting software development costs in scrum iterations. This method allows development teams to better plan their resources and timelines, contributing to the overall efficiency of the project. © The Author(s) 2024.|cost forecasting; iterations; least squares method; machine learning; scrum; software development||Article|Final||Scopus|2-s2.0-105011840920
scopus|Lafi M.; Farhan K.A.; Abusukhon A.|Lafi, Mohamamed (55364801600); Farhan, Khalid A. (24721337800); Abusukhon, Ahmad (25927828300)|55364801600; 24721337800; 25927828300|Machine Learning Model for Fault Prediction in Object-Oriented Systems|2025|Proceeding - 12th International Conference on Information Technology: Innovation Technologies, ICIT 2025||||644|646|2|0|10.1109/ICIT64950.2025.11049103|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105011974401&doi=10.1109%2fICIT64950.2025.11049103&partnerID=40&md5=df826d8968d627b9413d6d26b0cf2921|Predicting whether the module is faulty is vital to concentrating on the testing and evaluation process. We proposed a machine learning model to predict the faulty model in object-oriented systems. We employ a set of metrics to learn and test the module. The results show averages of 0.82, 0.98, 0.82, and 0.90 for precision, recall, and F1-score, respectively.This proposed model can be used to predict faulty models and decrease the effort of software testing. © 2025 IEEE.|CK-Metric Suite; fault prediction; Machine-learning; object-oriented systems|Forecasting; Learning systems; Machine learning; Object oriented programming; Prediction models; CK metrics; CK-metric suite; F1 scores; Fault prediction; Learn+; Machine learning models; Machine-learning; Metric suites; Object-oriented system; Testing and evaluation; Software testing|Conference paper|Final||Scopus|2-s2.0-105011974401
scopus|Sendas N.; Rajale D.|Sendas, Neel (59750623300); Rajale, Deepali (59750519100)|59750623300; 59750519100|The Definitive Guide to Machine Learning Operations in AWS: Machine Learning Scalability and Optimization with AWS|2025|The Definitive Guide to Machine Learning Operations in AWS: Machine Learning Scalability and Optimization with AWS||||1|440|439|0|10.1007/979-8-8688-1076-3|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003337282&doi=10.1007%2f979-8-8688-1076-3&partnerID=40&md5=785c3ef5ba78082a09233aff135a366c|Foreword by Dr. Shreyas Subramanian, Principal Data Scientist, Amazon This book focuses on deploying, testing, monitoring, and automating ML systems in production. It covers AWS MLOps tools like Amazon SageMaker, Data Wrangler, and AWS Feature Store, along with best practices for operating ML systems on AWS. This book explains how to design, develop, and deploy ML workloads at scale using AWS cloud’s well-architected pillars. It starts with an introduction to AWS services and MLOps tools, setting up the MLOps environment. It covers operational excellence, including CI/CD pipelines and Infrastructure as code. Security in MLOps, data privacy, IAM, and reliability with automated testing are discussed. Performance efficiency and cost optimization, like Right-sizing ML resources, are explored. The book concludes with MLOps best practices, MLOPS for GenAI, emerging trends, and future developments in MLOps By the end, readers will learn operating ML workloads on the AWS cloud. This book suits software developers, ML engineers, DevOps engineers, architects, and team leaders aspiring to be MLOps professionals on AWS. What you will learn: • Create repeatable training workflows to accelerate model development • Catalog ML artifacts centrally for model reproducibility and governance • Integrate ML workflows with CI/CD pipelines for faster time to production • Continuously monitor data and models in production to maintain quality • Optimize model deployment for performance and cost Who this book is for: This book suits ML engineers, DevOps engineers, software developers, architects, and team leaders aspiring to be MLOps professionals on AWS. © 2024 by Neel Sendas and Deepali Rajale.|AWS; Cost Optimization in MLOps; Machine Learning; MLOps; MLOPS for GenAI; Operational Excellence in MLOps; Reliability in MLOps; Security in MLOps|Cost effectiveness; Data privacy; DevOps; Engineering education; Learning systems; Machine learning; Personnel training; Software reliability; AWS; Cost optimization in MLOp; Costs Optimization; Machine-learning; MLOp; MLOPS for GenAI; Operational excellence; Operational excellence in MLOp; Reliability in MLOp; Security in MLOp; Engineers|Book|Final||Scopus|2-s2.0-105003337282
scopus|Peixoto M.; Baía D.; Nascimento N.; Alencar P.; Fonseca B.; Ribeiro M.|Peixoto, Myron (59366586200); Baía, Davy (57021844000); Nascimento, Nathalia (57219458130); Alencar, Paulo (6604014338); Fonseca, Baldoino (36175426900); Ribeiro, Márcio (57199329234)|59366586200; 57021844000; 57219458130; 6604014338; 36175426900; 57199329234|On the Effectiveness of LLMs for Manual Test Verifications|2025|Proceedings - 2025 IEEE/ACM International Workshop on Deep Learning for Testing and Testing for Deep Learning, DeepTest 2025||||45|52|7|0|10.1109/DeepTest66595.2025.00012|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105009161789&doi=10.1109%2fDeepTest66595.2025.00012&partnerID=40&md5=4325b9ff9769407297c48a3be79713fb|Background: Manual testing is vital for detecting issues missed by automated tests, but specifying accurate verifications is challenging. Aims: This study aims to explore the use of Large Language Models (LLMs) to produce verifications for manual tests. Method: We conducted two independent and complementary exploratory studies. The first study involved using 2 closed-source and 6 open-source LLMs to generate verifications for manual test steps and evaluate their similarity to original verifications. The second study involved recruiting software testing professionals to assess their perception and agreement with the generated verifications compared to the original ones. Results: The open-source models Mistral-7B and Phi-3-mini-4k demonstrated effectiveness and consistency comparable to closed-source models like Gemini-1.5-flash and GPT-3.5-turbo in generating manual test verifications. However, the agreement level among professional testers was slightly above 40%, indicating both promise and room for improvement. While some LLM-generated verifications were considered better than the originals, there were also concerns about AI hallucinations, where verifications significantly deviated from expectations. Conclusion: We contributed by evaluating the effectiveness of 8 LLMs through similarity and human acceptance studies, identifying top-performing models like Mistral-7B and GPT-3.5-turbo. Although the models show potential, the relatively modest 40% agreement level highlights the need for further refinement. Enhancing the accuracy, relevance, and clarity of the generated verifications is crucial to ensure greater reliability in real-world testing scenarios. © 2025 IEEE.|AI-generated testing; LLM; manual testing; model performance evaluation; test verifications|Human computer interaction; Model checking; Open source software; Open systems; AI-generated testing; Automated test; Closed source; Exploratory studies; Language model; Large language model; Manual testing; Manual tests; Model performance evaluations; Test verification; Software testing|Conference paper|Final||Scopus|2-s2.0-105009161789
scopus|Ahsan F.; Anwer F.|Ahsan, Fatma (58185090700); Anwer, Faisal (56021716200)|58185090700; 56021716200|A systematic literature review on software security testing using metaheuristics|2024|Automated Software Engineering|31|2|44||||2|10.1007/s10515-024-00433-0|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194029105&doi=10.1007%2fs10515-024-00433-0&partnerID=40&md5=c8d1e80d1dc10f5e799a685e2351e847|The security of an application is critical for its success, as breaches cause loss for organizations and individuals. Search-based software security testing (SBSST) is the field that utilizes metaheuristics to generate test cases for the software testing for some pre-specified security test adequacy criteria This paper conducts a systematic literature review to compare metaheuristics and fitness functions used in software security testing, exploring their distinctive capabilities and impact on vulnerability detection and code coverage. The aim is to provide insights for fortifying software systems against emerging threats in the rapidly evolving technological landscape. This paper examines how search-based algorithms have been explored in the context of code coverage and software security testing. Moreover, the study highlights different metaheuristics and fitness functions for security testing and code coverage. This paper follows the standard guidelines from Kitchenham to conduct SLR and obtained 122 primary studies related to SBSST after a multi-stage selection process. The papers were from different sources journals, conference proceedings, workshops, summits, and researchers’ webpages published between 2001 and 2022. The outcomes demonstrate that the main tackled vulnerabilities using metaheuristics are XSS, SQLI, program crash, and XMLI. The findings have suggested several areas for future research directions, including detecting server-side request forgery and security testing of third-party components. Moreover, new metaheuristics must also need to be explored to detect security vulnerabilities that are still unexplored or explored significantly less. Furthermore, metaheuristics can be combined with machine learning and reinforcement learning techniques for better results. Some metaheuristics can be designed by looking at the complexity of security testing and exploiting more fitness functions related to detecting different vulnerabilities. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.|Code coverage; Evolutionary algorithm; Meta-heuristic; Optimization algorithm; Program crash; SBSST; Software security testing; SQLI; XMLI; XSS|Evolutionary algorithms; Heuristic algorithms; Learning systems; Reinforcement learning; Security of data; Code coverage; Metaheuristic; Optimization algorithms; Program crash; Search-based; Search-based software security testing; Software security testing; SQLI; XMLI; XSS; Software testing|Article|Final||Scopus|2-s2.0-85194029105
scopus|Leotta M.; Yousaf H.Z.; Ricca F.; Garcia B.|Leotta, Maurizio (37104276100); Yousaf, Hafiz Zeeshan (59202257100); Ricca, Filippo (24822686600); Garcia, Boni (24724315500)|37104276100; 59202257100; 24822686600; 24724315500|AI-Generated Test Scripts for Web E2E Testing with ChatGPT and Copilot: A Preliminary Study|2024|ACM International Conference Proceeding Series||||339|344|5|2|10.1145/3661167.3661192|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197411849&doi=10.1145%2f3661167.3661192&partnerID=40&md5=1a2303942ff7d98117730c24418818b2|Automated testing is vital for ensuring the reliability of web applications. This paper presents a preliminary study on leveraging artificial intelligence (AI) models, specifically ChatGPT and Github Copilot, to generate test scripts for web end-to-end testing. Through experimentation, we evaluated the feasibility and effectiveness of AI language models in generating test scripts based on natural language descriptions of user interactions with web applications. Our preliminary results show that AI-based generation generally provides an advantage over fully manual test scripts development. Starting from test cases clearly defined in Gherkin, a reduction in development time is always observable. In some cases, this reduction is statistically significant (e.g., Manual vs. a particular use of ChatGPT). These results are valid provided that the tester has some skills in manual test script development and is therefore able to modify the code produced by the AI-generation tools. This study contributes to the exploration of AI-driven solutions in web test scripts generation and lays the foundation for future research in this domain. © 2024 Owner/Author.|ChatGPT; E2E Testing; Empirical Study.; GitHub Copilot; LLM; Selenium WebDriver; Test Automation|Natural language processing systems; ChatGPT; E2E testing; Empirical studies; Empirical study.; Github copilot; LLM; Selenia webdriver; Test Automation; Test scripts; WEB application; Selenium|Conference paper|Final||Scopus|2-s2.0-85197411849
scopus|Ning F.U.; Duksan R.Y.U.; Suntae K.I.M.|Ning, F.U. (58941414800); Duksan, R.Y.U. (59169550200); Suntae, K.I.M. (57223661189)|58941414800; 59169550200; 57223661189|MuSRGM: A Genetic Algorithm-Based Dynamic Combinatorial Deep Learning Model for Software Reliability Engineering|2024|IEICE Transactions on Information and Systems|E107.D|6||761|771|10|0|10.1587/transinf.2023EDP7183|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195775764&doi=10.1587%2ftransinf.2023EDP7183&partnerID=40&md5=58959a16aa32baad255763c9bab8e009|In the software testing phase, software reliability growth models (SRGMs) are commonly used to evaluate the reliability of software systems. Traditional SRGMs are restricted by their assumption of a continuous growth pattern for the failure detection rate (FDR) throughout the testing phase. However, the assumption is compromised by Change-Point phenomena, where FDR fluctuations stem from variations in testing personnel or procedural modifications, leading to reduced prediction accuracy and compromised software reliability assessments. Therefore, the objective of this study is to improve software reliability prediction using a novel approach that combines genetic algorithm (GA) and deep learning-based SRGMs to account for the Change-point phenomenon. The proposed approach uses a GA to dynamically combine activation functions from various deep learning-based SRGMs into a new mutated SRGM called MuSRGM. The MuSRGM captures the advantages of both concave and S-shaped SRGMs and is better suited to capture the change-point phenomenon during testing and more accurately reflect actual testing situations. Additionally, failure data is treated as a time series and analyzed using a combination of Long Short-Term Memory (LSTM) and Attention mechanisms. To assess the performance of MuSRGM, we conducted experiments on three distinct failure datasets. The results indicate that MuSRGM outperformed the baseline method, exhibiting low prediction error (MSE) on all three datasets. Furthermore, MuSRGM demonstrated remarkable generalization ability on these datasets, remaining unaffected by uneven data distribution. Therefore, MuSRGM represents a highly promising advanced solution that can provide increased accuracy and applicability for software reliability assessment during the testing phase. © 2024 The Institute of Electronics, Information and Communication Engineers.|attention; deep-learning; genetic algorithm; LSTM; software reliability growth models|Computer software selection and evaluation; Forecasting; Learning algorithms; Long short-term memory; Personnel testing; Reliability analysis; Safety testing; Software reliability; Software testing; Attention; Change-points; Deep-learning; Detection rates; Failure detection; Learning models; Software reliability assessment; Software reliability engineering; Software reliability growth models; Testing phase; Genetic algorithms|Article|Final|All Open Access; Gold Open Access|Scopus|2-s2.0-85195775764
scopus|García B.; Leotta M.; Ricca F.; Whitehead J.|García, Boni (24724315500); Leotta, Maurizio (37104276100); Ricca, Filippo (24822686600); Whitehead, Jim (8307167100)|24724315500; 37104276100; 24822686600; 8307167100|Use of ChatGPT as an Assistant in the End-to-End Test Script Generation for Android Apps|2024|A-TEST 2024 - Proceedings of the 15th ACM International Workshop on Automating Test Case Design, Selection and Evaluation, Co-located with: SSTA 2024||||5|11|6|3|10.1145/3678719.3685691|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207073256&doi=10.1145%2f3678719.3685691&partnerID=40&md5=b4a773b7c6d23a6779f7b9e30551f2b4|Automated testing is crucial in software development to ensure that applications perform as intended. However, generating automated End-to-End (E2E) tests can be time-consuming and challenging, especially for junior developers. This study investigates the use of ChatGPT, a popular Generative Artificial Intelligence (GenAI) model, as an assistant in developing automated E2E test scripts for Android apps. We present an empirical study that compares the effort required to create E2E test scripts and the resulting reliability of these tests using two treatments: manually and assisted by ChatGPT. We used Gherkin, a domain-specific language that allows non-technical practitioners to define test scenarios using a human-readable syntax. Our findings indicate that using ChatGPT significantly reduces the time required to develop automated test scripts without compromising the reliability of the scripts. Statistical analysis shows a notable reduction in development time for the ChatGPT-assisted group compared to the manual group, with a large effect size. While the reliability of the tests did not show a significant difference between the two groups, the results suggest practical benefits in terms of efficiency. © 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.|Android; E2E Automated Testing; Empirical Study; GenAI|Application programs; Automatic test pattern generation; Android; Android apps; Automated testing; E2E automated testing; Empirical studies; End to end; End-to-end tests; Generative artificial intelligence; Script generation; Test scripts; Software testing|Conference paper|Final||Scopus|2-s2.0-85207073256
scopus|Nettur S.B.; Karpurapu S.; Nettur U.; Gajja L.S.|Nettur, Suresh Babu (59489949300); Karpurapu, Shanthi (57195316200); Nettur, Unnati (58968141700); Gajja, Likhit Sagar (58967468800)|59489949300; 57195316200; 58968141700; 58967468800|Cypress Copilot: Development of an AI Assistant for Boosting Productivity and Transforming Web Application Testing|2025|IEEE Access|13|||3215|3229|14|3|10.1109/ACCESS.2024.3521407|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213278394&doi=10.1109%2fACCESS.2024.3521407&partnerID=40&md5=01915a93eddecf761ccf84af4242d48a|"In today's fast-paced software development environment, Agile methodologies demand rapid delivery and continuous improvement, making automated testing essential for maintaining quality and accelerating feedback loops. Our study addresses the challenges of developing and maintaining automation code for web-based application testing. In this paper, we propose a novel approach that leverages large language models (LLMs) and a novel prompt technique, few-shot chain, to automate code generation for web application testing. We chose the Behavior-Driven Development (BDD) methodology owing to its advantages and selected the Cypress tool for automating web application testing, as it is one of the most popular and rapidly growing frameworks in this domain. We comprehensively evaluated various OpenAI models, including GPT-4-Turbo, GPT-4o, and GitHub Copilot, using zero-shot and few-shot chain prompt techniques. Furthermore, we extensively validated with a vast set of test cases to identify the optimal approach. Our results indicate that the Cypress automation code generated by GPT-4o using a few-shot chained prompt approach excels in generating complete code for each test case, with fewer empty methods and improved syntactical accuracy and maintainability. Based on these findings, we developed a novel open-source Visual Studio Code (IDE) extension, ""Cypress Copilot""utilizing GPT-4o and a few-shot chain prompt technique, which has shown promising results. Finally, we validate the Cypress Copilot tool by generating automation code for end-to-end web tests, demonstrating its effectiveness in testing various web applications and its ability to streamline development processes. More importantly, we are releasing this tool to the open-source community, as it has the potential to be a promising partner in enhancing productivity in web application automation testing.  © 2013 IEEE."|Agile software development; AI assistant tools; behavior driven development; code generation; cypress; few-shot; GitHub Copilot; GPT-3; GPT-4; GPT-4o; GPT3.5; large language model; machine learning; OpenAI; prompt engineering; selenium; software testing; test automation; test case generation; web application; zero-shot|Ability testing; Agile manufacturing systems; Automatic test pattern generation; Computer debugging; Computer software selection and evaluation; Model checking; Open source software; Problem oriented languages; Program debugging; Report generators; Software testing; Subjective testing; Agile software development; AI assistant tool; Behavior driven development; Codegeneration; Cypress; Few-shot; Github copilot; GPT-3; GPT-4; GPT-4o; Gpt3.5; Language model; Large language model; Machine-learning; Openai; Prompt engineering; Software testings; Test Automation; Test case generation; WEB application; Web applications; Zero-shot; Application programs|Article|Final|All Open Access; Gold Open Access|Scopus|2-s2.0-85213278394
scopus|Qiu Y.|Qiu, Yuxin (59353368500)|59353368500|Full-Stack Collaboration for Robust Heterogeneity-Enabled AI Systems|2024|SPLASH Companion 2024 - Companion Proceedings of the 2024 ACM SIGPLAN International Conference on Systems, Programming, Languages, and Applications: Software for Humanity||||10|12|2|0|10.1145/3689491.3691817|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007531113&doi=10.1145%2f3689491.3691817&partnerID=40&md5=f5dd0c7b97a1b0984d6292e75bc6e3dd|In this new era of AI with diverse hardware accelerators such as GPUs and quantum circuits, achieving system-wide robustness requires tackling issues throughout all system layers, spanning from software applications to hardware components. My research is to enhance the robustness of heterogeneity-enabled AI systems by reinventing software testing and analysis techniques via leveraging full-stack insights and advanced AI capabilities. I have completed one research project and have collaborated on a couple of others at the application and language levels. As the next steps, I will explore (1) holistic regression testing to prioritize test inputs associated with system-wide changes and (2) full-stack analysis to optimize computing resource allocation and reduce hardware reliance by analyzing application characteristics and using alternative resources in tandem. © 2024 Copyright held by the owner/author(s)|artificial intelligence; Software engineering; software testing|Application programs; Computer aided software engineering; Computer operating systems; Computer software maintenance; Computer software selection and evaluation; Model checking; Search engines; Software design; Software packages; Software prototyping; Software quality; AI systems; Analysis techniques; Hardware accelerators; Hardware components; Quantum circuit; Software applications; Software testing and analysis; Software testing techniques; Software testings; System layer; Software testing|Conference paper|Final||Scopus|2-s2.0-105007531113
scopus|Panigrahi J.K.; Acharya D.P.|Panigrahi, Jayanta Kumar (57189688444); Acharya, Debiprasad Priyabrata (35747770900)|57189688444; 35747770900|GAN augmented phase noise modeling of PLL for use in automated testing|2025|International Journal of Electronics Letters|13|2||219|226|7|0|10.1080/21681724.2025.2453916|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215403790&doi=10.1080%2f21681724.2025.2453916&partnerID=40&md5=b9b5e9368a0836848662be7bed4231f9|Phase noise measurement of Phase Locked Loop (PLL) in automated test equipment (ATE) is expensive and time-consuming. Indirect phase noise measurement relies on a few correlated low-cost measurements called signatures obtained from specific nodes of the PLL. A regression model using these signatures is learned during the design phase for phase noise estimation. Extraction of these signatures and phase noise performance in PLL requires significant simulation time, raising non-recurring design costs and computer aided design (CAD) tool usage costs. In this work, a new methodology for indirect phase noise measurement is developed where Generative Adversarial Network (GAN), a deep learning framework, has been used for generating a substantial amount of model-driven synthetic signatures that are strongly correlated to simulation-driven real signatures. These model-driven signatures are then used to construct a regression model for phase noise prediction. The GAN model efficacy is verified by comparing the prediction accuracy of the simulation-driven signature-based model with the GAN-augmented signature-based regression model. © 2025 Informa UK Limited, trading as Taylor & Francis Group.|computer aided design (CAD) tool; generative adversarial network (GAN); machine learning (ML); Phase locked loop (PLL); phase noise measurement||Article|Final||Scopus|2-s2.0-85215403790
scopus|Behera A.; Acharya A.A.|Behera, Aishwaryarani (57216417483); Acharya, Arup Abhinna (57198072949)|57216417483; 57198072949|An Effective GRU-Based Deep Learning Method for Test Case Prioritization in Continuous Integration Testing|2025|Procedia Computer Science|258|||4070|4083|13|0|10.1016/j.procs.2025.04.658|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007160603&doi=10.1016%2fj.procs.2025.04.658&partnerID=40&md5=6d469f3696569891e4f25c95d1d42137|Continuous integrating (CI) testing is a key element in today's software development process, where automated testing of code changes occurs frequently. Test Case Prioritization (TCP) is a strategy aimed at boosting the performance of CI testing by choosing specific test cases that have a strong likelihood of detecting defects early in each cycle. Since CI testing generates a substantial volume of test execution data, the use of historical test data has become a common strategy in prioritizing test cases. However, many existing methods for test prioritization in CI face challenges: they may struggle with managing extensive test histories, involve numerous parameters that slow down the training process, or being improved for only a few sort of past test cycles. Such limitations can reduce the effectiveness of fault detection in prioritized test suites. In this research work, we developed a Gated Recurrent Unit-driven deep learning (GRU-driven deep learning) model that leverages the principles of regression to prioritize test cases using historical execution data across multiple test cycles. The GRU model learns to identify failed test cases by considering various factors including distance, duration, change in status, last run. The proposed GRU- based deep learning model is evaluated based on two key metrics i.e. time effectiveness and fault effectiveness when compared to some advanced approaches. The efficiency of the suggested methodology was extensively validated through experimentation on two separate datasets named as paint_ control and IOF/ROL. The experimental findings reveal that the GRU-based deep learning model achieves Total Algorithm Running Time (TT) values of 0.02 seconds and 0.01 seconds, along with APFD values of 0.77 and 0.70 regarding the paint_control and IOF/ROL datasets, respectively. These outcomes are notably lower than those obtained by other advanced existing models. It is evident from the result analysis that GRU model outperforms state-of-the-art test prioritization framework based on these two key metrics, and it can efficiently handle large datasets. © 2024 The Authors. Published by ELSEVIER B.V.|Continuous Integration; Deep Learning; Gated Recurrent Network; Regression Testing; Test case Prioritization|Automatic test pattern generation; Computer operating systems; Machine oriented languages; Open source software; Software prototyping; Testbeds; Continuous integrations; Deep learning; Gated recurrent network; Learning models; Recurrent networks; Regression testing; Test case; Test case prioritization; Test cycles; Test prioritization; Software design|Conference paper|Final||Scopus|2-s2.0-105007160603
scopus||||25th International Conference on Product-Focused Software Process Improvement, PROFES 2024|2025|Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) |15452 LNCS|||||185|0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211896041&partnerID=40&md5=eb289e67ff529f59413d59f4bbf9ec78|The proceedings contain 13 papers. The special focus in this conference is on Product-Focused Software Process Improvement. The topics include: A Multi-model Approach for Video Data Retrieval in Autonomous Vehicle Development; AI-Based Automotive Test Case Generation: An Action Research Study on Integration of Generative AI into Test Automation Frameworks; AI Act High-Risk Requirements Readiness: Industrial Perspectives and Case Company Insights; adopting Continuous Deployment in a Public Administration Project: An Industrial Case Study; an Automated Approach to Identify Source Code Files Affected by Architectural Technical Debt; on the Derivation of Quality Assurance Plans from Process Model Descriptions; Evaluating AI-Based Code Segmentation for ABAP Programs in an Industrial Use Case; quantum Algorithms: Application and Feasibility; towards Solving Short-Term Generation Scheduling Problems on Quantum Computers; generating and Evolving Real-Life Like Synthetic Data for e-Government Services Without Using Real-World Raw Data; a Data-Driven Approach to Optimize Internal Software Quality and Customer Value Delivery.|||Conference review|Final||Scopus|2-s2.0-85211896041
scopus|Ayli M.; Bakouny Y.; Jalloul N.; Kilany R.|Ayli, Maroun (59717897000); Bakouny, Youssef (59159028500); Jalloul, Nader (59718733800); Kilany, Rima (56109494000)|59717897000; 59159028500; 59718733800; 56109494000|Enhancing the Resiliency of Automated Web Tests with Natural Language|2024|ACM International Conference Proceeding Series||||63|69|6|0|10.1145/3700523.3700536|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001574094&doi=10.1145%2f3700523.3700536&partnerID=40&md5=9a64b266ec29357bd12014630a32d858|Web application testing has traditionally been the domain of specialized software professionals, with a significant portion still relying on manual execution by individuals with limited programming expertise. This research introduces a novel proof-of-concept tool that democratizes the creation of automated web tests through a restricted natural language interface. Leveraging the GPT-4 language model and introducing “smart web element locators, our tool enables both technical and non-technical professionals to design comprehensive test cases without explicit programming knowledge. The tool comprises three key components: (1) a pseudo-language definition mapping into Selenium actions, (2) a new concept for resilient locators, and (3) a semantic understanding system translating natural language into software assertions. This approach enhances test production speed by offering a no-code interface and improves test resiliency through non-fragile locators. While introducing a slight increase in execution time (approximately 15% on average), the benefits in creation speed and script resilience far outweigh this trade-off. Empirical evaluation demonstrates the tool’s effectiveness in real-world scenarios, enabling non-technical team members to contribute meaningfully to the testing process. Results show a significant reduction in test suite creation and maintenance time, as well as improved test coverage due to increased participation of domain experts. This research contributes to software testing by combining natural language processing, smart locators, and automated test generation. By lowering the barrier to entry for test automation, our tool has the potential to revolutionize web application testing practices, leading to more efficient, comprehensive, and reliable testing processes across the software development industry. © 2024 Copyright held by the owner/author(s).|Automated test scripts; Behavior-driven development; Domain-specific language for testing; Natural language processing in testing; Restricted natural language; Test automation frameworks; Test case generation; Web application testing; Web automation testing; Web UI testing|Automatic test pattern generation; Computer debugging; Computer software selection and evaluation; International trade; Natural language processing systems; Program debugging; Software testing; Automated test; Automated test script; Automation testing; Behavior-driven development; Domain-specific language for testing; Domains specific languages; Language processing; Natural language processing in testing; Natural languages; Restricted natural language; Test automation frameworks; Test case generation; Test scripts; Web application testing; Web automation; Web automation testing; Web UI testing; Semantics|Conference paper|Final||Scopus|2-s2.0-105001574094
scopus|Alshehri W.; Kammoun Jarraya S.; Allinjawi A.|Alshehri, Wafa (59492323400); Kammoun Jarraya, Salma (36975764400); Allinjawi, Arwa (56436740900)|59492323400; 36975764400; 56436740900|Software Reliability Prediction Based on Recurrent Neural Network and Ensemble Method|2024|Computers|13|12|335||||0|10.3390/computers13120335|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213421236&doi=10.3390%2fcomputers13120335&partnerID=40&md5=644d0f463f48578434d819e5b118db8e|Software reliability is a crucial factor in determining software quality quantitatively. It is also used to estimate the software testing duration. In software reliability testing, traditional parametric software reliability growth models (SRGMs) are effectively used. Nevertheless, a single parametric model cannot provide accurate predictions in all cases. Moreover, non-parametric models have proven to be efficient for predicting software reliability as alternatives to parametric models. In this paper, we adopted a deep learning method for software reliability testing in computer vision systems. Also, we focused on critical computer vision applications that need high reliability. We propose a new deep learning-based model that is combined and based on the ensemble method to improve the performance of software reliability testing. The experimental results of the new model architecture present fairly accurate predictive capability compared to other existing single Neural Network (NN) based models. © 2024 by the authors.|deep learning; ensemble model; neural networks; software reliability; software reliability growth model (SRGM)||Article|Final|All Open Access; Gold Open Access|Scopus|2-s2.0-85213421236
scopus|Silvis-Cividjian N.; Kenyon J.; Nazarian E.; Sluis S.; Gevonden M.|Silvis-Cividjian, Natalia (6506597542); Kenyon, Joshua (59223893100); Nazarian, Elina (59223821100); Sluis, Stijn (59223840000); Gevonden, Martin (55970006900)|6506597542; 59223893100; 59223821100; 59223840000; 55970006900|On Using Physiological Sensors and AI to Monitor Emotions in a Bug-Hunting Game|2024|Annual Conference on Innovation and Technology in Computer Science Education, ITiCSE|1|||429|435|6|4|10.1145/3649217.3653611|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198901025&doi=10.1145%2f3649217.3653611&partnerID=40&md5=83d36c36a74e59186cde9998048e2c8d|"Although software testing is key to a safe society, the process itself is often perceived by students as boring and stressful. Therefore, only few consider a career in testing. The adverse effect is sub-optimally tested code, with dangerous bugs left undetected. A better understanding of what testers ""feel""when learning the skill in class can remedy this situation, by means of personalized, motivating bio-feedback. In order to test our hypothesis, we propose an innovative approach that uses physiological wearable sensors (cardiac activity, respiration, and skin conductance) to monitor in real-time the affective state of testers engaged in a bug-hunting game. This is a work in progress. We present the envisioned methodology and the results of two feasibility experiments. The first experiment created a training dataset, by recording bio-signals and self-reports from eleven participants involved in a mood-induction session followed by a bug-hunting task. The second experiment showed that it is possible to use deep-learning to recognize emotions from a large set of labelled multimodal (ECG, EDA and ICG) physiological data. The classification accuracy using a binary (positive-negative) emotions model was 85%, higher than the accuracy obtained using a four-emotions (anxious, down, enthusiastic and relaxed) model (57%). Future work includes optimizing the sensory system, improving the accuracy of automated emotions recognition, increasing the validity of ground-truth emotions labelling, and investigating ways to provide individualized and formative (instead of summative) bio-feedback. The proposed approach can contribute to a more sentiment-aware education, and a more objective evaluation of the effect of teaching interventions. © 2024 Owner/Author."|automated emotion recognition; biometric ECG signals; bug-hunting gamification; deep-learning; sentiment analysis; software testing education|Biomedical signal processing; Deep learning; Electrocardiography; Feedback; Learning systems; Physiology; Software testing; Automated emotion recognition; Biometric ECG signal; Bug hunting; Bug-hunting gamification; Deep-learning; ECG signals; Emotion recognition; Gamification; Sentiment analysis; Software testing education; Software testings; Emotion Recognition|Conference paper|Final||Scopus|2-s2.0-85198901025
scopus||||ISSTA 2024 - Proceedings of the 33rd ACM SIGSOFT International Symposium on Software Testing and Analysis|2024|ISSTA 2024 - Proceedings of the 33rd ACM SIGSOFT International Symposium on Software Testing and Analysis||||||1941|0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205532430&partnerID=40&md5=6b4be4075630f8009cb372451978e06f|The proceedings contain 170 papers. The topics discussed include: detecting build dependency errors in incremental builds; face it yourselves: an LLM-based two-stage strategy to localize configuration errors via logs; FastLog: an end-to-end method to efficiently generate and insert logging statements; FortifyPatch: towards tamper-resistant live patching in Linux-based hypervisor; Unimocg: modular call-graph algorithms for consistent handling of language features; precise compositional buffer overflow detection via heap Disjointness; enhancing ROS system fuzzing through callback tracing; total recall? how good are static call graphs really?; CoderUJB: an executable and unified java benchmark for practical programming scenarios; CEBin: a cost-effective framework for large-scale binary code similarity detection; and model-less is the best model: generating pure code implementations to replace on-device DL models.|||Conference review|Final||Scopus|2-s2.0-85205532430
scopus|Sheng J.; Lin Y.; Wu J.; Huang Y.; Shi J.; Zhang M.; Wang X.|Sheng, Junjie (57219588412); Lin, Yanqiu (59672491800); Wu, Jiehao (59672491900); Huang, Yanhong (36622096100); Shi, Jianqi (24345145700); Zhang, Min (59619795200); Wang, Xiangfeng (55000633400)|57219588412; 59672491800; 59672491900; 36622096100; 24345145700; 59619795200; 55000633400|SolSearch: An LLM-Driven Framework for Efficient SAT-Solving Code Generation|2025|Proceedings - International Conference on Software Engineering||||6|10|4|0|10.1109/ICSE-NIER66352.2025.00007|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105008498097&doi=10.1109%2fICSE-NIER66352.2025.00007&partnerID=40&md5=7be033f68641a609c323254c301b6449|The Satisfiability (SAT) problem is a core challenge with significant applications in software engineering, including automated testing, configuration management, and program verification. This paper presents SolSearch, a novel framework that harnesses large language models (LLMs) to discover and optimize SAT-solving strategies automatically. Leveraging a curriculum-based, trial-and-error process, SolSearch enables the LLM to iteratively modify and generate SAT solver code, thereby improving solving efficiency and performance. This automated SAT-solving paradigm has the advantage of being plug-and-play, allowing integration with any SAT solver and accelerating the development or design process of new SAT solvers (new methods). Our preliminary experimental results are encouraging by demonstrating that the LLM-powered paradigm improves state-of-the-art SAT solvers on general SAT benchmarks and significantly enhances the performance of the widely used Z3 solver (11% on PAR-2 score). These results highlight the potential for using LLM-driven methods to advance solver adaptability and effectiveness in real-world software engineering challenges. Future research directions are discussed to further refine and validate this approach, offering a promising avenue for integrating AI with traditional software engineering tasks.  © 2025 IEEE.|Code Generation; Heuristic Method; Large Language Models (LLM); SAT Solver|Application programs; Automatic programming; Benchmarking; Codes (symbols); Iterative methods; Software testing; Verification; Automated testing; Codegeneration; Configuration management; Language model; Large language model; Model-driven; Satisfiability problems; Satisfiability solvers; Satisfiability solving; Testing configurations; Heuristic methods|Conference paper|Final||Scopus|2-s2.0-105008498097
scopus|Fatwanto A.; Nur Aslam M.; Ndugi R.; Syafrudin M.|Fatwanto, Agung (24724254600); Nur Aslam, Muh (59742517600); Ndugi, Rebbecah (59742681400); Syafrudin, Muhammad (57197741727)|24724254600; 59742517600; 59742681400; 57197741727|An Investigation Towards Resampling Techniques and Classification Algorithms on CM1 NASA PROMISE Dataset for Software Defect Prediction|2024|Jurnal RESTI|8|5||631|643|12|0|10.29207/resti.v8i5.5910|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002996874&doi=10.29207%2fresti.v8i5.5910&partnerID=40&md5=05a4ce30b8aa0c727a0a46a098eb87d7|Software defect prediction is a practical approach to improving the quality and efficiency of software testing processes. However, establishing robust and trustworthy models for software defect prediction is quite challenging due to the limitation of historical datasets that most developers are capable of collecting. The inherently imbalanced nature of most software defect datasets also posed another problem. Therefore, an insight into how to properly construct software defect prediction models on a small, yet imbalanced, dataset is required. The objective of this study is therefore to provide the required insight by way of investigating and comparing a number of resampling techniques, classification algorithms, and evaluation measurements (metrics) for building software defect prediction models on CM1 NASA PROMISE data as the representation of a small yet unbalanced dataset. This study is comparative descriptive research. It follows a positivist (quantitative) approach. Data were collected through observation towards experiments on four categories of resampling techniques (oversampling, under sampling, ensemble, and combine) combined with three categories of machine learning classification algorithms (traditional, ensemble, and neural network) to predict defective software modules on CM1 NASA PROMISE dataset. Training processes were carried out twice, each of which used the 5-fold cross-validation and the 70% training and 30% testing data splitting (holdout) method. Our result shows that the combined and oversampling techniques provide a positive effect on the performance of the models. In the context of classification models, ensemble-based algorithms, which extend the decision tree classification mechanism such as Random Forest and eXtreme Gradient Boosting, achieved sufficiently good performance for predicting defective software modules. Regarding the evaluation measurements, the combined and rank-based performance metrics yielded modest variance values, which is deemed suitable for evaluating the performance of the models in this context. © 2024, Ikatan Ahli Informatika Indonesia. All rights reserved.|classification algorithm; imbalanced data; machine learning; resampling; software defect prediction||Article|Final|All Open Access; Gold Open Access|Scopus|2-s2.0-105002996874
scopus|Mezzaro S.; Gambi A.; Fraser G.|Mezzaro, Simone (59203387100); Gambi, Alessio (23466827200); Fraser, Gordon (9247521200)|59203387100; 23466827200; 9247521200|An Empirical Study on How Large Language Models Impact Software Testing Learning|2024|ACM International Conference Proceeding Series||||555|564|9|1|10.1145/3661167.3661273|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197399801&doi=10.1145%2f3661167.3661273&partnerID=40&md5=3622263ccc8eea569c188b32a9e9689c|"Software testing is a challenging topic in software engineering education and requires creative approaches to engage learners. For example, the Code Defenders game has students compete over a Java class under test by writing effective tests and mutants. While such gamified approaches deal with problems of motivation and engagement, students may nevertheless require help to put testing concepts into practice. The recent widespread diffusion of Generative AI and Large Language Models raises the question of whether and how these disruptive technologies could address this problem, for example, by providing explanations of unclear topics and guidance for writing tests. However, such technologies might also be misused or produce inaccurate answers, which would negatively impact learning. To shed more light on this situation, we conducted the first empirical study investigating how students learn and practice new software testing concepts in the context of the Code Defenders testing game, supported by a smart assistant based on a widely known, commercial Large Language Model. Our study shows that students had unrealistic expectations about the smart assistant, ""blindly""trusting any output it generated, and often trying to use it to obtain solutions for testing exercises directly. Consequently, students who resorted to the smart assistant more often were less effective and efficient than those who did not. For instance, they wrote 8.6% fewer tests, and their tests were not useful in 78.0% of the cases. We conclude that giving unrestricted and unguided access to Large Language Models might generally impair learning. Thus, we believe our study helps to raise awareness about the implications of using Generative AI and Large Language Models in Computer Science Education and provides guidance towards developing better and smarter learning tools. © 2024 Owner/Author."|ChatGPT; Computer Science Education; Generative AI; Smart Learning Assistant|Codes (symbols); Computational linguistics; Education computing; Engineering education; Learning systems; Students; ChatGPT; Computer Science Education; Creatives; Empirical studies; Generative AI; Language model; Learning assistant; Smart learning assistant; Software engineering education; Software testings; Software testing|Conference paper|Final||Scopus|2-s2.0-85197399801
scopus|Park S.; Kim J.|Park, Soohyun (57210251609); Kim, Joongheon (8866990900)|57210251609; 8866990900|Trends in quantum reinforcement learning: State-of-the-arts and the road ahead|2024|ETRI Journal|46|5||748|758|10|4|10.4218/etrij.2024-0153|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205590960&doi=10.4218%2fetrij.2024-0153&partnerID=40&md5=ede59e67f864057c7a9effcfd431b9b8|This paper presents the basic quantum reinforcement learning theory and its applications to various engineering problems. With the advances in quantum computing and deep learning technologies, various research works have focused on quantum deep learning and quantum machine learning. In this paper, quantum neural network (QNN)-based reinforcement learning (RL) models are discussed and introduced. Moreover, the pros of the QNN-based RL algorithms and models, such as fast training, high scalability, and efficient learning parameter utilization, are presented along with various research results. In addition, one of the well-known multi-agent extensions of QNN-based RL models, the quantum centralized-critic and multiple-actor network, is also discussed and its applications to multi-agent cooperation and coordination are introduced. Finally, the applications and future research directions are introduced and discussed in terms of federated learning, split learning, autonomous control, and quantum deep learning software testing. 1225-6463/$ © 2024 ETRI.|quantum computing; quantum machine learning; quantum neural networks; quantum reinforcement learning|Adversarial machine learning; Application programs; Contrastive Learning; Deep learning; Deep reinforcement learning; Federated learning; Quantum electronics; Quantum optics; Reinforcement learning; Software testing; ITS applications; Machine-learning; Network-based; Quantum Computing; Quantum machine learning; Quantum machines; Quantum neural networks; Quantum reinforcement learning; Reinforcement learning models; State of the art; Quantum computers|Article|Final|All Open Access; Gold Open Access|Scopus|2-s2.0-85205590960
scopus|Mhiri I.; Börsig M.; Stark A.; Baumgart I.|Mhiri, Ibrahim (59605483700); Börsig, Matthias (57212304037); Stark, Akim (59124432300); Baumgart, Ingmar (24477278400)|59605483700; 57212304037; 59124432300; 24477278400|How to Train Your Llama – Efficient Grammar-Based Application Fuzzing Using Large Language Models|2025|Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) |15396 LNCS|||239|257|18|0|10.1007/978-3-031-79007-2_13|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218503387&doi=10.1007%2f978-3-031-79007-2_13&partnerID=40&md5=6863176b5c389521cba18dfb269e5cba|Fuzzing is an automated testing technique that generates random input to identify software bugs and vulnerabilities by provoking unexpected behavior. Although effective, traditional fuzzing lacks input generation guidance, which often leads to inefficiency and wasted time, especially for complex programs, because many inputs are invalid and are rejected. Grammar-based fuzzers address this problem by generating inputs that match the syntactic structure of the program, although they require expert knowledge to define accurate grammars. Large Language Models (LLMs) show remarkable capabilities in Natural Language Processing (NLP), improving efficiency in various domains. These models can be used to generate input for fuzzers, as they can quickly learn or already have familiarity with the required input formats. This paper explores the integration of LLMs with fuzzing methods to streamline directed input generation and thereby increase fuzzing efficiency. We specifically adapt Llama2 for use with American Fuzzy Lop (AFL), focusing on Extensible Markup Language (XML) due to its commonality as a structured file format. Our approach demonstrates the potential of LLMs to enhance traditional fuzzing by providing targeted, intelligent input generation. Experimental results show that our approach can achieve up to six times more code coverage after 24 h compared to using AFL alone. Furthermore, in our tests, our method provides up to 50% more coverage than a grammar-based fuzzer. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.|Fine-Tuning; Fuzzing; Grammar-Based Fuzzing; Large Language Models; Llama2; Prompt-Tuning; XML|Automatic test pattern generation; Context free grammars; Context sensitive grammars; Input output programs; Modeling languages; Natural language processing systems; Problem oriented languages; Program debugging; Syntactics; XML; Automated testing; Fine tuning; Fuzzing; Grammar-based fuzzing; Language model; Large language model; Llama2; Prompt-tuning; Random input; Testing technique; Software testing|Conference paper|Final||Scopus|2-s2.0-85218503387
scopus|Leotta M.; Ricca F.; Marchetto A.; Olianas D.|Leotta, Maurizio (37104276100); Ricca, Filippo (24822686600); Marchetto, Alessandro (23971457800); Olianas, Dario (57204112928)|37104276100; 24822686600; 23971457800; 57204112928|An empirical study to compare three web test automation approaches: NLP-based, programmable, and capture&replay|2024|Journal of Software: Evolution and Process|36|5|e2606||||8|10.1002/smr.2606|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168138686&doi=10.1002%2fsmr.2606&partnerID=40&md5=78e4702ab7b49c13b1c921b1b2b3a7fc|A new advancement in test automation is the use of natural language processing (NLP) to generate test cases (or test scripts) from natural language text. NLP is innovative in this context and promises of reducing test cases creation time and simplifying understanding for “non-developer” software testers as well. Recently, many vendors have launched on the market many proposals of NLP-based tools and testing frameworks but their superiority has never been empirically validated. This paper investigates the adoption of NLP-based test automation in the web context with a series of case studies conducted to compare the costs of the NLP testing approach—measured in terms of test cases development and test cases evolution—with respect to more consolidated approaches, that is, programmable (or script-based) testing and capture&replay testing. The results of our study show that NLP-based test automation appears to be competitive for small- to medium-sized test suites such as those considered in our empirical study. It minimizes the total cumulative cost (development and evolution) and does not require software testers with programming skills. © 2023 The Authors. Journal of Software: Evolution and Process published by John Wiley & Sons Ltd.|empirical study; natural language processing; page object pattern; Selenium; test automation; web testing|Automation; Natural language processing systems; Selenium; Capture-replay; Empirical studies; Language processing; Natural language processing; Natural languages; Object patterns; Page object pattern; Test Automation; Test case; Web testing; Software testing|Article|Final|All Open Access; Green Open Access; Hybrid Gold Open Access|Scopus|2-s2.0-85168138686
scopus|Speth S.; Pretschner A.|Speth, Simon (57718383300); Pretschner, Alexander (12645083400)|57718383300; 12645083400|GeMTest: A General Metamorphic Testing Framework|2025|Proceedings - International Conference on Software Engineering||||41|44|3|1|10.1109/ICSE-Companion66252.2025.00020|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105008489145&doi=10.1109%2fICSE-Companion66252.2025.00020&partnerID=40&md5=ff5eda9249a6bb33b0f7ab1ea0ce6401|Metamorphic testing (MT) is an established software testing methodology suitable for testing various types of systems under test (SUTs), but identifying and implementing metamorphic relations (MRs) remains a challenge. This paper presents GeMTest, a general-purpose metamorphic testing framework that is domain-independent, enabling software testers to implement MRs in Python and execute them with pytest. In GeMTest, MRs are implemented using custom decorators to annotate Python functions, which specify the follow-up generation function, the metamorphic oracle, and the SUT. GeMTest then automatically creates and executes a pytest test suite containing multiple metamorphic test cases derived from the user-defined MRs. We evaluate GeMTest on 16 program domains, ranging from trigonometric functions to deep learning image classifiers, implementing in total over 200 MRs. To enable the adoption and encourage further extension, the open-source implementation of GeMTest is available on GitHub. Our demo video is available at https://youtu.be/EcSSK-meu90. © 2025 IEEE.|metamorphic testing; pytest; python; testing framework; tool|Computer vision; Deep learning; Open source software; Open systems; Python; Software testing; Domain independents; Follow up; Metamorphic relations; Metamorphic testing; Pytest; Software testings; Systems under tests; Test case; Testing framework; Testing methodology; Tools|Conference paper|Final||Scopus|2-s2.0-105008489145
scopus|Erol E.; Senan S.|Erol, Ekrem (59153474800); Senan, Sibel (8268513100)|59153474800; 8268513100|Enhancing software testing through artificial intelligence: A comprehensive review|2024|Advancing Software Engineering Through AI, Federated Learning, and Large Language Models||||183|200|17|0|10.4018/979-8-3693-3502-4.ch012|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194993245&doi=10.4018%2f979-8-3693-3502-4.ch012&partnerID=40&md5=ffa0854048a1e0452c03754f2df38bb6|Software testing, a pivotal phase in the software development lifecycle, is becoming increasingly challenging with the escalating complexity of modern software. Traditional testing methods are often inadequate in this evolving landscape. As AI continues to advance, its application in software testing is anticipated to lead to more efficient and effective processes, potentially transforming the entire software development lifecycle. This study focuses on conducting an in-depth analysis of the integration of artificial intelligence (AI) in software testing. By thoroughly analyzing and comparing a wide range of AI methodologies, this chapter aims to provide a comprehensive understanding of AI's current and future role in software testing, serving as a valuable resource for both practitioners and researchers in the field. © 2024, IGI Global. All rights reserved.|||Book chapter|Final||Scopus|2-s2.0-85194993245
scopus||||33rd International Conference on Software and Data Engineering, SEDE 2024|2025|Communications in Computer and Information Science|2244 CCIS|||||201|0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207838337&partnerID=40&md5=53e3af3b37346b63cc6ef216daa8f852|The proceedings contain 14 papers. The special focus in this conference is on Software and Data Engineering. The topics include: Embracing Residuality Theory in Software Architecture to Address Uncertainty: Key Challenges and Strategies; zoned Role-Based Approach to System Design, Implementation, and Access Control of Integrated Web Applications; enhancing IoT Network Defense: A Comparative Study of Machine Learning Algorithms for Attack Classification; a Survey and Insights on Modern Game Development Processes for Software Engineering Education; evaluating the Impact of Combinatorial Interaction Testing on Test Automation: A Case Study from Industry; JSMBox—A Runtime Monitoring Framework for Analyzing and Classifying Malicious JavaScript; securing Wireless Sensor Network from Rank Attack Using Fast Sensor Data Encryption and Decryption Protocol; Enhancing Transparency and Privacy in Financial Fraud Detection: The Integration of Explainable AI and Federated Learning; Enhancing Generative AI Chatbot Accuracy Using Knowledge Graph; ReVisE: Emulated Visual Outfit Generation from User Reviews Using Generative-AI; A Case Study on AI to Automate Simulation Modelling; racial Disparity in Breast Cancer Prognosis.|||Conference review|Final||Scopus|2-s2.0-85207838337
scopus|Patil A.; Jadon A.|Patil, Avinash (57979579300); Jadon, Aryan (57979202600)|57979579300; 57979202600|Next-Generation Bug Reporting: Enhancing Development with AI Automation|2025|International Conference on Signal Processing and Communication, ICSC||2025||487|493|6|0|10.1109/ICSC64553.2025.10968932|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105005725272&doi=10.1109%2fICSC64553.2025.10968932&partnerID=40&md5=7ea90ebdb931d34d614254857acb66b0|In today's Agile and DevOps-driven software development landscape, rapid and accurate bug reporting is critical. This paper presents a next-generation automation tool powered by large language models and machine learning, innovating the bug reporting process. The tool automates various phases of bug reporting, such as failure detection, severity assessment, duplicate detection, and report generation. By addressing the limitations of manual bug reporting such as inconsistency, scalability challenges, and time inefficiencies, the proposed solution enhances the software testing workflow. Initial findings demonstrate significant time savings, reduced manual errors, and improved collaboration between testers and developers. This work establishes a foundation for fully automated bug reporting, poised to accelerate software development cycles and maintain high-quality standards. © 2025 IEEE.|Automated Bug Reporting; Bug Creation; Data Collection; Duplicate Detection; Failure Detection; Large Language Models; Machine Learning; Quality Metrics; Report Formatting; Severity Assessment|Computer software selection and evaluation; DevOps; Report generators; Software design; Software quality; Software testing; Automated bug reporting; Bug creation; Bug reporting; Data collection; Duplicate detection; Failure detection; Language model; Large language model; Machine-learning; Quality metrices; Report formatting; Severity assessment; Model checking|Conference paper|Final||Scopus|2-s2.0-105005725272
scopus|Alier-Forment M.; Pereira-Valera J.; Casañ-Guerrero M.J.; Garcia-Penalvo F.J.|Alier-Forment, Marc (57193538889); Pereira-Valera, Juanan (59947051100); Casañ-Guerrero, Maria Jose (57231716300); Garcia-Penalvo, Francisco Jose (16031087300)|57193538889; 59947051100; 57231716300; 16031087300|Enhancing Learning Assistant Quality Through Automated Feedback Analysis and Systematic Testing in the LAMB Framework|2025|Lecture Notes in Computer Science|15807 LNCS|||3|12|9|0|10.1007/978-3-031-93567-1_1|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105008203325&doi=10.1007%2f978-3-031-93567-1_1&partnerID=40&md5=32b7c57a5c54c7a74460e1d29b001c62|The Learning Assistant Manager and Builder (LAMB) is an open-source software framework that lets educators build and deploy AI learning assistants within institutional Learning Management Systems (LMS) without coding expertise. It addresses critical challenges in educational AI by providing privacy-focused integration, controlled knowledge bases, and seamless deployment through standard protocols. This paper presents major enhancements that enable systematic quality assurance and continuous improvement of these learning assistants. The new LAMB includes mechanisms for structured feedback on real-world assistant behavior, transforming it into a test suite with curated prompts and expected correct or incorrect responses. When changes are made—such as prompt engineering, retrieval-augmented generation optimization, or knowledge base expansions—this suite enables automated validation of their impact. A key innovation is using frontier large language models (LLMs) to evaluate responses automatically, generating detailed reports that reveal improvement areas and confirm performance gains. This systematic feedback-driven testing fosters continuous refinement while preserving quality standards. Validation studies show measurable boosts in reliability and consistency. In various educational contexts, the framework identifies edge cases, maintains consistency across iterations, and provides actionable insights. Automated testing is especially beneficial for assistants with extensive knowledge bases and complex interaction patterns. This work advances educational AI by providing a robust methodology for quality assurance and ongoing improvement of learning assistants. Its structured feedback and automated evaluations ensure alignment with educational goals while refining assistants over time. The enhanced LAMB framework offers a scalable and reliable solution for educators aiming to integrate AI-driven support into their LMS environments. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.|artificial intelligence in education; automated testing; continuous improvement; Learning assistants; LLM Evals; prompt engineering; quality assurance; retrieval-augmented generation|Automatic test pattern generation; Automation; Engineering education; Knowledge based systems; Learning systems; Open source software; Open systems; Quality control; Verification; Artificial intelligence in education; Automated feedback; Automated testing; Continuous improvements; Language model; Large language model evals; Learning assistant; Learning management system; Prompt engineering; Retrieval-augmented generation; Quality assurance|Conference paper|Final||Scopus|2-s2.0-105008203325
scopus|Goetz M.|Goetz, Marie (60009445600)|60009445600|Enhancing the Validation of Human Factors in User Interface Software Testing with AI|2025|Lecture Notes in Computer Science|15769 LNCS|||59|76|17|0|10.1007/978-3-031-93861-0_4|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105011347869&doi=10.1007%2f978-3-031-93861-0_4&partnerID=40&md5=a000cc75cda8fa365940d968a466efa1|This paper introduces a novel approach to human factor focused software testing in the loop that combines Optical Character Recognition (OCR), and large language models (LLMs) for scenario-driven, non-intrusive testing of graphical user interfaces (GUIs). By defining a testing scenario and analyzing a captured image of the UI, the system identifies visual elements using OCR and detection algorithms, storing them in a standardized format. This output serves as input for an LLM, which interprets scenario requirements and generates user actions, such as mouse clicks or keyboard inputs, to achieve the defined objectives. The system operates in a closed loop, iterating until the target outcome, e.g., the scenario is achieved, failures are detected, or usability metrics are generated. This non-intrusive method avoids software modification, making it ideal for cases where direct instrumentation is infeasible, like closed-source software. Fine-tuning the LLM for domain-specific metrics, such as cognitive load and task complexity, enhances usability testing by simulating users with varying expertise. The concept also supports environmental simulations, enabling realistic testing of safety-critical systems like automotive or aviation software. This idea offers a scalable and flexible addition to traditional GUI testing, enabling early in the software development loop human factor insights, and a first level of functionality validation for safety-relevant applications. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.|Error Detection; Evaluation; Human Factors; Large Language Model; Testing in the Loop; Usability; User Studies; Workload|Application programs; Cognitive systems; Graphical user interfaces; Human computer interaction; Human engineering; Safety factor; Security systems; Software design; Software testing; Usability engineering; Verification; Evaluation; Language model; Large language model; Optical-; Software testings; Testing in the loop; Usability; User interface software; User study; Workload; Safety testing|Conference paper|Final||Scopus|2-s2.0-105011347869
scopus|Franzosi D.B.; Alegroth E.; Isaac M.|Franzosi, Diogo Buarque (59934458100); Alegroth, Emil (55843479600); Isaac, Maycel (57545825900)|59934458100; 55843479600; 57545825900|LLM-Based Labelling of Recorded Automated GUI-Based Test Cases|2025|2025 IEEE Conference on Software Testing, Verification and Validation, ICST 2025||||453|463|10|0|10.1109/ICST62969.2025.10988984|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007522870&doi=10.1109%2fICST62969.2025.10988984&partnerID=40&md5=013f2fbd0c6fdf0833d74d31e6ae2cfd|Graphical User Interface (GUI) based testing is a commonly used practice in industry. Although valuable and, in many cases, necessary, it is associated with challenges such as high cost and requirements on both technical and domain expertise. Augmented testing, a novel approach to GUI test automation, aims to mitigate these challenges by allowing users to record and render test cases and test data directly on the GUI of the system under test (SUT). In this context, Scout is an augmented testing tool that captures system states and transitions during manual interaction with the SUT, storing them in a test model that is visually represented in the form of state trees and reports. While this representation provides basic overview of a test suite, e.g. about its size and number of scenarios, it is limited in terms of analysis depth, interpretability, and reproducibility. In particular, without human state labeling, it is challenging to produce meaningful and easily understandable test reports. To address this limitation, we present a novel solution and a demonstrator, integrated into Scout, which leverages large language models (LLMs) to enrich the model-based test case representation by automatically labeling and describing states and describing transitions. We conducted two experiments to evaluate the impact of the solution. First, we compared LLM-enhanced reports with expert-generated reports using embedding distance evaluation metrics. Second, we assessed the usability and perceived value of the enhanced reports through an industrial survey. The results of the study indicate that the plugin can improve readability, actionability, and interpretability of test reports. This work contributes to the automation of GUI testing by reducing the need for manual intervention, e.g. labeling, and technical expertise, e.g. to understand test case models. Although the solution is studied in the context of augmented testing, we argue for the solution's generalizability to related test automation techniques. In addition, we argue that this approach enables actionable insights and lays the groundwork for further research into autonomous testing based on Generative AI. © 2025 IEEE.||High costs; Interpretability; Labelings; Language model; Model-based OPC; Systems under tests; Technical expertise; Test Automation; Test case; Test reports; Graphical user interfaces|Conference paper|Final||Scopus|2-s2.0-105007522870
scopus|Parsa S.; Zakeri-Nasrabadi M.; Turhan B.|Parsa, Saeed (8407441400); Zakeri-Nasrabadi, Morteza (57219747851); Turhan, Burak (21744228000)|8407441400; 57219747851; 21744228000|Testability-driven development: An improvement to the TDD efficiency|2025|Computer Standards and Interfaces|91||103877||||1|10.1016/j.csi.2024.103877|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195814781&doi=10.1016%2fj.csi.2024.103877&partnerID=40&md5=a0bfbccdc6d8bbde5634e344f19e0c20|Test-first development (TFD) is a software development approach involving automated tests before writing the actual code. TFD offers many benefits, such as improving code quality, reducing debugging time, and enabling easier refactoring. However, TFD also poses challenges and limitations, requiring more effort and time to write and maintain test cases, especially for large and complex projects. Refactoring for testability is improving the internal structure of source code to make it easier to test. Refactoring for testability can reduce the cost and complexity of software testing and speed up the test-first life cycle. However, measuring testability is a vital step before refactoring for testability, as it provides a baseline for evaluating the current state of the software and identifying the areas that need improvement. This paper proposes a mathematical model for calculating class testability based on test effectiveness and effort and a machine-learning regression model that predicts testability using source code metrics. It also introduces a testability-driven development (TsDD) method that conducts the TFD process toward developing testable code. TsDD focuses on improving testability and reducing testing costs by measuring testability frequently and refactoring to increase testability without running the program. Our testability prediction model has a mean squared error of 0.0311 and an R2 score of 0.6285. We illustrate the usefulness of TsDD by applying it to 50 Java classes from three open-source projects. TsDD achieves an average of 77.81 % improvement in the testability of these classes. Experts’ manual evaluation confirms the potential of TsDD in accelerating the TDD process. © 2024 Elsevier B.V.|Automated refactoring; Machine learning; Software methodology; Software testability; Test-first development|Cost reduction; Life cycle; Machine learning; Mean square error; Open source software; Regression analysis; Software design; Automated refactoring; Automated test; Code quality; Machine-learning; Refactorings; Software development approach; Software methodologies; Software testability; Test-first development; Testability; Software testing|Article|Final|All Open Access; Green Open Access|Scopus|2-s2.0-85195814781
scopus|de Morais Barroca Filho I.; Malaquias R.S.; de Lima J.M.M.; Gurgel A.M.; de Oliveira N.P.T.; de Oliveira Bezerra M.H.D.; Lucena G.P.L.; da Silva V.O.|de Morais Barroca Filho, Itamir (56295334600); Malaquias, Ramon Santos (57209879957); de Lima, Jean Mário Moreira (57897186700); Gurgel, André Morais (54948714800); de Oliveira, Ney Pimentel Targino (59996150300); de Oliveira Bezerra, Murilo Henrique Dantas (59995217000); Lucena, Gabriel Paes Landim (59996333000); da Silva, Vinicius Oliveira (59995778800)|56295334600; 57209879957; 57897186700; 54948714800; 59996150300; 59995217000; 59996333000; 59995778800|A Generative AI Based Architecture for Data Seeding in Software Testing|2025|Lecture Notes in Computer Science|15649 LNCS|||234|249|15|0|10.1007/978-3-031-96997-3_15|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105010638649&doi=10.1007%2f978-3-031-96997-3_15&partnerID=40&md5=efca751de85292ea21e96b07fb3709d4|In software engineering, the testing phase is critical to ensuring application quality, reliability, and adherence to defined requirements. Effective testing requires realistic, consistent data that reflects real-world conditions and exists in sufficient volumes. This makes the data seeding process indispensable. However, traditional approaches to data creation—manual or automated—face challenges such as ensuring data diversity and compliance with business rules, often resulting in inadequate test coverage with consequences in undetected bugs, reduced reliability, higher costs and compromised software quality. Thus, the goal of this paper is to present a novel generative AI-based architecture for advancing data seeding practices in software testing. The proposed architecture integrates user interaction, data embedding, and retrieval-augmented generation (RAG) to form a seamless pipeline for generating contextually relevant and realistic data in real-time. For the purposes of validating the architecture, a Proof of Concept (POC) was implemented focused on generating fake data from Brazilian customers to assess the quality of the data generated and the effectiveness of the implemented solution, in order to evaluate the potential of the architecture for the development of broader applications and in different contexts. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.|Data seeding; Generative AI; Retrieval-augmented generation; Software testing|Application programs; Artificial intelligence; Computer software selection and evaluation; Data quality; Data reliability; Quality control; Software quality; Software reliability; Application quality; Condition; Data seeding; Effective testing; Generative AI; Quality reliability; Real-world; Retrieval-augmented generation; Software testings; Testing phase; Software testing|Conference paper|Final||Scopus|2-s2.0-105010638649
scopus|Mosca N.; Renò V.; Nitti M.; Patruno C.; Negri S.P.; Stella E.|Mosca, Nicola (16553109900); Renò, Vito (56433738300); Nitti, Massimiliano (6701634197); Patruno, Cosimo (56783950500); Negri, Simone Pio (55516771800); Stella, Ettore (57405457400)|16553109900; 56433738300; 6701634197; 56783950500; 55516771800; 57405457400|VISTA — Vision-based inspection system for automated testing of aircraft interiors: A panoramic view|2024|Results in Engineering|24||103168||||3|10.1016/j.rineng.2024.103168|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206475534&doi=10.1016%2fj.rineng.2024.103168&partnerID=40&md5=96d1ab5ab0adc49f4cf4a2f45361f5b2|Automation is a driving force in manufacturing, enabling quality and scalability during production and assembly. In contrast with the automotive industry, civil aerospace automation has traditionally lagged. However, the adoption rate of methodologies embracing automation for manufacturing, assembly, and testing is now accelerating, with new technologies being tested to enable reliable and safe assembly and inspection steps. This paper introduces a semi-automated system for quality control during the final production steps of single-aisle aircraft, namely after the automated assembly of hatrack and sidewall elements in the passengers' area, but before any seating elements are assembled in the environment. Quality control is performed using color and 3d cameras mounted on a custom holonomic mobile robot. The acquired data is processed for identifying geometrical or surface defects by using machine learning based models and 3D processing-based algorithms. The results are provided to an inspector officer using different on-site and off-site validation modalities. The obtained results enable us to affirm that the proposed solution looks very promising for semi-automatic quality control, and it can serve as a foundational framework for efficient manufacturing in the aerospace industry. © 2024 The Author(s)|Aircraft interiors; Assembly lining; Computer vision; Quality control; XR validation modalities|Aerospace industry; Aircraft manufacture; Computer control; Failure analysis; Industrial robots; Inspection; Mobile robots; Outages; Robot learning; Aircraft interiors; Assembly lining; Automated testing; Automotives; Driving forces; Inspection system; Manufacturing testing; Panoramic views; Vision based inspection; XR validation modality; Automotive industry|Article|Final|All Open Access; Gold Open Access|Scopus|2-s2.0-85206475534
scopus|Augusto C.; Morán J.; Bertolino A.; de la Riva C.; Tuya J.|Augusto, Cristian (57209270692); Morán, Jesús (56511075300); Bertolino, Antonia (7006797074); de la Riva, Claudio (14053780500); Tuya, Javier (6603310027)|57209270692; 56511075300; 7006797074; 14053780500; 6603310027|Software System Testing Assisted by Large Language Models: An Exploratory Study|2025|Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) |15383 LNCS|||239|255|16|0|10.1007/978-3-031-80889-0_17|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218458241&doi=10.1007%2f978-3-031-80889-0_17&partnerID=40&md5=f27b45ef6b62d00ee62e6fa9b2d1de3c|Large language models (LLMs) based on transformer architecture have revolutionized natural language processing (NLP), demonstrating excellent capabilities in understanding and generating human-like text. In Software Engineering, LLMs have been applied in code generation, documentation, and report writing tasks, to support the developer and reduce the amount of manual work. In Software Testing, one of the cornerstones of Software Engineering, LLMs have been explored for generating test code, test inputs, automating the oracle process or generating test scenarios. However, their application to high-level testing stages such as system testing, in which a deep knowledge of the business and the technological stack is needed, remains largely unexplored. This paper presents an exploratory study about how LLMs can support system test development. Given that LLM performance depends on input data quality, the study focuses on how to query general purpose LLMs to first obtain test scenarios and then derive test cases from them. The study evaluates two popular LLMs (GPT-4o and GPT-4o-mini), using as a benchmark a European project demonstrator. The study compares two different prompt strategies and employs well-established prompt patterns, showing promising results as well as room for improvement in the application of LLMs to support system testing. © IFIP International Federation for Information Processing 2025.|Large Language Model; Software Testing; System Testing; Test Cases; Test Scenarios|Application programs; Benchmarking; Electric transformer testing; High level languages; Input output programs; Model checking; Modeling languages; Natural language processing systems; Program processors; Query languages; System program documentation; Exploratory studies; Language model; Large language model; Model-based OPC; Software system testing; Software testings; Support systems; System testing; Test case; Test scenario; Software testing|Conference paper|Final||Scopus|2-s2.0-85218458241
scopus|Saoiabi F.; Kharmoum N.; Elasri C.; Lagmiri S.N.; Ziti S.|Saoiabi, Fadwa (59124037800); Kharmoum, Nassim (57210745538); Elasri, Chaimae (59124893400); Lagmiri, Souad Najoua (56748167600); Ziti, Soumia (55999104600)|59124037800; 57210745538; 59124893400; 56748167600; 55999104600|Generative AI in Software Engineering: Enhancing Development and Innovation|2025|Lecture Notes in Networks and Systems|1330 LNNS|||315|323|8|0|10.1007/978-3-031-86698-2_28|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002722481&doi=10.1007%2f978-3-031-86698-2_28&partnerID=40&md5=0ece1c92735ef615d14b6434f28f0550|This paper focuses on the review of the literature about the effects of generative AI for SE based on a comparison of research papers on methodologies, applications, and effects on SE processes. It plans to analyze and discuss existing classifications used for the purposes of MMA-based applications, including their potential and challenges, and analyze the productivity rate according to citation scores and other parameters. Generative AI models such as GPT-3, BERT, and Transformers are also involved in the paper, and this paper focuses on automatic coding, testing, and documentation. Primary research reveals that there is high interest in using generative AI for code generation with tools like OpenAI’s Codex and DeepMind’s AlphaCode, but at the same time, it reveals that there are issues like, quality of code, dealing with ambiguous requirements and integration problems. In the review, the author also covers generative AI in context to software testing and in relation to generating documentation, increased efficiency, and the identified limitations. The study reveals new opportunities of generative AI in SE but reveals basic issues such as explicability or ethic concerns at the same time. It seeks to improve the comprehension and chart future advancements in generative AI for SE; thus, focusing on the advancement and application of the strategies and ideas in the SE process for the researchers and practitioners. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.|Automatic Coding; Code Generation; Comparative Study; Generative Artificial Intelligence; Productivity rate; SE processes; Software Engineering; Software Testing|Application programs; Automatic test pattern generation; Computer software selection and evaluation; Generative adversarial networks; Integration testing; Software quality; Automatic coding; Citation score; Codegeneration; Comparatives studies; Generative artificial intelligence; Integration problems; Productivity rate; Research papers; SE process; Software testings; Automatic programming|Conference paper|Final||Scopus|2-s2.0-105002722481
scopus|Trivedi S.; Hebbale Ramkumar R.|Trivedi, Shubham (59491197700); Hebbale Ramkumar, Ramya (59490755000)|59491197700; 59490755000|Applying AI to Reduce Software Testing Defects' Rejection|2024|SAE Technical Papers|||||||0|10.4271/2024-28-0188|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213407085&doi=10.4271%2f2024-28-0188&partnerID=40&md5=0affd98ae0d19ce90afd70ca650c2cb9|The efficiency and accuracy of defect control are critical components in software testing, as they determine the final product's quality and cost. Rejection of defects for various reasons, like non-reproducibility, erroneous classification or inadequate information, is one of the largest issues that testers face. This paper presents an AI-driven approach that reduces the number of defect rejections by using the past defect data to give testers real-time advises and warnings. When a tester reports an issue, the model looks at the problem's description and title, making inferences and recommendations based on historical data to increase the fault's correctness. This feedback strategy reduces rejection rates and increases the overall efficiency of defect management by helping testers resolve potential issues before submitting a defect. The recommended solution involves training an AI model on a large dataset of previous defects, which includes details on DefectTitle, Description, ResolutionCategory, ReasonForRejection (optionally with RejectionCategory) and ResolutionDescription to be more accurate in its recommendation. The model uses natural language processing (NLP) technique to transform textual data into meaningful numerical representations. BERT (Bidirectional Encoder Representation for Transformers) language model is deployed for understanding the context and semantics of defect titles and descriptions. Next, a binary classification technique- Random Forest Algorithm is used to predict if the issue could be accepted or denied. Regular retraining and continuous monitoring ensure that the model remains accurate and flexible over time. This paper covers in depth the deployment process, model training, data preparation, and real-world implications of deploying this system in a real software testing environment. This strategy solves a common software testing problem in a scalable and efficient manner by utilizing artificial intelligence. © 2024 Continental Automotive Components (India) Private Ltd.||Computer software selection and evaluation; Large datasets; Modeling languages; Natural language processing systems; Software testing; Syntactics; Critical component; Defects control; Feedback strategies; Historical data; Non-reproducibility; Problem description; Product cost; Products quality; Real- time; Software testings; Semantics|Conference paper|Final||Scopus|2-s2.0-85213407085
scopus||||Proceedings - 2025 IEEE/ACM 9th International Workshop on Games and Software Engineering, GAS 2025|2025|Proceedings - 2025 IEEE/ACM 9th International Workshop on Games and Software Engineering, GAS 2025||||||50|0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-105009138011&partnerID=40&md5=582a9833695a0f7c6436376d6943ab8c|The proceedings contain 6 papers. The topics discussed include: preventing client-side exploits in games with capability architectures; a mapping study of the entity component system pattern; type token: a competitive, collaborative modeling game for ontology education and development; a mapping of recording-based game test automation tools; generative AI for facial expressions in 3D game characters: a retrieval-augmented approach; and towards a framework for exploratory testing in video games.|||Conference review|Final||Scopus|2-s2.0-105009138011
scopus|Alqurashi S.|Alqurashi, Saja (57188735669)|57188735669|Towards Automated Security and Privacy Policies Specification and Analysis|2025|Proceedings - IEEE International Conference on Mobile Data Management||||182|184|2|0|10.1109/MDM65600.2025.00043|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105011042769&doi=10.1109%2fMDM65600.2025.00043&partnerID=40&md5=9b7b68651fa49466d44297be209cd85c|Security and privacy policies, vital for information systems, are typically expressed in natural language documents. Security policy is represented by Access Control Policies (ACPs) within security requirements, initially drafted in natural language and subsequently translated into enforceable policy. The unstructured and ambiguous nature of the natural language documents makes the manual translation process tedious, expensive, labor-intensive, and prone to errors. On the other hand, Privacy policy, with its length and complexity, presents unique challenges. The dense language and extensive content of the privacy policies can be overwhelming, hindering both novice users and experts from fully understanding the practices related to data collection and sharing. The disclosure of these data practices to users, as mandated by privacy regulations such as the General Data Protection Regulation (GDPR) and the California Consumer Privacy Act (CCPA), is of utmost importance. To address these challenges, we have turned to Natural Language Processing (NLP) to automate extracting critical information from natural language documents and analyze those security and privacy policies. Addressing these challenges necessitates the development of a comprehensive framework comprising two key components. The first component, SR2ACM, focuses on translating natural language ACPs into the NGAC model. This component introduces a series of innovative contributions to the analysis of security policies. At the core of our contributions is an automated approach to constructing ACPs within the NGAC specification directly from natural language documents. Our approach integrates machine learning with software testing, a novel methodology to ensure the quality of the extracted access control model. The second component, Privacy2Practice, is designed to automate the extraction and analysis of the data practices from privacy policies written in natural language. We have developed an automated method to extract data practices mandated by privacy regulations and to analyze the disclosure of these data practices within the privacy policies. The novelty of this research lies in creating a comprehensive framework that identifies the critical elements within security and privacy policies. Thus, this innovative framework enables automated extraction and analysis of both types of policies directly from natural language documents.  © 2025 IEEE.|Access Control Policies (ACPs); Privacy Policy|Access control; Artificial intelligence; Consumer protection; Data privacy; Natural language processing systems; Quality control; Software testing; Specifications; Translation (languages); Access control policies; Access control policy; Data practices; Natural languages; Policy analysis; Policy specification; Privacy policies; Privacy regulation; Security and privacy; Security policy; Automation|Conference paper|Final||Scopus|2-s2.0-105011042769
scopus|Yi H.T.|Yi, He Tian (59359958900)|59359958900|Applying Artificial Intelligence for Emotional Cognition in Game Testing for Quality Assurance|2024|Journal of Ecohumanism|3|6||1447|1452|5|0|10.62754/joe.v3i6.4109|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205901064&doi=10.62754%2fjoe.v3i6.4109&partnerID=40&md5=9c85f97b0812fa593efd1649e76a1b94|Artificial intelligence (AI) is a branch of computer science that tries to develop computational tools and systems that can carry out tasks comparable to human decision-making and learning. The subject of AI is expanding quickly, and AI technology is becoming more and more significant in a variety of IT specialties. When more automated and intelligent solutions are employed instead of outdat ed techniques, the quantity of manpower and resources needed for game testing will be greatly decreased. The aim of this study is to find new models that will make game testing easier by utilising state-of-the-art AI techniques. In an attempt to determine the model base and algorithmic foundation for the new approach, the examination and comparison of existing theories, models, and algorithms is used to infer and identify the viability of certain current mainstream AI models and algorithms in game testing sessions. Standard software testing is not the same as game testing. Further consideration should be given to the whole gaming experience and entertainment value in addition to functional testing. User questionnaires and in-game testing are used in the current standard experience testing methodology. Artificial intelligence eliminates human aspects in emotional cognition. It may produce more objective test results while spending less money for both human and material resources by using massive data sets and its own learning and processing capabilities. This paper examines the state of AI in software testing, game creation, and emotion perception using expertise in using and applying AI approaches in game testing for quality assurance. It also demonstrates how well AI methods work for predicting player emotions during game testing. The AI testing reduces testing expenses related to labour and material resources while guaranteeing total game confidentiality before release. It also increases test accuracy and reduces the impact of subjectivity. © 2024, Creative Publishing House. All rights reserved.|Artificial Intelligence; Game Testing; Quality||Article|Final||Scopus|2-s2.0-85205901064
scopus|Patel S.; Patil K.; Chumchu P.|Patel, Soham (59239916300); Patil, Kailas (49862163900); Chumchu, Prawit (6603497525)|59239916300; 49862163900; 6603497525|BHRAMARI: Bug driven highly reusable automated model for automated test bed generation and integration|2024|Software Impacts|21||100687||||4|10.1016/j.simpa.2024.100687|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199965488&doi=10.1016%2fj.simpa.2024.100687&partnerID=40&md5=3726f6cfc9a05b3778ba430d8faad05c|Ensuring software quality is critical aspect of the development process, with test beds playing a vital role in validating applications under several conditions. Traditional methods of test bed generation are time-consuming and often fail to cover wide range of testing scenarios. To address these challenges, we introduce a novel test bed generator software application BHRAMARI that automates the creation of test beds with high-quality code smells and samples. The integration of advanced technologies such as natural language processing and generative-AI paves the way for a new era in software testing, where automation and innovation ensure the highest standards of reliability. © 2024 The Author(s)|Software engineering; Software preventative testing; Software TestBeds; Software testing; Software tool; TestBeds||Article|Final||Scopus|2-s2.0-85199965488
scopus|De Oliveira Neto F.G.|De Oliveira Neto, Francisco Gomes (35247739300)|35247739300|Unveiling Assumptions: Exploring the Decisions of AI Chatbots and Human Testers|2024|AIware 2024 - Proceedings of the 1st ACM International Conference on AI-Powered Software, Co-located with: ESEC/FSE 2024||||45|49|4|0|10.1145/3664646.3664762|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199918537&doi=10.1145%2f3664646.3664762&partnerID=40&md5=2fcc7f1a54a885482d6960657db320a7|"The integration of Large Language Models (LLMs) and chatbots introduces new challenges and opportunities for decision-making in software testing. Decision-making relies on a variety of information, including code, requirements specifications, and other software artifacts that are often unclear or exist solely in the developer's mind. To fill in the gaps left by unclear information, we often rely on assumptions, intuition, or previous experiences to make decisions. This paper explores the potential of LLM-based chatbots like Bard, Copilot, and ChatGPT, to support software testers in test decisions such as prioritizing test cases effectively. We investigate whether LLM-based chatbots and human testers share similar ""assumptions""or intuition in prohibitive testing scenarios where exhaustive execution of test cases is often impractical. Preliminary results from a survey of 127 testers indicate a preference for diverse test scenarios, with a significant majority (96%) favoring dissimilar test sets. Interestingly, two out of four chatbots mirrored this preference, aligning with human intuition, while the others opted for similar test scenarios, chosen by only 3.9% of testers. Our initial insights suggest a promising avenue within the context of enhancing the collaborative dynamics between testers and chatbots. © 2024 Owner/Author."|Chatbots; Software Testing; Test Prioritization|Integration testing; Chatbots; Code requirements; Decisions makings; Language model; Model-based OPC; Requirements specifications; Software testings; Test case; Test prioritization; Test scenario; Decision making|Conference paper|Final|All Open Access; Green Open Access|Scopus|2-s2.0-85199918537
scopus|Aranda M.; Oliveira N.; Soares E.; Ribeiro M.; Romão D.; Patriota U.; Gheyi R.; Souza E.; MacHado I.|Aranda, Manoel (57930305300); Oliveira, Naelson (57192694637); Soares, Elvys (35207103400); Ribeiro, Márcio (57199329234); Romão, Davi (59136912800); Patriota, Ullyanne (59136892000); Gheyi, Rohit (8365747700); Souza, Emerson (58550523700); MacHado, Ivan (36998427800)|57930305300; 57192694637; 35207103400; 57199329234; 59136912800; 59136892000; 8365747700; 58550523700; 36998427800|A Catalog of Transformations to Remove Smells From Natural Language Tests|2024|ACM International Conference Proceeding Series||||7|16|9|3|10.1145/3661167.3661225|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197373673&doi=10.1145%2f3661167.3661225&partnerID=40&md5=2ae2f09c9ab663300a99343814fe436c|Test smells can pose difficulties during testing activities, such as poor maintainability, non-deterministic behavior, and incomplete verification. Existing research has extensively addressed test smells in automated software tests but little attention has been given to smells in natural language tests. While some research has identified and catalogued such smells, there is a lack of systematic approaches for their removal. Consequently, there is also a lack of tools to automatically identify and remove natural language test smells. This paper introduces a catalog of transformations designed to remove seven natural language test smells and a companion tool implemented using Natural Language Processing (NLP) techniques. Our work aims to enhance the quality and reliability of natural language tests during software development. The research employs a two-fold empirical strategy to evaluate its contributions. First, a survey involving 15 software testing professionals assesses the acceptance and usefulness of the catalog's transformations. Second, an empirical study evaluates our tool to remove natural language test smells by analyzing a sample of real-practice tests from the Ubuntu OS. The results indicate that software testing professionals find the transformations valuable. Additionally, the automated tool demonstrates a good level of precision, as evidenced by a F-Measure rate of 83.70%. © 2024 ACM.|Natural Language Test; Software Testing; Test Smells|Acceptance tests; Natural language processing systems; Odors; Software design; Software reliability; Automated tools; Deterministic behavior; Empirical studies; F measure; Language processing techniques; Natural language test; Natural languages; Software testings; Test smell; Software testing|Conference paper|Final|All Open Access; Green Open Access|Scopus|2-s2.0-85197373673
scopus|Lee J.; Chen S.; Mordahl A.; Liu C.; Yang W.; Wei S.|Lee, Jaeseong (55652687800); Chen, Simin (57225130577); Mordahl, Austin (57210920990); Liu, Cong (56043633600); Yang, Wei (55607069500); Wei, Shiyi (55497866400)|55652687800; 57225130577; 57210920990; 56043633600; 55607069500; 55497866400|Automated Testing Linguistic Capabilities of NLP Models|2024|ACM Transactions on Software Engineering and Methodology|33|7|176||||2|10.1145/3672455|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205795483&doi=10.1145%2f3672455&partnerID=40&md5=03c2dc7531d8ab91d640f3c89e68e829|Natural language processing (NLP) has gained widespread adoption in the development of real-world applications. However, the black-box nature of neural networks in NLP applications poses a challenge when evaluating their performance, let alone ensuring it. Recent research has proposed testing techniques to enhance the trustworthiness of NLP-based applications. However, most existing works use a single, aggregated metric (i.e., accuracy) which is difficult for users to assess NLP model performance on fine-grained aspects, such as LCs. To address this limitation, we present ALiCT, an automated testing technique for validating NLP applications based on their LCs. ALiCT takes user-specified LCs as inputs and produces diverse test suite with test oracles for each of given LC. We evaluate ALiCT on two widely adopted NLP tasks, sentiment analysis and hate speech detection, in terms of diversity, effectiveness, and consistency. Using Self-BLEU and syntactic diversity metrics, our findings reveal that ALiCT generates test cases that are 190% and 2213% more diverse in semantics and syntax, respectively, compared to those produced by state-of-the-art techniques. In addition, ALiCT is capable of producing a larger number of NLP model failures in 22 out of 25 LCs over the two NLP applications. © 2024 Copyright held by the owner/author(s).|hate speech detection; LC; sentiment analysis; Software testing|Application programs; Black-box testing; Model checking; Natural language processing systems; Program debugging; Speech analysis; Syntactics; Automated testing; Hate speech detection; Language processing; LC; Natural language processing applications; Natural languages; Processing model; Sentiment analysis; Software testings; Speech detection; Semantics|Article|Final|All Open Access; Bronze Open Access|Scopus|2-s2.0-85205795483
scopus|Morokhovych V.; Levchuk O.; Morokhovych B.; Riabinchak V.; Leheta V.|Morokhovych, Vasyl (8572382100); Levchuk, Olexander (59740737300); Morokhovych, Bohdan (59198801700); Riabinchak, Valentyn (59953900100); Leheta, Vasylyna (59954639100)|8572382100; 59740737300; 59198801700; 59953900100; 59954639100|AI-powered information system for regional water and soil monitoring|2025|CEUR Workshop Proceedings|3974|||244|254|10|0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-105008493935&partnerID=40&md5=807d5496c30426f44f8af813a69e5511|This paper presents the development of an integrated online platform for monitoring soil and water resources, designed to enhance environmental management through real-time data collection, processing, and analysis. The platform addresses the increasing need for efficient environmental monitoring in the face of rapid urbanization and industrialization, which contribute to the degradation of natural ecosystems. The system architecture is based on a multi-tiered approach, employing Domain-Driven Design to ensure a clear separation of concerns and maintainability. The technology stack includes ASP.NET WebAPI for the backend, Angular for the frontend, and PostgreSQL for the database, complemented by Redis for caching to optimize performance. Key features of the platform include real-time data visualization, role-based access control (RBAC), and an intuitive user interface. The platform supports various user roles, such as super-administrator, owner, manager, supervisor, researcher, and guest, each with specific permissions and responsibilities. The system also incorporates automated testing using libraries like Moq, FluentAssertions, and Selenium to ensure reliability and robustness. The platform’s architecture facilitates seamless interaction between the user and the system, providing tools for data input, editing, and analysis. The use of Leaflet for geospatial data visualization allows for real-time mapping of environmental parameters, enhancing the user's ability to monitor and analyze environmental conditions. This research highlights the potential of integrating modern information technologies to address environmental challenges. The developed platform offers a scalable and reliable solution for environmental monitoring, with potential for further development including the integration of artificial intelligence (AI) algorithms for predictive analysis and the expansion of environmental factors monitored by the system. © 2025 Copyright for this paper by its authors.|artificial intelligence; modelling; natural resources monitoring; online platform; product; prototype system|Ecosystems; Environmental management; Environmental monitoring; Environmental technology; Information management; Information systems; Information use; Predictive analytics; Soil testing; Sustainable development; User interfaces; Visualization; Environmental Monitoring; Modeling; Natural resource monitoring; Online platforms; Product; Prototype system; Resource monitoring; Soil and water; Soil monitoring; Water monitoring; Data visualization|Conference paper|Final||Scopus|2-s2.0-105008493935
scopus||||40th International Conference on Computers and Their Applications, CATA 2025|2025|Communications in Computer and Information Science|2435 CCIS|||||250|0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-105010065783&partnerID=40&md5=e789da8ab6490f2841280eac6d4fe69a|The proceedings contain 19 papers. The special focus in this conference is on Computers and Their Applications. The topics include: Measurement and Characterization of Problems with Public API Support: A Case Study on YouTube APIs; Conversational AI in Healthcare: A Framework for Privacy, Security, Ethics, Transparency and Harm Prevention; chain Table: Protecting Table-Level Data Integrity by Digital Ledger Technology; sentiment, Volume, and Topics in University Tweets: Methodology, Insights, and Challenges; Automated Test Case Generation for Software Testing Using Generative AI; ensemble Machine Learning Approach to Phishing Website Detection; human Activity Recognition Using an Ensemble Learning Approach; comparison of Some Pseudorandom Binary Generators Based on Combinatorial Functions; design Process of a New Pseudorandom Binary Generator Model; machine Learning for Real World Water Consumption Forecasting; Comparative Analysis of Machine Learning Classifiers for Yellow Fever Diagnosis Using Causative Data: Evaluating Naïve Bayes, KNN, RIPPER, and PART; An Automated Framework of Ontology Generation for Abstract Concepts Using LLMs; using Machine Learning Techniques to Detect Network Intrusions; a Novel Feature Selection Method for Classification Against Email Phishing; reputation Proof with Load Services in Ad-Hoc Peer-to-Peer Networks; Scalable Automated Vulnerability Inspection Framework Using Nmap for CVE Detection in Distributed Remote Networks; Clustering of Processing-Induced Martensitic Phases Using AC-GAN and Magnetic Susceptibility Evaluation in High-Gradient Fields.|||Conference review|Final||Scopus|2-s2.0-105010065783
scopus|Li Y.; Yang W.-Z.; Zhang Y.; Xue Y.-X.|Li, Yan (59927217200); Yang, Wen-Zhang (59170986100); Zhang, Yi (59926953700); Xue, Yin-Xing (35101120400)|59927217200; 59170986100; 59926953700; 35101120400|Survey on Fuzzing Based on Large Language Model; [基于大语言模型的模糊测试研究综述]|2025|Ruan Jian Xue Bao/Journal of Software|36|6||2404|2431|27|1|10.13328/j.cnki.jos.007323|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007148334&doi=10.13328%2fj.cnki.jos.007323&partnerID=40&md5=23369a1090112b3b659af0a7b2325131|Fuzzing, as an automated software testing method, aims to detect potential security vulnerabilities, software defects, or abnormal behaviors by inputting a large quantity of automatically generated test data into the target software system. However, traditional fuzzing techniques are restricted by such factors as low automation level, low testing efficiency, and low code coverage, being unable to handle modern large-scale software systems. In recent years, the rapid development of large language models has not only brought significant breakthroughs to the field of natural language processing but also introduced new automation solutions to the field of fuzzing. Therefore, to better enhance the effectiveness of fuzzing technology, existing works have proposed various fuzzing methods combined with large language models, covering modules like test input generation, defect detection, and post-fuzzing. Nevertheless, the existing works lack systematic investigation and discussion on fuzzing techniques based on large language models. To fill the above-mentioned gaps in the review, this study comprehensively analyzes and summarizes the current research and development status of fuzzing techniques based on large language models. The main contents include (1) summarizing the overall process of fuzzing and the relevant technologies related to large language models commonly used in fuzzing research; (2) discussing the limitations of deep learning based fuzzing methods before the era of large language model (LLM); (3) analyzing the application methods of large language models in different stages of fuzzing; (4) exploring the main challenges and possible future development directions of large language model technology in fuzzing. © 2025 Chinese Academy of Sciences. All rights reserved.|defect detection; fuzzing; large language model (LLM); post-fuzzing; test input generation|Application programs; Automatic test pattern generation; Input output programs; Automated software testing; Defect detection; Fuzzing; Language model; Large language model; Post-fuzzing; Security vulnerabilities; Test input generation; Test inputs; Testing method; Software testing|Review|Final||Scopus|2-s2.0-105007148334
scopus|Corpaci L.; Wagner M.; Raubitzek S.; Kampel L.; Mallinger K.; Simos D.E.|Corpaci, Luiza (58622764500); Wagner, Michael (57212309647); Raubitzek, Sebastian (57208579969); Kampel, Ludwig (57191694231); Mallinger, Kevin (57221224243); Simos, Dimitris E. (15835741900)|58622764500; 57212309647; 57208579969; 57191694231; 57221224243; 15835741900|Estimating Combinatorial t-Way Coverage Based on Matrix Complexity Metrics|2025|Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) |15383 LNCS|||3|20|17|1|10.1007/978-3-031-80889-0_1|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218469183&doi=10.1007%2f978-3-031-80889-0_1&partnerID=40&md5=bc657e717c162aaa3de5b7a175927cf5|Efficiently estimating combinatorial t-way coverage in software testing remains a significant challenge due to the high-dimensional complexity of modern software systems and the inherent complexity of the problem. This article explores a novel method that uses matrix complexity metrics as features in machine learning algorithms to estimate the t-way coverage of random test sets. Based on an input parameter model of the system under test (SUT) we derive complexity metrics from the singular value decomposition of the matrix representation of the test set. This makes our approach independent of the SUT’s input space dimension and the size of the test set. Our approach provides a good estimation of the combinatorial t-way coverage while being faster and more scalable than a state of the art tool for the exact computation of combinatorial t-way coverage. Moreover, our experiments show a connection between the spectrum of singular values of a random test set and its t-way coverage. The use of complexity metrics as predictors in our machine learning pipeline adds a new dimension to the combinatorial testing domain, offering an additional tool for improving software testing processes. © IFIP International Federation for Information Processing 2025.|Combinatorial Testing; Complexity Metrics; Explainable Machine Learning; Machine Learning; Random Testing; Singular Value Decomposition; t-way Coverage|Adversarial machine learning; Matrix algebra; Combinatorial testing; Complexity metrics; Explainable machine learning; Machine-learning; Random testing; Singular values; T-way coverage; Test sets; Value decomposition; Software testing|Conference paper|Final||Scopus|2-s2.0-85218469183
scopus|Rafique K.A.; Biradar P.; Grimm C.|Rafique, Khushnood Adil (57835699600); Biradar, Pooja (60008188000); Grimm, Christoph (35247954100)|57835699600; 60008188000; 35247954100|Transformer-Based Unit Test Generation|2025|Proceedings - 2025 IEEE Conference on Artificial Intelligence, CAI 2025||||625|630|5|0|10.1109/CAI64502.2025.00115|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105011257903&doi=10.1109%2fCAI64502.2025.00115&partnerID=40&md5=81669614f95cecb3f4b446f5f259dba4|Automated test case generation reduces the manual effort of software testing, particularly for dynamic languages like Python. This study compares three transformer-based models-CodeT5, CodeBERT, and CodeGen. While CodeBERT and CodeGen were expected to excel due to their focus on code understanding and generation, CodeT5, a code summarization model, outperformed both, achieving higher code coverage and superior semantic and syntactic fidelity. Using a limited yet diverse dataset of Python functions with natural language descriptions and unit tests, we evaluated models with NLP metrics (BLEU, ROUGE-L) and practical measures like code coverage. CodeGen struggled with coherence under data constraints, while CodeBERT showed moderate effectiveness. Paired t-tests confirmed CodeT5's statistically significant advantage, highlighting that a well-adapted model can outperform more generalized architectures in realistic software testing scenarios.  © 2025 IEEE.|Artificial Intelligence; Automatic Unit Test Generation; CodeBERT; CodeGen; CodeT5; Large Language Models; Natural Language Processing; Transformers|Automatic programming; Automation; Codes (symbols); Computational linguistics; Electric transformer testing; Electric transformers; High level languages; Model checking; Natural language processing systems; Python; Semantics; Software testing; Statistical tests; Syntactics; Well testing; Automatic unit test generation; CodeBERT; Codegen; Codet5; Language model; Language processing; Large language model; Natural language processing; Natural languages; Transformer; Unit test generations; Artificial intelligence|Conference paper|Final||Scopus|2-s2.0-105011257903
scopus|Yasmin A.|Yasmin, Anum (58795674800)|58795674800|Cost Adjustment for Software Crowdsourcing Tasks Using Ensemble Effort Estimation and Topic Modeling|2024|Arabian Journal for Science and Engineering|49|9||12693|12728|35|1|10.1007/s13369-024-08746-8|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186210831&doi=10.1007%2fs13369-024-08746-8&partnerID=40&md5=1cfdde3c20088c8f3ccc3879807c443b|Crowdsourced software development (CSSD) is a fast-growing field among software practitioners and researchers from the last two decades. Despite being a favorable environment, no intelligent mechanism exists to assign price to CSSD tasks. Software development effort estimation (SDEE) on the other hand is already an established field in traditional software engineering. SDEE is largely facilitated by machine learning (ML), particularly, ML-based ensemble effort estimation (EEE) which targets accurate estimate by avoiding biases of single ML model. This accuracy of EEE can be exploited for CSSD platforms to establish intelligent cost assignment mechanism. This study aims to integrate EEE with CSSD platform to provide justified costing solution for crowdsourced tasks. Effort-based cost estimation model is proposed, implementing EEE to predict task’s effort along with natural language processing (NLP) analysis on task’s textual description to assign effort-based cost. TopCoder is selected as targeted CSSD platform, and the proposed scheme is implemented on TopCoder QA category comprising software testing tasks. Ensemble prediction is incorporated via random forest, support vector machine and neural network as base learners. LDA topic modeling is utilized for NLP analysis on the textual aspects of CSSD task, with a specific emphasis on the testing and technology factors. Effort estimation results confirm that EEE models, particularly stacking and weighted ensemble, surpass their base learners with 50% overall increased accuracy. Moreover, R2, log-likelihood and topic quality measures confirm considerable LDA model significance. Findings confirmed that cost adjustment achieved from EEE and NLP defines acceptable price range, covering major testing aspects. © King Fahd University of Petroleum & Minerals 2024.|Crowdsourcing; Ensemble effort estimation (EEE); Machine learning (ML); Software effort estimation; Topic modeling||Article|Final||Scopus|2-s2.0-85186210831
scopus|Darabseh R.J.; Saifan A.A.|Darabseh, Raghad J. (59352381600); Saifan, Ahmad A. (35222299300)|59352381600; 35222299300|DETECTIING REDUNDANT TEST CASES USING DEEP LEARNING|2024|Journal of Theoretical and Applied Information Technology|102|12||5021|5032|11|1||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205526563&partnerID=40&md5=056d53983fd254ad5323d586e12b254a|Software testing encompasses the examination of various data scenarios to assess output and observe software behaviour. However, comprehensive testing of all software cases poses challenges due to its intricate and complex nature. This paper is dedicated to the identification of redundant test cases through the application of deep learning techniques. Four distinct deep learning algorithms—Convolutional Neural Network (CNN), Deep Belief Network (DBN), Deep Neural Network (DNN), and Long-Term Memory (LSTM)—were employed in this study. These algorithms were applied to three datasets: Common Utils for Rapied, JSOUP, and Junit. The outcomes affirm the effectiveness of deep learning algorithms in pinpointing redundant test cases. The results demonstrated that the deep neural network (DNN) is able to detect repeated test cases, which ultimately leads to fewer test cases. Compared with other algorithms of deep learning algorithms, it was found that the deep neural network (DNN) is able to cover the test cases, and it has reached a relatively high accuracy, with a result of 82.66% © Little Lion Scientific.|Convolutional Neural Network; Deep Belief Network; Deep Learning; Deep Neural Network; Long-Term Memory; Redundant Test Cases; Test Case Reduction||Article|Final||Scopus|2-s2.0-85205526563
scopus|Hesenius M.; Bachert M.|Hesenius, Marc (55249675400); Bachert, Marvin (59219916600)|55249675400; 59219916600|Does My Data Fit? Assessing the Compatibility Between New and Existing Data|2024|EICS 2024 Companion - Companion of the 2024 ACM SIGCHI Symposium on Engineering Interactive Computing Systems||||113|114|1|0|10.1145/3660515.3662840|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198662405&doi=10.1145%2f3660515.3662840&partnerID=40&md5=38da71e8cabb829e574098e41462a260|With the widespread use of Machine Learning within interactive applications, high-quality data is key to ensuring an acceptable User Experience. This applies to training data as well as runtime data used for inference. Also, with the increasing demand for training data, data synthesis is interesting, but synthetic data must be similar to real data. Software Engineers thus need methods to assess data quality. This tutorial equips participants with techniques to check whether new data aligns with existing data. We offer practical insights and techniques to address the challenges in validating synthetic data, e.g., for test automation, and verifying if runtime data conforms to training data. Focusing on gesture recognition, participants will learn to differentiate between data suitable for the trained gesture recognizer and data that will potentially yield wrong results and thus lead to an undesirable User Experience.  Copyright © 2024 held by the owner/author(s). Publication rights licensed to ACM.|Data Synthesis; Human-Computer Interaction; Out-of-Distribution Testing|User interfaces; Data fits; Data synthesis; Distribution testing; Interactive applications; Machine-learning; Out-of-distribution testing; Run-time data; Synthetic data; Training data; Users' experiences; Human computer interaction|Conference paper|Final||Scopus|2-s2.0-85198662405
scopus||||25th International Conference on Product-Focused Software Process Improvement, PROFES 2024|2025|Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) |15453 LNCS|||||185|0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211223090&partnerID=40&md5=b1a212803b7addee96d95cf3fd397d3c|The proceedings contain 13 papers. The special focus in this conference is on Product-Focused Software Process Improvement. The topics include: A Multi-model Approach for Video Data Retrieval in Autonomous Vehicle Development; AI-Based Automotive Test Case Generation: An Action Research Study on Integration of Generative AI into Test Automation Frameworks; AI Act High-Risk Requirements Readiness: Industrial Perspectives and Case Company Insights; adopting Continuous Deployment in a Public Administration Project: An Industrial Case Study; an Automated Approach to Identify Source Code Files Affected by Architectural Technical Debt; on the Derivation of Quality Assurance Plans from Process Model Descriptions; Evaluating AI-Based Code Segmentation for ABAP Programs in an Industrial Use Case; quantum Algorithms: Application and Feasibility; towards Solving Short-Term Generation Scheduling Problems on Quantum Computers; generating and Evolving Real-Life Like Synthetic Data for e-Government Services Without Using Real-World Raw Data; a Data-Driven Approach to Optimize Internal Software Quality and Customer Value Delivery.|||Conference review|Final||Scopus|2-s2.0-85211223090
scopus|Siemonsmeier M.|Siemonsmeier, Matthias (59488338500)|59488338500|Automated Testing for All Developers: How Easy Access Can Make Your Dev Process More Efficient|2025|Game AI Uncovered: Volume Three||||99|110|11|0|10.1201/9781003411130-9|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213181006&doi=10.1201%2f9781003411130-9&partnerID=40&md5=bcd8778d8c559e734c80e7907a4dfcb6|Automated testing of game features received a lot of attention in recent years. While from the outside it appears that the industry is aligned and automated testing should be adopted, in real-life scenarios time constraints and limited resources are used as an excuse for not doing it. We argue from the other side: Automated testing saves time and lets you iterate and create new features with confidence to not break any of the existing functionality. During the early development of a prototype, we decided to implement a system that would allow us to create automated tests easily and bring down their maintenance cost. Our biggest challenge was to come up with a system that could be used by our QA and design teams with minimal code support. The outcome was a system that allowed us to verify AI behaviours in a continuous integration scenario and could be used for all types of functional gameplay tests. © 2025 Paul Roberts.|||Book chapter|Final||Scopus|2-s2.0-85213181006
scopus|Xiang J.-H.; Xu X.-Y.; Kong F.-C.; Peng P.; Zhang Z.; Zhang Y.-Q.|Xiang, Jia-Hong (57782648600); Xu, Xiao-Yang (59095429000); Kong, Fan-Chu (59096454900); Peng, Pai (59725291900); Zhang, Zhao (59225666100); Zhang, Yu-Qun (36931783900)|57782648600; 59095429000; 59096454900; 59725291900; 59225666100; 36931783900|Survey on Application and Development of Large Language Models in Software Defect Detection and Repair; [大模型在软件缺陷检测与修复的应用发展综述]|2025|Ruan Jian Xue Bao/Journal of Software|36|4||1489|1529|40|0|10.13328/j.cnki.jos.007268|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001967013&doi=10.13328%2fj.cnki.jos.007268&partnerID=40&md5=20a9e3bc298c51af5a1f2a1bbd4617b7|With the advancement of informationalization, the development of a variety of applications and iterative functions inevitably leads to software defects, posing significant threats to program reliability and security. Therefore, detecting and repairing software defects becomes essential yet onerous for developers in maintaining software quality. Accordingly, software engineering researchers have proposed numerous technologies over the past decades to help developers address defect-related issues. However, these technologies face serious challenges and make little progress in industrial implementation. Large language model (LLM), such as the code-based model CodeX and the prestigious ChatGPT, trained on massive datasets, can capture complex patterns and structures in code, process extensive contextual information, and flexibly adapt to various tasks. Their superior performance has attracted considerable attention from researchers. In many software engineering tasks, technologies based on LLM show significant advantages in addressing key challenges previously faced in different domains. Consequently, this study attempts to analyze and explore three defect detection domains where technologies based on LLM have been widely adopted: deep-learning library defect detection, GUI automated testing, and automated test case generation, along with one mature software defect repair domain: automated program repair (APR). This study delves into the progress of these domains and provides an in-depth discussion of their characteristics and challenges. Lastly, based on an analysis of existing research, this study summarizes the key challenges faced by these domains and technologies and offers insights for future research. © 2025 Chinese Academy of Sciences. All rights reserved.|automated GUI testing; automated program repair; automated test case generation; deep-learning library defect testing; defect detection; large language model (LLM)|Application programs; Automatic test pattern generation; Computer software maintenance; Computer software selection and evaluation; Model checking; Software quality; Software reliability; Automated GUI testing; Automated program repair; Automated test-case generations; Deep-learning library defect testing; Defect detection; GUI testing; Language model; Large language model; Software defects; Technology-based; Software testing|Article|Final||Scopus|2-s2.0-105001967013
scopus|Bushuyev S.; Ivko A.|Bushuyev, Sergiy (6506632335); Ivko, Andrii (58614581700)|6506632335; 58614581700|STUDY OF THE PRINCIPLE OF AUGMENTED COMPETENCY IN THE AUDIT OF IT PROJECTS IN THE ENVIRONMENT OF ARTIFICIAL INTELLIGENCE|2024|Technology Audit and Production Reserves|4|2||49|53|4|0|10.15587/2706-5448.2024.310525|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105011839222&doi=10.15587%2f2706-5448.2024.310525&partnerID=40&md5=7379cb3f3c800bda3c369007375a3968|The development of artificial intelligence (AI) is revolutionizing various industries, including IT project management. The object of research is the principle of augmented competence, which is a new approach that uses AI to strengthen and expand the capabilities of IT project teams. The essence of this principle lies in the complementary interaction of AI and the competence of project teams. Instead of replacing project managers, AI complements their competencies (knowledge, skills and experience). One of the hot spots is the application of AI in the process of automating routine tasks, analyzing large volumes of data and providing recommendations and predictions, freeing up time for team members to focus on more complex and creative tasks. The possibility of automating tasks and providing new knowledge, which will significantly improve the efficiency and productivity of the team, has been obtained through the use of the principle of augmented competence. As a result, data-driven recommendations and predictions enable teams to make more informed and effective decisions. Access to new knowledge and insights stimulates innovation and leads to new ideas and solutions, helps identify and mitigate potential risks, which can lead to more successful projects. Applying this principle to IT project management audits will automate software testing with AI, which replaces testers so they can focus on more complex types of testing such as exploratory testing, performs customer data analysis with AI, and enables companies to better understand your customers and their needs, which can lead to better marketing campaigns and products. It is important to note that this principle does not involve replacing project managers with AI. Instead, AI is used as a tool to empower human teams and help them achieve better results. As AI technologies continue to evolve, the principle of augmented competence is likely to play an even more important role in IT project management. AI can help teams overcome complex challenges, make better decisions, and succeed in a more dynamic and competitive environment. © The Author(s) 2024.|artificial intelligence; augmented competence; IT project management; project audit||Article|Final||Scopus|2-s2.0-105011839222
scopus|Alam M.M.; Priti S.I.; Ahmed S.; Fatema K.; Hasan M.; Nahar N.|Alam, Md Mahbub (59326185300); Priti, Sabrina Islam (59499226200); Ahmed, Selim (59499065700); Fatema, Kanij (59498363400); Hasan, Mahady (35105055600); Nahar, Nujhat (59868695000)|59326185300; 59499226200; 59499065700; 59498363400; 35105055600; 59868695000|AI-Driven Solutions for Regression Testing: Insights from Bangladesh Software Industry|2025|Smart Innovation, Systems and Technologies|431|||495|508|13|0|10.1007/978-981-96-1210-9_43|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105004794585&doi=10.1007%2f978-981-96-1210-9_43&partnerID=40&md5=cf0c5d9fb9f619f92e9d94e5156165c2|Context: Software companies in Bangladesh face challenges with regression testing due to dynamic systems, time constraints, and limited resources. Manual testing increases errors and reduces coverage, and the lack of a systematic framework for test case ranking hampers efficiency. Objective: This paper explores regression testing challenges in Bangladeshi random 10 software firms and proposes an AI-driven solution to enhance testing processes. Method: Summarizing selected works on AI in regression testing, the study identifies researchable problems and emphasizes the need for a systematic framework. It proposes a strategy integrating AI for test automation, adaptive testing techniques, strategic resource allocation, efficient test data management, and change management. Results: The AI-driven approach addresses challenges like limited resources, complex testing, rapid development cycles, and resistance to change. It aims to improve test coverage, reduce errors, and optimize resource utilization. Conclusion: AI-driven solutions are crucial for tackling regression testing challenges in Bangladesh software firms, supporting growth, and ensuring software excellence. Further research is needed to enhance understanding of AI-driven regression testing through comprehensive studies and industry-wide applications. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2025.|Adaptive testing techniques; AI-driven regression testing; Machine learning in software testing; Software quality assurance; Test automation|Application programs; Data quality; Failure analysis; Information management; Resource allocation; Software quality; Software testing; Adaptive testing; Adaptive testing technique; AI-driven regression testing; Machine learning in software testing; Machine-learning; Regression testing; Software quality assurance; Software testings; Test Automation; Testing technique; Reliability analysis|Conference paper|Final||Scopus|2-s2.0-105004794585
scopus|Xue Z.; Li L.; Tian S.; Chen X.; Li P.; Chen L.; Jiang T.; Zhang M.|Xue, Zhiyi (57994374900); Li, Liangguo (59152006300); Tian, Senyue (59151518900); Chen, Xiaohong (35236403100); Li, Pingping (59151840700); Chen, Liangyu (55739230800); Jiang, Tingting (59151519000); Zhang, Min (59619795200)|57994374900; 59152006300; 59151518900; 35236403100; 59151840700; 55739230800; 59151519000; 59619795200|LLM4Fin: Fully Automating LLM-Powered Test Case Generation for FinTech Software Acceptance Testing|2024|ISSTA 2024 - Proceedings of the 33rd ACM SIGSOFT International Symposium on Software Testing and Analysis||||1643|1655|12|2|10.1145/3650212.3680388|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205529439&doi=10.1145%2f3650212.3680388&partnerID=40&md5=975914ddcf3d0479f80a66a75af55576|FinTech software, crucial for both safety and timely market deployment, presents a compelling case for automated acceptance testing against regulatory business rules. However, the inherent challenges of comprehending unstructured natural language descriptions of these rules and crafting comprehensive test cases demand human intelligence. The emergence of Large Language Models (LLMs) holds promise for automated test case generation, leveraging their natural language processing capabilities. Yet, their dependence on human intervention for effective prompting hampers efficiency. In response, we introduce a groundbreaking, fully automated approach for generating high-coverage test cases from natural language business rules. Our methodology seamlessly integrates the versatility of LLMs with the predictability of algorithmic methods. We fine-tune pre-trained LLMs for improved information extraction accuracy and algorithmically generate comprehensive testable scenarios for the extracted business rules.Our prototype, LLM4Fin, is designed for testing real-world stock-trading software. Experimental results demonstrate LLM4Fin's superiority over both state-of-the-art LLM, such as ChatGPT, and skilled testing engineers. We achieve remarkable performance, with up to 98.18% and an average of 20%-110% improvement on business scenario coverage, and up to 93.72% on code coverage, while reducing the time cost from 20 minutes to a mere 7 seconds. These results provide robust evidence of the framework's practical applicability and efficiency, marking a significant advancement in FinTech software testing.  © 2024 Copyright is held by the owner/author(s). Publication rights licensed to ACM.|fintech software; large language model; Software acceptance testing; test case generation|Algorithmic languages; Automatic test pattern generation; Enterprise software; Financial markets; Fintech; Model checking; Software prototyping; Software testing; Acceptance testing; Automated acceptance testing; Business rules; Fintech software; Language model; Large language model; Natural languages; Software acceptance testing; Test case; Test case generation; Acceptance tests|Conference paper|Final||Scopus|2-s2.0-85205529439
scopus|Ahmad A.; Sun X.; Naeem M.R.; Javed Y.; Akour M.; Sandahl K.|Ahmad, Azeem (57203306573); Sun, Xin (59494472600); Naeem, Muhammad Rashid (57216075436); Javed, Yasir (56983138200); Akour, Mohammad (57750775000); Sandahl, Kristian (6602608546)|57203306573; 59494472600; 57216075436; 56983138200; 57750775000; 6602608546|Understanding Flaky Tests Through Linguistic Diversity: A Cross-Language and Comparative Machine Learning Study|2025|IEEE Access|13|||54561|54584|23|0|10.1109/ACCESS.2025.3553626|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002263225&doi=10.1109%2fACCESS.2025.3553626&partnerID=40&md5=a6d7fb74b8db1f708753dcf0893338d1|Software development is significantly impeded by flaky tests, which intermittently pass or fail without requiring code modifications, resulting in a decline in confidence in automated testing frameworks. Code smells (i.e., test case or production code) are the primary cause of test flakiness. In order to ascertain the prevalence of test smells, researchers and practitioners have examined numerous programming languages. However, one isolated experiment was conducted, which focused solely on one programming language. Across a variety of programming languages, such as Java, Python, C++, Go, and JavaScript, this study examines the predictive accuracy of a variety of machine learning classifiers in identifying flaky tests. We compare the performance of classifiers such as Random Forest, Decision Tree, Naive Bayes, Support Vector Machine, and Logistic Regression in both single-language and cross-language settings. In order to ascertain the impact of linguistic diversity on the flakiness of test cases, models were trained on a single language and subsequently tested on a variety of languages. The following key findings indicate that Random Forest and Logistic Regression consistently outperform other classifiers in terms of accuracy, adaptability, and generalizability, particularly in cross-language environments. Additionally, the investigation contrasts our findings with those of previous research, exhibiting enhanced precision and accuracy in the identification of flaky tests as a result of meticulous classifier selection. We conducted a thorough statistical analysis, which included t-tests, to assess the importance of classifier performance differences in terms of accuracy and F1-score across a variety of programming languages. This analysis emphasizes the substantial discrepancies between classifiers and their effectiveness in detecting flaky tests. The datasets and experiment code utilized in this study are accessible through an open source GitHub repository to facilitate reproducibility is available at: https://github.com/PELAB-LiU/FlakyCrossLanguage. Our results emphasize the effectiveness of probabilistic and ensemble classifiers in improving the reliability of automated testing, despite certain constraints, including the potential biases introduced by language-specific structures and dataset variability. This research provides developers and researchers with practical insights that can be applied to the mitigation of flaky tests in a variety of software environments. © 2013 IEEE.|artificial intelligence; Flaky tests; machine learning; non-deterministic tests; software testing|C++ (programming language); Computer software selection and evaluation; Decision trees; Java programming language; Logistic regression; Open source software; Problem oriented languages; Software reliability; Support vector regression; Automated testing; Cross languages; Deterministics; Flaky test; Linguistic diversity; Machine-learning; Non-deterministic test; Random forests; Software testings; Test case; Software testing|Article|Final|All Open Access; Gold Open Access|Scopus|2-s2.0-105002263225
scopus|Zhu X.; Zhou W.; Han Q.-L.; Ma W.; Wen S.; Xiang Y.|Zhu, Xiaogang (57215327205); Zhou, Wei (57838023900); Han, Qing-Long (7202485252); Ma, Wanlun (57196052588); Wen, Sheng (37108669800); Xiang, Yang (57114147900)|57215327205; 57838023900; 7202485252; 57196052588; 37108669800; 57114147900|When Software Security Meets Large Language Models: A Survey|2025|IEEE/CAA Journal of Automatica Sinica|12|2||317|334|17|17|10.1109/JAS.2024.124971|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213132111&doi=10.1109%2fJAS.2024.124971&partnerID=40&md5=171b7e072ad0c537ceff53551536bb24|Software security poses substantial risks to our society because software has become part of our life. Numerous techniques have been proposed to resolve or mitigate the impact of software security issues. Among them, software testing and analysis are two of the critical methods, which significantly benefit from the advancements in deep learning technologies. Due to the successful use of deep learning in software security, recently, researchers have explored the potential of using large language models (LLMs) in this area. In this paper, we systematically review the results focusing on LLMs in software security. We analyze the topics of fuzzing, unit test, program repair, bug reproduction, data-driven bug detection, and bug triage. We deconstruct these techniques into several stages and analyze how LLMs can be used in the stages. We also discuss the future directions of using LLMs in software security, including the future directions for the existing use of LLMs and extensions from conventional deep learning research. © 2014 Chinese Association of Automation.|Large language models (LLMs); software analysis; software security; software testing|Language model; Large language model; Learning technology; Security issues; Software analysis; Software security; Software testing and analysis; Software testings; Test projects; Unit tests; Software testing|Article|Final||Scopus|2-s2.0-85213132111
scopus|Sehgal V.; Sekaran N.|Sehgal, Vishal (59491622800); Sekaran, Nikhil (59490131900)|59491622800; 59490131900|Virtual Recording Generation Using Generative AI and Carla Simulator|2024|SAE Technical Papers|||||||0|10.4271/2024-28-0261|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213320680&doi=10.4271%2f2024-28-0261&partnerID=40&md5=37a924cf9beda31f2c23b3a2cdf575d2|To establish and validate new systems incorporated into next generation vehicles, it is important to understand actual scenarios which the autonomous vehicles will likely encounter. Consequently, to do this, it is important to run Field Operational Tests (FOT). FOT is undertaken with many vehicles and large acquisition areas ensuing the capability and suitability of a continuous function, thus guaranteeing the randomization of test conditions. FOT and Use case(a software testing technique designed to ensure that the system under test meets and exceeds the stakeholders' expectations) scenario recordings capture is very expensive, due to the amount of necessary material (vehicles, measurement equipment/objectives, headcount, data storage capacity/complexity, trained drivers/professionals) and all-time robust working vehicle setup is not always available, moreover mileage is directly proportional to time, along with that it cannot be scaled up due to physical limitations. During the early development phase, ground truth data is not available, and data that can be reused from other projects may not match 100% with current project requirements. All event scenarios/weather conditions cannot be ensured during recording capture, in such cases synthetic/virtual recording comes very handy which can accurately mimic real conditions on test bench and can very well address the before mentioned constraints. Car Learning to Act (CARLA) [1] is an autonomous open-source driving simulator, used for the development, training, and validation of autonomous driving systems is extended for generation of synthetic/virtual data/recordings, by integrating Generative Artificial Intelligence (Gen AI), particularly Generative Adversarial Networks (GANs) [2] and Retrieval Augmented Generation (RAG) [3] which are deep learning models. The process of creating synthetic data using vehicle models becomes more efficient and reliable as Gen AI can hold and reproduce much more data in scenario development than a developer or tester. A Large Language Model (LLM) [4] takes user input in the form of user prompts and generate scenarios that are used to produce a vast amount of high-quality, distinct, and realistic driving scenarios that closely resemble real-world driving data. Gen AI [5] empowers the user to generate not only dynamic environment conditions (such as different weather conditions and lighting conditions) but also dynamic elements like the behavior of other vehicles and pedestrians. Synthetic/Virtual recording [6] generated using Gen AI can be used to train and validate virtual vehicle models, FOT/Use case data which is used to indirectly prove real-world performance of functionality of tasks such as object detection, object recognition, image segmentation, and decision-making algorithms in autonomous vehicles. Augmenting LLM with CARLA involves training generative models on real-world driving data using RAG which allows the model to generate new, synthetic instances that resemble real-world conditions/scenarios. © 2024 SAE International. All Rights Reserved.||Access control; Air cushion vehicles; Associative storage; Augmented reality; Automobile driver simulators; Automobile drivers; Automobile simulators; Automobile testing; Benchmarking; Computer testing; Dynamic random access storage; Formal concept analysis; HDCP; Luminescent devices; Problem oriented languages; Sailing vessels; Ships; UNIX; Virtual addresses; Autonomous Vehicles; Condition; Continuous functions; Language model; Operational test; Operational use; Randomisation; Real-world drivings; Test condition; Vehicle modelling; Network security|Conference paper|Final||Scopus|2-s2.0-85213320680
scopus|Lochau M.; Schaefer I.|Lochau, Malte (24802606700); Schaefer, Ina (55152409100)|24802606700; 55152409100|Model-Based Testing of Quantum Computations|2025|Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)|15153 LNCS|||127|147|20|0|10.1007/978-3-031-72044-4_7|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204570138&doi=10.1007%2f978-3-031-72044-4_7&partnerID=40&md5=8322953032776e0ffe5ff40ef8f647fa|Quantum computers are able to effectively solve certain types of problems being intractable by classical computers, including tasks from linear optimization, machine learning and simulation of natural phenomena. The counter-intuitive behavior of quantum algorithms makes it particularly important to develop practical techniques and tools to support the analysis and quality assurance of quantum programs. For classical programs, software testing is today one of the most effective and easy-to-use quality-assurance techniques. However, many postulates of quantum physics like superposition, entanglement and non-cloneability of qubit states as well as the probabilistic outcome and destructive effects of qubit measurements obstruct any straight-forward adaptation of classical testing techniques to quantum programs. Recent works either treat quantum programs as black-box components with classical interfaces to apply end-to-end testing or shift the focus of quality assurance to formal verification of quantum programs. In this paper, we instead propose a model-based framework for testing quantum computations at the level of execution traces. Our approach is independent of the quantum programming language and hardware used and utilizes probabilistic transition systems as abstract test model for both the specification and implementation to be tested. In our model, we carefully distinguish between controllable and observable as well as between nondeterministic and probabilistic test steps. Our framework makes quantum program testing a partly reactive process that can be complemented by statistical approaches for identifying erroneous qubit states by repeated measurements. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.|Probabilistic Transition Systems; Quantum Computing; Testing Relations|Black-box testing; Computer debugging; Quantum electronics; Quantum entanglement; Quantum optics; Statistical optics; Linear optimization; Machine-learning; Model based testing; Optimisation machine; Probabilistic transition system; Probabilistics; Quanta computers; Quantum Computing; Qubit state; Testing relation; Qubits|Conference paper|Final||Scopus|2-s2.0-85204570138
scopus||||2025 IEEE Conference on Software Testing, Verification and Validation, ICST 2025|2025|2025 IEEE Conference on Software Testing, Verification and Validation, ICST 2025||||||842|0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007512344&partnerID=40&md5=e47c9a0058e6f2b94542a4ce4278cdd0|The proceedings contain 101 papers. The topics discussed include: metamorphic testing for pose estimation systems; suspicious types and bad neighborhoods: filtering spectra with compiler information; benchmarking open-source large language models for log level suggestion; introducing black-box fuzz testing for REST APIs in industry: challenges and solutions; AMBER: AI-enabled Java microbenchmark harness; AugmenTest: enhancing tests with LLM-driven oracles;; many-objective neuroevolution for testing games; batch execution of microbenchmarks for efficient performance testing; uncertainty-aware autonomous driving system testing with large language models; and combining logic and large language models for assisted debugging and repair of ASP programs.|||Conference review|Final||Scopus|2-s2.0-105007512344
scopus|Openja M.; Khomh F.; Foundjem A.; Jiang Z.M.; Abidi M.; Hassan A.E.|Openja, Moses (57205030030); Khomh, Foutse (24724747600); Foundjem, Armstrong (57210920185); Jiang, Zhen Mings (57197839751); Abidi, Mouna (57212458366); Hassan, Ahmed E. (7402686972)|57205030030; 24724747600; 57210920185; 57197839751; 57212458366; 7402686972|An Empirical Study of Testing Machine Learning in the Wild|2024|ACM Transactions on Software Engineering and Methodology|34|1|7||||2|10.1145/3680463|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202277996&doi=10.1145%2f3680463&partnerID=40&md5=585ddf93a92236bb31c16874c89d8050|Background: Recently, machine and deep learning (ML/DL) algorithms have been increasingly adopted in many software systems. Due to their inductive nature, ensuring the quality of these systems remains a significant challenge for the research community. Traditionally, software systems were constructed deductively, by writing explicit rules that govern the behavior of the system as program code. However, ML/DL systems infer rules from training data i.e., they are generated inductively. Recent research in ML/DL quality assurance has adapted concepts from traditional software testing, such as mutation testing, to improve reliability. However, it is unclear if these proposed testing techniques are adopted in practice, or if new testing strategies have emerged from real-world ML deployments. There is little empirical evidence about the testing strategies.Aims: To fill this gap, we perform the first fine-grained empirical study on ML testing in the wild to identify the ML properties being tested, the testing strategies, and their implementation throughout the ML workflow.Method: We conducted a mixed-methods study to understand ML software testing practices. We analyzed test files and cases from 11 open-source ML/DL projects on GitHub. Using open coding, we manually examined the testing strategies, tested ML properties, and implemented testing methods to understand their practical application in building and releasing ML/DL software systems.Results: Our findings reveal several key insights: (1) The most common testing strategies, accounting for less than 40%, are Grey-box and White-box methods, such as Negative Testing, Oracle Approximation, and Statistical Testing. (2) A wide range of ML properties are tested, out of which only 20% to 30% are frequently tested, including Consistency, Correctness, and Efficiency. (3) Bias and Fairness is more tested in Recommendation (6%) and Computer Vision (CV) (3.9%) systems, while Security and Privacy is tested in CV (2%), Application Platforms (0.9%), and NLP (0.5%). (4) We identified 13 types of testing methods, such as Unit Testing, Input Testing, and Model Testing.Conclusions: This study sheds light on the current adoption of software testing techniques and highlights gaps and limitations in existing ML testing practices.  © 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.|Deep learning; Machine learning; Machine learning workflow; ML properties; Software Testing; Test types/Types of testing; Testing methods; Testing strategies|Adversarial machine learning; Black-box testing; Computer software selection and evaluation; Contrastive Learning; Deep learning; Input output programs; Model checking; Open source software; Software reliability; Deep learning; Machine learning workflow; Machine-learning; ML property; Property; Software testings; Test type/type of testing; Testing method; Testing strategies; Work-flows; Application programs|Article|Final|All Open Access; Bronze Open Access; Green Open Access|Scopus|2-s2.0-85202277996
scopus|Ogrizović M.; Drašković D.; Bojić D.|Ogrizović, Mihajlo (58850807100); Drašković, Dražen (55030229200); Bojić, Dragan (55911186000)|58850807100; 55030229200; 55911186000|Quality assurance strategies for machine learning applications in big data analytics: an overview|2024|Journal of Big Data|11|1|156||||5|10.1186/s40537-024-01028-y|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208507234&doi=10.1186%2fs40537-024-01028-y&partnerID=40&md5=a46573915314676af08652f26d578759|Machine learning (ML) models have gained significant attention in a variety of applications, from computer vision to natural language processing, and are almost always based on big data. There are a growing number of applications and products with built-in machine learning models, and this is the area where software engineering, artificial intelligence and data science meet. The requirement for a system to operate in a real-world environment poses many challenges, such as how to design for wrong predictions the model may make; How to assure safety and security despite possible mistakes; which qualities matter beyond a model’s prediction accuracy; How can we identify and measure important quality requirements, including learning and inference latency, scalability, explainability, fairness, privacy, robustness, and safety. It has become crucial to test thoroughly these models to assess their capabilities and potential errors. Existing software testing methods have been adapted and refined to discover faults in machine learning and deep learning models. This paper covers a taxonomy, a methodologically uniform presentation of all presented solutions to the aforementioned issues, as well as conclusions about possible future development trends. The main contributions of this paper are a classification that closely follows the structure of the ML-pipeline, a precisely defined role of each team member within that pipeline, an overview of trends and challenges in the combination of ML and big data analytics, with uses in the domains of industry and education. © The Author(s) 2024.|Big data; Data quality; Integration and system testing; Machine learning; ML pipeline quality; Model quality; Quality assurance; Software in production|Contrastive Learning; Data accuracy; Integration testing; Data analytics; Data quality; Integration and system testing; Machine learning models; Machine learning pipeline quality; Machine-learning; Modeling quality; Software in production; System testing; Adversarial machine learning|Article|Final|All Open Access; Gold Open Access|Scopus|2-s2.0-85208507234
scopus|Yang Z.; Zhu H.; Zhang Q.|Yang, Zhaorui (59225992800); Zhu, Haichao (59225992900); Zhang, Qian (57192079396)|59225992800; 59225992900; 57192079396|Testing AI Systems Leveraging Graph Perturbation|2024|FSE Companion - Companion Proceedings of the 32nd ACM International Conference on the Foundations of Software Engineering||||665|666|1|0|10.1145/3663529.3663870|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199073581&doi=10.1145%2f3663529.3663870&partnerID=40&md5=4401f73c67895f7d8c4996f21459fcbe|Automated testing for emerging AI-enabled systems is challenging, because data is often highly structured, semantically rich, and continuously evolving. Fuzz testing has been proven to be highly effective; however, it is nontrivial to apply traditional fuzzing to AI systems directly for three reasons: (1) it often fails to bypass format validity checks, which are crucial for testing the core logic of an AI application; (2) it struggles to explore various semantic properties of inputs; and (3) it is incapable of accommodating the latency of AI systems. In this paper, we propose a novel fuzz testing framework specifically for AI systems, called SynGraph. Our approach stands out in two key aspects. First, we utilize graph perturbations to produce syntactically correct data, as opposed to traditional bit-level data manipulation. To achieve this, SynGraph captures the structured information intrinsic to the data and represents it as a graph. Second, we conduct directed mutations that preserve semantic similarity by applying the same mutations to adjacent and similar vertices. SynGraph has been successfully implemented for 5 input modalities. Experimental results demonstrate that this approach significantly enhances testing efficiency. © 2024 Copyright held by the owner/author(s).|Artificial intelligence; Fuzzing testing; Mutation-based software testing|Semantics; AI applications; AI systems; Automated testing; Core logic; Fuzz Testing; Fuzzing testing; Mutation-based software testing; Semantic properties; Software testings; Testing framework; Software testing|Conference paper|Final||Scopus|2-s2.0-85199073581
scopus|Soares E.; Ribeiro M.; Santos A.|Soares, Elvys (35207103400); Ribeiro, Márcio (57199329234); Santos, André (8832605700)|35207103400; 57199329234; 8832605700|A Multimethod Study of Test Smells: Cataloging Removal and New Types|2024|ACM International Conference Proceeding Series||||676|686|10|0|10.1145/3701625.3701699|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216240651&doi=10.1145%2f3701625.3701699&partnerID=40&md5=ea62aa31772a70f8449b114ff7809804|Test smells are signs in the test code that can indicate potential design or implementation issues. Despite being the subject of extensive academic literature, several questions about their impact in the industry remain unanswered. Some key areas lacking clarity include the absence of a publicly available catalog compiling their types, the lack of correspondence between new test framework features and their ability to prevent or refactor test smells, and the limited knowledge about test smells in manual test suites. To address these knowledge gaps, a multimethod study was conducted. It involved a Multivocal Literature Review, surveys with software testing professionals, studying new test framework features, contributing to popular open-source software, and analyzing manual and automatic test suites. The study resulted in: (i) a catalog that consolidates 480 distinct test smells, (ii) confirmation that new test framework features can refactor and prevent smells, and (iii) eight new smells for manual tests, (iv) a tool based on Natural Language Processing to identify such smells, and (v) their frequency in the tests of the Brazilian Eletronic Voting Machine, the Ubuntu OS and a large smartphones manufacturer. The findings of this work also provide guidance for further study fronts on test smells. © 2024 Copyright held by the owner/author(s).|Natural Language Tests; Software Quality; Software Testing; Test Automation; Test Refactoring; Test Smells; Verification and Validation|Ability testing; Computer software selection and evaluation; Odor removal; Open source software; Program compilers; Voting machines; Natural language test; Natural languages; Refactorings; Software Quality; Software testings; Test Automation; Test framework; Test refactoring; Test smell; Verification-and-validation; Software testing|Conference paper|Final||Scopus|2-s2.0-85216240651
scopus|Nagele A.-T.T.; Schindewolf M.; Sax E.|Nagele, Ann-Therese Tabea (57963596500); Schindewolf, Marc (57340315800); Sax, Eric (35243409200)|57963596500; 57340315800; 35243409200|Collaborative Continuous Testing of Automotive Services (CoCo Test)|2025|SysCon 2025 - 19th Annual IEEE International Systems Conference, Proceedings|||||||1|10.1109/SysCon64521.2025.11014795|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007775507&doi=10.1109%2fSysCon64521.2025.11014795&partnerID=40&md5=a299802cbb2743b0c9f585fe305e3fdf|With the increased use of information technology (IT), cars are transforming into software-defined vehicles. Software with machine learning algorithms is realizing components dedicated to automated driving. However, the established processes for development and testing cannot keep pace with the innovations in vehicle software architecture. An increasing number of IT experts are involved in system design and development to cope with the rising proportion of software in vehicles. The development team is growing and spans the mechanical, electronic, software, and machine learning domains, resulting in a heterogeneous team structure. These heterogeneous teams must overcome challenges related to collaboration during development and testing. A process is needed to test the vehicle software architecture, which is currently changing to service orientation. The testing process must be re-usable for software updates after release to maintain the vehicle software throughout the entire product life cycle. In this paper, we propose an approach where we use existing concepts from the IT domain for collaboration and continuous software testing and, where appropriate, tailor them to the automotive industry's needs, considering existing organizational structures and established standards. The approach presented is abstracted to a set of technologies that create a solution for the existing problems being as independent of the realization as possible.  © 2025 IEEE.|Automotive SPICE; CI/CD; collaborative work; continuous testing; software-defined vehicle|Automated driving; Automotive SPICE; Automotives; CI/CD; Collaborative Work; Continuous testing; Development and testing; Machine learning algorithms; Software-defined vehicle; Technology experts|Conference paper|Final||Scopus|2-s2.0-105007775507
scopus|Ajorloo S.; Jamarani A.; Kashfi M.; Haghi Kashani M.; Najafizadeh A.|Ajorloo, Sedighe (59149975500); Jamarani, Amirhossein (58308871000); Kashfi, Mehdi (59149975600); Haghi Kashani, Mostafa (57211014522); Najafizadeh, Abbas (57226458485)|59149975500; 58308871000; 59149975600; 57211014522; 57226458485|A systematic review of machine learning methods in software testing|2024|Applied Soft Computing|162||111805||||18|10.1016/j.asoc.2024.111805|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194532575&doi=10.1016%2fj.asoc.2024.111805&partnerID=40&md5=f0eb7914ba71957f3632ab5918b09a3c|Background: The quest for higher software quality remains a paramount concern in software testing, prompting a shift towards leveraging machine learning techniques for enhanced testing efficacy. Objective: The objective of this paper is to identify, categorize, and systematically compare the present studies on software testing utilizing machine learning methods. Method: This study conducts a systematic literature review (SLR) of 40 pertinent studies spanning from 2018 to March 2024 to comprehensively analyze and classify machine learning methods in software testing. The review encompasses supervised learning, unsupervised learning, reinforcement learning, and hybrid learning approaches. Results: The strengths and weaknesses of each reviewed paper are dissected in this study. This paper also provides an in-depth analysis of the merits of machine learning methods in the context of software testing and addresses current unresolved issues. Potential areas for future research have been discussed, and statistics of each review paper have been collected. Conclusion: By addressing these aspects, this study contributes to advancing the discourse on machine learning's role in software testing and paves the way for substantial improvements in testing efficacy and software quality. © 2024 Elsevier B.V.|Machine learning; Quality of software; Software testing; Systematic review|Computer software selection and evaluation; Reinforcement learning; Learning reinforcements; Machine learning methods; Machine learning techniques; Machine-learning; Quality of softwares; Reinforcement learnings; Software Quality; Software testings; Systematic literature review; Systematic Review; Software testing|Review|Final||Scopus|2-s2.0-85194532575
scopus||||27th RoboCup International Symposium, 2024|2025|Lecture Notes in Computer Science|15570 LNAI|||||551|0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003879183&partnerID=40&md5=0bd24fa6643321568a8992228a861ab9|The proceedings contain 46 papers. The special focus in this conference is on RoboCup. The topics include: Using Off-the-Shelf Deep Neural Networks for Position-Based Visual Servoing; deep Learning Based Measurement Model for Monte Carlo Localization in the RoboCup Humanoid League; semantic Path Planning for Heterogeneous Robots from Building Digital Twin Data; planning the Path with Reinforcement Learning: Optimal Robot Motion Planning in RoboCup Small Size League Environments; holes and Clashes in Simulated Soccer: When a Real-Time Simulation System Meets Compute-Hungry Agents; lightweight Real-Time Gesture Recognition for Dynamic Soccer Referee Signals; Quantized Neural Networks for Ball Detection on the NAO Robot: An Optimized Implementation; Decision Tree-Like Dynamic Conditional Stand-Up Routines for NAO Robots; a Mental Simulation Based Decision-Making Algorithm for the RoboCupSoccer Goalkeeper; analysis of the Introduction Trajectory Planning in Control Applied in Small Size League Robots; cross Language Soccer Framework: An Open Source Framework for the RoboCup 2D Soccer Simulation; position and Altitude of the Nao Camera Head from Two Points on the Soccer Field Plus the Gravitational Direction; LLCoach: Generating Robot Soccer Plans Using Multi-role Large Language Models; Introduction of Automated Testing and Continuous Metrics & KPI Monitoring in Student-Driven Projects: a Use Case; proposal of a Method for Acquiring Characteristics of Large-Diameter Solenoids; on Graph Reduction in Consensus Control of Multi-agent Systems: A Preliminary Study; Enhancing Autonomous Vehicle Control Through Sensor Fusion, NARX-Based Reinforcement Learning with Soft Actor-Critic (SAC) in CARLA Simulator; digital Environment Description and Reconstruction Using Panoptic Segmentation; efficient Sequence Model for Early Fall Detection of Humanoid Robots; Steam Deck: A Handheld ROS 2 Based Rescue Robot Controller; planning Robot Placement for Object Grasping; automated Game Statistics for the RoboCup Standard Platform League; a Light-Weighted Event-Based Simulation for the RoboCup Logistics League; event-Based Vision for Robot Soccer; soS: A Semi-Synthetic RoboCup Soccer Dataset for Visual Segmentation; Hibikino-Musashi@Home RoboCup@Home DSPL Champion 2024.|||Conference review|Final||Scopus|2-s2.0-105003879183
scopus|Lim J.W.; Chiew T.K.; Su M.T.; Ong S.; Subramaniam H.; Mustafa M.B.; Chiam Y.K.|Lim, Jin Wei (58903772200); Chiew, Thiam Kian (37039247700); Su, Moon Ting (55667169700); Ong, Simying (38761832800); Subramaniam, Hema (37082135800); Mustafa, Mumtaz Begum (59390098100); Chiam, Yin Kia (35092266800)|58903772200; 37039247700; 55667169700; 38761832800; 37082135800; 59390098100; 35092266800|Test case information extraction from requirements specifications using NLP-based unified boilerplate approach|2024|Journal of Systems and Software|211||112005||||2|10.1016/j.jss.2024.112005|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185827737&doi=10.1016%2fj.jss.2024.112005&partnerID=40&md5=0af798aab480e22e3d6932c8933cd9ec|Automated testing which extracts essential information from software requirements written in natural language offers a cost-effective and efficient solution to error-free software that meets stakeholders’ requirements in the software industry. However, natural language can cause ambiguity in requirements and increase the challenges of automated testing such as test case generation. Negative requirements also cause inconsistency and are often neglected. This research aims to extract test case information (actors, conditions, steps, system response) from positive and negative requirements written in natural language (i.e. English) using natural language processing (NLP). We present a unified boilerplate that combines Rupp's and EARS boilerplates, and serves as the grammar guideline for requirements analysis. Extracted information is populated in a test case template, becoming the building blocks for automated test case generation. An experiment was conducted with three public requirements specifications from PURE datasets to investigate the correctness of information extracted using this proposed approach. The results presented correctness of 50 % (Mdot), 61.7 % (Pointis) and 10 % (Npac) on information extracted. The lower correctness on negative over positive requirements was observed. The correctness by specific categories is also analysed, revealing insights into actors, steps, conditions, and system response extracted from positive and negative requirements. © 2024|Automation; Natural language processing; Software requirements; Software Testing; Test Case; Test case generation|Automation; Cost effectiveness; Information use; Natural language processing systems; Requirements engineering; Specifications; Automated testing; Case informations; Language processing; Natural language processing; Natural languages; Requirements specifications; Software requirements; Software testings; Test case; Test case generation; Software testing|Article|Final||Scopus|2-s2.0-85185827737
scopus|de Almeida Á.; Collins E.; Oran A.C.|de Almeida, Ágatha (59531076900); Collins, Eliane (55319962600); Oran, Ana Carolina (57188562490)|59531076900; 55319962600; 57188562490|AI in Service of Software Quality: How ChatGPT and Personas Are Transforming Exploratory Testing|2024|ACM International Conference Proceeding Series||||179|188|9|0|10.1145/3701625.3701657|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216224209&doi=10.1145%2f3701625.3701657&partnerID=40&md5=3f0d09e10bc5a75e0211fabeb58b15f6|Context: Exploratory testing is essential in the software validation process as a way to find unexpected and critical failures in a short time, complementing documented functional test cases. However, creating scenarios to explore the software (such as test charters) can be time-consuming, and depending on the team’s experience, it may lack adequate coverage of functionalities and scenarios that target specific user profiles of the application. Objective: This article investigates how AI, through LLMs (Large Language Models), can assist in creating exploratory test charters that reflect the characteristics and needs of different user personas. Method: To achieve this, an experimental study was conducted where personas were used as input in ChatGPT 3.5 to generate exploratory test charters. The effectiveness of the approach was evaluated by Software Engineering students, who analyzed the performance and usefulness of the generated charters through a questionnaire based on the TAM model, supplemented by qualitative and quantitative analyses. Results: Data analysis indicated positive acceptance of ChatGPT 3.5 by the participants, highlighting its ease of use and perceived usefulness. Conclusion: This study contributes to the field of Software Engineering by demonstrating a practical application of artificial intelligence in the automated generation of test charters. ChatGPT 3.5 has proven to be a promising tool to support the creation of personalized exploratory test charters, contributing to software quality improvement. The integration of artificial intelligence techniques with user-centered design methods can significantly optimize the software testing process. © 2024 Copyright held by the owner/author(s).|Artificial Intelligence; ChatGPT; Exploratory Testing; Personas; Software Quality|Application programs; Computer software selection and evaluation; Integration testing; User centered design; ChatGPT; Critical failures; Exploratory testing; Functional test; Persona; Software Quality; Software validation; Test case; Unexpected Failures; Validation process; Software quality|Conference paper|Final||Scopus|2-s2.0-85216224209
scopus||||FSE Companion - Companion Proceedings of the 32nd ACM International Conference on the Foundations of Software Engineering|2024|FSE Companion - Companion Proceedings of the 32nd ACM International Conference on the Foundations of Software Engineering||||||741|0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199112643&partnerID=40&md5=299876d85e94c3161d86c88d97a422d3|The proceedings contain 107 papers. The topics discussed include: paths to testing: why women enter and remain in software testing?; FinHunter: improved search-based test generation for structural testing of FinTech systems; automated end-to-end dynamic taint analysis for WhatsApp; exploring hybrid work realities: a case study with software professionals from underrepresented groups; MonitorAssistant: simplifying cloud service monitoring via large language models; chain-of-event: interpretable root cause analysis for microservices through automatically learning weighted event causal graph; how well industry-level cause bisection works in real-world: a study on Linux kernel; AgraBOT: accelerating third-party security risk management in enterprise setting through generative AI; a machine learning-based error mitigation approach for reliable software development on IBM’s quantum computers; and neat: mobile app layout similarity comparison based on graph convolutional networks.|||Conference review|Final||Scopus|2-s2.0-85199112643
scopus|Freeda R.A.; Rajendran P.S.|Freeda, R. Adline (57191618601); Rajendran, P. Selvi (57212397497)|57191618601; 57212397497|A HYBRID CLASSIFIER MODEL - DR-XA FOR DEFECT PRIORITIZATION|2024|Journal of Theoretical and Applied Information Technology|102|19||7038|7047|9|1||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207391491&partnerID=40&md5=27f60fad02e5795fe73dc2837f17b7af|Fault prioritization in software testing involves determining the sequence in which identified faults should be addressed. Effective fault prioritization is crucial in software development and testing as it helps allocate resources efficiently and ensures that the most critical issues are resolved first. The criteria for prioritization may vary so by addressing the most serious flaws promptly and allocating resources effectively, software quality can be significantly enhanced. Machine learning algorithms offer powerful tools for fault prioritization by leveraging the complexity of the problem and the available data. Common machine-learning approaches for prioritization include classifier models such as Decision Trees, Random Forests, and XGBoost. This research compares the performance of these different classifier models with the proposed DR-XA hybrid prediction model. The DR-XA model, which incorporates advanced techniques for handling unbalanced data and improving prediction accuracy, has been evaluated in the context of fault prioritization. The experimental analysis demonstrates that the DR-XA hybrid model surpasses existing classifier models in prioritization accuracy, achieving superior results compared to current prioritization techniques. © Little Lion Scientific.|Defect Prioritization; Hybrid classifier model; Machine learning; Prediction; Software Testing||Article|Final||Scopus|2-s2.0-85207391491
scopus|Nascimento A.M.; Shimanuki G.K.G.; Dias L.A.V.|Nascimento, Alexandre M. (23397934200); Shimanuki, Gabriel Kenji G. (59090995700); Dias, Luiz Alberto V. (36011475700)|23397934200; 59090995700; 36011475700|Making More with Less: Improving Software Testing Outcomes Using a Cross-Project and Cross-Language ML Classifier Based on Cost-Sensitive Training|2024|Applied Sciences (Switzerland)|14|11|4880||||0|10.3390/app14114880|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195891027&doi=10.3390%2fapp14114880&partnerID=40&md5=2751bf61e95c1e6116c06689756564b8|Featured Application: The technique uses Machine Learning (ML) models to support decision-making on software testing scope and resource allocation to augment the outcomes with the available resources. As digitalization expands across all sectors, the economic toll of software defects on the U.S. economy reaches up to $2.41 trillion annually. High-profile incidents like the Boeing 787-Max 8 crash have shown the devastating potential of these defects, highlighting the critical importance of software testing within quality assurance frameworks. However, due to its complexity and resource intensity, the exhaustive nature of comprehensive testing often surpasses budget constraints. This research utilizes a machine learning (ML) model to enhance software testing decisions by pinpointing areas most susceptible to defects and optimizing scarce resource allocation. Previous studies have shown promising results using cost-sensitive training to refine ML models, improving predictive accuracy by reducing false negatives through addressing class imbalances in defect prediction datasets. This approach facilitates more targeted and effective testing efforts. Nevertheless, these models’ in-company generalizability across different projects (cross-project) and programming languages (cross-language) remained untested. This study validates the approach’s applicability across diverse development environments by integrating various datasets from distinct projects into a unified dataset, using a more interpretable ML technique. The results demonstrate that ML can support software testing decisions, enabling teams to identify up to 7× more defective modules compared to benchmark with the same testing effort. © 2024 by the authors.|cost-sensitive; cross-language; cross-project; generalization; imbalance; machine learning; NASA MDP; random forest; software defect prediction; software quality||Article|Final|All Open Access; Gold Open Access; Green Open Access|Scopus|2-s2.0-85195891027
scopus|Kondareddy A.; Azad S.; Singh A.; Henderson T.A.D.|Kondareddy, Avi (58313517700); Azad, Sushmita (57215658425); Singh, Abhayendra (57210978773); Henderson, Tim A. D. (55842247800)|58313517700; 57215658425; 57210978773; 55842247800|Speculative Testing at Google with Transition Prediction|2025|2025 IEEE Conference on Software Testing, Verification and Validation, ICST 2025||||510|521|11|0|10.1109/ICST62969.2025.10988976|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007525300&doi=10.1109%2fICST62969.2025.10988976&partnerID=40&md5=faa319d0420b8fdb8ad5b42a5d8e896f|Google's approach to testing includes both testing prior to code submission (for fast validation) and after code submission (for comprehensive validation). However, Google's ever growing testing demand has lead to increased continuous integration cycle latency and machine costs. When the post code submission continuous integration cycles get longer, it delays detecting breakages in the main repository which increases developer friction and lowers productivity. To mitigate this without increasing resource demand, Google is implementing Postsubmit Speculative Cycles in their Test Automation Platform (TAP). Speculative Cycles prioritize finding novel breakages faster. In this paper we present our new test scheduling architecture and the machine learning system (Transition Prediction) driving it. Both the ML system and the end-to-end test scheduling system are empirically evaluated on 3-months of our production data (120 billion test × cycle pairs, 7.7 million breaking targets, with ∼20 thousand unique breakages). Using Speculative Cycles we observed a median (p50) reduction of approximately 65% (from 107 to 37 minutes) in the time taken to detect novel breaking targets. © 2025 IEEE.||Program processors; Software testing; Breakings; Continuous integrations; Google+; Latency costs; Machine costs; Resource demands; Scheduling architecture; Test Automation; Test scheduling; Transition prediction; Search engines|Conference paper|Final||Scopus|2-s2.0-105007525300
scopus|Xiu T.; Qi H.; Xu J.; Liang X.|Xiu, Tianyu (57226073046); Qi, Hanwen (57226592293); Xu, Jiabo (57864466200); Liang, XinLian (35488207000)|57226073046; 57226592293; 57864466200; 35488207000|Individual tree extraction through 3D promptable segmentation networks|2025|Methods in Ecology and Evolution|||||||0|10.1111/2041-210X.70057|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007973350&doi=10.1111%2f2041-210X.70057&partnerID=40&md5=fee3403615c86f489bdbe3eba24e4de4|The extraction of individual trees from three-dimensional (3D) forest point clouds plays a pivotal role in forest inventory updates, forest resource management, growth and yield estimation of trees, etc. Existing end-to-end deep learning-based methods for extracting individual trees typically rely on extracting instance-sensitive features and clustering techniques. In this paper, inspired by the Segment Anything Model (SAM) and prompt-driven paradigm, we propose a novel approach to forest point cloud instance segmentation, called the 3D Promptable Segmentation Network (3DPS-Net). This network generates object masks using prompt points, thereby enabling the extraction of individual trees. We have designed two testing modes: prompt testing and automated testing. Prompt testing allows for interactive manual tree segmentation, providing a flexible and controllable analysis tool, while automated testing supports the autonomous identification and segmentation of individual trees within the input dataset. Through accuracy evaluation experiments conducted on two forest point cloud datasets (the ForestSemantic dataset and the FOR-instance dataset), we have demonstrated the integrity and reliability of the individual tree instances predicted by 3DPS-Net. Our proposed network exhibits robust performance with overstory trees. It requires only 1.5 seconds to predict a 3D individual tree mask from a prompt point, indicating significant potential for real-time processing applications. This innovative approach introduces a new methodology for individual tree extraction using deep learning, thereby contributing to the advancement and future progress of this field. © 2025 The Author(s). Methods in Ecology and Evolution published by John Wiley & Sons Ltd on behalf of British Ecological Society.|deep learning; forestry; individual tree extraction; instance segmentation; point cloud||Article|Article in press||Scopus|2-s2.0-105007973350
scopus|Padmanabhan M.|Padmanabhan, Mani (57205416969)|57205416969|A Systematic Review of AI Based Software Test Case Optimization|2024|International Research Journal of Multidisciplinary Scope|5|4||847|859|12|1|10.47857/irjms.2024.v05i04.01451|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210429925&doi=10.47857%2firjms.2024.v05i04.01451&partnerID=40&md5=cd25386214be24954d449bd23dd3dca1|Software test case optimization for real-time systems is a vulnerability detection methodology that assesses the resilience of targeted programs by subjecting them to irregular input data. As the volume, size, and intricacy of software continue to escalate, conventional manual test case generation has encountered challenges like insufficient logical coverage, minimal automation levels, and inadequate test scenarios. These difficulties underscore the need for innovative approaches that maximize software dependability and performance. An artificial intelligence powered fuzzing technique, which exhibits remarkable proficiency in data analysis and classification prediction. This paper examines the recent advancements in fuzzing research and conducts a comprehensive review of artificial intelligence driven fuzzing approaches in software test cases optimization. The major review explains the test case validation workflow and discusses the optimization of distinct phases within fuzzing utilizing in the software testing. Particular emphasis is placed on the implementation of artificial intelligence in the following software testing phases. This process involves position selection, which includes organizing and cleaning data; generating test cases that cover different inputs and expected outputs; selecting fuzzy input values for testing edge cases; validating the results of each test case to ensure accuracy and reliability. Finally, it synthesizes the obstacles and complexities associated with integrating artificial intelligence into software test case optimization techniques and anticipate potential future directions in the software testing. © 2024, Iquz Galaxy Publisher. All rights reserved.|Artificial Intelligence; Software Testing; Test Case Optimization; Test Case Validation Techniques||Article|Final|All Open Access; Gold Open Access|Scopus|2-s2.0-85210429925
scopus|Islam A.; Zaman M.S.; Jahan H.|Islam, Aminul (59940212600); Zaman, Muhammad Shahriar (58931443100); Jahan, Hosney (57194977421)|59940212600; 58931443100; 57194977421|A 2-Layer Ensemble Machine Learning Based System for Software Defect Prediction|2025|2025 International Conference on Electrical, Computer and Communication Engineering, ECCE 2025|||||||0|10.1109/ECCE64574.2025.11013826|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007822315&doi=10.1109%2fECCE64574.2025.11013826&partnerID=40&md5=64b8b0a7b200a5e2c266955061b99f4c|Software defects are anomalies in software projects that lead to incorrect outcomes and deviate from predefined requirements set by customers, developers, and other stakeholders. These defects pose significant challenges and can cause substantial losses if left unresolved. Detecting software defects in the early stages of development is crucial, as it can save considerable resources and reduce costs. To address this, we propose a machine learning model capable of automatic defect prediction at the early stages of development. Our approach introduces a two-layer ensemble-based system that leverages static code analysis by extracting software testing metrics. The proposed double-layer ensemble model aims to surpass the predictive accuracy of standalone models and traditional ensemble techniques, ensuring higher reliability in defect prediction. By implementing this advanced methodology on static code, our research demonstrates the potential of achieving improved defect detection performance, thereby contributing to more efficient and cost-effective software development processes. © 2025 IEEE.|accuracy; defect; ensemble; hyperparameter; metric; prediction; software; stacking|Computer operating systems; Computer software selection and evaluation; Leak detection; Software design; Software prototyping; Software reliability; Verification; 2 layer; Accuracy; Defect prediction; Ensemble; Hyper-parameter; Machine-learning; Metric; Software; Software defects; Stackings; Software testing|Conference paper|Final||Scopus|2-s2.0-105007822315
scopus|Yilmazer M.; Karakose M.|Yilmazer, Merve (57454268200); Karakose, Mehmet (8881363800)|57454268200; 8881363800|LLM-Based Video Analytics Test Scenario Generation in Smart Cities|2025|2025 29th International Conference on Information Technology, IT 2025|||||||0|10.1109/IT64745.2025.10930297|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001810574&doi=10.1109%2fIT64745.2025.10930297&partnerID=40&md5=eada3b1f45167c9b42948fb289fa9967|Rapid advances in the field of artificial intelligence have made significant contributions to the automation of software development and testing stages. Software created for use in various fields is tested with test scenarios created manually by software test experts or using test automation. Testing large-scale software with these methods complicates the testing phases because it requires increased human intervention and includes complex applications. In this study, an LLM-based scenario generation framework enhanced with prompt engineering is proposed for testing software to be used for video analysis in smart cities and smart campus areas. Thus, software test scenarios are created by strengthening large language models that are fast, flexible and have high learning ability using prompt engineering techniques. Test scenarios produced through LLM reinforced with prompt engineering techniques were evaluated with rarity and reality metrics and it was determined that more robust scenarios were produced compared to randomly generated test scenarios in the relevant field. © 2025 IEEE.|generative artificial intelligence; large language model; prompt engineering; smart cities; software testing|Application programs; Smart city; Software testing; Development and testing; Engineering techniques; Generative artificial intelligence; Language model; Large language model; Prompt engineering; Scenarios generation; Software testings; Test scenario; Video analytics|Conference paper|Final||Scopus|2-s2.0-105001810574
scopus|Manchala P.; Bisi M.|Manchala, Pravali (57736671700); Bisi, Manjubala (56664163800)|57736671700; 56664163800|A novel source project and optimized training data selection approach for cross-project fault prediction|2025|Journal of Supercomputing|81|1|316||||0|10.1007/s11227-024-06750-1|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212954788&doi=10.1007%2fs11227-024-06750-1&partnerID=40&md5=8c16c92fa58bc680c4ca8e189a389e61|Software fault prediction (SFP) is a great tool for limiting the software testing resources allocation and enhancing the software reliability. In reality, collecting adequate historical training data for a new developing project might be a challenging task, in such cases cross-project fault prediction (CPFP) is useful. Prior studies have demonstrated transfer learning and training data selection models for CPFP. However, existing models are unstable to the source projects that are used to train the prediction model. In addition, imbalanced projects and irrelevant features are issues to review in CPFP. To address the limitations in existing CPFP models, we propose a novel optimized source data selection model for CPFP through Wilcoxon signed-rank test-based source project selection (WPS) and an optimized training data construction (optimizedTC) technique called WPSTC. We evaluate WPSTC with 31 datasets and seven performance measures and compare it with existing fault prediction models over five conventional and one ensemble machine learning model. On average, WPSTC outperforms CPFP models and can solve existing models’ sensitivity towards selected source projects and solve the imbalance and curse of dimensionality issues of CPFP models. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.|Cross-project fault prediction; Curse of dimensionality; Feature selection; Instance filtering; Source project selection; Training data construction|Software reliability; Software testing; Cross-project fault prediction; Curse of dimensionality; Data construction; Fault prediction; Features selection; Instance filtering; Project selection; Source project selection; Training data; Training data construction; Prediction models|Article|Final||Scopus|2-s2.0-85212954788
scopus|Rahman M.; Zamli K.Z.; Kader M.A.; Sidek R.M.; Din F.|Rahman, Mizanur (57235543900); Zamli, Kamal Z. (8701576800); Kader, Md Abdul (57219838707); Sidek, Roslina Mohd (57196628620); Din, Fakhrud (56070700100)|57235543900; 8701576800; 57219838707; 57196628620; 56070700100|Comprehensive Review on the State-of-the-arts and Solutions to the Test Redundancy Reduction Problem with Taxonomy|2024|Journal of Advanced Research in Applied Sciences and Engineering Technology|35|1||62|87|25|3|10.37934/araset.34.3.6287|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179942706&doi=10.37934%2faraset.34.3.6287&partnerID=40&md5=baaa6a38025f166be08026b89dcb48a9|The process of software testing is of utmost importance and requires a major allocation of resources. It has a substantial influence on the quality and dependability of software products. Nevertheless, as the quantity of test cases escalates, the feasibility of executing all of them diminishes, and the accompanying expenses related to preparation, execution time, and upkeep grow excessively exorbitant. The objective of Test Redundancy Reduction (TRR) is to mitigate this issue by determining a minimal subset of the test suite that satisfies all the requirements of the primary test suite while lowering the number of test cases. In order to attain this objective, multiple methodologies have been suggested, encompassing heuristics, meta-heuristics, exact algorithms, hybrid approaches, and machine-learning techniques. This work provides a thorough examination of prior research on TRR, addressing deficiencies and making a valuable contribution to the current scholarly understanding. The literature study encompasses a comprehensive examination of the complete chronology of TRR, incorporating all pertinent scholarly articles and practitioner-authored research papers published in English. This study aims to provide managers with valuable insights into the strengths and shortcomings of different TRR methodologies, enabling them to make well-informed decisions regarding the most appropriate approach for their specific needs. The primary objective of this study is to offer a comprehensive analysis of Test Result Reduction (TRR) and its consequential impact on mitigating expenses related to software testing. This study makes a valuable contribution to extant literature by elucidating the present state-of-the-art and delineating potential avenues for future research. © 2024, Semarak Ilmu Publishing. All rights reserved.|Software testing; Test case reduction; Test redundancy reduction; Test suite reduction||Article|Final|All Open Access; Hybrid Gold Open Access|Scopus|2-s2.0-85179942706
scopus||||17th Annual ACM India Compute Conference, COMPUTE 2024|2025|Communications in Computer and Information Science|2400 CCIS|||||191|0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001293928&partnerID=40&md5=a11763cb5a6116f0dd83641efd16e916|The proceedings contain 15 papers. The special focus in this conference is on India Compute. The topics include: Challenges and Outcomes of Organizing an Open Discussion Forum for Building the CSEd Research Community; Exploring the Effectiveness of a Multilingual Generative AI Programming Chatbot for Vernacular Medium CS Students; Scaling Evaluation of Non-objective Assessments Using AI-Based Solutions; Leveraging ChatGPT-3.5 for Automated Evaluation of Time Complexity in Programming Assignments; RECE: A Family of Explainable Rubrics for Autograding Refute Problems; jestViz: Towards Supporting Novice Web Developers Debug JavaScript; an Interactive Lambda Calculus Interpreter and Visualization Tool; exploring Recursion Pedagogies: Innovative Strategies and Their Effects on Engineering Students; Enhancing and Analyzing Log Generation for Collaborative Problem-Solving Activities: Video Analysis and OCR  Techniques; identifying the Root Cause of a Cyber Attack Through Log Data Analysis: An Overview of the Challenges Faced by Novice Learners; Teaching NLP in the Age of Large Language Models: Challenges and Strategies for Indian Universities; Bridging Ethics and Code: A PBL Framework for Digital Citizenship in CS; mapping Challenges in Teaching-Learning Software Testing: Limitations and Unaddressed Issues in Contemporary Research.|||Conference review|Final||Scopus|2-s2.0-105001293928
scopus|Chhabra D.; Chadha R.|Chhabra, Deepshikha (57202846462); Chadha, Raman (57780472600)|57202846462; 57780472600|Machine Learning Approaches in Contemporary Automatic Bug Triaging and Analysis of Research Gaps|2024|Proceedings - 2024 6th International Conference on Computational Intelligence and Communication Technologies, CCICT 2024||||583|588|5|0|10.1109/CCICT62777.2024.00097|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199871836&doi=10.1109%2fCCICT62777.2024.00097&partnerID=40&md5=d48a8617fa9afe62f90c75f790922785|The main aim of software development is to release the product with zero defects. Software development methodology starts from gathering the requirements till software testing maintenance. The testers perform a Software Testing process by comparing the actual and expected results. In the process of software testing whenever there is a mismatch between the expected and actual results, a bug is reported. Bug Triaging is a crucial process in software testing. Bug triaging refers to the process of getting the bug resolved at the right time by the right resource person The main idea of bug triaging is to get the bugs fixed within the timelines by the appropriate resource person. Bugs are addressed by the testing team using a bug report template. If a bug report is well-defined and easy to understand the developer finds it easier to understand and fix the bugs within the timelines. The bug report contains the bug's characteristics including the description, ID, priority, steps to replicate the bug, hardware, and software configurations in which the bug was reported, and various other characteristics of the bug. Initially, the developers allocated the bugs using a manual distribution process. When there are hundreds or thousands of bugs reported in the software every month automatic bug triaging plays an efficient role in the timely resolution of the bugs. Bug triaging problems can be viewed as a machine learning application in which automatically the bugs are assigned to the appropriate developer. The main objective of Automatic Bug Triaging is to make a model that assigns bugs to appropriate developers with high accuracy to reduce the time of bug allocation to the developers. Various Machine Learning approaches have been used in the past years. In this paper, we will study various automatic bug-triaging approaches and discuss the findings and gaps of the discussed approaches. The main agenda of this research paper is to provide a detailed study related to Bug and Bug reports, analyze the various approaches to Automatic Bug Triaging and its practical implications, discuss the gaps in the existing approaches, and focus on the future scope and challenges related to automatic triaging. The customization, scalability, and adaptability of the machine learning techniques make it best suitable for Bug triaging purposes. ©2024 IEEE.|Bug; Bug Report; Bug Triaging; Machine Learning|Application programs; Machine learning; Program debugging; Software design; Bug; Bug reports; Bug triaging; Machine learning approaches; Machine-learning; Research gaps; Software development methodologies; Software testings; Testing process; Zero defects; Software testing|Conference paper|Final||Scopus|2-s2.0-85199871836
scopus|Yang Z.; Lin C.; Hu P.; Shen C.|Yang, Zixuan (57219766730); Lin, Chenhao (57221245073); Hu, Pengwei (56637561700); Shen, Chao (36446592900)|57219766730; 57221245073; 56637561700; 36446592900|DeepSensitive: A Fuzzing Test for Deep Neural Networks with Sensitive Neurons|2024|Communications in Computer and Information Science|2014 CCIS|||351|362|11|0|10.1007/978-981-97-0903-8_33|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187691764&doi=10.1007%2f978-981-97-0903-8_33&partnerID=40&md5=8658f8a6ee5d4171c2dc53a81a93d098|Deep learning (DL) systems have exhibited remarkable capabilities in various domains, such as image classification, natural language processing, and recommender systems, thereby establishing themselves as significant contributors to the advancement of software intelligence. Nevertheless, in domains emphasizing security assurance, the reliability and stability of deep learning systems necessitate thorough testing prior to practical implementation. Given the increasing demand for high-quality assurance of DL systems, the field of DL testing has gained significant traction. Researchers have adapted testing techniques and criteria from traditional software testing to deep neural networks, yielding results that enhance the overall security of DL technology. To address the challenge of enriching test samples in DL testing systems and resolving the issue of unintelligibility in samples generated by multiple mutations, we propose an innovative solution called DeepSensitive. DeepSensitive functions as a fuzzy testing tool, leveraging DL interpretable algorithms to identify sensitive neurons within the input layer via the DeepLIFT algorithm. Employing a fuzzy approach, DeepSensitive perturbs these sensitive neurons to generate novel test samples. We conducted evaluations of DeepSensitive using various mainstream image processing datasets and deep learning models, thereby demonstrating its efficient and intuitive capacity for generating test samples. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2024.|Deep learning testing; Fuzzing test; Neural networks|Deep neural networks; Image processing; Learning algorithms; Learning systems; Natural language processing systems; Quality assurance; Software testing; Deep learning testing; Fuzzing test; High quality; Images classification; Neural-networks; Reliability and stability; Security assurance; Software intelligences; Test samples; Testing criteria; Neurons|Conference paper|Final||Scopus|2-s2.0-85187691764
scopus|Elmourabit Z.; Retbi A.; El Faddouli N.-E.|Elmourabit, Zohair (59153980700); Retbi, Asmaâ (56275916700); El Faddouli, Nour-Eddine (54784300600)|59153980700; 56275916700; 54784300600|The Impact of Generative Artificial Intelligence on Education: A Comparative Study|2024|Proceedings of the European Conference on e-Learning, ECEL|23|1||470|476|6|1||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215655306&partnerID=40&md5=8d69735022f5b41ad61e6cc4ae546286|Generative Artificial Intelligence (GAI), also known as creative AI, is a technology capable of independently producing original and creative content, such as text, images, videos, music, or code. It uses machine learning algorithms to analyze and learn from a vast amount of data to generate similar or even innovative content. This type of AI is used in several fields, such as health for the production of new drugs, design to generate adaptive designs, video games to create immersive environments, and artificial intelligence to generate training data for new networks. Seizing the opportunities offered by AI innovations in education is crucial. We cannot afford to let time pass without doing anything and without benefiting from this technique. It is time to enhance traditional learning methods and adopt more innovative approaches that take advantage of the potential of AI, like content and exam generation, and also improve students' learning experience by exploiting their closeness to the technology. This paper aims to answer the question of when and how to use artificial intelligence responsibly, considering it as a technology and limiting its excessive use. Additionally, we present the impact of GAI through a comparative study of student performance in three exam types: a classical MCQ exam written by the teacher, an adaptive MCQ exam generated by GAI from a topic, and a third MCQ exam generated by GAI based on the content of the provided documents. This study is conducted on students undergoing a software testing training program. By evaluating their performance in the AI-generated adaptive MCQ exams and the traditional MCQ exam, we can gain insights into the potential of this technology to enhance educational practices and provide personalized learning experiences. This research will contribute to the ongoing discussion on responsible and effective utilization of GAI in education, paving the way for future advancements in the field. © 2024 Academic Conferences Limited. All rights reserved.|Adaptive exam; Education; educational content; Generative AI; Generative artificial intelligence; IA; Learning experiences; MCQ|Adversarial machine learning; Computer software selection and evaluation; Contrastive Learning; Generative adversarial networks; Personnel training; Students; Adaptive exam; Comparatives studies; Creatives; Educational contents; Generative AI; Generative artificial intelligence; IA; Learning experiences; MCQ; Text images; Software testing|Conference paper|Final||Scopus|2-s2.0-85215655306
scopus|Santos R.; Santos I.; Magalhaes C.; De Souza Santos R.|Santos, Robson (58966059700); Santos, Italo (57842835100); Magalhaes, Cleyton (57211147199); De Souza Santos, Ronnie (57485848700)|58966059700; 57842835100; 57211147199; 57485848700|Are We Testing or Being Tested? Exploring the Practical Applications of Large Language Models in Software Testing|2024|Proceedings - 2024 IEEE Conference on Software Testing, Verification and Validation, ICST 2024||||353|360|7|12|10.1109/ICST60714.2024.00039|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203829482&doi=10.1109%2fICST60714.2024.00039&partnerID=40&md5=13e61dc8c5dbd29ae06e0af565b501df|A Large Language Model (LLM) represents a cutting-edge artificial intelligence model that generates content, including grammatical sentences, human-like paragraphs, and syntactically code snippets. LLMs can play a pivotal role in soft-ware development, including software testing. LLMs go beyond traditional roles such as requirement analysis and documentation and can support test case generation, making them valuable tools that significantly enhance testing practices within the field. Hence, we explore the practical application of LLMs in software testing within an industrial setting, focusing on their current use by professional testers. In this context, rather than relying on existing data, we conducted a cross-sectional survey and collected data within real working contexts-specifically, engaging with practitioners in industrial settings. We applied quantitative and qualitative techniques to analyze and synthesize our collected data. Our findings demonstrate that LLMs effectively enhance testing documents and significantly assist testing professionals in programming tasks like debugging and test case automation. LLMs can support individuals engaged in manual testing who need to code. However, it is crucial to emphasize that, at this early stage, software testing professionals should use LLMs with caution while well-defined methods and guidelines are being built for the secure adoption of these tools.  © 2024 IEEE.|large language models; LLMs; software testing; survey; test engineers|Computer debugging; Model checking; Program debugging; Software testing; Syntactics; Cutting edges; Human like; Industrial settings; Intelligence models; Language model; Large language model; LLM; Requirement analysis; Software testings; Test engineers; Application programs|Conference paper|Final|All Open Access; Green Open Access|Scopus|2-s2.0-85203829482
scopus||||Proceedings - 2024 ACM/IEEE 46th International Conference on Software Engineering: Software Engineering Education and Training, ICSE-SEET 2024|2024|Proceedings - International Conference on Software Engineering||||||404|0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195492018&partnerID=40&md5=3b4dc64c368436d125252c4d4afb2797|The proceedings contain 38 papers. The topics discussed include: assessing the impact of hints in learning formal specification; assessing AI detectors in identifying AI-generated code: implications for education; building collaborative learning: exploring social annotation in introductory programming; teaching software development for real-world problems using a microservice-based collaborative problem-solving approach; gamifying a software testing course with continuous integration; adopting an agile approach for reflective learning and teaching; experiences with summer camp communication via discord; using accessibility awareness interventions to improve computing education; training app developers in a software studio: the business nano challenge experience; breaking barriers: investigating the sense of belonging among women and non-binary students in software engineering; and an empirical study of the content and quality of sprint retrospectives in undergraduate team software projects.|||Conference review|Final||Scopus|2-s2.0-85195492018
scopus|Bao S.; Jiang N.; Zhu W.; Zhang P.|Bao, Shenglin (57895584100); Jiang, Nan (59496334700); Zhu, Weijie (59496313300); Zhang, Pei (59496466200)|57895584100; 59496334700; 59496313300; 59496466200|Generative Model-Based Test Case Generation and Operational Testing for Deep Learning|2024|2024 5th International Conference on Big Data and Artificial Intelligence and Software Engineering, ICBASE 2024||||565|570|5|0|10.1109/ICBASE63199.2024.10762049|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213814553&doi=10.1109%2fICBASE63199.2024.10762049&partnerID=40&md5=b0de1d39488097d7432d7697c51dccb6|As deep learning technologies, particularly those driven by deep neural networks, revolutionize various industries, testing and verifying deep learning models remain challenging, especially regarding their security. Traditional software testing methods like test case selection and generation are often unsuitable for deep learning applications due to their reliance on high-cost, manually labeled data. This paper introduces a test case generation method using deep generative models and a testing framework tailored for operational testing. This approach reduces the need for data annotation and lowers the costs associated with testing deep learning software. The framework focuses on using training data alone to assess quality metrics in operational environments, without additional annotated test cases. Experimental results confirm the method's efficacy in accurately evaluating the performance of deep learning models and identifying regression issues, offering significant advantages over traditional testing methods. © 2024 IEEE.|deep generative models; deep learning; deep learning testing; operational testing; test input generation|Federated learning; Generative adversarial networks; Deep generative model; Deep learning; Deep learning testing; Generative model; Learning models; Operational testing; Test case generation; Test input generation; Test inputs; Testing method; Contrastive Learning|Conference paper|Final||Scopus|2-s2.0-85213814553
scopus|Konuk M.; Bağlum C.; Yayan U.|Konuk, Metin (59490582000); Bağlum, Cem (58503905300); Yayan, Uğur (46061619200)|59490582000; 58503905300; 46061619200|Evaluation of Large Language Models for Unit Test Generation|2024|2024 Innovations in Intelligent Systems and Applications Conference, ASYU 2024|||||||0|10.1109/ASYU62119.2024.10756954|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213306844&doi=10.1109%2fASYU62119.2024.10756954&partnerID=40&md5=8783eb704ccf38967ab5fb555397cf4a|"In recent years, Artificial Intelligence (AI) has significantly transformed various industries, especially software development, through automation and enhanced decision-making processes. Traditional software testing, often manual and error-prone, cannot keep up with rapid development cycles and complex systems, leading to extended development times, higher costs, and undetected bugs. This study develops an AI-based platform using OpenAI models to generate and execute unit tests across multiple programming languages. By leveraging Large Language Models (LLMs) like GPT, we automate unit test creation, demonstrating proficiency in understanding and generating natural language to interpret code. Our web-based system architecture ensures efficient test generation and execution, significantly reducing manual effort and mitigating human error, thus revolutionizing software testing. Furthermore, we introduce unique evaluation metrics such as ""Is Executable"" and ""Assertion Count"" to assess the performance and effectiveness of the generated unit tests, providing a comprehensive measure of the models' capabilities. © 2024 IEEE."|AI-based Software Testing; Large Language Models (LLMs); Model Performance Evaluation; Unit Test Automation; Web-based Testing Platforms|Computer software selection and evaluation; Model checking; Multiprocessing programs; Program debugging; Software design; Artificial intelligence-based software testing; Language model; Large language model; Model performance evaluations; Software testings; Test Automation; Testing platforms; Unit test automation; Unit tests; Web-based testing; Web-based testing platform; Software testing|Conference paper|Final||Scopus|2-s2.0-85213306844
scopus|Haldar S.; Pierce M.; Capretz L.F.|Haldar, Susmita (58419715100); Pierce, Mary (59195600700); Capretz, Luiz Fernando (6602660867)|58419715100; 59195600700; 6602660867|WIP: Assessing the Effectiveness of ChatGPT in Preparatory Testing Activities|2024|Proceedings - Frontiers in Education Conference, FIE|||||||1|10.1109/FIE61694.2024.10893214|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000624682&doi=10.1109%2fFIE61694.2024.10893214&partnerID=40&md5=8dae0b8edad1244f74864b98a95aec50|This innovative practice WIP paper describes a research study that explores the integration of ChatGPT into the software testing curriculum and evaluates its effectiveness compared to human-generated testing artifacts. In a Capstone Project course, students were tasked with generating preparatory testing artifacts using ChatGPT prompts, which they had previously created manually. Their understanding and the effectiveness of the Artificial Intelligence generated artifacts were assessed through targeted questions. The results, drawn from this in-class assignment at a North American community college indicate that while ChatGPT can automate many testing preparation tasks, it cannot fully replace human expertise. However, students already familiar with Information Technology at the postgraduate level, found the integration of ChatGPT into their workflow to be straightforward. The study suggests that AI can be gradually introduced into software testing education to keep pace with technological advancements. © 2024 IEEE.|Black-box Testing; ChatGPT; Higher Education; Product Testing; Software Testing Education|Black-box testing; Computer software selection and evaluation; Curricula; Integration testing; Program debugging; Teaching; Black boxes; Capstone projects; ChatGPT; High educations; Innovative practices; Product testing; Project course; Research studies; Software testing education; Software testings; Students|Conference paper|Final||Scopus|2-s2.0-105000624682
scopus|Shekhawat D.; Saboo S.|Shekhawat, Deependra (59064748400); Saboo, Siddharth (58696879000)|59064748400; 58696879000|Fortifying the Energy Frontier: Overcoming Cybersecurity Challenges in the Oil and Gas Industry Through Resilient Strategies and Innovative Solutions|2024|Society of Petroleum Engineers - ADIPEC 2024|||||||0|10.2118/222471-MS|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215106339&doi=10.2118%2f222471-MS&partnerID=40&md5=eed4e682f6893f10bc6ffeef931fe7a3|"The oil and gas industry, a vital lifeline fueling the global economy, find itself at a pivotal juncture where the convergence of operational technology (OT) and information technology (IT) has ushered in unprecedented opportunities and challenges. As digital transformation sweeps across this sector, the imperative to fortify cybersecurity defenses against ever-evolving threats has become paramount. Innovative and forward-looking oil and gas organizations across the globe are adopting the Cloud in many forms because of their digital transformation initiatives. Data lakes, edge technology, machine-to-machine communication, and machine learning (ML) algorithms have been enabling this industrial digital transformation. This transformation is also driving changes to the OT landscape, and as these environments continue to evolve, OT environments are leveraging well proven IT solution patterns to improve the productivity and efficiency of production operations. Industrial customers often start their digital transformation journey by sending OT data to the cloud for analysis and analytics without sending commands back to the industrial automation and control systems (ICAS). This process is often called ""open loop"" operations, since there is one-way communication from edge to cloud. Customers generally find this relatively easy to secure and manage. However, more often we are witnessing requirements to optimize operations by generating an automatic or operator-initiated response in the oil and gas production operation, rig management based on insights gained from cloud analytics. This process is often referred to as ""closed loop"" operations with two-way communication between edge and cloud. The security and compliance practices for closed loop operations are more rigorous because closed operations manipulate OT devices remotely. Developing these practices should be rooted in a cyber risk assessment to help businesses understand and prioritize security concerns. In this paper we propose how strengths of Cloud computing can become key enabler for oil and gas organizations in helping them enhance their overall security posture and manage risks within OT environments. We have deployed solution patterns described in this paper as the foundational pillar of several Oil and Gas organization's overall OT system architecture to unlock both ""open loop"" and ""closed loop"" operations in a secure, reliable and cost-effective manner. The specific scope items we will cover in this paper focus on a custom security uplift framework having four foundational components - 1) Cloud led architecture patterns to provide next generation network segmentation strategies in OT De-militarized Zone 2) OT asset inventory and vulnerability management 3) Centralized security monitoring and incident response with help of Artificial Intelligence and most recently providing Generative AI based virtual assistant to query security event data from OT systems. For organizations to plan their industrial digital transformation safely and securely, it is recommended that a multi-layered approach to secure the Industrial Control Systems (ICS)/OT and Cloud environments be implemented as captured in ten security golden rules in the following paper [1]. In addition to this, in the paper we propose a comprehensive architecture framework that aligns with established cybersecurity framework (CSF) such as NIST. The use case studies discussed in the paper will highlight how customer have been able to remediate critical security vulnerabilities within weeks post implementation by deploying a comprehensive asset inventory discovery and vulnerability assessment. This has help reduce mean time to identify and mitigate vulnerabilities from months to days with automated testing in pre-production environments, ensure quick detection and response towards security incidents with help of advanced security monitoring and incident response playbooks, covering 100% of the OT assets through this capability and leverage advanced data analytics, machine learning to perform log mining, data cleansing, data validation, log mining and analysis through natural language processing such as conversational AI assistants powered by large language model (LLM) in the Cloud. Copyright 2024, Society of Petroleum Engineers."||Asphaltenes; Bearing pads; Bolts; Coal deposits; Costs; Critical path analysis; Drug products plants; Earnings; Financial markets; Foil bearings; Gasoline; Helical springs; Hydrostatic bearings; Journal bearings; Liquefied petroleum gas; Locks (fasteners); Loss prevention; Mineral oils; Naphthas; Nonmetallic bearings; Nonmetallic gears; Oil shale; Petroleum industry; Petroleum tar; Pipelines; Piston displacement; Piston rings; Proven reserves; Resource valuation; Ring springs; Rotating disks; Screws; Speed reducers; Steam; Variable speed drives; Wire belts; Closed-loop operation; Cyber security; Digital transformation; Oil and gas; Oil and Gas Industry; Operational technologies; Production operations; Security incident; Solution patterns; Technology system; Gas industry|Conference paper|Final||Scopus|2-s2.0-85215106339
scopus|Wang J.; Huang Y.; Chen C.; Liu Z.; Wang S.; Wang Q.|Wang, Junjie (55976866600); Huang, Yuchao (57225204798); Chen, Chunyang (57191225906); Liu, Zhe (57221434139); Wang, Song (56995463200); Wang, Qing (55698296000)|55976866600; 57225204798; 57191225906; 57221434139; 56995463200; 55698296000|Software Testing With Large Language Models: Survey, Landscape, and Vision|2024|IEEE Transactions on Software Engineering|50|4||911|936|25|161|10.1109/TSE.2024.3368208|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187981851&doi=10.1109%2fTSE.2024.3368208&partnerID=40&md5=b71952c4e45ad7ff9a41d511f92a830e|Pre-trained large language models (LLMs) have recently emerged as a breakthrough technology in natural language processing and artificial intelligence, with the ability to handle large-scale datasets and exhibit remarkable performance across a wide range of tasks. Meanwhile, software testing is a crucial undertaking that serves as a cornerstone for ensuring the quality and reliability of software products. As the scope and complexity of software systems continue to grow, the need for more effective software testing techniques becomes increasingly urgent, making it an area ripe for innovative approaches such as the use of LLMs. This paper provides a comprehensive review of the utilization of LLMs in software testing. It analyzes 102 relevant studies that have used LLMs for software testing, from both the software testing and LLMs perspectives. The paper presents a detailed discussion of the software testing tasks for which LLMs are commonly used, among which test case preparation and program repair are the most representative. It also analyzes the commonly used LLMs, the types of prompt engineering that are employed, as well as the accompanied techniques with these LLMs. It also summarizes the key challenges and potential opportunities in this direction. This work can serve as a roadmap for future research in this area, highlighting potential avenues for exploration, and identifying gaps in our current understanding of the use of LLMs in software testing. © 1976-2012 IEEE.|GPT; LLM; Pre-trained large language model; software testing|Computational linguistics; Engineering research; Large datasets; Natural language processing systems; Software reliability; Breakthrough technology; GPT; Language model; Language processing; Large language model; Large-scale datasets; Natural languages; Pre-trained large language model; Software testings; Software testing|Article|Final|All Open Access; Green Open Access|Scopus|2-s2.0-85187981851
scopus|Sindhu P.; Peruri G.S.; Yalavarthi M.|Sindhu, Pusarla (58714755400); Peruri, Giri Sainath (58926255100); Yalavarthi, Monisha (58927125400)|58714755400; 58926255100; 58927125400|An empirically based object-oriented testing using Machine learning|2024|EAI Endorsed Transactions on Internet of Things|10||||||1|10.4108/eetiot.5344|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187131305&doi=10.4108%2feetiot.5344&partnerID=40&md5=226a7a6ff348a4f07b51f8d91bbc8d53|INTRODUCTION: The rapid growth of machine learning has the potential to revolutionize various industries and applications by automating complex tasks and enhancing efficiency. Effective software testing is crucial for ensuring software quality and minimizing resource expenses in software engineering. Machine learning techniques play a vital role in software testing by aiding in test case prioritization, predicting software defects, and analyzing test results. OBJECTIVES: The primary objective of this study is to explore the use of machine learning algorithms for software defect prediction. METHODS: Machine Learning models including Random Forest Classifier, Logistic Regression, K Nearest Neighbors, Gradient Boosting Classifiers, Catboost Classifier, and Convolutional Neural Networks have been employed for the study. The dataset includes a wide range of features relevant to software defect prediction and evaluates the performance of different prediction models. The study also focussed on developing hybrid models using stacking classifiers, which combine multiple individual models to improve accuracy. RESULTS: The experimental results show that the hybrid models combining CatBoost and Convolutional Neural Network have outperformed individual models, achieving the highest accuracy of 89.5%, highlighting the effectiveness of combining machine learning algorithms for software defect prediction. CONCLUSION: In conclusion, this study sheds light on the pivotal role of machine learning in enhancing software defect prediction. © 2024 P. Sindhu et al.|Early defect prediction; Machine learning; Software defect; Software quality assurance; stacking classifier||Article|Final|All Open Access; Gold Open Access|Scopus|2-s2.0-85187131305
scopus|Mohandas P.; Duraipandian A.; Chaitanya V.; Tharun A.N.; Vishnuvardhan D.B.; Kumar D.N.V.|Mohandas, Parthiban (59724689900); Duraipandian, Amaravathi (59724998300); Chaitanya, Voleti (59724223400); Tharun, Allam Naga (59724535700); Vishnuvardhan, Divi Bala (59725160600); Kumar, Donelli Naga Vinay (59724066500)|59724689900; 59724998300; 59724223400; 59724535700; 59725160600; 59724066500|Leveraging Machine Learning for Enhanced Software Defect Prediction and Quality Assurance: A Comparative Analysis|2024|International Conference on Computing and Intelligent Reality Technologies, Proceedings of ICCIRT 2024||||198|202|4|0|10.1109/ICCIRT59484.2024.10921974|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001924835&doi=10.1109%2fICCIRT59484.2024.10921974&partnerID=40&md5=53829dbcc388b44e9f3020173d39ed99|The evolution of software engineering practices has heightened the emphasis on quality assurance, particularly in defect prediction and testing methodologies. Traditional approaches often fall short in addressing the complexities of modern software systems, prompting the integration of advanced technologies such as deep learning and machine learning. Recent research highlights the development of robust models for predicting defect density, which effectively tackle issues of data sparsity, alongside the introduction of specialized validation frameworks for AI-driven software that utilize innovative testing methods. Additionally, advancements in automated testing practices, including the use of large language models for test case generation and ensemble machine learning for bug classification, underscore the critical role of efficient maintenance in ensuring software quality. Furthermore, novel frameworks for validating unsupervised learning systems bridge user expectations with system performance evaluations. Collectively, these contributions reveal a trend towards leveraging cutting-edge methodologies to address the multifaceted challenges of software quality, emphasizing the need for adaptive and innovative strategies as software systems continue to evolve. © 2024 IEEE.|Artificial Intelligence; Automated Testing; Bug Classification; Cross-Project Defect Detection; Machine Learning; Software Testing|Computer software maintenance; Computer software selection and evaluation; Contrastive Learning; Deep learning; Integration testing; Multiprocessing programs; Unsupervised learning; Automated testing; Bug classification; Cross-project defect detection; Defect detection; Enhanced software; Machine-learning; Software defect prediction; Software Quality; Software testings; Software-systems; Software quality|Conference paper|Final||Scopus|2-s2.0-105001924835
scopus|Heider I.; Baumgärtner J.; Bott A.; Ströbel R.; Puchta A.; Fleischer J.|Heider, I. (57884258200); Baumgärtner, J. (57889703400); Bott, A. (57844672500); Ströbel, R. (57750683800); Puchta, A. (57203760223); Fleischer, J. (55798911800)|57884258200; 57889703400; 57844672500; 57750683800; 57203760223; 55798911800|Towards a Testing Framework for Machine Learning Model Deployment in Manufacturing Systems|2024|Procedia CIRP|127|||122|128|6|2|10.1016/j.procir.2024.07.022|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208537776&doi=10.1016%2fj.procir.2024.07.022&partnerID=40&md5=82622703a23ed92b2e90172b713cbb19|The deployment of machine learning models in manufacturing systems presents unique challenges, necessitating robust testing procedures to ensure reliable and efficient operation. This paper proposes an automated testing framework specifically designed to address these challenges, focusing on verifying the correct utilization of data sources, validating model functionality, and assessing the compatibility of the target machine with the deployed model. By automating the testing process, this framework aims to enhance the reliability and effectiveness of machine learning model deployment in manufacturing systems. Through a comprehensive literature review, the paper explores existing methodologies and identifies gaps in current practices. The proposed framework incorporates various test types, including unit tests, integration tests, regression tests, and performance tests, each tailored to the specific requirements of manufacturing systems. Experimental results demonstrate the framework's effectiveness in detecting errors and failures during the deployment process. Overall, this research contributes to advancing the field of machine learning deployment in manufacturing systems and provides practical insights for practitioners seeking to optimize the reliability and efficiency of their deployed models. © 2024 Elsevier B.V.. All rights reserved.|separated by semicolons; Type your keywords here|Computer aided manufacturing; Automated testing; Data-source; Literature reviews; Machine learning models; Separated by semicolons; Target machines; Testing framework; Testing procedure; Testing process; Type your keyword here; Smart manufacturing|Conference paper|Final|All Open Access; Gold Open Access|Scopus|2-s2.0-85208537776
scopus|Boukhlif M.; Kharmoum N.; Hanine M.; Elasri C.; Rhalem W.; Ezziyyani M.|Boukhlif, Mohamed (58247381400); Kharmoum, Nassim (57210745538); Hanine, Mohamed (57219370936); Elasri, Chaimae (59124893400); Rhalem, Wajih (57209215242); Ezziyyani, Mostafa (16032898300)|58247381400; 57210745538; 57219370936; 59124893400; 57209215242; 16032898300|Exploring the Application of Classical and Intelligent Software Testing in Medicine: A Literature Review|2024|Lecture Notes in Networks and Systems|904 LNNS|||37|46|9|4|10.1007/978-3-031-52388-5_4|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192893434&doi=10.1007%2f978-3-031-52388-5_4&partnerID=40&md5=71be3bcaa5e4fd493bba47320f26bf95|This literature review explores the vital role of both classic and intelligent software testing in ensuring the quality and safety of medical software. Classic approaches establish a solid foundation for testing and ensuring adherence to regulatory standards. On the other hand, intelligent testing methods, leveraging artificial intelligence, machine learning, and deep learning, offer valuable advantages such as automation, pattern recognition, and performance insights. However, these approaches also present challenges concerning data quality and potential bias. To optimize medical software testing, the review recommends a combined approach based on specific requirements and available resources. Ultimately, these testing approaches work towards improving the quality and safety of medical software, leading to enhanced patient outcomes and a more efficient healthcare system. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.|Artificial Intelligence; Biology; Deep Learning; Diabetes; Electrocardiology; Epidemiology; Histology; Literature Review; Machine Learning; Medical Software; Software Testing|Application programs; Deep learning; Learning systems; Pattern recognition; Safety testing; Deep learning; Electrocardiology; Intelligent software; Intelligent testing; Literature reviews; Machine-learning; Medical software; Quality and safeties; Regulatory standards; Software testings; Software testing|Conference paper|Final||Scopus|2-s2.0-85192893434
scopus|Khan S.A.; Oshin N.T.; Nizam M.; Ahmed I.; Musfique M.M.; Hasan M.|Khan, Saquib Ali (58938630900); Oshin, Nabilah Tabassum (58635125300); Nizam, Mahmuda (58938205900); Ahmed, Ishtiaque (58277234000); Musfique, Md Masum (58938424700); Hasan, Mahady (35105055600)|58938630900; 58635125300; 58938205900; 58277234000; 58938424700; 35105055600|AI-Based Software Testing|2024|Lecture Notes in Networks and Systems|833|||323|334|11|2|10.1007/978-981-99-8346-9_28|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187692741&doi=10.1007%2f978-981-99-8346-9_28&partnerID=40&md5=a1ddab0d8ce11150d587f78b04562e61|As the complexity of software applications continues to increase, software testing becomes more challenging and time-consuming. The use of artificial intelligence (AI) in software testing has emerged as a promising approach to address these challenges. AI-based software testing techniques leverage machine learning, natural language processing, and other AI technologies to automate the testing process, improve test coverage, and enhance the accuracy of test results. This paper provides an overview of AI-based software testing, including its benefits and limitations, and discusses various techniques and tools used in this field. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2024.|AI; Machine learning; Natural language processing; Software testing|Application programs; Learning algorithms; Machine learning; Natural language processing systems; Artificial intelligence technologies; Language processing; Machine-learning; Natural language processing; Natural languages; Software applications; Software testing techniques; Software testings; Test-coverage; Testing process; Software testing|Conference paper|Final||Scopus|2-s2.0-85187692741
scopus|Edirisinghe H.; Wickramaarachchi D.|Edirisinghe, Hasali (59563651300); Wickramaarachchi, Dilani (55787377800)|59563651300; 55787377800|Quality Assurance for LLM-Generated Test Cases: A Systematic Literature Review|2024|2024 8th SLAAI - International Conference on Artificial Intelligence, SLAAI-ICAI 2024|||||||0|10.1109/SLAAI-ICAI63667.2024.10844968|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218185301&doi=10.1109%2fSLAAI-ICAI63667.2024.10844968&partnerID=40&md5=096afb652d321b84bfbd34016a40afaf|The rapid advancements in artificial intelligence have transformed software testing, with Large Language Models (LLMs) emerging as powerful tools for automating test case generation. This paper explores Quality Assurance (QA) for LLM-generated test cases in black-box testing through a systematic literature review. Though LLMs are increasingly used for test case generation, challenges in ensuring their quality remain. Following PRISMA guidelines, relevant studies were selected from databases focusing on critical quality attributes, QA frameworks, metrics, and challenges. LLMs demonstrate high efficiency but face numerous issues. A recommendation for future research is given on addressing standardized metrics and improving human-AI collaboration for enhanced testing outcomes.  © 2024 IEEE.|black-box testing; evaluation metrics; large language models (LLMs); Quality Assurance (QA); test case generation|Model checking; Program debugging; Software quality; Black boxes; Critical quality; Evaluation metrics; Language model; Large language model; Quality assurance; Software testings; Systematic literature review; Test case; Test case generation; Black-box testing|Conference paper|Final||Scopus|2-s2.0-85218185301
scopus|Yao Y.; Wang J.; Hu Y.; Wang L.; Zhou Y.; Chen J.; Gai X.; Wang Z.; Liu W.|Yao, Yi (57192372183); Wang, Jun (59196398200); Hu, Yabai (57208483117); Wang, Lifeng (57192383389); Zhou, Yi (57192378121); Chen, Jack (57192383390); Gai, Xuming (59195556600); Wang, Zhenming (59196811800); Liu, Wenjun (59195556700)|57192372183; 59196398200; 57208483117; 57192383389; 57192378121; 57192383390; 59195556600; 59196811800; 59195556700|BugBlitz-AI: An Intelligent QA Assistant|2024|Proceedings of the IEEE International Conference on Software Engineering and Service Sciences, ICSESS||||57|63|6|0|10.1109/ICSESS62520.2024.10719045|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208189129&doi=10.1109%2fICSESS62520.2024.10719045&partnerID=40&md5=456349144d794316d9a8ee27dccc99b3|The evolution of software testing from manual to automated methods has significantly influenced quality assurance (QA) practices. However, challenges persist in post-execution phases, particularly in result analysis and reporting. Traditional post-execution validation phases require manual intervention for result analysis and report generation, leading to inefficiencies and potential development cycle delays. This paper introduces BugBlitz-AI, an AI-powered validation toolkit designed to enhance end-to-end test automation by automating result analysis and bug reporting processes. BugBlitz-AI leverages recent advancements in artificial intelligence to reduce the time-intensive tasks of manual result analysis and report generation, allowing QA teams to focus more on crucial aspects of product quality. By adopting BugBlitz-AI, organizations can advance automated testing practices and integrate AI into QA processes, ensuring higher product quality and faster time-to-market. The paper outlines BugBlitz-AI's architecture, discusses related work, details its quality enhancement strategies, and presents results demonstrating its effectiveness in real-world scenarios. © 2024 IEEE.|large language model (LLM); log analysis; software quality assurance; test automation|Computer software selection and evaluation; Software quality; Intelligent qualities; Language model; Large language model; Log analysis; Products quality; Report generation; Result analysis; Software quality assurance; Software testings; Test Automation; Software testing|Conference paper|Final|All Open Access; Green Open Access|Scopus|2-s2.0-85208189129
scopus|Amalfitano D.; Coppola R.; Distante D.; Ricca F.|Amalfitano, Domenico (25926238800); Coppola, Riccardo (57191261885); Distante, Damiano (14008871000); Ricca, Filippo (24822686600)|25926238800; 57191261885; 14008871000; 24822686600|AI in GUI-Based Software Testing: Insights from a Survey with Industrial Practitioners|2024|Communications in Computer and Information Science|2178 CCIS|||328|343|15|1|10.1007/978-3-031-70245-7_23|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204553132&doi=10.1007%2f978-3-031-70245-7_23&partnerID=40&md5=040504ba31081b4d3a8d92c5020cbed3|In today’s technology-driven world, there is a growing interest in leveraging Artificial Intelligence (AI) to streamline software testing processes. Our research delves into GUI-based testing, a prominent technique for verifying software functionality. Preliminary findings from our industrial survey of 45 respondents provide insights into the use of AI in GUI-based software testing. The survey aims to understand how AI supports GUI-based testing, the AI techniques and tools used, and the perceived advantages and limitations. The collected results suggest a diffuse yet superficial utilization of AI-based mechanisms among GUI-based testers. Practitioners often employ AI techniques in a technology-agnostic way, treating commercial tools as black boxes. These findings underscore the need for additional research aimed at gaining a deeper understanding of the AI techniques and tools employed in industry and their intended purposes. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.|Artificial Intelligence; GUI-based testing; Industrial survey|Graphical user interfaces; Artificial intelligence techniques; Artificial intelligence tools; GUI-based testing; Industrial practitioners; Industrial surveys; Intelligence support; Software functionality; Software testings; Techniques and tools; Testing process; Software testing|Conference paper|Final||Scopus|2-s2.0-85204553132
scopus|Zhang L.; Wang B.; Liu C.; Wen M.; Zhang Y.; Wang L.|Zhang, Lei (57214917458); Wang, Binbin (8718199000); Liu, Chang (58509595700); Wen, Mi (16235443200); Zhang, Yan (58996304700); Wang, Liangliang (56313943300)|57214917458; 8718199000; 58509595700; 16235443200; 58996304700; 56313943300|AMNeuzz: A Strongly Directed Fuzz Testing Method Based on Attention Mechanism|2024|ACM International Conference Proceeding Series||||105|110|5|1|10.1145/3641181.3641182|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191024178&doi=10.1145%2f3641181.3641182&partnerID=40&md5=ccf7faacf943fcb038a5fcf0bd8c70f7|Fuzzy testing is one of the most popular vulnerability mining techniques recently, it plays a huge role in exploiting software security vulnerabilities and improving software security. Fuzzy testing mainly performs specific variations on the collected seeds to obtain a large number of test cases that can be used to execute the target program and trigger potential crashes in the program. However, traditional fuzzy testing generally suffers from a low level of test automation and fewer types of vulnerabilities detected. Aiming at the above problems, the application of machine learning techniques to fuzzy testing has become a hot research topic in academia. However, some recent studies still have problems, such as low edge coverage and poor generalization ability. Therefore, this paper proposes a strongly directed fuzz testing method based on attention mechanism and we name the fuzzer as AMNeuzz. AMNeuzz uses neural networks combined with attention mechanisms to construct an automatic sample generation model, which is trained so that the model learns the intrinsic formatting features of the samples, thus being able to automatically generate test samples that conform to certain syntactic specifications to quickly examine program paths that may have vulnerabilities, and this improves efficiency. In addition, the performance of the fuzzers is improved by improving Neuzz's gradient strategy. The final experimental results show that the AMNeuzz method proposed in this paper can achieve higher edge coverage than NEUZZ under the same time overhead.  © 2024 ACM.|attention mechanism; fuzzing; machine learning; neural network|Machine learning; Attention mechanisms; Edge coverages; Fuzz Testing; Fuzzing; Machine-learning; Mining techniques; Neural-networks; Software security; Testing method; Vulnerabilities minings; Software testing|Conference paper|Final||Scopus|2-s2.0-85191024178
scopus|Haldar S.; Pierce M.; Capretz L.F.|Haldar, Susmita (58419715100); Pierce, Mary (59195600700); Capretz, Luiz Fernando (6602660867)|58419715100; 59195600700; 6602660867|Factors Influencing the Performance of Students in Software Automated Test Tools Course|2024|Proceedings - 2024 IEEE International Conference on Software Testing, Verification and Validation Workshops, ICSTW 2024||||331|339|8|0|10.1109/ICSTW60967.2024.00064|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205941840&doi=10.1109%2fICSTW60967.2024.00064&partnerID=40&md5=2e25f710f927e963f260fa8db48c985a|Formal software testing education is important for building efficient QA professionals. Various aspects of quality assurance approaches are usually covered in courses for training software testing students. Automated Test Tools is one of the core courses in the software testing post-graduate curriculum due to the high demand for automated testers in the workforce. It is important to understand which factors are affecting student performance in the automated testing course to be able to assist the students early on based on their needs. Various metrics that are considered for predicting student performance in this testing course are student engagement, grades on individual deliverables, and prerequisite courses. This study identifies the impact of assessing students based on individual vs. group activities, theoretical vs. practical components, and the effect of having taken prerequisite courses in their final grade. To carry out this research, student data was collected from the automated test tools course of a community college-based postgraduate certificate program in software testing. The dataset contained student records from the years 2021 to 2022 and consisted of information from five different semesters. Various machine learning algorithms were applied to develop an effective model for predicting students' performance in the automated software testing tools course, and finally, important features affecting the students' performance were identified. The predictive performance model of the automated test tools course that was developed by applying the logistic regression technique, showed the best performance, with an accuracy score of 90%.  © 2024 IEEE.|Automated Testing; Quality Assurance; Selenium; Software Testing Education; Student Engagement|Computer software selection and evaluation; Curricula; Logistic regression; Personnel training; Teaching; Automated test tools; Automated testing; Core course; Graduate curriculum; High demand; Performance; Software testing education; Software testings; Student engagement; Student performance; Students|Conference paper|Final|All Open Access; Green Open Access|Scopus|2-s2.0-85205941840
scopus|Hosni M.; Medarhri I.; Carrillo de Gea J.M.|Hosni, Mohamed (57189341317); Medarhri, Ibtissam (55818093100); Carrillo de Gea, Juan Manuel (36462477200)|57189341317; 55818093100; 36462477200|Software Testing Effort Estimation Based on Machine Learning Techniques: Single and Ensemble Methods|2024|International Joint Conference on Knowledge Discovery, Knowledge Engineering and Knowledge Management, IC3K - Proceedings|1|||517|524|7|0|10.5220/0013072400003838|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215294618&doi=10.5220%2f0013072400003838&partnerID=40&md5=6f6da6a2725407f1c12c633eedea7724|Delivering an accurate estimation of the effort required for software system development is crucial for the success of any software project. However, the software development lifecycle (SDLC) involves multiple activities, such as software design, software build, and software testing, among others. Software testing (ST) holds significant importance in the SDLC as it directly impacts software quality. Typically, the effort required for the testing phase is estimated as a percentage of the overall predicted SDLC effort, typically ranging between 10% and 60%. However, this approach poses risks as it hinders proper resource allocation by managers. Despite the importance of this issue, there is limited research available on estimating ST effort. This paper aims to address this concern by proposing four machine learning (ML) techniques and a heterogeneous ensemble to predict the effort required for ST activities. The ML techniques employed include K-nearest neighbor (KNN), Support Vector Regression, Multilayer Perceptron Neural Networks, and decision trees. The dataset used in this study was obtained from a well-known repository. Various unbiased performance indicators were utilized to evaluate the predictive capabilities of the proposed techniques. The overall results indicate that the KNN technique outperforms the other ML techniques, and the proposed ensemble showed superior performance accuracy compared to the remaining ML techniques. © 2024 by SCITEPRESS – Science and Technology Publications, Lda.|Ensemble Method; ISBSG; Machine Learning; Software Testing; Software Testing Effort|Computer aided software engineering; Computer software selection and evaluation; Federated learning; Multilayer neural networks; Nearest neighbor search; Software design; Software quality; Software testing; Support vector regression; Effort Estimation; Ensemble methods; ISBSG; Machine learning techniques; Machine-learning; Software development life-cycle; Software testing effort; Software testings; Testing effort; Contrastive Learning|Conference paper|Final||Scopus|2-s2.0-85215294618
scopus|Bahi A.; Gharib J.; Gahi Y.|Bahi, Anas (57199648769); Gharib, Jihane (57194158677); Gahi, Youssef (25929173300)|57199648769; 57194158677; 25929173300|Integrating Generative AI for Advancing Agile Software Development and Mitigating Project Management Challenges|2024|International Journal of Advanced Computer Science and Applications|15|3||54|61|7|8|10.14569/IJACSA.2024.0150306|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189940766&doi=10.14569%2fIJACSA.2024.0150306&partnerID=40&md5=7c9a6d1d09b1dc98d3d23c6146f4f519|Agile software development emphasizes iterative progress, adaptability, and stakeholder collaboration. It champions flexible planning, continuous improvement, and rapid delivery, aiming to respond swiftly to change and deliver value efficiently. Integrating Generative Artificial Intelligence (AI) into Agile software development processes presents a promising avenue for overcoming project management challenges and enhancing the efficiency and effectiveness of software development endeavors. This paper explores the potential benefits of leveraging Generative AI in Agile methodologies, aiming to streamline development workflows, foster innovation, and mitigate common project management challenges. By harnessing the capabilities of Generative AI for tasks such as code generation, automated testing, and predictive analytics, Agile teams can augment their productivity, accelerate delivery cycles, and improve the quality of software products. Additionally, Generative AI offers opportunities for enhancing collaboration, facilitating decision-making, and addressing uncertainties inherent in Agile project management. Through an in-depth analysis of the integration of Generative AI within Agile frameworks, this paper provides insights into how organizations can harness the transformative potential of AI to advance Agile software development practices and navigate the complexities of modern software projects more effectively. © (2024), (Science and Information Organization). All Rights Reserved.|Agile software development; Artificial intelligence; software engineering|Decision making; Iterative methods; Predictive analytics; Project management; Software design; Software testing; Agile Methodologies; Agile software development; Agile software development process; Codegeneration; Common projects; Continuous improvements; Development workflow; Flexible planning; Management challenges; Potential benefits; Artificial intelligence|Article|Final|All Open Access; Gold Open Access|Scopus|2-s2.0-85189940766
scopus|Liu Y.|Liu, Yanyan (59419196400)|59419196400|Natural Language Processing Technology Based on Artificial Intelligence in Software Testing|2024|2024 3rd International Conference on Artificial Intelligence and Computer Information Technology, AICIT 2024|||||||0|10.1109/AICIT62434.2024.10730603|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209775473&doi=10.1109%2fAICIT62434.2024.10730603&partnerID=40&md5=3305dd32c31514d71cf4a6293caf8d1a|The application of Natural Language Processing (NLP) technology based on artificial intelligence technology in the field of software testing is becoming increasingly widespread. This article explores how NLP technology based on BERT (Bidirectional Encoder Representations from Transformers) can be deeply integrated into various aspects of software testing, achieving automation in requirement analysis, test case generation, defect report processing, and test result description. Through a series of experiments, the significant advantages of BERT technology in improving testing efficiency, accuracy, and reducing manual intervention have been verified. This article first introduces the theoretical foundation and key technologies of NLP technology in software testing, then describes in detail the integration framework based on BERT algorithm, and demonstrates its application effects in test data preparation, preprocessing, automated defect recognition, and report generation through experimental results. Experimental data shows that BERT technology has significant advantages in test case coverage, defect detection accuracy, and test regression cycle, with a maximum regression cycle of only 599ms. Despite challenges such as model generalization ability, data quality dependency, and computational resource consumption, the integrated framework of BERT technology provides new possibilities for the automation and intelligence of software testing.  © 2024 IEEE.|Bidirectional Encoder Representations from Transformers; Defect Detection; Natural Language Processing; Software Testing|Ability testing; Computer software selection and evaluation; Data integration; Distribution transformers; Electric transformer testing; Integration testing; Natural language processing systems; Report generators; Artificial intelligence technologies; Bidirectional encoder representation from transformer; Defect detection; Defect reports; Language processing; Natural language processing; Natural languages; Processing technologies; Software testings; Technology-based; Application programs|Conference paper|Final||Scopus|2-s2.0-85209775473
scopus|Sebastian A.; Naseem H.; Catal C.|Sebastian, Anila (58098282800); Naseem, Hira (57327838300); Catal, Cagatay (22633325800)|58098282800; 57327838300; 22633325800|Unsupervised Machine Learning Approaches for Test Suite Reduction|2024|Applied Artificial Intelligence|38|1|2322336||||2|10.1080/08839514.2024.2322336|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186618818&doi=10.1080%2f08839514.2024.2322336&partnerID=40&md5=16b5af7dc9cb15b5c5b0ee81cb57d7a7|Ensuring quality and reliability mandates thorough software testing at every stage of the development cycle. As software systems grow in size, complexity, and functionality, the parallel expansion of the test suite leads to an inefficient utilization of computational power and time, presenting challenges to optimization. Therefore, the Test Suite Reduction (TSR) process is of great importance, contributing to the reduction of time and costs in executing test suites for complex software by minimizing the number of test cases to be executed. Over the past decade, machine learning-based solutions have emerged, demonstrating remarkable effectiveness and efficiency. Recent studies have delved into the application of Machine Learning (ML) in the software testing domain, where the high cost and time consumption associated with data annotation have prompted the use of unsupervised algorithms. In this research, we conducted a Systematic Mapping Study (SMS), examining the types of unsupervised algorithms implemented in developed models and thoroughly exploring the evaluation metrics employed. This study highlighted the prevalence of the K-Means clustering algorithm and the coverage metric for validation in various studies. Additionally, we identified a gap in the literature regarding scalability considerations. Our findings underscore the effective use of unsupervised learning approaches in test suite reduction. © 2024 The Author(s). Published with license by Taylor & Francis Group, LLC.||Application programs; K-means clustering; Machine learning; Software reliability; Computational time; Development cycle; Machine learning approaches; Machine-learning; Size complexity; Software testings; Software-systems; Test suite reduction; Unsupervised algorithms; Unsupervised machine learning; Software testing|Review|Final|All Open Access; Gold Open Access|Scopus|2-s2.0-85186618818
scopus|Li Y.; Li Y.; Yang Y.|Li, Youwei (59512711200); Li, Yangyang (59512711300); Yang, Yangzhao (55513481300)|59512711200; 59512711300; 55513481300|Test-Agent: A Multimodal App Automation Testing Framework Based on the Large Language Model|2024|Proceedings - 2024 IEEE 4th International Conference on Digital Twins and Parallel Intelligence, DTPI 2024||||609|614|5|1|10.1109/DTPI61353.2024.10778901|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214923908&doi=10.1109%2fDTPI61353.2024.10778901&partnerID=40&md5=f4f6eebe8327b84768c0ef95e7315b76|This paper introduces a multimodal agent-based app automation testing framework, named Test-Agent, built on the Large Language Model (LLM), designed to address the growing challenges in mobile application automation testing. As mobile applications become more prevalent and emerging systems like Harmony OS Next and mini-programs emerge, traditional automated testing methods, which depend on manually crafting test cases and scripts, are no longer sufficient for cross-platform compatibility and complex interaction logic. The Test-Agent framework employs artificial intelligence technologies to analyze application interface screenshots and user natural language instructions. Combined with deep learning models, it automatically generates and executes test actions on mobile devices. This innovative approach eliminates the need for pre-written test scripts or backend system access, relying solely on screenshots and UI structure information. It achieves cross-platform and cross-application universality, significantly reducing the workload of test case writing, enhancing test execution efficiency, and strengthening cross-platform adaptability. Test-Agent offers an innovative and efficient solution for automated testing of mobile applications. © 2024 IEEE.|Agent; App Automation Testing; Large Language Model|Application programs; Computer debugging; Computer operating systems; Mobile agents; Model checking; Software testing; App automation testing; Automated testing; Automation testing; Cross-platform; Language model; Large language model; Mobile applications; Test case; Test scripts; Testing framework; Mobile applications|Conference paper|Final||Scopus|2-s2.0-85214923908
scopus|Ramadevi P.; Das R.|Ramadevi, Potharla (59123918000); Das, Raja (55548318900)|59123918000; 55548318900|An Extensive Analysis of Machine Learning Techniques With Hyper-Parameter Tuning by Bayesian Optimized SVM Kernel for the Detection of Human Lung Disease|2024|IEEE Access|12|||97752|97770|18|8|10.1109/ACCESS.2024.3422449|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199191699&doi=10.1109%2fACCESS.2024.3422449&partnerID=40&md5=bd399e5899d35acd503bddf17e088d6a|The COVID-19 coronavirus epidemic started in Wuhan in 2019, had a detrimental impact on millions of people's lives, and caused many fatalities. Different limitation choices were made globally to prevent the disease, which is still present, from spreading. To stop the spread of COVID-19, it is important to use individually a medical method and automated testing technologies aimed at quick identification. Artificial intelligence (AI) methods for diagnosing COVID-19 might effectively use chest X-ray (CXR) images from chest radiography. In this research, we developed training Support Vector machine kernel option hyperparameters of the Convolutional neural networks (CNN) optimized using the Bayesian method. Additionally, CNN pre-trained models and Support Vector Machine (SVM) classifiers were used to classify the CXR images. Six well-known deep pre-trained models are compared to the optimized CNN's performance using the CXR image dataset: COVID-19, Normal, Pneumonia Bacterial, Pneumonia Viral, and Tuberculosis (TB) for multi-classification. In this research, CNN models such as AlexNet, ReseNet50, ReseNet101, VGG16, VGG19, and InceptionV3 with the proposed method SVM kernel utilized the dataset. The proposed approach shows that using the SVM kernel could give it a better forecasting technique. ReseNet101 achieved the best accuracy of 98.7% result, a hybrid model that included Deep CNN features with Bayesian optimization produced a high degree of classification performance within a short amount of time. © 2013 IEEE.|Bayesian optimization; Convolutional neural networks; machine learning model; ReseNet101; SVM kernel|Barium compounds; Bayesian networks; Classification (of information); Convolution; COVID-19; Diagnosis; Neural networks; Statistical tests; X ray radiography; Bayesian optimization; Chest X-ray image; Convolutional neural network; Hyper-parameter; Machine learning models; Machine learning techniques; Parameters tuning; Resenet101; Support vector machine kernel; Support vectors machine; Support vector machines|Article|Final|All Open Access; Gold Open Access|Scopus|2-s2.0-85199191699
scopus|Ridder B.|Ridder, Bram (56495213600)|56495213600|Automated Testing Using AI Planning|2024|Game AI Uncovered: Volume Two|2|||148|159|11|0|10.1201/9781003323549-18|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194015284&doi=10.1201%2f9781003323549-18&partnerID=40&md5=d7aaac7096f31bf94eba7d671401d400|This chapter describes a novel automated testing framework that can play any game from start to finish like a player would. It will demonstrate how this framework combines traditional techniques, like behaviour trees (BTs), finite-state machines (FSMs), with a Numeric Domain-independent AI Planning system. The drawbacks of BTs and FSMs are explained and how this system reduces the complexity of BTs to a few behaviours, because the AI planning system deals with the high-level reasoning and complexity. Due to the low complexity of the behaviours and the ease of creating abstract models of game worlds, it is shown how you can test game projects very early in production and provide valuable data throughout the entire game development cycle. This chapter details how AI Planning works and how to create abstract models of the game and present a generic framework that has been used in practice to create a capable bot that can play through entire games, start to finish like a player would. © 2024 selection and editorial matter, Paul Roberts; individual chapters, the contributors.|||Book chapter|Final||Scopus|2-s2.0-85194015284
scopus|Garlapati A.; Parmesh M.N.V.S.S.M.; Savitha; Jaisri S.|Garlapati, Anusha (57221905674); Parmesh, M. N. V. Satya Sai Muni (59729614300); Savitha (59369797500); Jaisri, S. (59531398300)|57221905674; 59729614300; 59369797500; 59531398300|AI-Powered Multi-Agent Framework for Automated Unit Test Case Generation: Enhancing Software Quality through LLM's|2024|2024 5th IEEE Global Conference for Advancement in Technology, GCAT 2024|||||||0|10.1109/GCAT62922.2024.10923987|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002210499&doi=10.1109%2fGCAT62922.2024.10923987&partnerID=40&md5=3c73936e6d2ea644305928987024f057|"Recent years have witnessed an enormous rise in the design, repair and the enhancement of software automation tests. The reliability of program's unit testing has major impact on its overall performance. The anticipated influence of Artificial Intelligence advancements on test automation methodologies are significant. Many studies on automated testing implicitly assume that the test results are deterministic, means that similar tests faults remain same. The precision of software is largely ensured by unit testing. But writing unit tests manually is a time-consuming process, which leads us to drive into ""Automation Analysis"". Recent years comprised the application of Large Language Models (LLM's) in numerous fields related to software development, especially the automated creation of unit testing.However, these frameworks require more instructions, or few shot learnings on sample tests that already exist. This research provides a comprehensive empirical assessment of the efficiency of LLM's for automating unit testing production, with no need for further manual analysis. The method we employ is put into practice for test cases, an adaptable Agents and LLM-based testing framework that evaluates test cases generated, by reviewing and re-writing them in different phases. Evaluation of this test cases was done by using mistral-large LLM Model. The analysis results that developed acquired an overall coverage of 100% for code given. Finally, to enhance the typical evaluation, this research suggests and concludes that LLMs, can be successfully incorporated into present practices, through adaptative instructions and improvements. © 2024 IEEE."|Agents; Artificial Intelligence; Automation; Large Language Models - LLM's; Manual Testing; Unit Tests|Application programs; Automatic test pattern generation; Computer software selection and evaluation; Intelligent agents; Model checking; Software design; Software quality; Software reliability; Automated units; Language model; Large language model - large language model; Manual testing; Multiagent framework; Test case; Test case generation; Unit testing; Unit tests; Software testing|Conference paper|Final||Scopus|2-s2.0-105002210499
scopus|Trifunova A.; Jakimovski B.; Chorbev I.; Lameski P.|Trifunova, Andrea (59541712600); Jakimovski, Boro (8979316800); Chorbev, Ivan (14018877400); Lameski, Petre (35107267200)|59541712600; 8979316800; 14018877400; 35107267200|AI in Software Testing: Revolutionizing Quality Assurance|2024|2024 32nd Telecommunications Forum, TELFOR 2024 - Proceedings of Papers|||||||1|10.1109/TELFOR63250.2024.10819179|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216863896&doi=10.1109%2fTELFOR63250.2024.10819179&partnerID=40&md5=88f1cc91f8fb6becb303b9ce41242013|Artificial intelligence (AI) is an area of tremendous potential, especially in the software testing domain, where it has changed the dynamics of the process, storms in efficiency, accuracy, and flexibility in a given SDLC. This paper presents findings from recent investigations of AI in the testing and quality assurance focusing on its transformational potential. Particular attention is paid to such issues as automation of testing processes through AI, testing process enhancement, and possible changes in software engineering due to AI implementation. In this paper, various research perspectives have been integrated to reveal the effectiveness of AI in enhancing the perceived quality assurance processes, improving product quality, and adopting principles of agile methodology in today's software development. © 2024 IEEE.|Artificial intelligence; Software testing|Agile Methodologies; Perceived quality; Process enhancements; Process Improving; Products quality; Quality assurance process; Software testings; Testing process; Software quality|Conference paper|Final||Scopus|2-s2.0-85216863896
scopus|Sahu A.; Carlan C.|Sahu, Amit (59890487300); Carlan, Carmen (57191252830)|59890487300; 57191252830|Defect-based Testing for Safety-critical ML Components|2024|Proceedings - 2024 IEEE 35th International Symposium on Software Reliability Engineering Workshops, ISSREW 2024||||255|262|7|0|10.1109/ISSREW63542.2024.00088|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215264499&doi=10.1109%2fISSREW63542.2024.00088&partnerID=40&md5=239b1977e2ecfed65dfb33839614fae2|The input space of machine learning (ML) components used in safety-critical applications is complex. Due to practical restrictions, testing such components on exponentially large datasets that cover all potential real-world situations to meaningfully measure performance metrics, such as the false negative rate, is infeasible. Hence, we must limit the test data while adequately covering critical input data points. Inspired by defect-based software testing, a methodology for specifying adequate test cases for software components, we propose a process for collecting adequate test data for ML components. Concretely, we propose systematically employing different existing ML data quality metrics and methods for enhancing the test data to uncover critical scenarios where the ML component may be less performant. We exemplify the usage of our process in two case studies involving ML components implementing different functionalities, i.e., stop sign recognition and railway track segmentation. © 2024 IEEE.|defect-based testing; Machine Learning (ML); ML test data; safety engineering|Critical machine; Defect-based testing; Input space; Large datasets; Machine learning; Machine learning test data; Machine-learning; Safety critical applications; Test data; Input output programs|Conference paper|Final||Scopus|2-s2.0-85215264499
scopus|Shanmugam P.; Kumar P.K.M.; Hussain M.M.; Revathi R.; Deepa P.; Sakthivelu U.|Shanmugam, P. (57211794479); Kumar, P.K. Manoj (59973570500); Hussain, Mohammad Manzoor (57832139600); Revathi, R. (59924449200); Deepa, P. (55250539600); Sakthivelu, U. (57982408100)|57211794479; 59973570500; 57832139600; 59924449200; 55250539600; 57982408100|A Deep Learning Model-Based Neural Network Framework for Diabetic Foot Ulcer Classification|2024|5th International Conference on Electronics and Sustainable Communication Systems, ICESC 2024 - Proceedings||||1305|1310|5|1|10.1109/ICESC60852.2024.10690106|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206655180&doi=10.1109%2fICESC60852.2024.10690106&partnerID=40&md5=c4d5fb1b1e5ad1f7bb9f6b2111d670a1|Diabetic Foot Ulcer (DFU) is a severe complication of diabetes, frequently resulting in amputation and having a significant impact on patients' quality of life. Early and accurate DFU classification is essential for prompt and efficient therapy. This study introduces an innovative neural network framework that utilizes deep learning techniques to categorize DFU based on thermograms. The proposed framework employs the pre-trained EfficientNet-B0 deep learning model, well-known for its exceptional performance in image classification tasks. The framework underwent training and assessment using a dataset sourced from Kaggle, consisting of 1866 colored images. Among them, 890 images depict plantar thermograms with negative DFU, whereas 976 images depict foot thermograms with positive DFU. The proposed framework demonstrated a higher accuracy of 98.71, outperforming previous approaches by a wide margin. The findings demonstrate the ability of deep learning to categorize DFU, paving the way for the development of automated testing techniques to assist healthcare practitioners in the timely identification and treatment of this incapacitating ailment.  © 2024 IEEE.|classification; Deep learning; diabetic foot ulcers; neural networks; thermograms|Deep neural networks; Deep learning; Diabetic foot ulcer; Learning models; Learning techniques; Model based neural networks; Network frameworks; Neural-networks; Performance; Quality of life; Thermogram; Ability testing|Conference paper|Final||Scopus|2-s2.0-85206655180
scopus|Zhang L.; Tsai W.-T.|Zhang, Li (57218408896); Tsai, Wei-Tek (7402907369)|57218408896; 7402907369|Adaptive attention fusion network for cross-device GUI element re-identification in crowdsourced testing|2024|Neurocomputing|580||127502||||2|10.1016/j.neucom.2024.127502|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187188338&doi=10.1016%2fj.neucom.2024.127502&partnerID=40&md5=37f6c35a4ddde0482e1e444f957dcf88|The rapid growth of mobile devices has ushered in an era of different device platforms. Different devices require a consistent user experience, especially with similar graphical user interfaces (GUIs). However, the different code bases of the various operating systems as well as the different GUI layouts and resolutions of the various devices pose a challenge for automated software testing. Crowdsourced software testing (CST) has emerged as a viable solution where crowdsourced workers perform tests on their own devices and provide detailed bug reports. Although CST is cost-effective, it is not very efficient and requires a large number of workers for manual testing. The potential of optimizing CST reproduction testing through computer vision remains largely untapped, especially when considering the uniformity of GUI elements on different devices. In this study, we present a novel deep learning model specifically designed to re-identify GUI elements in CST reproduction test scenarios, regardless of the underlying code changes on different devices. The model features a robust backbone network for feature extraction, an innovative attention mechanism with learnable factors to enhance the features of GUI elements and minimize interference from their backgrounds, and a classifier to determine matching labels for these elements. Our approach was validated on a large GUI element dataset containing 31,098 element images for training, 115,704 element images from real apps for testing, and 67 different background images. The results of our experiments underline the excellent accuracy of the model and the importance of each component. This work is a major step forward in improving the efficiency of reproduction testing in CST. The innovative solutions we propose could further reduce labor costs for CST platforms. © 2024 Elsevier B.V.|Adaptive attention mechanism; Computer vision; Convolutional neural network; Cross-device testing; Crowdtesting; GUI element re-identification|Cell proliferation; Computer vision; Convolutional neural networks; Crowdsourcing; Deep learning; Graphical user interfaces; Large datasets; Software testing; Statistical tests; Wages; Well testing; Adaptive attention mechanism; Attention mechanisms; Convolutional neural network; Cross-device testing; Crowdtesting; Device testing; Element re; Graphical user interface element re-identification; Interface elements; Re identifications; Article; computer vision; convolutional neural network; crowdsourcing; data analysis; deep learning; detection algorithm; image processing; information processing; kernel method; mathematical computing; Cost effectiveness|Article|Final||Scopus|2-s2.0-85187188338
scopus|Shameem M.; Niazi M.; Nadeem M.; Kumar A.|Shameem, Mohammad (57197706146); Niazi, Mahmood (14045585000); Nadeem, Mohammad (57141925600); Kumar, Ankur (57226074958)|57197706146; 14045585000; 57141925600; 57226074958|AI-enabled Software Engineer: A Taxonomy of Challenges and Success Factors|2024|Proceedings of the International Conference on Software Engineering and Knowledge Engineering, SEKE||||69|71|2|0|10.18293/SEKE2024-063|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218637529&doi=10.18293%2fSEKE2024-063&partnerID=40&md5=d47fb4791232447c8841401ee974b13e|Artificial intelligence (AI) is revolutionizing software development by enabling high-quality products at lower costs and faster delivery. While existing research highlights ChatGPT’s role in various phases of software development, little attention has been given to its use in end-to-end project delivery. This study explores the challenges and success factors for using AI tools in complete project workflows through interviews with software practitioners. Key challenges identified include knowledge gaps in LLMs, programming languages, and automated testing, while success factors include cost efficiency, early prototyping, and continuous improvement. These insights offer a framework for implementing AI-assisted software engineering in end-to-end projects. © 2024 Knowledge Systems Institute Graduate School. All rights reserved.|Distributed agile process; Global software development; Systematic literature review|Automatic testing; Computer aided software engineering; Software prototyping; Software quality; Software testing; Agile process; Artificial intelligence tools; Distributed agile process; End to end; Global software development; High-quality products; Low-costs; Project delivery; Success factors; Systematic literature review; Software design|Conference paper|Final||Scopus|2-s2.0-85218637529
scopus|Braiek H.B.; Khomh F.|Braiek, Houssem Ben (57203412343); Khomh, Foutse (24724747600)|57203412343; 24724747600|Machine learning robustness: a primer|2024|Trustworthy Ai in Medical Imaging||||37|71|34|1|10.1016/B978-0-44-323761-4.00012-2|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218359898&doi=10.1016%2fB978-0-44-323761-4.00012-2&partnerID=40&md5=1520c0846de4243605bab6e7bed621b3|This chapter explores the foundational concept of robustness in Machine Learning (ML) and its integral role in establishing trustworthiness in Artificial Intelligence (AI) systems. The discussion begins with a detailed definition of robustness, portraying it as the ability of ML models to maintain stable performance across varied and unexpected environmental conditions. ML robustness is dissected through several lenses: its complementarity with generalizability, its status as a requirement for trustworthy AI, its adversarial vs. nonadversarial aspects, its quantitative metrics, and its indicators such as reproducibility and explainability. The chapter delves into the factors that impede robustness, such as data bias, model complexity, and the pitfalls of underspecified ML pipelines. It surveys key techniques for robustness assessment from a broad perspective, including adversarial attacks, encompassing both digital and physical realms. It covers nonadversarial data shifts and nuances of Deep Learning (DL) software testing methodologies. The discussion progresses to explore amelioration strategies for bolstering robustness, starting with data-centric approaches like debiasing and augmentation. Further examination includes a variety of model-centric methods such as transfer learning, adversarial training, and randomized smoothing. Lastly, posttraining methods are discussed, including ensemble techniques, pruning, and model repairs, emerging as cost-effective strategies to make models more resilient against the unpredictable. This chapter underscores the ongoing challenges and limitations in estimating and achieving ML robustness by existing approaches. It offers insights and directions for future research on this crucial concept, a prerequisite for trustworthy AI systems. © 2025 Elsevier Inc. All rights reserved.|Adversarial robustness; Deep learning; DL software testing; Machine learning; Model verification; Nonadversarial robustness; Robust AI; Robust training; Robustness assurance; Trustworthy AI||Book chapter|Final|All Open Access; Green Open Access|Scopus|2-s2.0-85218359898
scopus|Layman L.; Vetter R.|Layman, Lucas (8324841200); Vetter, Ron (7103032994)|8324841200; 7103032994|Generative Artificial Intelligence and the Future of Software Testing|2024|Computer|57|1||27|32|5|9|10.1109/MC.2023.3306998|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183077943&doi=10.1109%2fMC.2023.3306998&partnerID=40&md5=b75bacfb63d6710200a262db6e818d28|This virtual roundtable focuses on applications of generative artificial intelligence (GenAI) to software testing with four leading experts from the field. Our experts reflect on transforming the work of software testing with GenAI, its impact on quality assurance engineers, and privacy concerns. COMPUTER0018-9162/24 ©2024 IEEE.||Application programs; Artificial intelligence; Quality assurance; Leading experts; Privacy concerns; Software testings; Software testing|Article|Final|All Open Access; Bronze Open Access|Scopus|2-s2.0-85183077943
scopus|Jha P.; Sahu M.; Bisoy S.K.; Pati B.; Panigrahi C.R.|Jha, Pragya (57771707700); Sahu, Madhusmita (59428530400); Bisoy, Sukant Kishoro (59454537600); Pati, Bibudhendu (56439232500); Panigrahi, Chhabi Rani (35810907800)|57771707700; 59428530400; 59454537600; 56439232500; 35810907800|Application of Machine Learning in Software Testing of Healthcare Domain|2024|Lecture Notes in Networks and Systems|1|||63|73|10|0|10.1007/978-981-99-5015-7_6|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200324216&doi=10.1007%2f978-981-99-5015-7_6&partnerID=40&md5=327f8337a9aff2d3e66be94921083fc4|Software testing stage plays an important role in the software development life cycle. Structural testing is a popular method of software testing among other sorts. By traveling through all potential software code paths, structural testing can be greatly enhanced. The most popular search method for automating path testing and test case generation is the genetic algorithm. In this research, an algorithm based on ant colony optimization (ACO) has been suggested, which will produce a set of best paths and rank them. In order to produce test data for structural testing, the basic ACO algorithm is transformed into discrete version in this study. The technical road map for integrating the modified ACO algorithm and test procedure is presented first. The method also creates test data sequences within the domain for the produced pathways to use as inputs. The suggested method ensures complete software coverage with the least amount of redundancy. This paper also applies the suggested strategy by way of a program module. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2024.|Activity diagram; Activity flow graph (AFG); Ant colony optimization (ACO); Software testing; Test data generation; UML|Ant colony optimization; Application programs; Flow graphs; Genetic algorithms; Life cycle; Machine learning; Software design; Activity diagram; Activity flow; Activity flow graph; Ant colony optimization; Flow-graphs; Software testings; Structural testing; Test data; Test data generation; UML; Software testing|Conference paper|Final||Scopus|2-s2.0-85200324216
scopus|Staron M.; Abrahao S.; Gay G.; Serebrenik A.|Staron, Miroslaw (6505767603); Abrahao, Silvia (8211929700); Gay, Gregory (25723089800); Serebrenik, Alexander (8987563200)|6505767603; 8211929700; 25723089800; 8987563200|Testing, Debugging, and Log Analysis With Modern AI Tools|2024|IEEE Software|41|2||99|102|3|2|10.1109/MS.2023.3339408|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187131916&doi=10.1109%2fMS.2023.3339408&partnerID=40&md5=5ef2b48f0f1769387a748bc93d73e481|This edition of the Practitioners Digest covers recent papers employing generative artificial intelligence in support of testing, debugging, and log analysis that were presented at the 38th IEEE/ACM International Conference on Automated Software Engineering (ASE 2023) and the 16th IEEE International Conference on Software, Testing, Verification and Validation (ICST 2023). Feedback or suggestions are welcome. In addition, if you try or adopt any of the practices included in the column, please send us and the authors of the paper(s) a note about your experiences.  © 1984-2012 IEEE.||Program debugging; Verification; Well logging; Log analysis; Software testings; Software validation; Software verification; Testing analysis; Verification-and-validation; Software testing|Article|Final||Scopus|2-s2.0-85187131916
scopus|Amini M.H.; Naseri S.; Nejati S.|Amini, Mohammad Hossein (59283133300); Naseri, Shervin (58775621600); Nejati, Shiva (18038340600)|59283133300; 58775621600; 18038340600|Evaluating the impact of flaky simulators on testing autonomous driving systems|2024|Empirical Software Engineering|29|2|47||||6|10.1007/s10664-023-10433-5|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185541427&doi=10.1007%2fs10664-023-10433-5&partnerID=40&md5=aafc29c7cb1a42b3e03a3fdcba8086b1|Simulators are widely used to test Autonomous Driving Systems (ADS), but their potential flakiness can lead to inconsistent test results. We investigate test flakiness in simulation-based testing of ADS by addressing two key questions: (1) How do flaky ADS simulations impact automated testing that relies on randomized algorithms? and (2) Can machine learning (ML) effectively identify flaky ADS tests while decreasing the required number of test reruns? Our empirical results, obtained from two widely-used open-source ADS simulators and five diverse ADS test setups, show that test flakiness in ADS is a common occurrence and can significantly impact the test results obtained by randomized algorithms. Further, our ML classifiers effectively identify flaky ADS tests using only a single test run, achieving F1-scores of 85%, 82% and 96% for three different ADS test setups. Our classifiers significantly outperform our non-ML baseline, which requires executing tests at least twice, by 31%, 21%, and 13% in F1-score performance, respectively. We conclude with a discussion on the scope, implications and limitations of our study. We provide our complete replication package in a Github repository (Github paper 2023). © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.|Autonomous driving systems; Machine learning and simulators; Search-based testing|Deceleration; Machine learning; Autonomous driving; Autonomous driving system; Driving systems; F1 scores; Machine learning and simulator; Machine-learning; Randomized Algorithms; Search-based testing; System test; Test setups; Autonomous vehicles|Article|Final||Scopus|2-s2.0-85185541427
scopus|Naimi L.; Bouziane E.M.; Manaouch M.; Jakimi A.|Naimi, Lahbib (58861073200); Bouziane, El Mahi (57204502717); Manaouch, Mohamed (57221976757); Jakimi, Abdeslam (24724576600)|58861073200; 57204502717; 57221976757; 24724576600|A new approach for automatic test case generation from use case diagram using LLMs and prompt engineering|2024|2024 International Conference on Circuit, Systems and Communication, ICCSC 2024|||||||5|10.1109/ICCSC62074.2024.10616548|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201652274&doi=10.1109%2fICCSC62074.2024.10616548&partnerID=40&md5=03754c6624e0ef6a170cfc201645419f|The automation of test case generation from UML diagrams is a growing field that aims to make the software development process smoother. This paper suggests a new framework that uses generative artificial intelligence (AI) to turn use case diagrams into test cases that can be executed. By getting information from the XML representation of use case diagrams, we can create detailed instructions that guide a generative AI model to make test cases for each use case scenario. This method not only makes test case creation easier but also ensures we cover everything well and accurately, which could make software products get to market faster. this approach shows how traditional software engineering methods and new AI techniques can work well together, giving us an idea of what automated software testing might look like in the future.  © 2024 IEEE.|LLMs prompt engineering; software testing; test cases|Automatic test pattern generation; Computer aided software engineering; Software design; Automatic testcase generation; LLM prompt engineering; New approaches; Software development process; Software testings; Test case; Test case generation; UML diagrams; Use cases diagrams; XML representation; Software testing|Conference paper|Final||Scopus|2-s2.0-85201652274
scopus|Panda P.; Sahoo D.; Sahoo D.|Panda, Prasanta (59126205800); Sahoo, Debaryaan (59313537700); Sahoo, Debarjun (59313491000)|59126205800; 59313537700; 59313491000|Automating Fault Prediction in Software Testing Using Machine Learning Techniques: A Real-World Applications|2024|2nd International Conference on Sustainable Computing and Smart Systems, ICSCSS 2024 - Proceedings||||841|844|3|3|10.1109/ICSCSS60660.2024.10625524|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203106400&doi=10.1109%2fICSCSS60660.2024.10625524&partnerID=40&md5=778edba4d641e464208dd8b317bab0fc|Software testing is essential for ensuring the reliability and quality of software systems. Fault prediction and proneness have become critical concerns for the tech industry and software professionals. Traditional methods rely on past fault occurrences or faulty modules, which are often resource-intensive and exhaustive. Consequently, there's a growing interest in predictive techniques for early fault detection during the development lifecycle. In this research, Machine learning (ML) classification models have been proposed for fault prediction in software testing, using historical data to train models that recognize patterns indicative of faulty code. Automated software fault recovery models driven by ML further enhance performance, reduce faults, and optimize time and costs. Software defect predictive development models using various ML classification models, including Neural Networks (NN), applied to a real-world testing dataset have been proposed. To overcome Class imbalance problem, SMOTE ENN (Synthetic Minority Oversampling Technique Edited Nearest Neighbor) method has been implemented and accuracy has been used as the primary evaluation metric. The Random Forest model achieved a notable fault prediction accuracy of 93 %. Additionally, through comprehensive literature analysis, the research delineates trends, highlights strengths, and suggests potential future research directions. © 2024 IEEE.|Fault Modelling; Fault prediction; Machine learning; Software testing|Application programs; Computer software selection and evaluation; Prediction models; Software quality; Software testing; Classification models; Fault model; Fault prediction; Machine learning classification; Machine learning techniques; Machine-learning; Quality of softwares; Real-world; Software testings; Software-systems; Software reliability|Conference paper|Final||Scopus|2-s2.0-85203106400
scopus||||Proceedings - 2024 IEEE/ACM 11th International Conference on Mobile Software Engineering and Systems, MOBILESoft 2024|2024|Proceedings - 2024 IEEE/ACM 11th International Conference on Mobile Software Engineering and Systems, MOBILESoft 2024||||||104|0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196414668&partnerID=40&md5=fda2087633676bb9aae492f54b1101cf|The proceedings contain 15 papers. The topics discussed include: a study on the battery usage of deep learning frameworks on iOS devices; an empirical study on the impact of CSS prefixes on the energy consumption and performance of mobile web apps; an empirical evaluation of the energy consumption of using web push APIs in mobile web apps – the case of telegram; how have iOS development technologies changed over time? a study in open-source; detection of inconsistencies between guidance pages and actual data collection of third-party SDKs; generating rate features for mobile applications; toward an android static analysis approach for data protection; are your android app analyzers still relevant?; and towards benchmarking the coverage of automated testing tools in android against manual testing.|||Conference review|Final||Scopus|2-s2.0-85196414668
scopus|Awad A.; Qutqut M.H.; Ahmed A.; Al-Haj F.; Almasalha F.|Awad, Abdallah (59547341700); Qutqut, Mahmoud H. (55978971300); Ahmed, Ali (57268954100); Al-Haj, Fatima (57215345467); Almasalha, Fadi (26422024800)|59547341700; 55978971300; 57268954100; 57215345467; 26422024800|Artificial Intelligence Role in Software Automation Testing|2024|2024 International Conference on Decision Aid Sciences and Applications, DASA 2024|||||||0|10.1109/DASA63652.2024.10836630|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217203842&doi=10.1109%2fDASA63652.2024.10836630&partnerID=40&md5=58e8fb13184a001116e5b8bb10785070|Artificial intelligence (AI) significantly influences the systems and applications that underpin modern life. Large datasets are generated from diverse sources. Hence, there is a need for effective data monitoring, processing, and reporting, which is crucial for making influential decisions. In developing complex software systems, AI has become essential for ensuring rigorous testing that aligns with business requirements within constrained timelines. The main advantage of AI in software testing lies in its ability to enhance accuracy and streamline repetitive tasks, ultimately reducing the time required for testing. To this end, this paper explores the role of AI in automated software testing, critically analyzing the limitations of traditional automated testing methods, which often struggle with inconsistent bug detection and have limited adaptability across different environments. By expanding test coverage and addressing these limitations, AI-driven tools can significantly enhance testing efficiency. Additionally, we investigate various AI-based tools designed to optimize software testing and strengthen quality assurance processes.  © 2024 IEEE.|Artificial Intelligence (AI); Machine Learning (ML); Software Testing; Software Testing Automation|Application programs; Large datasets; Software quality; Software testing; Artificial intelligence; Automation testing; Large datasets; Machine learning; Machine-learning; Software automation; Software testing automation; Software testings; Testing automation; Adversarial machine learning|Conference paper|Final||Scopus|2-s2.0-85217203842
scopus|Zhang H.; Kuang W.|Zhang, Han (59219946800); Kuang, Wenzhen (55447242100)|59219946800; 55447242100|Computer interlocking host computer recognition based on OpenCV and neural network|2024|IMCEC 2024 - IEEE 6th Advanced Information Management, Communicates, Electronic and Automation Control Conference||||1171|1174|3|0|10.1109/IMCEC59810.2024.10574961|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198653569&doi=10.1109%2fIMCEC59810.2024.10574961&partnerID=40&md5=87fc36c3ebfd2e97d5dd27bca6604b4f|With the rapid development of artificial intelligence technologies such as computer vision and deep learning, computer interlocking systems have gradually developed from traditional manual testing to automated testing. The premise of realizing automatic testing is that reliable station information needs to be provided, which is mainly displayed and controlled by the interface of the interlocking upper computer, so this paper proposes a method for extracting the interface information of the computer interlocking software based on computer vision image analysis and text recognition technology, which excavates the characteristics of the quantifiable signal equipment and function button elements. and the character features of the names of the two in the interface, so as to realize the station information extraction function based on the screenshot of the interface of the host computer.  © 2024 IEEE.|computer inerlocking; Image recongnition; station information; upper conpputer|Automatic testing; Character recognition; Deep learning; Artificial intelligence technologies; Computer inerlocking; Computer interlocking; Host computers; Image recongnition; Interlocking systems; Neural-networks; Recongnition; Station information; Upper conpputer; Computer vision|Conference paper|Final||Scopus|2-s2.0-85198653569
scopus|Khadka K.; Chandrasekaran J.; Lei Y.; Kacker R.N.; Kuhn D.R.|Khadka, Krishna (57208149074); Chandrasekaran, Jaganmohan (56704897000); Lei, Yu (57191863726); Kacker, Raghu N. (6603751138); Kuhn, D. Richard (55666229700)|57208149074; 56704897000; 57191863726; 6603751138; 55666229700|A Combinatorial approach to hyperparameter optimization|2024|Proceedings - 2024 IEEE/ACM 3rd International Conference on AI Engineering - Software Engineering for AI, CAIN 2024||||140|149|9|10|10.1145/3644815.3644941|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196551992&doi=10.1145%2f3644815.3644941&partnerID=40&md5=d0f2a873580892a2d9764163bc3d1f9d|In machine learning, hyperparameter optimization (HPO) is essential for effective model training and significantly impacts model performance. Hyperparameters are predefined model settings which fine-tune the model's behavior and are critical to modeling complex data patterns. Traditional HPO approaches such as Grid Search, Random Search, and Bayesian Optimization have been widely used in this field. However, as datasets grow and models increase in complexity, these approaches often require a significant amount of time and resources for HPO. This research introduces a novel approach using t-way testing-a combinatorial approach to software testing used for identifying faults with a test set that covers all t-way interactions-for HPO. T-way testing substantially narrows the search space and effectively covers parameter interactions. Our experimental results show that our approach reduces the number of necessary model evaluations and significantly cuts computational expenses while still outperforming traditional HPO approaches for the models studied in our experiments. © 2024 Copyright is held by the owner/author(s). Publication rights licensed to ACM.|AutoML; combinatorial testing; hyperparameter optimization|Barium compounds; Statistical tests; Automl; Combinatorial approach; Combinatorial testing; Hyper-parameter optimizations; Impact modelling; Machine-learning; Model training; Modeling performance; Optimization approach; T-way testing; Software testing|Conference paper|Final|All Open Access; Hybrid Gold Open Access|Scopus|2-s2.0-85196551992
scopus|Liang R.; Wang H.; Gao S.; Chen J.|Liang, Ruihong (59700855500); Wang, Hui (59701576900); Gao, ShengJie (59701577000); Chen, Jing (59504114800)|59700855500; 59701576900; 59701577000; 59504114800|Design and Implementation of an AI-Based Enterprise Mobile Platform Automated Testing System|2024|2024 11th International Forum on Electrical Engineering and Automation, IFEEA 2024||||1365|1372|7|0|10.1109/IFEEA64237.2024.10878667|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000506495&doi=10.1109%2fIFEEA64237.2024.10878667&partnerID=40&md5=8e285cbff33fcd6b50a2a100e368340b|As enterprise mobile applications proliferate, ensuring their quality and security has become increasingly essential. Common challenges include content duplication, security vulnerabilities, sensitive data leaks, and compatibility issues across diverse devices, all of which can harm user experience and corporate reputation. This paper presents an AI-driven automated testing system designed to address these issues. The system integrates advanced technologies such as OCR, CNN, NLP, BERT, Twin Network Model, Isolation Forest, and K-Means Clustering to analyze page elements, intelligently select appropriate test components, and generate automated testing scripts. By dynamically refining testing strategies based on feedback and results, the system delivers a reliable and efficient quality assurance framework, empowering enterprises to meet the demands of digital transformation. © 2024 IEEE.|AI feature analysis; automated testing; deep learning; mobile platform applications|AI feature analyze; Automated testing; Deep learning; Design and implementations; Feature analysis; Mobile applications; Mobile platform; Mobile platform application; Security vulnerabilities; Testing systems; Deep learning|Conference paper|Final||Scopus|2-s2.0-105000506495
scopus|Song S.; ZhanweiHui; Xia L.|Song, Shuang (57215009001); ZhanweiHui (58972294300); Xia, Linlin (58972724000)|57215009001; 58972294300; 58972724000|Research on Deep Learning Operator Testing of Intelligent Software Based on Fuzz Testing Technology|2024|Lecture Notes in Electrical Engineering|1043|||1|9|8|0|10.1007/978-981-99-7545-7_1|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189501107&doi=10.1007%2f978-981-99-7545-7_1&partnerID=40&md5=51cafdcf29fea7ab09d4c586a460480e|This paper introduces the mainstream deep learning framework and deep learning operators, studies the accuracy problems and cause analysis of deep learning operators, and proposes a guided fuzz testing method based on differential testing to test deep learning operators by studying the current mainstream intelligent software testing methods differential testing and fuzz testing, and provides the scheme design and testing operation process. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2024.|AFL tool; Deep learning framework; Deep learning operator; Fuzz testing technology; Neural network model CNN|Engineering education; Software testing; AFL tool; Deep learning framework; Deep learning operator; Fuzz Testing; Fuzz testing technology; Learning frameworks; Learning operator; Neural network model; Neural network model CNN; Testing technology; Deep learning|Conference paper|Final||Scopus|2-s2.0-85189501107
scopus|Zhang Y.|Zhang, Yajie (59490904200)|59490904200|Software Defect Prediction Model Based on Deep Learning|2024|Proceedings - 2024 International Conference on Power, Electrical Engineering, Electronics and Control, PEEEC 2024||||954|959|5|0|10.1109/PEEEC63877.2024.00177|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217868734&doi=10.1109%2fPEEEC63877.2024.00177&partnerID=40&md5=5a70d339cfac96214435d72256d51f18|At present, under the background of the vigorous development of Internet technology and the era of the Internet of Everything, the diversification and complexity of software application scenarios are growing at an unprecedented rate. Although this trend has greatly enriched the user experience, it is also accompanied by the problem of frequent software failures. Software defects, as the key factor to weaken software reliability, are increasingly attracting extensive attention from the industry and academia. The software defect prediction model based on deep learning (DL) proposed in this article is a cutting-edge exploration in this field. This model fully utilizes the powerful ability of DL in processing large-scale and high-dimensional data, and can automatically learn complex features and patterns from historical data of software projects, achieving accurate prediction of software defects. The experimental results show that compared with traditional prediction methods, this model exhibits significant advantages in key indicators such as prediction accuracy and recall rate, effectively improving the comprehensiveness and accuracy of software defect prediction, and providing strong technical support for software testing and quality assurance work. © 2024 IEEE.|Deep learning; prediction model; software defects|Application scenario; Deep learning; Defect prediction models; Internet technology; Model-based OPC; Prediction modelling; Software applications; Software defect prediction; Software defects; Users' experiences; Prediction models|Conference paper|Final||Scopus|2-s2.0-85217868734
scopus|Wang H.; Xu T.; Wang B.|Wang, Hailong (59198945200); Xu, Tongtong (57210911094); Wang, Bei (59148536800)|59198945200; 57210911094; 59148536800|Deep Multiple Assertions Generation|2024|Proceedings - 2024 IEEE/ACM 1st International Conference on AI Foundation Models and Software Engineering, FORGE 2024||||1|11|10|5|10.1145/3650105.3652293|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197287161&doi=10.1145%2f3650105.3652293&partnerID=40&md5=bbf926d8b27d6cfa7f3f2ffa55332518|Software testing is one of the most crucial parts of the software development life cycle. Developers spend substantial amount of time and efforts on software testing. Recently, there has been a growing scholarly interest in the automation of software testing. However, recent studies have revealed significant limitations in the quality and efficacy of the generated assert statements. These limitations primarily arise due to: (i) the inherent complexity involved in generating assert statements that are both meaningful and effective; (ii) the challenge of capturing the relationship between multiple assertions in a single test case. In recent research, deep learning techniques have been employed to generate meaningful assertions. However, it is typical for a single assertion to be generated for each test case, which contradicts the current situation where over 40% of test cases contain multiple assertions.To address these open challenges, we propose a novel approach, called DeepAssert that exploits the pre-trained model GraphCode-BERT to automatically generate multiple assertions for test methods. It can recommend a sequence of assert statements effectively given a test method and a focal method (the method under test).To evaluate the effectiveness of our approach, we conduct extensive experiments on the dataset built on the top of Methods2Test dataset. Experimental results show that DeepAssert achieves scores of 54.16%, 18.36%, and 15.38% in terms of CodeBLEU, accuracy and perfect prediction and substantially outperforms the state-of-the-art baselines by a large margin. Furthermore, we evaluate the effectiveness of DeepAssert on the task of bug detection and the result indicates that the assert sequences generated by DeepAssert can assist in exposing 42 real-world bugs extracting from Defects4J while only considering the first compiled assert sequence, outperforming the SOTA approaches by a large margin as well.  © 2024 is held by the owner/author(s). Publication rights licensed to ACM.|assert statement generation; deep learning; software testing|Deep learning; Life cycle; Software design; Assert statement generation; Assertion generations; Deep learning; Inherent complexity; Large margins; Recent researches; Software development life-cycle; Software testings; Test case; Test method; Software testing|Conference paper|Final|All Open Access; Bronze Open Access|Scopus|2-s2.0-85197287161
scopus|Alkaberi W.; Assiri F.|Alkaberi, Wahaj (57606844700); Assiri, Fatmah (56225558300)|57606844700; 56225558300|Predicting the Number of Software Faults using Deep Learning|2024|Engineering, Technology and Applied Science Research|14|2||13222|13231|9|12|10.48084/etasr.6798|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191699859&doi=10.48084%2fetasr.6798&partnerID=40&md5=fc828f6f65cdaef22c10e33af6f771e5|The software testing phase requires considerable time, effort, and cost, particularly when there are many faults. Thus, developers focus on the evolution of Software Fault Prediction (SFP) to predict faulty units in advance, therefore, improving software quality significantly. Forecasting the number of faults in software units can efficiently direct software testing efforts. Previous studies have employed several machine learning models to determine whether a software unit is faulty. In this study, a new, simple deep neural network approach that can adapt to the type of input data was designed, utilizing Convolutional Neural Networks (CNNs) and Multi-Layer Perceptron (MLP), to predict the number of software faults. Twelve open-source software project datasets from the PROMISE repository were used for testing and validation. As data imbalance can negatively impact prediction accuracy, the new version of synthetic minority oversampling technique (SMOTEND) was used to resolve data imbalance. In experimental results, a lower error rate was obtained for MLP, compared to CNN, reaching 0.195, indicating the accuracy of this prediction model. The proposed approach proved to be effective when compared with two of the best machine learning models in the field of prediction. The code will be available on GitHub. © 2024, Dr D. Pylarinos. All rights reserved.|-deep learning; class imbalance; CNN; fault; MLP; prediction; software testing||Article|Final|All Open Access; Gold Open Access|Scopus|2-s2.0-85191699859
scopus|Xue Y.; Zhang Z.; Liu C.; Chen S.; Huang Z.|Xue, Yinjie (59366842500); Zhang, Zhiyi (57202893201); Liu, Chen (57197744294); Chen, Shuxian (59367050500); Huang, Zhiqiu (14325169600)|59366842500; 57202893201; 57197744294; 59367050500; 14325169600|DeepWeak: Weak Mutation Testing for Deep Learning Systems|2024|IEEE International Conference on Software Quality, Reliability and Security, QRS||||49|60|11|0|10.1109/QRS62785.2024.00015|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206349659&doi=10.1109%2fQRS62785.2024.00015&partnerID=40&md5=8e9126f940ba678ce84c873ead0f6c5e|The widespread application of deep learning (DL) makes it crucial to ensure its reliability. Mutation testing has been employed in DL testing to evaluate the quality of test suite. However, the largest problem of DL mutation testing is the high cost of executing numbers of mutants. Weak mutation technology can alleviate this problem by reducing the execution time of mutants in traditional software testing. However, the compared components in traditional software are too trivial to apply weak mutation to DL models directly for that it is impractical for testers to track and monitor massive parameters during execution process. In this paper, we propose a novel weak mutation framework for mutants generated by source-level mutation operators. DeepWeak treats all layers that make up the DL model directly as a set of components of model to replace trivial parameters. And it pays attention to the last convolutioanl layer for that they not only have impacts on prediction results but also are evident for weak analysis. By quantifying contribution of feature maps to the prediction, weight maps will be obtained on the basis of their weights. Finally, the judgements on whether mutants have been killed will be reached by comparing the maps. To evaluate the applicability and effectiveness of our approach, we conduct experiments on three widely used datasets and four deep learning models using three metrics. Experimental results show that DeepWeak is effective at alleviating costs problem, reducing runtime by 11.21% to 18.21% compared with the DL mutation testing with little accuracy loss. © 2024 IEEE.|deep learning; mutation testing; software testing; weak mutation|Application programs; Deep learning; Software reliability; Software testing; Deep learning; Execution process; High costs; Large problems; Learning models; Mutation testing; Software testings; Source level; Weak mutation; Weak mutation testing; Deep reinforcement learning|Conference paper|Final||Scopus|2-s2.0-85206349659
scopus|Muqeet A.; Yue T.; Ali S.; Arcaini P.|Muqeet, Asmar (57914513400); Yue, Tao (25651096400); Ali, Shaukat (56962801700); Arcaini, Paolo (35791597000)|57914513400; 25651096400; 56962801700; 35791597000|Mitigating Noise in Quantum Software Testing Using Machine Learning|2024|IEEE Transactions on Software Engineering|50|11||2947|2961|14|3|10.1109/TSE.2024.3462974|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204479563&doi=10.1109%2fTSE.2024.3462974&partnerID=40&md5=8035c66f76cf1a3afd9e92dd14454a8e|Quantum Computing (QC) promises computational speedup over classic computing. However, noise exists in near-term quantum computers. Quantum software testing (for gaining confidence in quantum software's correctness) is inevitably impacted by noise, i.e., it is impossible to know if a test case failed due to noise or real faults. Existing testing techniques test quantum programs without considering noise, i.e., by executing tests on ideal quantum computer simulators. Consequently, they are not directly applicable to test quantum software on real quantum computers or noisy simulators. Thus, we propose a noise-aware approach (named QOIN) to alleviate the noise effect on test results of quantum programs. QOIN employs machine learning techniques (e.g., transfer learning) to learn the noise effect of a quantum computer and filter it from a program's outputs. Such filtered outputs are then used as the input to perform test case assessments (determining the passing or failing of a test case execution against a test oracle). We evaluated QOIN on IBM's 23 noise models, Google's two available noise models, and Rigetti's Quantum Virtual Machine, with six real-world and 800 artificial programs. We also generated faulty versions of these programs to check if a failing test case execution can be determined under noise. Results show that QOIN can reduce the noise effect by more than 80% on most noise models. We used an existing test oracle to evaluate QOIN's effectiveness in quantum software testing. The results showed that QOIN attained scores of 99%, 75%, and 86% for precision, recall, and F1-score, respectively, for the test oracle across six real-world programs. For artificial programs, QOIN achieved scores of 93%, 79%, and 86% for precision, recall, and F1-score respectively. This highlights QOIN's effectiveness in learning noise patterns for noise-aware quantum software testing.  © 1976-2012 IEEE.|and machine learning; computing methodologies; quantum computing; Software testing and debugging|Computer debugging; Computer software selection and evaluation; Input output programs; Program debugging; Quantum electronics; Quantum noise; Quantum optics; Software testing; Virtual machine; Computing methodologies; Machine-learning; Noise effects; Noise models; Quanta computers; Quantum Computing; Software Testing and Debugging; Software testings; Test case; Test oracles; Quantum computers|Article|Final|All Open Access; Green Open Access|Scopus|2-s2.0-85204479563
scopus|Zhang Y.|Zhang, Yuli (59590830000)|59590830000|New Approaches to Automated Software Testing Based on Artificial Intelligence|2024|2024 5th International Conference on Artificial Intelligence and Computer Engineering, ICAICE 2024||||806|810|4|0|10.1109/ICAICE63571.2024.10863866|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218460111&doi=10.1109%2fICAICE63571.2024.10863866&partnerID=40&md5=008722a2d9b2ee459471fa9416d58e28|With the increasing complexity of software development, traditional automated testing methods face significant challenges in efficiency and coverage. This paper proposes a novel AI-driven automated testing method aimed at optimizing test case generation and selection through machine learning and deep learning techniques. Experimental results demonstrate that this approach significantly enhances test coverage and accuracy, addressing limitations inherent in existing methods. This research provides new insights for automation and intelligence in the field of software testing, advancing the application of artificial intelligence in software engineering.  © 2024 IEEE.|automated testing; machine learning; test case generation|Automatic test pattern generation; Contrastive Learning; Automated software testing; Automated testing; Learning techniques; Machine-learning; New approaches; Test accuracy; Test case generation; Test case selection; Test-coverage; Testing method; Adversarial machine learning|Conference paper|Final||Scopus|2-s2.0-85218460111
scopus|Guo M.; Guo D.; Li M.|Guo, Mengfei (59542718200); Guo, Dong (57608035500); Li, Mo (58070574100)|59542718200; 57608035500; 58070574100|Metrics and Testing Methods for Artificial Intelligence Software Quality Models and Their Application Examples|2024|Proceedings - 2024 11th International Conference on Dependable Systems and Their Applications, DSA 2024||||35|42|7|0|10.1109/DSA63982.2024.00016|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216920748&doi=10.1109%2fDSA63982.2024.00016&partnerID=40&md5=c7ddf55b7a6167966de2ec6ce45a5a9f|As artificial intelligence technology rapidly advances, AI software is being increasingly employed across various industries. To ensure the quality and reliability of these software systems, the paper extends the quality measurement and testing methods for artificial intelligence software by utilizing the ISO/IEC 25059 quality model. It not only refines traditional software testing methods to better suit artificial intelligence software but also introduces specific testing methods for quality attributes unique to AI systems, which include five main characteristics: User contrallability ensures timely user intervention in system operations to avoid potential errors or security risks, thereby enhancing system usability; transparency increases the level of information disclosure, allowing users and stakeholders to better understand and trust the AI system, facilitating greater user acceptance; functional adaptability emphasizes the system' s learning and adaptability in dynamic environments, ensuring it can effectively handle changing data and diverse usage scenarios, which is crucial for maintaining functionality; robustness assesses the stability and reliability of the system under abnormal inputs or attacks, ensuring it can continue operating under all conditions; and intervenability ensures users can quickly and effectively manage system faults, thereby minimizing potential damage. To validate the proposed quality measurement methods, face recognition software based on deep learning was employed as a case study to evaluate its performance through experimental analysis. These validations not only demonstrated the effectiveness of the quality measurement methods in practical applications but also further enriched the testing methods for AI software.  © 2024 IEEE.|artificial intelligence software; face recognition; quality model; testing method|Acceptance tests; Application programs; Computer software selection and evaluation; Deep learning; Model checking; Software reliability; Software testing; AI systems; Application examples; Artificial intelligence software; Artificial intelligence technologies; Intelligence software; Measurement methods; Quality measurements; Quality modeling; Software quality modeling; Testing method; Software quality|Conference paper|Final||Scopus|2-s2.0-85216920748
scopus|Yang F.; Zhong F.; Zeng G.; Xiao P.; Zheng W.|Yang, Fengyu (35340193800); Zhong, Fa (58088653000); Zeng, Guangdong (58088653100); Xiao, Peng (57224641873); Zheng, Wei (55704749700)|35340193800; 58088653000; 58088653100; 57224641873; 55704749700|LineFlowDP: A Deep Learning-Based Two-Phase Approach for Line-Level Defect Prediction|2024|Empirical Software Engineering|29|2|50||||2|10.1007/s10664-023-10439-z|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185826349&doi=10.1007%2fs10664-023-10439-z&partnerID=40&md5=0c21915715b6c8a64e8d81bf346157bf|Software defect prediction plays a key role in guiding resource allocation for software testing. However, previous defect prediction studies still have some limitations: (1) the granularity of defect prediction is still coarse, so high-risk code statements cannot be accurately located; (2) in fine-grained defect prediction, the semantic and structural information available in a single line of code is limited, and the content of code semantic information is not sufficient to achieve semantic differentiation. To address the above problems, we propose a two-phase line-level defect prediction method based on deep learning called LineFlowDP. We first extract the program dependency graph (PDG) of the source files. The lines of code corresponding to the nodes in the PDG are extended semantically with data flow and control flow information and embedded as nodes, and the model is further trained using an relational graph convolutional network. Finally, a graph interpreter GNNExplainer and a social network analysis method are used to rank the lines of code in the defective file according to risk. On 32 datasets from 9 projects, the experimental results show that LineFlowDP is 13%-404% more cost-effective than four state-of-the-art line-level defect prediction methods. The effectiveness of the flow information extension and code line risk ranking methods was also verified via ablation experiments. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.|Graph neural network; Line-level software defect prediction; Social network analysis; Software quality assurance|Computer software selection and evaluation; Cost effectiveness; Data flow analysis; Deep learning; Defects; Flow graphs; Forecasting; Graph neural networks; Quality control; Risk assessment; Semantics; Social networking (online); Defect prediction; Defect prediction methods; Graph neural networks; Line of codes; Line-level software defect prediction; Semantics Information; Social Network Analysis; Software defect prediction; Software quality assurance; Two phase; Software testing|Article|Final||Scopus|2-s2.0-85185826349
scopus|Retzlaff N.|Retzlaff, Niklas (59261989500)|59261989500|AI Integrated ST Modern System for Designing Automated Standard Affirmation System|2024|2024 4th International Conference on Advance Computing and Innovative Technologies in Engineering, ICACITE 2024||||1386|1391|5|0|10.1109/ICACITE60783.2024.10616416|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201833072&doi=10.1109%2fICACITE60783.2024.10616416&partnerID=40&md5=48c21402676006c2a97f7217542db43b|This is a phenomenal approach toward a game-changer in AI-driven software testing and assures quality automation of the software product, facilitating faster, more exact, and very comprehensive checking of the software product. This would present a very solid architecture that would lay the ground for leveraging the capabilities of artificial intelligence (AI) in the automation and enhancement of the software testing process. The framework assumes that AI integrated with software testing can make a giant leap in test coverage, precision, and efficiency, which eventually ensures software with higher quality. A number of key constituents, each with the aim of tackling specific challenges that the software testing lifecycle poses, join to form the foundation of the Mitra framework. It includes at its very base machine learning (ML) algorithms and natural language processing (NLP) techniques that automatically produce and optimize test cases. Not only does this bring down the manual effort in creating test cases, but it also betters the detection capability for not-identified cases earlier, especially edge cases, which helps in bettering the test coverage. Other than that, the very important feature of the framework includes AI for better predictive analysis. The system is able to predict potential future software defects based on the historical data of software defects and test results, hence alerting the testers at an early time for correction before the issues become bigger defects. This predictive capability helps reduce the investment of time and resources taken in finding and fixing defects and further provides the ability to prioritize testing efforts considering their likelihood and the severity of potential defects. © 2024 IEEE.|Adaptive Learning; AI-Driven Software Testing; Anomaly Detection; Automated Quality Assurance; Dynamic Test Environment Management; Ethical Considerations; Machine Learning Algorithms; Natural Language Processing; Predictive Analysis; Test Coverage|Ability testing; Adversarial machine learning; Computer software selection and evaluation; Contrastive Learning; Predictive analytics; Adaptive learning; Anomaly detection; Artificial intelligence-driven software testing; Automated quality assurance; Dynamic test environment management; Dynamic tests; Environment management; Ethical considerations; Language processing; Machine learning algorithms; Natural language processing; Natural languages; Software testings; Test Environment; Test-coverage; Software testing|Conference paper|Final||Scopus|2-s2.0-85201833072
scopus|Ileana M.; Miroiu M.|Ileana, Marian (58882460300); Miroiu, Maria (42262233600)|58882460300; 42262233600|Intelligent Automated Testing Frameworks for IoT Networks Utilizing Machine Learning for Advanced Anomaly Detection|2024|International Conference Automatics and Informatics, ICAI 2024 - Proceedings||||341|346|5|0|10.1109/ICAI63388.2024.10851706|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218180458&doi=10.1109%2fICAI63388.2024.10851706&partnerID=40&md5=0bbcf2e4c2d4041a1ae9a871e4c498aa|The widespread deployment of Internet of Things (IoT) networks has brought new challenges in terms of ensuring system reliability and security. This paper presents intelligent automated testing frameworks designed specifically for IoT environments, leveraging machine learning for advanced anomaly detection. Traditional testing methods are often insufficient in the dynamic and heterogeneous landscape of IoT systems. The approach explores the use of machine learning algorithms to identify patterns and anomalies in real-time, thereby increasing the robustness and resilience of IoT networks. By integrating predictive analytics and real-time monitoring, the proposed framework not only detects failures but also anticipates potential problems, thus facilitating system maintenance. This innovative approach underscores the importance of intelligent automation in addressing the complexities of modern IoT ecosystems.  © 2024 IEEE.|automated testing; intelligent systems; internet of things; IoT networks; machine learning; Python|Contrastive Learning; Federated learning; Intelligent systems; Predictive analytics; Anomaly detection; Automated testing; Heterogeneous landscapes; Internet of thing network; Machine learning algorithms; Machine-learning; System reliability; System security; Testing framework; Testing method; Adversarial machine learning|Conference paper|Final||Scopus|2-s2.0-85218180458
scopus|Neelofar N.; Aleti A.|Neelofar, Neelofar (57193616871); Aleti, Aldeida (35092219900)|57193616871; 35092219900|Towards Reliable AI: Adequacy Metrics for Ensuring the Quality of System-level Testing of Autonomous Vehicles|2024|Proceedings - International Conference on Software Engineering|||||||9|10.1145/3597503.3623314|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185530251&doi=10.1145%2f3597503.3623314&partnerID=40&md5=c6fccb32a3bf45d3c21d7649eb088372|"AI-powered systems have gained widespread popularity in various domains, including Autonomous Vehicles (AVs). However, ensuring their reliability and safety is challenging due to their complex nature. Conventional test adequacy metrics, designed to evaluate the effectiveness of traditional software testing, are often insufficient or impractical for these systems. White-box metrics, which are specifically designed for these systems, leverage neuron coverage information. These coverage metrics necessitate access to the underlying AI model and training data, which may not always be available. Furthermore, the existing adequacy metrics exhibit weak correlations with the ability to detect faults in the generated test suite, creating a gap that we aim to bridge in this study. In this paper, we introduce a set of black-box test adequacy metrics called ""Test suite Instance Space Adequacy"" (TISA) metrics, which can be used to gauge the effectiveness of a test suite. The TISA metrics offer a way to assess both the diversity and coverage of the test suite and the range of bugs detected during testing. Additionally, we introduce a framework that permits testers to visualise the diversity and coverage of the test suite in a two-dimensional space, facilitating the identification of areas that require improvement. We evaluate the efficacy of the TISA metrics by examining their correlation with the number of bugs detected in system-level simulation testing of AVs. A strong correlation, coupled with the short computation time, indicates their effectiveness and efficiency in estimating the adequacy of testing AVs. © 2024 IEEE Computer Society. All rights reserved."||Black-box testing; Program debugging; Autonomous Vehicles; Complex nature; Coverage metrics; Modeling data; Reliability and safeties; Software testings; System level testing; Test adequacy metric; Training data; White box; Autonomous vehicles|Conference paper|Final|All Open Access; Green Open Access|Scopus|2-s2.0-85185530251
scopus|Baral K.; Johnson J.; Mahmud J.; Salma S.; Fazzini M.; Rubin J.; Offutt J.; Moran K.|Baral, Kesina (57209662110); Johnson, Jack (57842835600); Mahmud, Junayed (57226030720); Salma, Sabiha (58150612300); Fazzini, Mattia (55342023600); Rubin, Julia (12545361700); Offutt, Jeff (55375749200); Moran, Kevin (57095532500)|57209662110; 57842835600; 57226030720; 58150612300; 55342023600; 12545361700; 55375749200; 57095532500|Automating GUI-based Test Oracles for Mobile Apps|2024|Proceedings - 2024 IEEE/ACM 21st International Conference on Mining Software Repositories, MSR 2024||||309|321|12|3|10.1145/3643991.3644930|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197426449&doi=10.1145%2f3643991.3644930&partnerID=40&md5=c39da9081d4887ac508e99bc09e4ecf4|In automated testing, test oracles are used to determine whether software behaves correctly on individual tests by comparing expected behavior with actual behavior, revealing incorrect behavior. Automatically creating test oracles is a challenging task, especially in domains where software behavior is difficult to model. Mobile apps are one such domain, primarily due to their event-driven, GUI-based nature, coupled with significant ecosystem fragmentation.This paper takes a step toward automating the construction of GUI-based test oracles for mobile apps, first by characterizing common behaviors associated with failures into a behavioral taxonomy, and second by using this taxonomy to create automated oracles. Our taxonomy identifies and categorizes common GUI element behaviors, expected app responses, and failures from 124 reproducible bug reports, which allow us to better understand oracle characteristics. We use the taxonomy to create app-independent oracles and report on their generalizability by analyzing an additional dataset of 603 bug reports. We also use this taxonomy to define an app-independent process for creating automated test oracles, which leverages computer vision and natural language processing, and apply our process to automate five types of app-independent oracles. We perform a case study to assess the effectiveness of our automated oracles by exposing them to 15 real-world failures. The oracles reveal 11 of the 15 failures and report only one false positive. Additionally, we combine our oracles with a recent automated test input generation tool for Android, revealing two bugs with a low false positive rate. Our results can help developers create stronger automated tests that can reveal more problems in mobile apps and help researchers who can use the understanding from the taxonomy to make further advances in test automation.CCS CONCEPTS• Software and its engineering → Software maintenance tools; Software testing and debugging; Software usability.  © 2024 ACM.|Mobile apps; Software Testing; Test Oracles; UI Analysis|Automation; Graphical user interfaces; Natural language processing systems; Program debugging; Software testing; Automated test; Automated testing; Bug reports; Event-driven; Mobile app; Natural languages; Software behavior; Software testings; Test oracles; UI analyse; Taxonomies|Conference paper|Final||Scopus|2-s2.0-85197426449
scopus|Ajitha P.|Ajitha, P. (57190397555)|57190397555|MedAI-DevOps Imaging Suite: Integrating CNN in Diagnostic Imaging with Continuous Deployment and Real-time Monitoring|2024|TQCEBT 2024 - 2nd IEEE International Conference on Trends in Quantum Computing and Emerging Business Technologies 2024|||||||1|10.1109/TQCEBT59414.2024.10545123|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204442437&doi=10.1109%2fTQCEBT59414.2024.10545123&partnerID=40&md5=578c949919dce8def74fe5f78e6fcf06|"The ""MedAI-DevOps Imaging Suite""integrates Convolutional Neural Networks (CNNs) into diagnostic imaging, coupled with effective DevOps practices. This comprehensive algorithm addresses the increasing demand for advanced diagnostic tools in medical artificial intelligence. The process begins with meticulous data preprocessing to optimize medical imaging datasets for CNN training. A CNN model is then defined and trained, emphasizing hyperparameter configuration for optimal performance.The framework includes a DevOps pipeline, incorporating continuous integration (CI) for automated testing and continuous deployment (CD) for efficient model deployment to production environments. Real-time monitoring tools capture performance metrics like accuracy and resource utilization. Data drift monitoring ensures the model's adaptability to changing data distributions over time. User feedback is actively sought, allowing for model refinement based on real-world insights. Additionally, Explainable AI techniques enhance transparency by providing interpretable explanations for model predictions. Deployment of the diagnostic models in healthcare settings, ensuring continuous improvement through user feedback and maintaining model robustness in dynamic data environments.  © 2024 IEEE."|Artificial Intelligence; CI.CD; DevOps; health care|Diagnosis; Advanced diagnostics; Continuous deployment; Continuous integration.; Continuous integrations; Convolutional neural network; Deployment time; Diagnostic imaging; Diagnostics tools; Real time monitoring; User feedback; DevOps|Conference paper|Final||Scopus|2-s2.0-85204442437
scopus|Manojkumar V.; Mahalakshmi R.|Manojkumar, V. (58813757300); Mahalakshmi, R. (59187134100)|58813757300; 59187134100|Test Case Optimization Technique for Web Applications|2024|3rd IEEE International Conference on Distributed Computing and Electrical Circuits and Electronics, ICDCECE 2024|||||||1|10.1109/ICDCECE60827.2024.10548325|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196817294&doi=10.1109%2fICDCECE60827.2024.10548325&partnerID=40&md5=4bb244cf8f8c4cd9382f7d114e398d9e|Software testing is indeed an important part of the application development. In order to identify the bugs, present in the developed source code, software testing techniques are applied. The testing method considers various test cases provided to meet the software outcome on demand. The emerging growth of artificial intelligence (AI) technology and machine learning (ML) techniques reduces the complexity in test case running sequences, as the AI algorithms reduces the frequently repeated test cases, accelerating the processing depth by understanding the pattern of test logs etc. The comprehensive study is proposed on optimization of test case execution on development of web applications is given. The challenges in existing implementations such as latency, duplicate test cases, redundant test cases are considered. The proposed model is developed with a novel architecture using a case study on machine learning model named Regressive vector analysis (RV A). Since the optimization process increase the quality of the test sequence, the quantitative outcome of the test model is improved. The system achieved with accuracy of 92 % and Mathew's correlation constant (MCC) is 98%.  © 2024 IEEE.|Artificial Intelligence; Data analytics; Machine learning; Neural network; Test case optimization|Application programs; Data Analytics; Program debugging; Software testing; Data analytics; Machine-learning; Neural-networks; Optimisations; Optimization techniques; Software testings; Test case; Test case optimization; WEB application; Web applications; Machine learning|Conference paper|Final||Scopus|2-s2.0-85196817294
scopus|Ali Q.; Riganelli O.; Mariani L.|Ali, Qurban (59194362300); Riganelli, Oliviero (14020561200); Mariani, Leonardo (8965048200)|59194362300; 14020561200; 8965048200|Testing in the Evolving World of DL Systems: Insights from Python GitHub Projects|2024|IEEE International Conference on Software Quality, Reliability and Security, QRS||||25|35|10|1|10.1109/QRS62785.2024.00013|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206357044&doi=10.1109%2fQRS62785.2024.00013&partnerID=40&md5=81febb291f39752551b1d5596b1852b2|In the ever-evolving field of Deep Learning (DL), ensuring project quality and reliability remains a crucial challenge. This research investigates testing practices within DL projects in GitHub. It quantifies the adoption of testing methodologies, focusing on aspects like test automation, the types of tests (e.g., unit, integration, and system), test suite growth rate, and evolution of testing practices across different project versions. We analyze a subset of 300 carefully selected repositories based on quantitative and qualitative criteria. This study reports insights on the prevalence of testing practices in DL projects within the open-source community. © 2024 IEEE.|Deep learning; Open Source; Software Quality Assurance; Software Testing; Testing Practice; Validation&Verification|Software quality; Deep learning; Learning projects; Open-source; Project quality; Software quality assurance; Software testings; Test Automation; Testing methodology; Testing practice; Validation&verification; Integration testing|Conference paper|Final|All Open Access; Green Open Access|Scopus|2-s2.0-85206357044
scopus||||SIST 2024 - 2024 IEEE 4th International Conference on Smart Information Systems and Technologies, Proceedings|2024|SIST 2024 - 2024 IEEE 4th International Conference on Smart Information Systems and Technologies, Proceedings||||||706|0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202905657&partnerID=40&md5=cb5e8459157a4ceece1d1064bdd6e6ca|The proceedings contain 110 papers. The topics discussed include: review of machine learning models in cyberbullying detection problem; quantum computing in the object-oriented model of quality management; regression and machine learning methods for predicting human movements based on skeletal data; application of game theory methods to optimize the stakeholder management process; conceptualizing the ICT project management in the sustainability context; human-computer testing of students’ knowledge; fuzzy inference system for test case prioritization in software testing; mobile application of convolutional neural networks for melanoma classification; an investigation of sensing and technologies for supporting the intelligent transport management system in urban area; and a comparative study of supervised machine learning and deep learning techniques with feature selection methods for classifying Parkinson’s disease based on speech impairments.|||Conference review|Final||Scopus|2-s2.0-85202905657
scopus|Maharana T.; Agrawal N.; Sharma V.; Alkhayyat A.|Maharana, Tannistha (59561750900); Agrawal, Nitya (59561309700); Sharma, Vandana (58957195700); Alkhayyat, Ahmed (59268596900)|59561750900; 59561309700; 58957195700; 59268596900|An Intelligent Hybrid GenAI Model for Software Testing|2024|Intelligent Computing and Emerging Communication Technologies, ICEC 2024|||||||0|10.1109/ICEC59683.2024.10837186|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218038776&doi=10.1109%2fICEC59683.2024.10837186&partnerID=40&md5=b800aaf14e684205bfa2e6fc64401378|Software Testing, a well-defined process and a major component of software development. It covers various methods such as execution of a software program, predicting errors, to meet user needs, and ensure that the system is working correctly. Due to the advanced development in technology around the world, new methods are introduced to test the software. This summary talk discusses the current state of the art of AI(Artificial Intelligence) for software testing. The purpose of software testing is validation, verifying and detection of errors. For the study, we explored around 30 articles from different research surveys. 12-15 articles were selected for the final review. Artificial intelligence(AI) which has emerged in a promising approach to software testing in recent years. The main aim of this paper was to review how Artificial Intelligence(AI) works in Software testing. This paper had also proposed many key offerings of AI in the upcoming future for the area of software testing.  © 2024 IEEE.|Gen AI; Machine Learning; Software testing; Technical; Test Automation|'current; Gen artificial intelligence; Machine-learning; Research survey; Software project; Software testings; State of the art; Technical; Test Automation; User need; Adversarial machine learning|Conference paper|Final||Scopus|2-s2.0-85218038776
scopus|Abbas D.; Olszewska J.I.|Abbas, D. (59138862200); Olszewska, J.I. (55623356800)|59138862200; 55623356800|Optical Character Recognition Based-On System for Automated Software Testing|2024|International Conference on Enterprise Information Systems, ICEIS - Proceedings|1|||894|906|12|0|10.5220/0012740000003690|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193942921&doi=10.5220%2f0012740000003690&partnerID=40&md5=3b6ef79858d86732ac40aa52ed26eac5|The paper presents the development and deployment of an artificial intelligence (AI) test automation framework that allows testers to more fluidly develop scripts and carry out their day-to-day tasks. In particular, the framework aims to speed up the test automation process by enabling its users to locate elements on a webpage through the use of template-matching-based image recognition as well as optical character recognition (OCR). Indeed, test automation specialists spend much of their time creating page-object models (POMs), where they capture elements on the screen via complex locators such as cascading style sheet (CSS) or XPath. However, when webpages are updated or elements are moved around, locators become void, eventually pointing to nothing unless written in such a dynamic way as to prevent this. This heavily relies on developers providing meaningful tags to elements that they can then be located by, whereas with the introduction of an image recognition engine in our AI framework, this tedious and long-winded approach has been be shortened. Copyright © 2024 by SCITEPRESS – Science and Technology Publications, Lda.|Automated Software Testing; Autonomous Systems; Computer Vision; Expert Systems; Intelligent Systems; Machine Learning; Optical Character Recognition; Software Robots; Trustworthy Artificial Intelligence|Automation; Computer vision; Expert systems; Image recognition; Learning systems; Machine learning; Optical character recognition; Software testing; Template matching; Websites; Automated software testing; Autonomous system; Intelligence tests; Machine-learning; Software robot; Speed up; Test Automation; Test automation frameworks; Trustworthy artificial intelligence; Web-page; Intelligent systems|Conference paper|Final|All Open Access; Hybrid Gold Open Access|Scopus|2-s2.0-85193942921
scopus|Ghantous G.B.|Ghantous, Georges Bou (57204020559)|57204020559|Enhancing devops using ai|2024|CEUR Workshop Proceedings|3790|||133|145|12|0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207849487&partnerID=40&md5=6039b15361645c681408bb862f90ffc6|This literature review delves into the amalgamation of Artificial Intelligence (AI) technologies with DevOps methodologies to augment software development and deployment processes. The paper explores into the multifaceted contributions of AI across various facets of DevOps, encompassing source code management, continuous integration/continuous deployment (CI/CD) pipelines, deployment infrastructure, software testing frameworks, logging mechanisms, data analysis tools, and comprehensive reporting systems. Furthermore, the research investigates the impact of AI on team communication, collaboration, and workflow orchestration within DevOps environments. Through a meticulous analysis of AI-driven advancements, this review aims to shed light on the symbiotic relationship between AI and DevOps, showcasing their collective potential in fostering efficient, high-quality software delivery pipelines. The insights gleaned from this exploration offer valuable perspectives and opinions for researchers and practitioners seeking to leverage cutting-edge technologies for optimizing their software development lifecycle. © 2024 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0)|AI; Automation; CI/CD; DevOps; Machine Learning; Software Development Process|Computer software selection and evaluation; DevOps; Information management; Pipeline codes; Artificial intelligence technologies; Code management; Continuous integration/continuous deployment; Continuous integrations; Creative Commons; Deployment process; Literature reviews; Machine-learning; Software development process; Source codes; Integration testing|Conference paper|Final||Scopus|2-s2.0-85207849487
scopus|Lilholt A.; Heverin T.|Lilholt, Addison (59523053100); Heverin, Thomas (37022912900)|59523053100; 37022912900|Mapping Software-Engineering Industry AI Use to Software-Engineering Curriculum: Developing the AI-USE Framework|2024|Proceedings of the 4th International Conference on AI Research, ICAIR 2024||||234|242|8|0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215657483&partnerID=40&md5=e28e0917d4449d472dc8a3fcc6acd658|"Estimates predict a global deficit of 4 million software engineers by 2025, further complicated by the software engineering (SE) industry's escalating use of artificial intelligence (AI). To tackle this issue, our research suggests that computer science (CS) curricula in middle and high schools need to be updated to incorporate SE industry segments that significantly employ AI. This strategic curriculum alignment is significant for preparing a workforce equipped to meet future industry demands. Our initial analysis involved reviewing nine international AI education guidelines to evaluate current methods for integrating AI into SE education. The findings indicated a pronounced lack of specific guidance connecting AI applications in the SE industry with educational content. To address this, we performed a systematic literature review of 12 research papers focusing on AI's role across the SE industry, followed by multiple rounds of inductive content analysis. An industry segment was deemed ""essential"" if it was referenced in 75% or more of the papers' findings. Through this method, we identified 10 essential SE industry segments for inclusion in CS education: software development, software maintenance, process improvement, software economics, knowledge management, project management, software testing, software security, quality assurance, and deployment and operations (DevOps). These findings led to the creation of the AI-USE (Artificial Intelligence Usage in Software Engineering) framework, which maps these 10 key segments to the predominant uses of SE in the industry as identified in the literature. Further inductive content analysis helped us develop subsegments for these essential areas. Ongoing framework development involves refining these subsegments and gathering feedback from industry and academic professionals. We anticipate that the fully developed AI-USE framework will significantly enhance SE education, equipping the next generation of software engineers with the AI proficiency required to address the industry’s evolving demands. © Proceedings of the 4th International Conference on AI Research, ICAIR 2024."|Artificial intelligence in education; Computer science education; Generative AI; SE education; Software engineering|Application programs; Computer software maintenance; Computer software selection and evaluation; Curricula; Engineering education; Integration testing; Software design; Software quality; Teaching; Artificial intelligence in education; Computer Science Education; Content analysis; Curriculum developing; Engineering industries; Generative artificial intelligence; Mapping softwares; Software engineering curricula; Software engineering education; Subsegments; Project management|Conference paper|Final||Scopus|2-s2.0-85215657483
scopus||||6th International conference on Software Testing, Machine Learning and Complex Process Analysis, TMPA 2021|2024|Communications in Computer and Information Science|1559|||||195|0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182007858&partnerID=40&md5=27195e78a415534a9f2355e6e7c9f102|The proceedings contain 18 papers. The special focus in this conference is on Software Testing, Machine Learning and Complex Process Analysis. The topics include: Link Graph and Data-Driven Graphs as Complex Networks: Comparative Study; An Approach to Creating a Synthetic Financial Transactions Dataset Based on an NDA-Protected Dataset; optic Flow Approximated by a Homogeneous, Three-Dimensional Point Renewal Process; fair Mutual Exclusion for N Processes; data Stream Processing in Reconciliation Testing: Industrial Experience; Detection of Flying Objects Using the YOLOv4 Convolutional Neural Network; modern Experiment Management Systems Architecture for Scientific Big Data; an Approach to Modules Similarity Definition Based on System Trace Analysis; process Mining Algorithm for Online Intrusion Detection System; bayesian Optimization with Time-Decaying Jitter for Hyperparameter Tuning of Neural Networks; investigation of the Capabilities of Artificial Neural Networks in the Problem of Classifying Objects with Dynamic Features; analysis of Hardware-Implemented U-Net–Like Convolutional Neural Networks; early Detection of Tasks with Uncommonly Long Run Duration in Post-trade Systems; Unpaired Image-To-Image Translation Using Transformer-Based CycleGAN; model-Based Testing Approach for Financial Technology Platforms: An Industrial Implementation; searching for Deviations in Trading Systems: Combining Control-Flow and Data Perspectives.|||Conference review|Final||Scopus|2-s2.0-85182007858
scopus|Chennareddy V.; Patibandla P.K.; Koppula R.C.|Chennareddy, Venkateswarlu (24472478500); Patibandla, Pavan Kumar (59182632200); Koppula, Rama C. (59182947000)|24472478500; 59182632200; 59182947000|A Methodology for Efficient Data Processing in AI Applications Using Adaptive Sampling and Automated Testing|2024|2024 4th International Conference on Computer Communication and Artificial Intelligence, CCAI 2024||||552|556|4|2|10.1109/CCAI61966.2024.10603318|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201159263&doi=10.1109%2fCCAI61966.2024.10603318&partnerID=40&md5=408e743ca39d6830d137257f6ecf801e|As data volumes continue to surge, the resources required to accelerate data processing for model training remain a challenge, leading to increased costs and extended processing times. This paper presents a novel method that combines Adaptive Sampling with an automated, self-adaptive comprehensive test suite module to address these challenges. This approach maintains model accuracy and ensures coverage of essential data required for business use cases. Experiments conducted on diverse datasets, some as large as several hundred terabytes, demonstrate that this method can reduce processing times by up to 75%. This achievement is realized by efficiently identifying and processing only representative samples. These results demonstrate the promising potential for improving data processing efficiency in model training for Artificial Intelligence (AI) applications across diverse sectors. © 2024 IEEE.|adaptive sampling; artificial intelligence; data efficiency; efficient data processing; self-adaptive comprehensive test suite|Artificial intelligence; Automation; Data handling; Large datasets; Adaptive sampling; Automated testing; Data efficiency; Data volume; Efficient data processing; Model training; Modeling accuracy; Novel methods; Processing time; Self-adaptive comprehensive test suite; Efficiency|Conference paper|Final||Scopus|2-s2.0-85201159263
scopus|He Y.; Wei X.; Gao Z.; Zhang Y.|He, Yajun (59542429200); Wei, Xuzeng (59542591300); Gao, Zhixuan (59542645200); Zhang, Yichi (59542700000)|59542429200; 59542591300; 59542645200; 59542700000|AN AUTOMATED TESTING METHOD FOR AIRCRAFT DISPLAY SYSTEM BASED ON IMAGE RECOGNITION|2024|IET Conference Proceedings|2024|13||1496|1500|4|0|10.1049/icp.2024.3103|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216926557&doi=10.1049%2ficp.2024.3103&partnerID=40&md5=dca73f913902e44d7ea4ab0b1ad41cc8|The development and airworthiness verification of aircraft software is a complex systematic engineering, which involves a lot of software testing work. The testing of aircraft display systems is highly complex, involving numerous testing parameters and a large amount of testing data. Therefore, testers may misjudge the test results due to visual fatigue or distraction during the testing process. This paper proposes an automated testing method for aircraft display systems, which implements automated testing functions based on computer vision technologies such as deep learning. The test results are automatically determined and recorded through technologies such as image recognition and text recognition. © The Institution of Engineering & Technology 2024.|CONVOLUTIONAL NEURAL NETWORK; DEEP LEARNING; IMAGE RECOGNITION|Convolutional neural networks; Deep neural networks; Fatigue testing; Flight testing; Software testing; Automated testing; Complex systematic engineering; Convolutional neural network; DEEP LEARNING; Display system; Large amounts; Software testings; Testing data; Testing method; Testing parameters; Display devices|Conference paper|Final||Scopus|2-s2.0-85216926557
scopus|Penagos D.T.; Agudelo N.|Penagos, Dalia Trujillo (59535939200); Agudelo, Nelson (57448995700)|59535939200; 57448995700|Agile testing using user language automation with artificial intelligence in Enjisst|2024|2024 IEEE Latin American Conference on Computational Intelligence, LA-CCI 2024 - Proceedings|||||||0|10.1109/LA-CCI62337.2024.10814749|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216521910&doi=10.1109%2fLA-CCI62337.2024.10814749&partnerID=40&md5=6b5d8ea1f05cf34c94d73b2a9f3d1e48|"Current software engineering focuses on achieving higher quality and speed in development and generating value for the business. This article proposes combining scenario thinking from requirement analysis techniques, such as Use Case 2.0, with test design and automation using the approaches of ""Behavior-Driven Development (BDD)""and ""Acceptance Test-Driven Development (ATDD).""This approach involves designing automated functional tests supported by artificial intelligence before development, which provides benefits regarding the time and cost of test automation. Enjisst is a user-language test automation platform aimed at creating different options for functional testing, which improves the understanding of the problem and promotes more effective communication of requirements across the entire team. This article demonstrates how Enjisst implements the described approach, which, supported by artificial intelligence and other sophisticated aspects, improves development speed and quality by over 50%. In summary, applying the required quality concepts in current agile and DevOps methodologies is a practical way.  © 2024 IEEE."|Agile Testing; Agility; Artificial Intelligence in Software Testing; BDD; DevOps; Test Automation|Acceptance tests; DevOps; Problem oriented languages; Program debugging; Software quality; 'current; Agile testing; Agility; Artificial intelligence in software testing; Behavior-driven development; High quality; High Speed; Requirements Analysis Techniques; Software testings; Test Automation; Software testing|Conference paper|Final||Scopus|2-s2.0-85216521910
scopus|Cagle A.; Ahmed A.C.|Cagle, Anton (59767592700); Ahmed, Ahmed Ceifelnasr (59767657400)|59767592700; 59767657400|Architecting Enterprise AI Applications: A Guide to Designing Reliable, Scalable, and Secure Enterprise-Grade AI Solutions|2024|Architecting Enterprise AI Applications: A Guide to Designing Reliable, Scalable, and Secure Enterprise-Grade AI Solutions||||1|286|285|0|10.1007/979-8-8688-0902-6|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105004114634&doi=10.1007%2f979-8-8688-0902-6&partnerID=40&md5=6ca49abbe9bd3a5a5dd794030d39e1c2|This book explores how to define, design, and maintain enterprise AI applications, exploring the impacts they will have on the teams who work with them. The book is structured into four parts. In Part 1: Defining Your AI Application, you are introduced to the dynamic interplay between human adaptability and AI specialization, the concept of meta systems, and the mechanics of prediction machines. In Part 2: Designing Your AI Application, the book delves into the anatomy of an AI application, unraveling the intricate relationships among data, machine learning, and reasoners. This section introduces the building blocks and enterprise architectural framework for designing multi-agent systems. Part 3: Maintaining Your AI Application takes a closer look at the ongoing life cycle of AI systems. You are guided through the crucial aspects of testing and test automation, providing a solid foundation for effective development practices. This section covers the critical tasks of security and information curation that ensure the long-term success of enterprise AI applications. The concluding section, Part 4: AI Enabled Teams, navigates the evolving landscape of collaborative efforts between humans and AI. It explores the impact of AI on remote work dynamics and introduces the new roles of the expert persona and the AI handler. This section concludes with a deep dive into the legal and ethical dimensions that AI-enabled teams must navigate. This book is a comprehensive guide that not only equips developers, architects, and product owners with the technical know-how of AI application development, but also delves into the broader implications for teams and society. What You Will Learn Understand the algorithms and processes that enable AI to make accurate predictions and enhance decision making Grasp the concept of metasystems and their role in the design phase of AI applications Know how data, machine learning, and reasoners drive the functionality and decision-making capabilities of AI applications Know the architectural components necessary for scalable and maintainable multi-agent AI applications Understand methodologies for testing AI applications, ensuring their robustness, accuracy, and reliability in real-world applications Understand the evolving dynamics of human-AI coordination facing teams in the new enterprise working environment Who This book Is For A diverse audience, primarily targeting enterprise architects, middle managers, tech leads, and team leads entrenched in the IT sector or possessing a tech-savvy background, including professionals such as digital marketers. Additionally, tech-savvy individual contributors—ranging from digital content creators and data analysts to administrators and programmers—stand to benefit significantly. © 2024 by Anton Cagle, Ahmed Mohamed Ceifelnasr Ahmed.|AI Architecture; AI Observability; AI Safety; Artificial Intelligence; AWS Bedrock; ChatGPT; Foundational Models; Large Language Models; Machine Learning|Ethical aspects; Veneers; AI applications; AI architecture; AI observability; AI safety; AWS bedrock; ChatGPT; Foundational model; Language model; Large language model; Machine-learning; Technology transfer|Book|Final||Scopus|2-s2.0-105004114634
scopus|Agarwal S.; Chimalakonda S.; Krishnan S.; Kanvar V.; Shah S.|Agarwal, Shivali (55452894400); Chimalakonda, Sridhar (26767549200); Krishnan, Saravanan (55947017000); Kanvar, Vini (57190183055); Shah, Samveg (59037557600)|55452894400; 26767549200; 55947017000; 57190183055; 59037557600|Legacy Software Modernization: A Journey From Non-AI to Generative AI Approaches|2024|ACM International Conference Proceeding Series|||19||||1|10.1145/3641399.3641434|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186766261&doi=10.1145%2f3641399.3641434&partnerID=40&md5=67f0620fda481dde9b4322b9faa8693b|Dealing with ageing software is a reality of the industry, and even open source software systems. This is a great opportunity for the software engineering researchers to apply the traditional techniques of program analysis to solve problems of refactoring and modernization. The generative AI advancements have opened up a whole new world of possibilities for software engineering tasks such as code generation, code translation, bug fixing among others. Industry is keen on exploring scalable solutions for refactoring, automated testing and now automatic code generation. In this tutorial, we aim to (i) provide a background and overview of legacy software modernization and its importance amidst the emergence of AI-Assisted software and Generative AI (ii) discuss the challenges being faced by industry due to monolithic legacy code and systems (iii) introduce architectural and technological paradigms to modernize this legacy or ageing software (iv) highlight the research and engineering problems that remain to be solved in this space discussing the opportunities for the software engineering research community. © 2024 Copyright held by the owner/author(s).|Code LLMs; Legacy Software Modernization; Program Analysis; Refactoring|Automatic programming; Automation; Codes (symbols); Legacy systems; Modernization; Open source software; Software testing; Code LLM; Codegeneration; Engineering tasks; Legacy software; Legacy software modernization; Open source software systems; Program analysis; Refactorings; Software modernization; Traditional techniques; Open systems|Conference paper|Final||Scopus|2-s2.0-85186766261
scopus|Jodat B.A.|Jodat, Baharin A. (58031468900)|58031468900|Insights into System Failures: ML-Assisted Testing and Failure Models for Cyber-Physical Systems|2024|Proceedings - 2024 IEEE Conference on Software Testing, Verification and Validation, ICST 2024||||460|462|2|0|10.1109/ICST60714.2024.00055|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203846120&doi=10.1109%2fICST60714.2024.00055&partnerID=40&md5=11be8e56a35d4598d787e827dffc5635|Traditional software testing techniques focus on discovering inputs that reveal failures in the system under test. However, such techniques often fall short of providing explanations for the underlying reasons of system failures. I have made efforts to employ simulation-based testing to provide interpretable feedback to the developers regarding the circum-stances of system failures. To achieve this, I first explore machine learning (ML)-assisted test generation techniques for building failure models. These techniques leverage ML models to enhance the effectiveness and efficiency of testing, either by predicting the test outputs or providing guidance through a reduced search space. Subsequently, I build failure models using interpretable machine learning models based on tests generated by the ML-assisted test generation algorithms. Such failure models generate a set of rules that developers can easily interpret. The systems for which I build failure models belong to the cyber-physical and network domains. In this doctoral symposium, I present my research and outline plans for the remainder of my Ph.D. study.  © 2024 IEEE.|Interpretable machine learning; Simulation-based testing; Test generation assisted by machine learning|Learning systems; Machine learning; Failure modelling; Interpretable machine learning; Machine learning models; Machine-learning; Simulation-based testing; System failures; Test generation assisted by machine learning; Test generations; Testing models; Software testing|Conference paper|Final||Scopus|2-s2.0-85203846120
scopus|Ouaarous R.; Hilal I.; Mezrioui A.|Ouaarous, Randa (59470422400); Hilal, Imane (56612043400); Mezrioui, Abdellatif (15926025000)|59470422400; 56612043400; 15926025000|On Using Artificial Intelligence in Software Quality Assurance: A State of the Art|2024|CEUR Workshop Proceedings|3845||||||0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211934561&partnerID=40&md5=353de73b6285e07acdc2ca5f3895c459|Artificial intelligence (AI) techniques and models have been applied to assist numerous activities in software engineering, specifically in Software Quality Assurance (SQA), covering both technical and management parts. Several studies have examined the utilization of AI in various tasks within the SQA field, with a particular focus on software testing. This study seeks to investigate the overall impact of AI on SQA, while identifying the prevalent applications and possible areas for further research. We thoroughly examined a selection of articles that study the use of AI approaches in various SQA activities. We have selected relevant research papers that were published in the last 5 years. The analysis was conducted by utilizing established AI and SQA taxonomies and categorizing the chosen papers based on these taxonomies. The resulting mapping and conversations indicate that the use of AI to assist in SQA is a well-established and expanding area of scientific interest with interesting opportunities for future. Evidence of several AI benefits was found when applied to SQA such as cost reduction and process improvement, as well as challenges in case of high complexity and questionable data quality. The discussions of the impact of AI on the roles of the SQA showed better outcomes when adopting a Human-AI collaboration approach. © 2024 Copyright for this paper by its authors.|AI; Artificial Intelligence; Software Quality Assurance; Software Testing; SQA|Application programs; Computer software selection and evaluation; Data quality; Software quality; Software testing; Artificial intelligence techniques; Cost-reduction improvement; Data quality; High complexity; Process Improvement; Research papers; Software quality assurance; Software testings; State of the art; Taxonomies|Conference paper|Final||Scopus|2-s2.0-85211934561
scopus|Boukhlif M.; Hanine M.; Kharmoum N.; Ruigomez Noriega A.; Garcia Obeso D.; Ashraf I.|Boukhlif, Mohamed (58247381400); Hanine, Mohamed (57219370936); Kharmoum, Nassim (57210745538); Ruigomez Noriega, Atenea (59223793200); Garcia Obeso, David (59223796400); Ashraf, Imran (57195478761)|58247381400; 57219370936; 57210745538; 59223793200; 59223796400; 57195478761|Natural Language Processing-Based Software Testing: A Systematic Literature Review|2024|IEEE Access|12|||79383|79400|17|9|10.1109/ACCESS.2024.3407753|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194863173&doi=10.1109%2fACCESS.2024.3407753&partnerID=40&md5=b65433d02cc027fd7322851e5cb3bd35|New approaches to software testing are required due to the rising complexity of today's software applications and the rapid growth of software engineering practices. Among these methods, one that has shown promise is the introduction of Natural Language Processing (NLP) tools to software testing practices. NLP has witnessed a rise in popularity within all IT fields, especially in software engineering, where its use has improved the way we extract information from textual data. The goal of this systematic literature review (SLR) is to provide an in-depth analysis of the present body of the literature on the expanding subject of NLP-based software testing. Through a repeatable process, that takes into account the quality of the research, we examined 24 papers extracted from Web of Science and Scopus databases to extract insights about the usage of NLP techniques in the field of software testing. Requirements analysis and test case generation popped up as the most hot topics in the field. We also explored NLP techniques, software testing types, machine/deep learning algorithms, and NLP tools and frameworks used in the studied body of literature. This study also stressed some recurrent open challenges that need further work in future research such as the generalization of the NLP algorithm across domains and languages and the ambiguity in the natural language requirements. Software testing professionals and researchers can get important insights from the findings of this SLR, which will help them comprehend the advantages and challenges of using NLP in software testing.  © 2013 IEEE.|natural language processing (NLP); Software testing; systematic review; test case generation|Application programs; Engineering research; Natural language processing systems; Language processing; Natural language processing; Natural languages; Software; Software algorithms; Software testings; Systematic; Systematic Review; Test case generation; Software testing|Article|Final|All Open Access; Gold Open Access|Scopus|2-s2.0-85194863173
scopus|Hu Y.|Hu, Yu (59377112600)|59377112600|Research on Artificial Intelligence-Assisted Software Test Automation Methods|2024|Applied Mathematics and Nonlinear Sciences|9|1|20242874||||1|10.2478/amns-2024-2874|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207051548&doi=10.2478%2famns-2024-2874&partnerID=40&md5=4c915f15efd32e7564306d4bfa5e9006|Software testing faces problems such as low automation and difficult reuse of testing methods. The purpose of this paper is to explore software testing automation methods with the aid of artificial intelligence. In this paper, based on the BS algorithm, the RF algorithm is constructed by Bagging integration, the RF algorithm is optimized by reducing the generalization error through the residual function, and the random forest model for software automation detection is constructed. After that, the model is examined and analyzed using automated detection of malicious software samples as a case study. The experimental results show that the accuracy of the Random Forest algorithm after feature selection reaches 98.9%, its prediction time is the least (7 seconds), and the Random Forest algorithm for training is the best. Z software's optimized RF algorithm model has an accuracy of between 86% and 99.3% when detecting seven malicious types of samples. This paper's proposed random forest algorithm model based on artificial intelligence assistance is well-suited for automated software testing, and the detection method is feasible.  © 2024 Yu Hu, published by Sciendo.|Bagging integration; BS algorithm; RF algorithm; Software testing automation|Computer software reusability; Random forests; Algorithm model; Bagging integration; BS algorithm; Random forest algorithm; Reuse; RF algorithm; Software test automation; Software testing automation; Software testings; Testing automation; Integration testing|Article|Final|All Open Access; Gold Open Access|Scopus|2-s2.0-85207051548
scopus|Liu C.; Jiang Y.; Zheng D.|Liu, Chang (59962986600); Jiang, Yan (59962759100); Zheng, Dongxia (58331697200)|59962986600; 59962759100; 58331697200|"Exploration of Course Practice on the Integration of AI Language Model and Ideological and Political Education : The Course of ""Software Testing""as an Example"|2024|2024 5th International Conference on Information Science and Education, ICISE-IE 2024||||392|396|4|0|10.1109/ICISE-IE64355.2024.11025195|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105009166291&doi=10.1109%2fICISE-IE64355.2024.11025195&partnerID=40&md5=f117892197e175adbd6c93922b087da1|With the rapid development of information technology, artificial intelligence technology, and digital technology, cutting-edge technologies such as big data, intelligent algorithms, cloud computing, the Internet of Things, and blockchain are gradually penetrating into the field of education, promoting the modernization and digitization of education. In this context, software testing courses, as important courses in computer science and technology and software engineering majors, are facing new challenges and opportunities. In response to the mismatch between the curriculum teaching system and the new demands of the artificial intelligence era, it is proposed to focus on artificial intelligence technology, optimize the curriculum system from multiple dimensions, introduce AI language models to drive teaching, and pay attention to the deep integration of ideological and political education in the curriculum. This article demonstrates how to integrate ideological and political elements into software testing courses through specific cases. Practice has proven that AI driven courses can better stimulate students' interest in learning, help improve their ideological level, technical ability, and industry competitiveness. © 2024 IEEE.|AI; Course ideology and politics; Large Language Model; Software test|Big data; Curricula; Education computing; Engineering education; Integration testing; Teaching; Artificial intelligence technologies; Course ideology and politic; Course practices; Cutting edge technology; Digital technologies; Ideological and political educations; Language model; Large language model; Software test; Software testings; Artificial intelligence|Conference paper|Final||Scopus|2-s2.0-105009166291
scopus|Stojanovic D.; Pavkovic B.; Cetic N.; Krunic M.; Vidakovic L.|Stojanovic, Dimitrije (57215117047); Pavkovic, Bogdan (27467638800); Cetic, Nenad (24779359800); Krunic, Momcilo (55028218600); Vidakovic, Luka (59541714500)|57215117047; 27467638800; 24779359800; 55028218600; 59541714500|Unit Test Generation Multi-Agent AI System for Enhancing Software Documentation and Code Coverage|2024|2024 32nd Telecommunications Forum, TELFOR 2024 - Proceedings of Papers|||||||0|10.1109/TELFOR63250.2024.10819096|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216854650&doi=10.1109%2fTELFOR63250.2024.10819096&partnerID=40&md5=390101446437cb2070397ec716edb741|Software development necessitates a robust testing plan though test development can be laborious and nonappealing task. We explore the utilization of the application artificial intelligence agents for generating and executing unit tests, enhancing the 'Mostly Basic Python Problems' dataset. We employ behavior-driven development within a three-agent system to generate user stories and unit tests. Empirical results indicate improvements in branch coverage, illustrating the effective utilization of large language models in software testing and development processes. © 2024 IEEE.|AI agents; BDD; code generation; SW test automation; transformers; unit test generation|Distribution transformers; Electric transformer testing; Model checking; Problem oriented languages; Program debugging; Software agents; Software design; System program documentation; AI agent; AI systems; BDD; Codegeneration; Multi agent; SW test automation; Test Automation; Transformer; Unit test generations; Unit tests; Software testing|Conference paper|Final||Scopus|2-s2.0-85216854650
scopus||||8th International Conference on Engineering of Computer-Based Systems, ECBS 2023|2024|Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)|14390 LNCS|||||298|0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180301290&partnerID=40&md5=989c185fe3e9f257fee2fd7a67bc2866|The proceedings contain 26 papers. The special focus in this conference is on Engineering of Computer-Based Systems. The topics include: Comparative Analysis of Uppaal SMC, ns-3 and MATLAB/Simulink; Using Automata Learning for Compliance Evaluation of Communication Protocols on an NFC Handshake Example; Towards LLM-Based System Migration in Language-Driven Engineering; synthesizing Understandable Strategies; ReProInspect: Framework for Reproducible Defect Datasets for Improved AOI of PCBAs; cyber-Physical Ecosystems: Modelling and Verification; integrating IoT Infrastructures in Industrie 4.0 Scenarios with the Asset Administration Shell; A Software Package (in progress) that Implements the Hammock-EFL Methodology; toward Responsible Artificial Intelligence Systems: Safety and Trustworthiness; Dynamic Priority Scheduling for Periodic Systems Using ROS 2; continuous Integration of Neural Networks in Autonomous Systems; building a Digital Twin Framework for Dynamic and Robust Distributed Systems; a Simple End-to-End Computer-Aided Detection Pipeline for Trained Deep Learning Models; astrocyte-Integrated Dynamic Function Exchange in Spiking Neural Networks; Correct Orchestration of Federated Learning Generic Algorithms: Formalisation and Verification in CSP; careProfSys - Combining Machine Learning and Virtual Reality to Build an Attractive Job Recommender System for Youth: Technical Details and Experimental Data; ambient Temperature Prediction for Embedded Systems Using Machine Learning; a Federated Learning Algorithms Development Paradigm; machine Learning Data Suitability and Performance Testing Using Fault Injection Testing Framework; IDPP: Imbalanced Datasets Pipelines in Pyrus; learning in Uppaal for Test Case Generation for Cyber-Physical Systems; a Literature Survey of Assertions in Software Testing; FPGA-Based Encryption for Peer-to-Peer Industrial Network Links.|||Conference review|Final||Scopus|2-s2.0-85180301290
scopus|Boukhlif M.; Kharmoum N.; Hanine M.|Boukhlif, Mohamed (58247381400); Kharmoum, Nassim (57210745538); Hanine, Mohamed (57219370936)|58247381400; 57210745538; 57219370936|LLMs for Intelligent Software Testing: A Comparative Study|2024|ACM International Conference Proceeding Series|||42||||3|10.1145/3659677.3659749|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202557416&doi=10.1145%2f3659677.3659749&partnerID=40&md5=8bddab575d201dbd93ceb8a19d172611|The need for effective and timely testing processes has become critical in the constantly changing field of software development. Large Language Models (LLMs) have demonstrated promise in automating test case creation, defect detection, and other software testing tasks through the use of the capabilities of machine/deep learning and natural language processing. This work explores the field of intelligent software testing, with a focus on the use of LLMs in this context. The purpose of this comparative study is to assess the corpus of research in the field in terms of used LLMs, how to interact with them, the use of fine-tuning, and prompt engineering, and explore the different technologies and testing types automated using LLMs. The findings of this study not only contribute to the growing body of knowledge on intelligent software testing but also guide fellow researchers and industry engineers in selecting the most suitable LLM for their specific testing needs.  © 2024 ACM.|Comparative Study; Large Language Models; Natural Language Processing; Software Testing; Test Case Generation|Natural language processing systems; Software design; Software testing; Comparatives studies; Intelligent software; Language model; Language processing; Large language model; Natural language processing; Natural languages; Software testings; Test case generation; Testing process; Contrastive Learning|Conference paper|Final||Scopus|2-s2.0-85202557416
scopus|Alqurashi S.; Ray I.; Abdelgawad M.; Shirazi H.|Alqurashi, Saja (57188735669); Ray, Indrakshi (58830606300); Abdelgawad, Mahmoud (59268433300); Shirazi, Hosein (59467778400)|57188735669; 58830606300; 59268433300; 59467778400|SR2ACM: A Methodical Approach for Translating Natural Language Security Requirements to Access Control Model|2024|Proceedings - 2024 IEEE 6th International Conference on Trust, Privacy and Security in Intelligent Systems, and Applications, TPS-ISA 2024||||303|312|9|0|10.1109/TPS-ISA62245.2024.00042|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217846205&doi=10.1109%2fTPS-ISA62245.2024.00042&partnerID=40&md5=7fce1c65ef68fa9be1cd64204e711182|Access control policies (ACPs), embedded in the security requirements of an enterprise, are typically expressed in natural languages. Security administrators manually extract ACPs, interpret them, and construct a formal access control model which is later enforced by security mechanisms. The manual process is tedious, complex, expensive, labor-intensive, and error-prone. To address these limitations, we introduce a Natural Language Processing (NLP) pipeline called Security Requirements to Access Control Model (SR2ACM). This pipeline is designed to extract ACPs from statements in natural language automatically, convert these ACPs into the Next Generation Access Control (NGAC) model that we represent in the form of a graph, propose a set of properties that can be tested on the graph to assess the quality of the NGAC model so derived. SR2ACM performs downstream NLP tasks that include identifying ACP sentences, identifying NGAC relations, and identifying NGAC user and object attributes. The experimental results are promising as we achieved, on average, F1-score of 93% when identifying ACP sentences, F1-score of 97% when extracting NGAC relations between attributes, and F1-score of 96% when extracting user attributes and 89% for object attributes from natural language access control policies that we obtained from real-world applications. We utilize six diverse datasets representing access control policies of various domains to ensure a comprehensive evaluation. To assess the correctness of the NGAC policies generated, we propose a set of formal properties, namely, completeness (checks no ACPs have been omitted), well-formedness (checks the ACP construct), minimality (checks for absences of redundancies), and consistency (checks for absence of conflicts). Our formal analysis on our dataset reveals a completeness rate of 95% on average, a perfect rate of 100% of well-formedness, non-redundancy in 98% of NGAC ACPs, and an absence of inconsistencies. Our research is unique as it combines machine learning with software testing to assure the quality of the extracted model.  © 2024 IEEE.|Access Control Policies (ACPs); Bidirectional Encoder Representations from Transformers (BERT); Graph Analysis; Next Generation Access Control (NGAC)|Access control models; Application programs; Computer software selection and evaluation; Model checking; Modeling languages; Natural language processing systems; Pipeline processing systems; Problem oriented languages; Software testing; Access control models; Access control policies; Access control policy; Bidirectional encoder representation from transformer; F1 scores; Graph analysis; Natural languages; Next generation access control; Next-generation access; Security requirements; Redundancy|Conference paper|Final||Scopus|2-s2.0-85217846205
scopus|Rodrigues A.; Vilela J.; Silva C.|Rodrigues, Alessandro (59139731100); Vilela, Jéssyka (56428808300); Silva, Carla (55522898600)|59139731100; 56428808300; 55522898600|A Systematic Mapping Study on Techniques for Generating Test Cases from Requirements|2024|International Conference on Internet of Things, Big Data and Security, IoTBDS - Proceedings||||141|148|7|0|10.5220/0012551900003705|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193938137&doi=10.5220%2f0012551900003705&partnerID=40&md5=35013c663fb771493d6763dbff54ab06|Context: Software testing can be costly for organizations. Techniques and tools that deal with the automatic generation of test cases provide a way to reduce the efforts employed and the time-to-market, in addition to increasing the quality of the software. Objective: This work aims to investigate the literature regarding techniques used to generate test cases from requirements automatically. Method: We performed a Systematic Mapping Study (SMS) using the Snowballing technique to investigate these techniques, the information presented in the test plan/case, the languages used to specify the requirements, and finally, the steps proposed by the techniques. Results: techniques such as Model-based testing (MBT) and Natural Language Processing (NLP) are the most used, mainly based on requirements specified through Natural Language that can be structured or not, as well as UML (Unified Modeling Language) diagrams. We also extracted and presented a series of languages and tools developed, and some are under development that perform this generation. © 2024 by SCITEPRESS – Science and Technology Publications, Lda.|Generation; Requirements; Systematic Mapping Study; Test Cases|Mapping; Model checking; Natural language processing systems; Tensile testing; Unified Modeling Language; Well testing; Automatic Generation; Generation; Natural languages; Requirement; Software testings; Systematic mapping studies; Techniques and tools; Test case; Test plan; Time to market; Software testing|Conference paper|Final|All Open Access; Hybrid Gold Open Access|Scopus|2-s2.0-85193938137
scopus|Sani B.; Jan S.|Sani, Balqees (59381042800); Jan, Sadaqat (36623918000)|59381042800; 36623918000|Empirical Analysis of Widely Used Website Automated Testing Tools|2024|EAI Endorsed Transactions on AI and Robotics|3||||||1|10.4108/airo.7285|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207261883&doi=10.4108%2fairo.7285&partnerID=40&md5=21db5a69bbf7194ca0b7b1c116f97d25|In today’s software development, achieving product quality while minimising cost and time is critical. Automated testing is crucial to attaining these goals by lowering inspection efforts and discovering faults more effectively. This paper compares widely used automated testing tools, such as Selenium, Appium, JUnit (Java Unit), Test Next Generation (TestNG), Jenkins, Cucumber, LoadRunner, Katalon Studio, Simple Object Access Protocol User Interface (SoapUI), and TestComplete, based on functionality, ease of use, platform compatibility, and integration capabilities. Our findings show that no single tool is inherently superior, with each excelling in certain areas such as online, mobile, Application Programming Interface (API), or performance testing. While Selenium and Appium are the dominant online and mobile testing frameworks, TestComplete and Katalon Studio offer complete, user-friendly cross-platform testing solutions. Despite the benefits of automation, obstacles such as tool maintenance, scalability, and cost issues remain. The report finishes with advice for picking the best tool for the project and offers potential approaches for enhancing testing frameworks, such as AI-driven optimisation, cloud-based testing, and greater Continuous Integration/ Continuous Deployment (CI/CD) integration. This study offers useful information for developers and testers looking to optimise their testing methods and increase software quality. © 2024 Sani et al.|Automated testing tools; Cloud-based testing; performance testing; Selenium||Review|Final|All Open Access; Hybrid Gold Open Access|Scopus|2-s2.0-85207261883
scopus|Roberts P.; Dent N.|Roberts, Paul (57205056019); Dent, Nicholas (59140543600)|57205056019; 59140543600|Game AI Uncovered: Volume Two|2024|Game AI Uncovered: Volume Two|2|||1|210|209|0|10.1201/9781003323549|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194026923&doi=10.1201%2f9781003323549&partnerID=40&md5=c74dbc198852e7f1892897230df83f11|Game AI Uncovered: Volume Two continues the series with the collected wisdom, ideas, tricks and cutting-edge techniques from 22 of the top game AI professionals and researchers from around the world. The techniques discussed in these pages cover the underlying development of a wide array of published titles, including The Survivalists, Wheelman, Plants vs. Zombies: Battle for Neighborville, Dead Space, Zombie Army 4, Evil Genius 2, Sniper Elite 5, Sonic & All-Stars Racing Transformed, DiRT: Showdown, and more. Contained within this volume are overviews and insights covering a host of different areas within game AI, including generalised planners, player imitation, awareness, dynamic behaviour trees, decision-making architectures, agent learning for automated playthroughs, utility systems, machine learning for cinematography, directed acyclic graphs, environment steering, difficulty scenarios, environmental cues through voxels, automated testing approaches, dumbing down your AI, synchronized path following, and much more. Beginners to the area of game AI, along with professional developers, will find a wealth of knowledge that will not only help in the development of your own games but also spark ideas for new approaches. This volume includes chapters written by Nuno Vicente Barreto, Steve Bilton, Andy Brown, Dr Allan Bruce, Richard Bull, Phil Carlisle, Sarah Cook, Michele Condò, Steven Dalton, Rodolfo Fava, Jonas Gillberg, Dominik Gotojuch, Dale Green, Tobias Karlsson, Jonathan Keslake, Fernando Penousal Machado, Ivan Mateev, Dr Nic Melder, Dr Bram Ridder, Paul Roberts, Licínio Roque, and Andrea Schiel. © 2024 selection and editorial matter, Paul Roberts; individual chapters, the contributors.||Artificial intelligence; Behavioral research; Agent learning; Architecture agents; Behaviour Trees; Cutting edges; Dead space; Decisions makings; Dynamic behaviors; Game AI; Machine-learning; Utility systems; Decision trees|Book|Final||Scopus|2-s2.0-85194026923
scopus|Jiang S.; Wu L.; Liu B.; Jin K.; Shen X.|Jiang, Shixian (59416817200); Wu, Lijin (55978341400); Liu, Bojiang (57203635999); Jin, Kuangyu (58519115700); Shen, Xiaomei (57222117462)|59416817200; 55978341400; 57203635999; 58519115700; 57222117462|Research on the Credibility Test Technology of Intelligent Autonomous System|2024|2024 IEEE 2nd International Conference on Sensors, Electronics and Computer Engineering, ICSECE 2024||||542|546|4|0|10.1109/ICSECE61636.2024.10729479|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209624863&doi=10.1109%2fICSECE61636.2024.10729479&partnerID=40&md5=9cab4ff2c5c318090b3675a5cb6fca5f|With significant breakthroughs in key technologies such as machine learning, computer vision, and natural language processing, artificial intelligence technology is accelerating the profound transformation of the military field from mechanization and informatization to intelligence, and traditional software testing methods are no longer applicable. This article first analyzes the credibility of artificial intelligence software, then elaborates on the testing techniques of artificial intelligence software, and finally summarizes the credibility evaluation system, providing technical support for the validation of artificial intelligence software.  © 2024 IEEE.|intelligent software; software credibility; software testing|Credibility tests; Intelligence software; Intelligent autonomous systems; Intelligent software; Key technologies; Machine-learning; Natural languages; Software credibility; Software testings; Test technology; Adversarial machine learning|Conference paper|Final||Scopus|2-s2.0-85209624863
scopus|Li N.; Chen C.; Wang J.; Hu H.|Li, Na (57224588686); Chen, Chen (58741034600); Wang, Jun (59250542100); Hu, Hongfei (58245301600)|57224588686; 58741034600; 59250542100; 58245301600|Application of API automation testing based on microservice mode in industry software|2024|ACM International Conference Proceeding Series||||460|464|4|1|10.1145/3677182.3677264|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201938071&doi=10.1145%2f3677182.3677264&partnerID=40&md5=e39668f1cb9bcdca12984cfcc778da77|Set against the backdrop of a corporate cloud billing system testing initiative, this paper delves into the pragmatic approach to API automation testing within a microservices architectural context. It commences by underscoring the significance and the inherent challenges posed by API testing in a microservices ecosystem, with a particular focus on the quandaries encountered when managing intricate and voluminous test data. To surmount these obstacles and enhance both the efficacy and scope of testing, the research advocates for an innovative paradigm in test data administration and procreation. This paradigm harnesses machine learning techniques to automate the generation of high-fidelity test data. By leveraging machine learning algorithms to dissect historical data and discern patterns of application utilization, the methodology affords the creation of test datasets that mirror authentic operational scenarios. Such an approach substantially elevates the pertinence and exhaustiveness of the test data, concurrently diminishing the demand for labor-intensive manual test case design. During the regression testing phase, the expounded microservices-based API automation testing strategy has demonstrated its efficacy in bolstering software quality and refining the testing process’s efficiency. The paper concludes by encapsulating best practices for API automation testing within microservices architectures and suggests avenues for future research aimed at further streamlining software testing protocols and propelling ongoing advancements in industry software quality assurance. © 2024 ACM.|Consumer-Contract-Based Testing; Microservice; REST API|Application programs; Automatic test pattern generation; Computer software selection and evaluation; Automation testing; Billing systems; Consumer-contract-based testing; Corporates; Data administration; Machine learning techniques; Microservice; REST API; System testing; Test data; Software testing|Conference paper|Final||Scopus|2-s2.0-85201938071
scopus|Xie S.; Zhu S.; He Q.; Cui Z.|Xie, Songcheng (59542379400); Zhu, Shengpeng (59542433600); He, Qifan (58815359100); Cui, Zhanqi (35172605800)|59542379400; 59542433600; 58815359100; 35172605800|Autonomous Driving Software Testing Based on Interpretation Analysis|2024|Proceedings - 2024 11th International Conference on Dependable Systems and Their Applications, DSA 2024||||432|433|1|0|10.1109/DSA63982.2024.00067|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216923058&doi=10.1109%2fDSA63982.2024.00067&partnerID=40&md5=5eb0eee9b2203699a30ee1808df46d40|With the development of artificial intelligence, autonomous driving has become a typical use of AI technology, while its safety has received widespread attention. However, current mainstream data-driven automated driving test methods lack interpretability, automation features, and a high degree of realism in generating test images. To solve the above problems, this paper proposes a method ATIA (Autonomous Test based on Interpretation Analysis), which generates gradient heatmaps based on Grad-CAM and uses deep image synthesis network to generate test images by replacing key objects according to the heatmap, and also designs a corresponding automated testing tool. The experimental results show that ATIA has the ability to detect defects, while generating images that are closer to real images.  © 2024 IEEE.|autonomous driving; deep image synthesis; grad-CAM; interpretation analysis; software testing|Automatic testing; 'current; AI Technologies; Autonomous driving; Deep image synthesis; Grad-CAM; Heatmaps; Images synthesis; Interpretation analyze; Software testings; Test images; Software testing|Conference paper|Final||Scopus|2-s2.0-85216923058
scopus|Gnacy-Gajdzik A.; Przystałka P.|Gnacy-Gajdzik, Anna (58284479800); Przystałka, Piotr (23088934700)|58284479800; 23088934700|Automating the Analysis of Negative Test Verdicts: A Future-Forward Approach Supported by Augmented Intelligence Algorithms|2024|Applied Sciences (Switzerland)|14|6|2304||||1|10.3390/app14062304|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192500661&doi=10.3390%2fapp14062304&partnerID=40&md5=6c08c3f747d1f5bc6170c54353f861e8|In the epoch characterized by the anticipation of autonomous vehicles, the quality of the embedded system software, its reliability, safety, and security is significant. The testing of embedded software is an increasingly significant element of the development process. The application of artificial intelligence (AI) algorithms in the process of testing embedded software in vehicles constitutes a significant area of both research and practical consideration, arising from the escalating complexity of these systems. This paper presents the preliminary development of the AVESYS framework which facilitates the application of open-source artificial intelligence algorithms in the embedded system testing process. The aim of this work is to evaluate its effectiveness in identifying anomalies in the test environment that could potentially affect testing results. The raw data from the test environment, mainly communication signals and readings from temperature, as well as current and voltage sensors are pre-processed and used to train machine learning models. A verification study is carried out, proving the high practical potential of the application of AI algorithms in embedded software testing. © 2024 by the authors.|anomaly detection; artificial neural network; automation; automotive; machine learning; testing embedded systems||Article|Final|All Open Access; Gold Open Access|Scopus|2-s2.0-85192500661
scopus|Laine A.; Ojanen V.|Laine, A. (59560853000); Ojanen, V. (6603268134)|59560853000; 6603268134|Leveraging AI in Software Testing: Applying ADKAR for Effective Change Management|2024|IEEE International Conference on Industrial Engineering and Engineering Management||||673|677|4|0|10.1109/IEEM62345.2024.10857157|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218046013&doi=10.1109%2fIEEM62345.2024.10857157&partnerID=40&md5=8fe338a411f9237f241841fd979be840|This paper aims to highlight effective change management practices in AI-related change initiatives. Through 15 expert interviews, we conducted an in-depth case study on the incorporation of an AI coding assistant tool into a global telecommunications company’s software testing process. The tool is intended to aid with test automation development. The study highlights how the ADKAR model was utilized for developing a change management plan tailored to a technology context. Our findings suggest that while the ADKAR model provides a flexible framework that addresses key aspects of AI-related change, its emphasis on a bottom-up approach may limit its applicability for large-scale transformations. © 2024 IEEE.|ADKAR model; artificial intelligence; change management; software testing|ADKAR model; Case-studies; Change management; Global telecommunication; Management plans; Management practises; Software testings; Telecommunication companies; Test Automation; Testing process|Conference paper|Final||Scopus|2-s2.0-85218046013
scopus|Hagar J.; Masuda S.|Hagar, Jon (56241124900); Masuda, Satoshi (36803608600)|56241124900; 36803608600|Prompt Engineering Impacts to Software Test Architectures for Beginner to Experts|2024|Proceedings - 2024 IEEE International Conference on Software Testing, Verification and Validation Workshops, ICSTW 2024||||116|121|5|0|10.1109/ICSTW60967.2024.00034|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205956224&doi=10.1109%2fICSTW60967.2024.00034&partnerID=40&md5=9557a01774661ad91553e8f672003225|Interest in Artificial Intelligence is everywhere today, including mass media news articles, government research, academic writing, industry usage, and student learning assignments. AI will impact software, testing and related concepts such as software test environments and architectures. This paper presents a consideration of AI regarding test engineering concepts. The focus is on a concept supporting AI called prompt engineering, which helps people and testers using AI get better results. AI cannot be expected to help solve software test engineering problems without proper prompting. The paper introduces the AI concepts and relationships to historical testing. Actual example prompts are explored with implications and results. People learning prompt engineering to support testing will include students and active test engineer designers. While this paper is just a beginning on the test support concept of prompt engineering, future work is considered.  © 2024 IEEE.|Artificial Intelligence (AI); Prompt Engineering; Software Test Architecture (STA); Student-Tester/Designer Learning and Skills|Computer aided software engineering; Engineering education; Software testing; Students; Academic writings; Artificial intelligence; Mass media; News articles; Prompt engineering; Software test architecture; Student learning; Student-tester/designer learning and skill; Test architecture; Test engineering; Software architecture|Conference paper|Final||Scopus|2-s2.0-85205956224
scopus|Yalçıner A.; Dikici A.; Gökalp E.|Yalçıner, Aybüke (59337586500); Dikici, Ahmet (15073885700); Gökalp, Ebru (56403164300)|59337586500; 15073885700; 56403164300|Data-Driven Software Engineering: A Systematic Literature Review|2024|Communications in Computer and Information Science|2179 CCIS|||19|32|13|3|10.1007/978-3-031-71139-8_2|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204536678&doi=10.1007%2f978-3-031-71139-8_2&partnerID=40&md5=a31571d45813f8f0615400061ac72184|Over the past few years, emerging technologies have had a significant impact on the processes of software engineering (SE). Consequently, there has been a shift from a more experience-based approach to a data-driven decision-making approach. This shift to data-driven decision-making has resulted in more reliable and accurate decision-making, ultimately leading to more efficient and effective SE processes and a reduction in rework. Our study involved a comprehensive systematic literature review (SLR) examining the utilization of data-driven approaches in SE processes over the last decade. Our analysis of 34 primary studies revealed that data-driven approaches are most commonly utilized. After analyzing the primary studies, we found that data-driven methods are commonly employed in SE processes for software management and software testing. Researchers are delving into subfields of artificial intelligence, including machine learning and deep learning, to devise decision-making models for SE processes that have undergone extensive validation. We aim to provide valuable insights into the usage of data-driven approaches in SE by conducting a systematic mapping based on the studies that we have found. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.|Data-driven Software Engineering; Data-drivenness; Software Engineering; Systematic Literature Review|Adversarial machine learning; Data accuracy; Data consistency; % reductions; Data driven; Data driven decision; Data-driven approach; Data-driven software engineering; Data-drivenness; Decisions makings; Emerging technologies; Software engineering process; Systematic literature review; Software testing|Conference paper|Final||Scopus|2-s2.0-85204536678
scopus|Kalouptsoglou I.; Siavvas M.; Ampatzoglou A.; Kehagias D.; Chatzigeorgiou A.|Kalouptsoglou, Ilias (57219327969); Siavvas, Miltiadis (57194500913); Ampatzoglou, Apostolos (16027681600); Kehagias, Dionysios (7003972544); Chatzigeorgiou, Alexander (6701702023)|57219327969; 57194500913; 16027681600; 7003972544; 6701702023|Vulnerability Classification on Source Code Using Text Mining and Deep Learning Techniques|2024|Proceedings - 2024 IEEE 24th International Conference on Software Quality, Reliability and Security Companion, QRS-C 2024||||47|56|9|1|10.1109/QRS-C63300.2024.00017|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209784889&doi=10.1109%2fQRS-C63300.2024.00017&partnerID=40&md5=ab8cfc0f3a46cc9b0e599abae84d2e34|Nowadays, security testing is an integral part of the testing activities during the software development life-cycle. Over the years, various techniques have been proposed to identify security issues in the source code, especially vulnerabilities, which can be exploited and cause severe damages. Recently, Machine Learning (ML) techniques capable of predicting vulnerable software components and indicating high-risk areas have appeared, among others, accelerating the effort demanding and time consuming process of vulnerability localization. For effective subsequent vulnerability elimination, there is a need for automating the process of labeling detected vulnerabilities in vulnerability categories i.e., identifying the type of the vulnerability. Several techniques have been proposed over the years for automating the labeling process of vulnerabilities. However, the vast majority of the proposed methods attempt to identify the type of vulnerabilities based on their textual description that is provided by experts, such as the description provided by the vulnerability report in the National Vulnerability Database, and not on their actual source code, hindering their full automation and the vulnerability categorization from the software testing phase. This work examines the vulnerability classification directly from the source code during the vulnerability detection step. Moreover, this way, a vulnerability detection method will be able to provide complete information and interpretation of its findings. Leveraging the advances in the field of Artificial Intelligence and Natural Language Processing, we construct and compare several multi-class classification models for categorizing vulnerable code snippets. The results highlight the importance of the context-aware embeddings of the pre-trained Transformer-based models, as well as the significance of transfer learning from a programming language-related domain. © 2024 IEEE.|contextual word embedding; large language models; natural language processing; security testing; transfer learning; vulnerability classification|Adversarial machine learning; Contrastive Learning; Embeddings; Natural language processing systems; Transfer learning; Contextual word embedding; Contextual words; Embeddings; Language model; Language processing; Large language model; Natural language processing; Natural languages; Security testing; Transfer learning; Vulnerability classifications; Deep learning|Conference paper|Final|All Open Access; Green Open Access|Scopus|2-s2.0-85209784889
scopus|Nikravesh N.; Keyvanpour M.R.|Nikravesh, Nazgol (58001487100); Keyvanpour, Mohammad Reza (24476189600)|58001487100; 24476189600|Parameter tuning for software fault prediction with different variants of differential evolution|2024|Expert Systems with Applications|237||121251||||10|10.1016/j.eswa.2023.121251|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172696643&doi=10.1016%2fj.eswa.2023.121251&partnerID=40&md5=fc6c7dbc80fcfc906a315e3c25a69201|The cost of software testing could be reduced if faulty entities were identified prior to the testing phase, which is possible with software fault prediction (SFP). In most SFP models, machine learning (ML) methods are used, and one aspect of improving prediction accuracy with these methods is tuning their control parameters. However, parameter tuning has not been addressed properly in the field of software analytics, and the conventional methods (such as basic Differential Evolution, Random Search, and Grid Search) are either not up-to-date, or suffer from shortcomings, such as the inability to benefit from prior experience, or are overly expensive. This study aims to examine and propose parameter tuners, called DEPTs, based on different variants of Differential Evolution for SFP with the Swift-Finalize strategy (to reduce runtime), which in addition to being up-to-date, have overcome many of the challenges associated with common methods. An experimental framework was developed to compare DEPTs with three widely used parameter tuners, applied to four common data miners, on 10 open-source projects, and to evaluate the performance of DEPTs, we used eight performance measures. According to our results, the three tuners out of five DEPTs improved prediction accuracy in more than 70% of tuned cases, and occasionally, they exceeded benchmark methods by over 10% in case of G-measure. The DEPTs took reasonable amounts of time to tune parameters for SFP as well. © 2023 Elsevier Ltd|Differential evolution; Grid search; Machine learning; Parameter tuning; Random search; Software fault prediction|Data mining; Evolutionary algorithms; Forecasting; Open source software; Optimization; Software testing; Tuners; Differential Evolution; Grid search; Machine-learning; Parameter tuner; Parameters tuning; Prediction accuracy; Random searches; Software fault prediction; Software testings; Testing phase; Machine learning|Article|Final||Scopus|2-s2.0-85172696643
scopus||||Proceedings - 2024 IEEE/ACM International Workshop on Software-Intensive Business, IWSiB 2024|2024|Proceedings - 2024 IEEE/ACM International Workshop on Software-Intensive Business, IWSiB 2024||||||92|0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203841077&partnerID=40&md5=bbee230ed884797ebc1dfd248eca5994|The proceedings contain 11 papers. The topics discussed include: artificial intelligence in the public sector — an agenda for responsible innovation through learning; human ai collaboration in software engineering: lessons learned from a hands on workshop; towards stability, predictability, and quality of intelligent automation services: product journey from on-premise to as-a-service at ECIT Group; researchers’ concerns on artificial intelligence ethics: results from a scenario-based survey; how to get good at data: 5 steps; developing a taxonomy for agile scaling frameworks; unveiling customer needs: a comprehensive exploration of jobs to be done interviews; security practices in agile software development: a mapping study; modeling 6G software business ecosystem: a look ahead; topic modeling for software ecosystem orchestration; and bridging the gap: addressing software testing challenges in Namibian startups through a tailored training approach.|||Conference review|Final||Scopus|2-s2.0-85203841077
scopus|Thompson T.|Thompson, Tommy (57212425143)|57212425143|The Changing Landscape of AI for Game Development|2024|Game AI Uncovered: Volume One|1|||1|11|10|1|10.1201/9781003324102-1|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186699730&doi=10.1201%2f9781003324102-1&partnerID=40&md5=3335e14731ef60e065bce3f0822d7dd5|The world of artificial intelligence has changed drastically in the past 10 years, with the rise of deep learning bringing significant gains in a myriad of industrial and creative sectors. But what benefit can it provide for the video games industry? Game AI has been an established field for over 30 years, catering to the unique problems of the field, be it strategic opponents, non-player characters, gameplay pacing and procedural content generation. This chapter highlights the core areas that classical, symbolic AI continues to thrive within and how machine learning is providing new alternatives to these established practices. Plus, the new opportunities that are emerging courtesy of AI that are changing how games are being made, including player modelling, graphical upscaling, animation controllers, and automated testing. © 2024 selection and editorial matter, Paul Roberts; individual chapters, the contributors.||Deep learning; Human computer interaction; Interactive computer graphics; Software design; Core area; Creatives; Game AI; Game development; Gameplay; Machine-learning; Non-player character; Player modeling; Procedural content generations; Video game industry; Animation|Book chapter|Final||Scopus|2-s2.0-85186699730
scopus|Ahammad A.; El Bajta M.; Radgui M.|Ahammad, Abdellatif (58787752000); El Bajta, Manal (57219228044); Radgui, Maryam (55611397000)|58787752000; 57219228044; 55611397000|Automated Software Testing Using Machine Learning: A Systematic Mapping Study|2024|10th Edition of the International Conference on Optimization and Applications, ICOA 2024 - Proceedings|||||||0|10.1109/ICOA62581.2024.10754031|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212713603&doi=10.1109%2fICOA62581.2024.10754031&partnerID=40&md5=0e7a1a0415dd15b19e9caecccb9744d3|In today's digital world, software quality assurance is a crucial part of the Software Development Life Cycle (SDLC), and automated testing is essential to this effort. This study investigates how machine learning (ML) can augment automated testing by analyzing research from 2006 onward to determine its possible uses, prevalent techniques, and related advantages and disadvantages. Our findings reveal a growing interest in leveraging ML for testing, particularly in tasks like test case generation and user interface validation. Common ML techniques such as symbolic AI, evolutionary algorithms, and deep learning are emerging as the primary methods. ML holds promise for accelerating testing processes, enhancing accuracy, and improving adaptability. However, challenges such as sourcing high-quality training data, understanding complex ML models, and integrating ML with existing tools persist. This study illuminates the transformative potential of ML in testing and provides valuable insights for guiding future research in this dynamic field. © 2024 IEEE.|Artificial Intelligence; Automated testing; Machine learning; Software Development; Software Quality Assurance|Computer software selection and evaluation; Contrastive Learning; Federated learning; Software testing; Automated software testing; Automated testing; Digital world; Life cycle testing; Machine learning techniques; Machine-learning; Software development life-cycle; Software quality assurance; Systematic mapping studies; Test case generation; Adversarial machine learning|Conference paper|Final||Scopus|2-s2.0-85212713603
scopus|Arasteh B.; Golshan S.; Shami S.; Kiani F.|Arasteh, Bahman (39861139000); Golshan, Sahar (58982426200); Shami, Shiva (59101680800); Kiani, Farzad (36662461100)|39861139000; 58982426200; 59101680800; 36662461100|Sahand: A Software Fault-Prediction Method Using Autoencoder Neural Network and K-Means Algorithm|2024|Journal of Electronic Testing: Theory and Applications (JETTA)|40|2||229|243|14|3|10.1007/s10836-024-06116-8|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190088218&doi=10.1007%2fs10836-024-06116-8&partnerID=40&md5=c112e6570c539ac9a832c0505c26a40c|Software is playing a growing role in many safety-critical applications, and software systems dependability is a major concern. Predicting faulty modules of software before the testing phase is one method for enhancing software reliability. The ability to predict and identify the faulty modules of software can lower software testing costs. Machine learning algorithms can be used to solve software fault prediction problem. Identifying the faulty modules of software with the maximum accuracy, precision, and performance are the main objectives of this study. A hybrid method combining the autoencoder and the K-means algorithm is utilized in this paper to develop a software fault predictor. The autoencoder algorithm, as a preprocessor, is used to select the effective attributes of the training dataset and consequently to reduce its size. Using an autoencoder with the K-means clustering method results in lower clustering error and time. Tests conducted on the standard NASA PROMIS data sets demonstrate that by removing the inefficient elements from the training data set, the proposed fault predictor has increased accuracy (96%) and precision (93%). The recall criteria provided by the proposed method is about 87%. Also, reducing the time necessary to create the software fault predictor is the other merit of this study. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.|Accuracy; Autoencoder; Clustering; K-means; Software Fault Prediction|Ability testing; Application programs; Forecasting; Learning algorithms; Machine learning; NASA; Safety engineering; Software reliability; Software testing; Statistical tests; Accuracy; Auto encoders; Clusterings; K-mean algorithms; K-means; Neural-networks; Prediction methods; Software fault; Software fault prediction; Training dataset; K-means clustering|Article|Final||Scopus|2-s2.0-85190088218
scopus|Angamuthu S.; Maheswari K.G.|Angamuthu, Suguna (57217988281); Maheswari, K.G. (36710207400)|57217988281; 36710207400|A Comprehensive Review of SDP Using Machine and Deep Learning Techniques in Software Testing|2024|2024 2nd International Conference on Computing and Data Analytics, ICCDA 2024 - Proceedings|||||||0|10.1109/ICCDA64887.2024.10867332|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85219157180&doi=10.1109%2fICCDA64887.2024.10867332&partnerID=40&md5=1517f9d70dc73a818167e55fe1b71e84|Software Defect Prediction (SDP) is essential to ensure the high quality and dependability of the Software Testing process in the Software Development Life Cycle (SDLC). Early identification of defects plays a significant role in minimizing the efforts, resources and time. Conventional manual testing techniques have become insufficient due to the increasing intricacy of software programs and the demand for automated techniques. To evaluate vast amounts of data and find defect patterns, Deep Learning (DL) and Machine Learning (ML) techniques have emerged as promising solutions for accurate SDP. A comprehensive analysis of recent developments in ML and DL techniques for SDP is provided in this review paper. The reviewed SDP methodologies, their advantages and limitations, along with their comparative performance, are discussed. The recent research trends, emerging methods, and promising paths for future research in this field are also identified in this domain. This paper aims to be a beneficial source for researchers to understand the current state of SDP and how to use ML, DL, and ensemble approaches to improve software quality assurance practices for effective software testing performance in SDLC.  © 2024 IEEE.|Deep Learning; Ensemble Methods; Machine Learning; Software Defect Prediction; Software Development Life Cycle; Software Testing|Federated learning; Software quality; Deep learning; Ensemble methods; High quality; Learning techniques; Machine-learning; Manual testing; Software defect prediction; Software development life-cycle; Software testings; Testing process; Contrastive Learning|Conference paper|Final||Scopus|2-s2.0-85219157180
scopus|Mehmood A.; Ilyas Q.M.; Ahmad M.; Shi Z.|Mehmood, Abid (55010514100); Ilyas, Qazi Mudassar (36458584600); Ahmad, Muneer (57221463579); Shi, Zhongliang (59398644100)|55010514100; 36458584600; 57221463579; 59398644100|Test Suite Optimization Using Machine Learning Techniques: A Comprehensive Study|2024|IEEE Access|12|||168645|168671|26|3|10.1109/ACCESS.2024.3490453|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208392173&doi=10.1109%2fACCESS.2024.3490453&partnerID=40&md5=7e48a81d28f2af9805f4f824e4cbd847|Software testing is an essential yet costly phase of the software development lifecycle. While machine learning-based test suite optimization techniques have shown promise in reducing testing costs and improving fault detection, a comprehensive evaluation of their effectiveness across different environments is still lacking. This paper reviews 43 studies published between 2018 and 2023, covering various test case selection, prioritization, and reduction techniques using machine learning. The findings reveal that conventional machine learning techniques, particularly supervised learning methods, have been widely adopted for test case prioritization and selection. Recent advancements, such as deep learning and hybrid models, show potential in improving fault detection rates and scalability, though challenges remain in adapting these techniques to large-scale and dynamic environments. Additionally, Generative AI and large language models (LLMs) are emerging as promising tools for automating aspects of test case generation and prioritization, offering new avenues for future research in enhancing test suite optimization. The study identifies recent trends, challenges, and opportunities for further research, with a focus on both conventional and emerging methods, including deep learning, hybrid approaches, and Generative AI models. By systematically analyzing these techniques, this work contributes to the understanding of how machine learning and Generative AI can enhance test suite optimization and highlights future directions for improving the scalability and real-world applicability of these methods. © 2013 IEEE.|evaluation metrics for test suite optimization; machine learning in software testing; Software quality; software testing; test case selection; test suite optimization (TSO)|Federated learning; Self-supervised learning; Software testing; Evaluation metric for test suite optimization; Evaluation metrics; Machine learning in software testing; Machine-learning; Optimisations; Software Quality; Software testings; Test case selection; Test suite optimization; Contrastive Learning|Article|Final|All Open Access; Gold Open Access|Scopus|2-s2.0-85208392173
scopus|Haldar S.; Capretz L.F.|Haldar, Susmita (58419715100); Capretz, Luiz Fernando (6602660867)|58419715100; 6602660867|Feature Importance in the Context of Traditional and Just-In-Time Software Defect Prediction Models|2024|Canadian Conference on Electrical and Computer Engineering||||818|822|4|1|10.1109/CCECE59415.2024.10667167|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204957059&doi=10.1109%2fCCECE59415.2024.10667167&partnerID=40&md5=6480ace1a3adb907a144494378f2af5a|Software defect prediction models can assist software testing initiatives by prioritizing testing error-prone modules. In recent years, in addition to the traditional defect prediction model approach of predicting defects from class, modules, etc., Just-In-Time defect prediction research, which focuses on the change history of software products is becoming prominent. For building these defect prediction models, it is important to understand which features are primary contributors to these classifiers. This study considered developing defect prediction models incorporating the traditional and the Just-In-Time approaches from the publicly available datasets including the Apache Camel project. A multi-layer Deep Learning algorithm was applied to these datasets in comparison with machine learning algorithms. The prediction models developed using the Deep Learning algorithm achieved an accuracy of 80% and 86%, with the area under receiving operator curve (AUC) scores of 66% and 78% for traditional and Just-In-Time defect prediction, respectively. Finally, the feature importance of these models was identified using a model-specific integrated gradient method and a model-agnostic Shapley Additive Explanation (SHAP) technique.  © 2024 IEEE.|Feature Importance; Just-In-Time Defect Prediction; Process Metrics; Software Defect Prediction; Source Code Metrics|Deep learning; Software testing; Defect prediction; Defect prediction models; Feature importance; Just-in-time; Just-in-time defect prediction; Process metrics; Software defect prediction; Software testings; Source code metrics; Testing errors; Prediction models|Conference paper|Final|All Open Access|Scopus|2-s2.0-85204957059
scopus|Elvira T.; Procko T.T.; Vonderhaar L.; Ochoa O.|Elvira, Timothy (57561184200); Procko, Tyler Thomas (57561957000); Vonderhaar, Lynn (59214075700); Ochoa, Omar (8982210700)|57561184200; 57561957000; 59214075700; 8982210700|Exploring Testing Methods for Large Language Models|2024|Proceedings - 2024 International Conference on Machine Learning and Applications, ICMLA 2024||||1152|1157|5|0|10.1109/ICMLA61862.2024.00177|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000843419&doi=10.1109%2fICMLA61862.2024.00177&partnerID=40&md5=b2d07da722e51efd84c8fe93035fff5c|Large Language Models (LLMs) are extensive aggregations of human language, designed to understand and generate sophisticated text. LLMs are becoming ubiquitous in a range of applications, from social media to code generation. With their immense size, LLMs face scalability challenges, making testing methods particularly difficult to implement effectively. Traditional machine learning and software testing methods, derived and adapted for LLMs, test these models to a point; however, they still struggle to accurately capture the full complexity of model behavior. This paper aims to capture the current efforts and techniques in testing LLMs, specifically focusing on stress testing, mutation testing, regression testing, metamorphic testing, and adversarial testing. This survey focuses on how traditional testing methods must be adapted to fit the needs of LLMs. Furthermore, while this area is fairly novel, there are still gaps in the literature that have been identified for future research.  © 2024 IEEE.|Large Language Model; Metamorphic testing; Mutation testing; Penetration testing; Regression testing; Stress testing; Testing|Computer simulation languages; Digital elevation model; Model checking; Human language; Language model; Large language model; Metamorphic testing; Mutation testing; Penetration testing; Regression testing; Social media; Stress Testing; Testing method; Software testing|Conference paper|Final||Scopus|2-s2.0-105000843419
scopus|Prasad S.; Mukhopadhyay N.; Khatal K.; Nabage T.; Borude S.|Prasad, Shreya (59046445000); Mukhopadhyay, Nirmalya (57486147500); Khatal, Komal (59046445100); Nabage, Tejas (59043658900); Borude, Sagar (59045904300)|59046445000; 57486147500; 59046445100; 59043658900; 59045904300|CampusXchange: Design and Implementation of an AI-empowered College Social Networking Platform|2024|2024 IEEE International Conference on Interdisciplinary Approaches in Technology and Management for Social Innovation, IATMSI 2024|||||||1|10.1109/IATMSI60426.2024.10502669|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192244730&doi=10.1109%2fIATMSI60426.2024.10502669&partnerID=40&md5=e7fbe2488fd0bacb5695024772b3ae9d|The paper aims to address the pressing need for an inclusive and efficient social networking platform tailored specifically for college students. The absence of a dedicated platform has led to challenges in connecting with peers, seniors, and alumni, hindering the exchange of knowledge, opportunities, and support within the college community. The lack of an integrated digital space also limits campus engagement, hinders access to valuable resources, and impedes the development of essential soft skills. Thus, the paper seeks to design and implement a user-friendly and secure social networking platform, which fosters meaningful interactions, that facilitates academic and professional growth, and promotes a vibrant and well-connected college experience. Based on the experimentation that we have conducted through automated testing tool exhibits that the performance of our proposed social networking platform is standard if we consider the benchmark values of the evaluation parameters.  © 2024 IEEE.|Campus engagement; College community; College experience; Digital space; Social networking platform|Benchmarking; Knowledge management; Social networking (online); Campus engagement; College community; College experience; College students; Design and implementations; Digital space; Pressung; Social networking platform; Social-networking; Soft skills; Students|Conference paper|Final||Scopus|2-s2.0-85192244730
scopus|Aliaga C.; Vidal C.; Sepulveda G.K.; Romero N.; Gonzalez F.; Barriga N.A.|Aliaga, Camila (57215528072); Vidal, Cristian (58628874800); Sepulveda, Gabriel K. (57215528236); Romero, Nicolas (58674457900); Gonzalez, Fernanda (58674441500); Barriga, Nicolas A. (36442423500)|57215528072; 58628874800; 57215528236; 58674457900; 58674441500; 36442423500|Level Building Sidekick: An AI-Assisted Level Editor Package for Unity|2023|Proceedings - AAAI Artificial Intelligence and Interactive Digital Entertainment Conference, AIIDE|19|1||392|399|7|1||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175400001&partnerID=40&md5=20a2adf8be2c7429380c4f734c20f559|Developing an original video game requires high investment levels, market research, cost-effective solutions, and a quick development process. Game developers usually reach for commercial off-the-shelf components often available in the engine’s marketplace to reduce costs. Mixed-initiative authoring tools allow us to combine the thoughtful work of human designers with the productivity gains of automated techniques. However, most commercial AI-assisted Procedural Content Generation tools focus on generating small independent components, and standalone research tools available for generating full game levels with state-of-the-art algorithms usually lack integration with commercial game engines. This article aims to fill this gap between industry and academia. The Level Building Sidekick (LBS) is a mixed-initiative procedural content generation tool built by our research lab in association with four small independent game studios. It has a modular software architecture that enables developers to extend it for their particular projects. The current version has two working modules for building game maps, an early version of a module for populating the level with NPCs or items, and the first stages of a quest editor module. An automated testing module is planned. LBS is distributed as an AI-Assisted videogame-level editor Unity package. Usability testing performed using the “Think-Aloud” methodology indicates LBS has the potential to improve game development processes convincingly. However, at this stage, the user interface and the AI recommendations could improve their intuitiveness. As a general comment, the tool is perceived as a substantial contribution to facilitating and shortening development times, compared to only using the base game engine. There is an untapped market for mixed-initiative tools that assist the game designer in creating complete game levels. We expect to fill that market for our partner development studios and provide the community with an open research and development platform in a standard game engine. Copyright © 2023, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.||Artificial intelligence; Commerce; Computer games; Cost effectiveness; Human computer interaction; Interactive computer graphics; Investments; Software design; User interfaces; Commercial off-the-shelf components; Content generation tools; Cost-effective solutions; Development process; Game Engine; Market researches; Mixed-initiative; Procedural content generations; Reduce costs; Video-games; Studios|Conference paper|Final||Scopus|2-s2.0-85175400001
scopus|Xu F.; Sun Z.|Xu, Fanjiang (8552693700); Sun, Zeyu (57211525326)|8552693700; 57211525326|Defect-Introducing Defect Prediction Testing|2024|Proceedings - 2024 IEEE 24th International Conference on Software Quality, Reliability and Security Companion, QRS-C 2024||||401|410|9|0|10.1109/QRS-C63300.2024.00057|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209810295&doi=10.1109%2fQRS-C63300.2024.00057&partnerID=40&md5=d2e6c43b6800515ea474c61dc6bdd204|Machine learning (ML) innovations have significantly advanced the field of defect prediction in software development, offering the potential for automated error detection across vast codebases. These advancements promise to elevate software quality assurance by improving reliability and security. However, despite their benefits, existing defect prediction models are not without limitations, often failing to identify vulnerabilities or inaccurately flagging non-defective code segments as problematic. To overcome these shortcomings, this study introduces DPTester, a novel approach that diverges from traditional label-preserving transformations, aiming to more accurately mimic the complexities of real-world software development. Unlike previous methods, DPTester intentionally injects defects into source code to transform its semantics fundamentally. This methodology tests a defect prediction model's ability to identify and anticipate defects amidst semantic alterations. DPTester employs a two-step framework, consisting of automated test input and oracle generation. The initial phase generates test inputs by modifying conditional statements to induce potential defects. The subsequent phase evaluates the defect prediction models' performance using these inputs. A failure by a model to detect DPTester-introduced defects is considered an issue. Our evaluation of DPTester on two prominent defect prediction models, CodeT5+ and CodeBERT, involved the generation of 222,112 test inputs. This process demonstrated a 99% success rate in creating valid test scenarios. However, it exposed significant weaknesses in both models: CodeT5+ and CodeBERT's accuracy plummeted to 43% and 30%, respectively, when assessed against DPTester's complex test scenarios. Moreover, our analysis uncovered 144,104 and 98,574 prediction inconsistencies in CodeBERT and CodeT5+, respectively, underscoring the urgent need for model improvements to adeptly handle sophisticated testing landscapes. Furthermore, DPTester's operational efficiency-evidenced by its rapid test input generation and issue detection capabilities, averaging 0.002 seconds per test input and 0.025 seconds per issue-positions it as a valuable addition to automated testing frameworks, highlighting the necessity for advancements in defect prediction models to navigate complex testing environments effectively. © 2024 IEEE.|Defect Prediction; Neural Network; Testing|Ability testing; Automatic test pattern generation; Computer software selection and evaluation; Software reliability; Software testing; Code segments; Defect prediction; Defect prediction models; Machine-learning; Neural-networks; Real-world; Software quality assurance; Source codes; Test inputs; Test scenario; Prediction models|Conference paper|Final||Scopus|2-s2.0-85209810295
scopus|Juneja S.; Bhathal G.S.; Sidhu B.K.|Juneja, Shallu (57216356132); Bhathal, Gurjit Singh (57207908791); Sidhu, Brahmaleen K. (57201698524)|57216356132; 57207908791; 57201698524|Current Trends and Literature Review of Machine Learning Models for Predicting Software Fault Based onTextual and Numeric Data|2023|AIP Conference Proceedings|2916|1|30007||||0|10.1063/5.0179256|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181560105&doi=10.1063%2f5.0179256&partnerID=40&md5=002ea1bfaeb13837a215ca4c9a46f522|Software fault prediction is critical for optimizing and simplifying the software testing process. A software fault is a bug, defect, or error that causes unexpected erroneous output. Software faults occur due to several reasons such as an error in programming, source code error or design error. Software defects decrease its quality by increasing cost and time of software testing for its development which leads to delay in the software’s delivery. Thus, software defects are undesirable and required to be resolved at priority. A software defect when encountered by a developer or tester is reported by open-source repositories. A defect tracking system maintains various defects that occur in the software. Many defect tracking systems exist in the study. Identifying and correcting a software flaw early throughout the development process is crucial for enhancing software quality. A software defect should be analyzed and predicted for better quality. Therefore, an efficient software defect prediction model is significant in comprehending and evaluating the software quality. So, in this paper, literature review of various issues tracking system along with machine learning techniques for predicting software faults are taken into the consideration along with future trends and scope. The future trends are very much significant for further research for predicting faults in software using machine learning techniques whichcan leadto optimize time and cost. © 2023 American Institute of Physics Inc.. All rights reserved.|Confusion Matrix; NASA datasets; Prediction Techniques; PROMISE; Software Fault||Conference paper|Final||Scopus|2-s2.0-85181560105
scopus||||CBSoft 2023 - Brazilian Conference on Software: Theory and Practice; Proceedings - 8th Brazilian Symposium on Systematic and Automated Software Testing, SAST 2023|2023|ACM International Conference Proceeding Series||||||130|0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175448538&partnerID=40&md5=f141026c9a9c95b6113ad17e198112d9|The proceedings contain 17 papers. The topics discussed include: test volume mitigation for mobile devices software development: an improvement approach considering shared requirements; an experimental study evaluating cost, adequacy, and effectiveness of Pynguin’s test sets; an initial investigation of ChatGPT unit test generation capability; an approach to regression testing selection based on code changes and smells; test data selection based on applying mutation testing to decision tree models; machine learning techniques for escaped defect analysis in software testing; automating android rotation vector testing in Google’s compatibility test suite using a robotic arm; implementing exploratory testing in an agile context: a study based on design science research; investigating developers’, contributions to test smell survivability: a study of open-source projects; and an industrial experience report on the challenges in training localization and internationalization testers.|||Conference review|Final||Scopus|2-s2.0-85175448538
scopus||||17th International Conference on the Quality of Information and Communications Technology, QUATIC 2024|2024|Communications in Computer and Information Science|2178 CCIS|||||460|0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204649289&partnerID=40&md5=009bdddac34bf0bd211193d3c625ec8b|The proceedings contain 34 papers. The special focus in this conference is on Quality of Information and Communications Technology. The topics include: RSUTT: Robust Search Using T-Way Testing; exploring Image Similarity-Based Splitting Techniques in Automotive Perception Systems; a Meta-model for Documenting Conversational Requirements in Chatbots; do Modern Systems Require New Quality Dimensions?; mutation Testing of Smart Contracts As a Service; Conceptualization of Multi-user Collaborative GUI-Testing for Web Applications; towards Generating Executable Metamorphic Relations Using Large Language Models; exploring Browser Automation: A Comparative Study of Selenium, Cypress, Puppeteer, and Playwright; improving Model-Based Testing Through Interactive Validation, Evaluation and Reconstruction of Test Cases; a Controlled Experiment on the Energy Efficiency of the Source Code Generated by Code Llama; electron vs. Web: A Comparative Analysis of Energy and Performance in Communication Apps; On the Energy Consumption of CPython; Self-adaptation for Sustainable Software and Its Application in Current Approaches - An SLR; a New Metric of Adaptivity for Self-adaptive Systems; classification of Crowd-Based Software Requirements via Unsupervised Learning; supporting Q&A Processes in Requirements Elicitation: Bad Smell Detection and Version Control; goal Model Extraction from User Stories Using Large Language Models; digitalization Impact Evaluation Model: A Case Study; Improving the Quality of Self-service in an IT Service Provider Organization: A Case Study; understanding How Power Distance Affects Agile Organizations; AI in GUI-Based Software Testing: Insights from a Survey with Industrial Practitioners; a Preliminary Interview Study on Developers’ Perceptions of Code Smell Detection in Industry; a Rapid Review on Graph-Based Learning Vulnerability Detection; towards the Use of Domain Knowledge to Enhance Transformer-Based Vulnerability Detection; Black-Box Reconstruction Attacks on LLMs: A Preliminary Study in Code Summarization; do Static Analysis Tools Improve Awareness and Attitude Toward Secure Software Development?; a User-Centric Privacy Control Framework for Decentralized IoT Platforms; towards Cyber-Physical-Ethical Systems.|||Conference review|Final||Scopus|2-s2.0-85204649289
scopus|Zhang Y.; Shen X.; Ding J.; Wu L.; Tang L.|Zhang, Yaming (57955920500); Shen, Xiaomei (57222117462); Ding, Jianyang (57222132512); Wu, Lijin (55978341400); Tang, Longli (57196392651)|57955920500; 57222117462; 57222132512; 55978341400; 57196392651|Research on Intelligent Algorithm Evaluation Technology of AI Software|2024|2024 IEEE 3rd International Conference on Electrical Engineering, Big Data and Algorithms, EEBDA 2024||||354|358|4|0|10.1109/EEBDA60612.2024.10485944|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191157395&doi=10.1109%2fEEBDA60612.2024.10485944&partnerID=40&md5=9b692ccb4ce411e969833d794c3abf76|AI software is regarded as the key to the formation of new domain and new quality combat capabilities in the future. In response to the characteristics of randomness, autonomy, and learning of AI software, traditional testing methods lack comprehensive coverage of non-functional requirements, test data is difficult to obtain and annotate, and evaluation indicators are not comprehensive. This paper focuses on the research of intelligent algorithm evaluation technology, proposing a multi-perspective and multi-attribute evaluation method for intelligent algorithms from four aspects: accuracy evaluation, efficiency evaluation, data robustness evaluation and algorithm coverage evaluation. This can effectively support future AI software evaluation work and improve the AI software testing technology system.  © 2024 IEEE.|Algorithm accuracy; Algorithm coverage; Algorithm efficiency; Algorithm robustness; Intelligent algorithm|Efficiency; Algorithm accuracies; Algorithm coverage; Algorithm efficiency; Algorithm evaluation; Algorithm robustness; Combat capability; Intelligent Algorithms; Non-functional requirements; Test data; Testing method; Software testing|Conference paper|Final||Scopus|2-s2.0-85191157395
scopus|Abo-eleneen A.; Palliyali A.; Catal C.|Abo-eleneen, Amr (57475587400); Palliyali, Ahammed (57475313800); Catal, Cagatay (22633325800)|57475587400; 57475313800; 22633325800|The role of Reinforcement Learning in software testing|2023|Information and Software Technology|164||107325||||10|10.1016/j.infsof.2023.107325|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170561513&doi=10.1016%2fj.infsof.2023.107325&partnerID=40&md5=c0f8845f647b401f10d11febf9519de0|Context: Software testing is applied to validate the behavior of the software system and identify flaws and bugs. Different machine learning technique types such as supervised and unsupervised learning were utilized in software testing. However, for some complex software testing scenarios, neither supervised nor unsupervised machine learning techniques were adequate. As such, researchers applied Reinforcement Learning (RL) techniques in some cases. However, a systematic overview of the state-of-the-art on the role of reinforcement learning in software testing is lacking. Objective: The objective of this study is to determine how and to what extent RL was used in software testing. Methods: In this study, a Systematic Literature Review (SLR) was conducted on the use of RL in software testing, and 40 primary studies were investigated. Results: This study highlights different software testing types to which RL has been applied, commonly used RL algorithms and architecture for learning, challenges faced, advantages and disadvantages of using RL, and the performance comparison of RL-based models against other techniques. Conclusions: RL has been widely used in software testing but has almost narrowed to two applications. There is a shortage of papers using advanced RL techniques in addition to multi-agent RL. Several challenges were presented in this study. © 2023 The Author(s)|Artificial intelligence; Machine learning; Reinforcement Learning; Software testing|Application programs; Learning algorithms; Multi agent systems; Program debugging; Software testing; Complex software; Machine learning techniques; Machine-learning; Reinforcement learning techniques; Reinforcement learnings; Software testings; Software-systems; State of the art; Supervised and unsupervised learning; Unsupervised machine learning; Reinforcement learning|Review|Final|All Open Access; Green Open Access; Hybrid Gold Open Access|Scopus|2-s2.0-85170561513
scopus|Çetiner G.; Bağlum C.; Yayan U.; Yazıcı A.|Çetiner, Gökhan (59388798200); Bağlum, Cem (58503905300); Yayan, Uğur (46061619200); Yazıcı, Ahmet (15836109300)|59388798200; 58503905300; 46061619200; 15836109300|White Box Testing Module for Evaluation of Transformers-Based DNNs|2024|2024 Innovations in Intelligent Systems and Applications Conference, ASYU 2024|||||||0|10.1109/ASYU62119.2024.10757012|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213315332&doi=10.1109%2fASYU62119.2024.10757012&partnerID=40&md5=b524c2ec43308a8cd42e644043baffe0|Artificial intelligence is actively becoming widespread in every field. The complex structure of deep neural network models, especially those used in real-world applications, may contain faults that lead to unexpected model behavior, even well-trained AI models. To detect these types of faults and model behaviors, it is necessary to perform a white box test of the model's reliability and adequacy by mutating its layers, activation functions, and similar model structures and parameters. White box testing is a method that tests the logical flow of software to detect possible faults and deficiencies in the code. The proposed module performs model-based testing using this testing technique. The module was developed as an extension of the traditional testing tool IM-FIT. It was inspired by IM-FIT's advanced fault detection capacity in traditional software testing, autonomous or customized testing options, and detailed report generation capabilities. The module carries out an advanced scanning and mutation process using its own unique fault library for deep neural networks. The module successfully performed the test by autonomously generating mutants and classifying these mutants. Tests were performed on a Transformer model using the TensorFlow library during the testing process. As a result of the tests performed with 5, 10, and 20 epoch values, a total of 606 mutants were produced. While 414 of these mutants were classified as killed, 192 were classified as survived. This study presents it to the literature as an effective mutation testing tool focusing on deep neural networks. © 2024 IEEE.|Deep Neural Networks; Machine Learning; Mutation Testing; Transformers|Black-box testing; Deep neural networks; Electric transformer testing; Model checking; Model structures; Classifieds; Complexes structure; Machine-learning; Modeling behaviour; Mutation testing; Neural-networks; Testing modules; Testing tools; Transformer; White-box testing; Distribution transformers|Conference paper|Final||Scopus|2-s2.0-85213315332
scopus|Liu P.; Luo R.; Jiang C.; Gao T.; Li Y.|Liu, Pan (57195976524); Luo, Ruyi (59542487500); Jiang, Chengwu (59542543100); Gao, Tong (59542650600); Li, Yihao (55367133500)|57195976524; 59542487500; 59542543100; 59542650600; 55367133500|AI-Assisted Bug Detection in Open-Source Software|2024|Proceedings - 2024 11th International Conference on Dependable Systems and Their Applications, DSA 2024||||428|429|1|0|10.1109/DSA63982.2024.00065|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216930126&doi=10.1109%2fDSA63982.2024.00065&partnerID=40&md5=edbcce3d40cb68b2870dbd82d7708a30|With the rapid development of internet technology, open-source software mirror sites have become indispensable tools for developers and tech enthusiasts, serving as crucial platforms for resource acquisition. We selected and tested two open-source applications by downloading them from the Tsinghua University Open Source Software Mirror Site and the Nanjing University Open Source Software Mirror Site. By implementing black-box testing strategies, we identified several bugs and design flaws in the software. Furthermore, we utilized large language models such as ChatGPT-3.5, Gemini, Kimi, Llama, ERNIE Bot, and Tongyi Qianwen to analyze the potential causes of these issues, exploring new approaches to AI-assisted software quality assurance. Through comparative analysis of feedback from multiple interactions with these large language models, we systematically evaluated their effectiveness in the field of software testing. This study provides empirical evidence for optimizing model applications and enhancing testing efficiency.  © 2024 IEEE.|AI-assisted testing; Large language models; open-source software; software bug analysis|Application programs; Bot (Internet); Computer software selection and evaluation; Mirrors; Model checking; Open source software; Software quality; AI-assisted testing; Bug detection; Indispensable tools; Internet technology; Language model; Large language model; Open-source softwares; Resource acquisition; Software bug; Software bug analyze; Black-box testing|Conference paper|Final||Scopus|2-s2.0-85216930126
scopus|Do V.-N.; Nguyen Q.-V.; Nguyen T.-B.|Do, Van-Nho (57209143117); Nguyen, Quang-Vu (56878280700); Nguyen, Thanh-Binh (59662896000)|57209143117; 56878280700; 59662896000|Predicting higher order mutation score based on machine learning|2024|Journal of Information and Telecommunication|8|1||57|70|13|1|10.1080/24751839.2023.2252186|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169166385&doi=10.1080%2f24751839.2023.2252186&partnerID=40&md5=75778ce040334de41c088f5d0dd9b6f0|In software testing, the quality of the test suite plays a very important role for not only the effectiveness of the testing but also the quality assurance of software. Mutation testing is considered as the usable, automatic and very effective technique in detecting mistakes of the set of test cases such as missing test cases, redundant test cases··· However, when using the mutation testing technique in practice, the generation of a large number of mutants has led to very high computational costs. This raises the question of whether we can reliably and accurately predict this mutation score without running mutants or not. If we can do this, it will save a lot of time and effort but still ensure the effectiveness of mutation testing. In this paper, we propose the approach using machine learning to perform mutation score cross-prediction for software which are new and completely different from the software used to generate test data (mutants) in model training and testing. The experimental results have shown that our proposed approach has achieved the positive results and is highly feasible. Thus, we believe that the approach can be applied to significantly reduce the cost of mutation testing. © 2023 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.|higher order mutation testing; machine learning; mutation score prediction; mutation testing; Software testing|Forecasting; Machine learning; Quality assurance; High order mutation testing; High-order; Higher-order; Machine-learning; Mutation score; Mutation score prediction; Mutation testing; Software testings; Test case; Software testing|Article|Final|All Open Access; Gold Open Access|Scopus|2-s2.0-85169166385
scopus|Chen Z.; Liu Q.; Dai S.; Yang Q.|Chen, Zhouning (59834528500); Liu, Qiaoyun (59832850900); Dai, Shengxin (56608572200); Yang, Qiuhui (37025901800)|59834528500; 59832850900; 56608572200; 37025901800|A DNN Fuzz Testing Method Based on Gradient-Weighted Class Activation Map|2024|Proceedings - Asia-Pacific Software Engineering Conference, APSEC||||1|10|9|0|10.1109/APSEC65559.2024.00011|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105004740219&doi=10.1109%2fAPSEC65559.2024.00011&partnerID=40&md5=cafe2b88baa2b5a45a4b9c54587bce62|Recently, deep learning systems have been widely utilized in various fields, prompting increased attention to their security. Fuzz testing is a crucial automated testing method; however, traditional approaches are not directly applicable to the testing of deep neural networks (DNNs). In light of this challenge, this study proposes a DNN fuzz testing method based on gradient weighted class activation graphs. By integrating model visualization interpretation technology and Grad-CAM technology, only significant areas are disrupted to rapidly generate test cases capable of inducing DNN errors. Additionally, high-quality initial seeds are selected based on the heat map to assess the degree of image feature distinctiveness. Adversarial perturbations are then exclusively applied to areas with high heat values in order to enhance the authenticity of the generated images. Experimental results demonstrate that this approach effectively enhances model robustness and accuracy, produces high-quality test cases, and significantly contributes to model repair efforts.  © 2024 IEEE.|Fuzz testing; Gradient-weighted class activation map; Interpretability; Test case generation|Automatic test pattern generation; Flow visualization; Photointerpretation; Activation maps; Automated testing; Fuzz Testing; Gradient-weighted class activation map; Interpretability; Neural-networks; Test case; Test case generation; Testing method; Traditional approachs; Deep neural networks|Conference paper|Final||Scopus|2-s2.0-105004740219
scopus|Yuan M.; Fan Y.; Pan Y.; Chao Y.; Ji G.; Zhong W.|Yuan, Minghao (59666281800); Fan, Yong (57198562777); Pan, Ya (55473441700); Chao, Yang (59707382600); Ji, Gangcheng (59708083200); Zhong, Wenfeng (59708789500)|59666281800; 57198562777; 55473441700; 59707382600; 59708083200; 59708789500|AT2D: An Automated Testing Framework for Deepfake Detection Models|2024|Proceedings - 2024 17th International Congress on Image and Signal Processing, BioMedical Engineering and Informatics, CISP-BMEI 2024|||||||0|10.1109/CISP-BMEI64163.2024.10906287|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000844476&doi=10.1109%2fCISP-BMEI64163.2024.10906287&partnerID=40&md5=52e7279a9f02c763e6535bd4c41bd9d0|Deepfake videos are rapidly spreading across the internet, posing significant threats to public interests. To counter this issue, researchers have developed various deep learning-based deepfake detection methods, which have demonstrated excellent performance. However, these detection methods are typically evaluated based on relevant benchmarks that often fail to fully reflect the complexity of real-world scenarios, particularly when it comes to systematically measuring the various video distortions caused by uncontrollable factors in everyday life. To address this problem, this paper proposes an automated testing framework that constructs three types of metamorphic relations-focusing on background color, lens distortion, and weather conditions-to simulate various video distortions and assess their impact on detection models. To validate the effectiveness of this framework, we conducted experiments using two popular deepfake detection methods. Statistical results indicate that under our testing framework, the detected error rates ranged from 21% to 74%. © 2024 IEEE.|automated testing framework; deepfake detection; metamorphic relations|Benchmarking; Error statistics; Automated testing; Automated testing framework; Deepfake detection; Detection methods; Detection models; Metamorphic relations; Performance; Public interest; Testing framework; Video distortions; Model checking|Conference paper|Final||Scopus|2-s2.0-105000844476
scopus|Nascimento L.P.G.; Prudêncio R.B.C.; Mota A.C.; Filho A.D.A.P.; Cruz P.H.A.; Oliveira D.C.C.A.D.; Moreira P.R.S.|Nascimento, Lidia Perside Gomes (58674393900); Prudêncio, Ricardo Bastos Cavalcante (6602721735); Mota, Alexandre Cabral (8886017800); Filho, Audir De Araujo Paiva (58674375400); Cruz, Pedro Henrique Alves (58674394000); Oliveira, Daniel Cardoso Coelho Alves De (58710922000); Moreira, Pedro Roncoli Sarmet (58674358100)|58674393900; 6602721735; 8886017800; 58674375400; 58674394000; 58710922000; 58674358100|Machine Learning Techniques for Escaped Defect Analysis in Software Testing|2023|ACM International Conference Proceeding Series||||47|53|6|1|10.1145/3624032.3624039|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175402409&doi=10.1145%2f3624032.3624039&partnerID=40&md5=43467241c6c0bae48223b8225b792fde|Software testing is crucial to ensure the quality of a software under development. Once a potential bug is identified, a Bug Report (BR) is opened with information to describe and reproduce the found issue. Usually in big companies, hundreds of BRs are opened weekly by different testing teams, which have to be inspected and fixed adequately. This paper is focused on the use of Machine Learning (ML) techniques to automate the Escaped Defect Analysis (EDA), which is an important (but expensive) task to improve the effectiveness of the testing teams. In our work, Escaped Defects (EDs) are bugs or issues that should have been opened by a specific team, but which was accidentally found by another team. The occurrence of EDs is risky, as it is usually related to failures in the testing activities. EDA is usually performed manually by software engineers, who read each BR's textual content to judge whether it is an ED or not. This is challenging and time-consuming. In our solution, the BR's content is preprocessed by textual operations and then a feature representation is adopted by a ML classifier to return the probability of EDA labels. Experiments were performed in a dataset of 3767 BRs provided by the Motorola Mobility Comércio de Produtos Eletrônicos Ltda. Different ML algorithms were adopted to build classifiers, obtaining high AUC values (usually higher than 0.8), in a cross-validation experiment. This result indicates a good trade-off between the number of EDs correctly identified and the number of BRs that have to be actually inspected in the EDA process. This paper presents a ML based approach to classify escaped defects described in bug reports. EDs are bugs missed by the QA team in charge and happened to be uncovered by a different team. To automate the identification of EDs (a costly and error-prone task), a dataset of a partner company is leveraged, text processing operators are adopted for feature engineering and 6 classical ML algorithms are applied. The results show satisfactory accuracy and AUC and the experiments indicate a good trade-off between the number of EDs correctly identified and the number of BRs that have to be inspected in the EDA.  © 2023 ACM.|Bug Reports; Escaped Defect Analysis; Machine Learning|Cost engineering; Economic and social effects; Inspection; Machine learning; Software testing; Text processing; Bug reports; Defect analysis; Escaped defect analyse; Machine learning algorithms; Machine learning techniques; Machine-learning; Software testings; Testing teams; Textual content; Trade off; Defects|Conference paper|Final||Scopus|2-s2.0-85175402409
scopus|Das S.|Das, Suddhasvatta (57314666900)|57314666900|Agile Regression Testing|2024|Proceedings - 2024 IEEE Conference on Software Testing, Verification and Validation, ICST 2024||||457|459|2|0|10.1109/ICST60714.2024.00054|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203822957&doi=10.1109%2fICST60714.2024.00054&partnerID=40&md5=848b3ce4bb1eb5841bfb62e77f410d38|Agile software development emphasizes rapid delivery of incremental features, raising concerns about software testing quality before release. Regression testing ensures new code modifications do not cause defects in already delivered features. The challenge is ensuring new code modifications do not break existing code after stopping the delivery pipeline. The research community is adapting existing regression test selection and prioritization algorithms to account for agile-specific process attributes such as time and value. The research aims to formally describe how regression testing is incorporated within the context of Agile Software Development. Additionally, the research aims to develop Regression Test Selection and Prioritization algorithms using Machine Learning techniques tailored to the characteristics of agile software development. The goal is to revolutionize the current approach to Regression Testing in Agile Software Development and deliver high-quality software within stringent timeframes.  © 2024 IEEE.|agile; machine learning; regression testing|Software design; Software testing; Agile; Agile software development; Code modifications; Machine-learning; Regression test selection; Regression testing; Research communities; Selection and prioritisation; Software testings; Test prioritization; Software quality|Conference paper|Final||Scopus|2-s2.0-85203822957
scopus|Labidi T.; Sakhrawi Z.|Labidi, Taher (56487826900); Sakhrawi, Zaineb (57211166983)|56487826900; 57211166983|On the value of parameter tuning in stacking ensemble model for software regression test effort estimation|2023|Journal of Supercomputing|79|15||17123|17145|22|10|10.1007/s11227-023-05334-9|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85158111910&doi=10.1007%2fs11227-023-05334-9&partnerID=40&md5=2363c4ed787162ad07bfe67fa4e1c628|A type of software testing, regression testing is often costly and labour-intensive. As such, multiple corporations have intensified efforts to estimate the amount of effort required. However, frequent alterations in software projects impact the precision of software regression test effort estimation (SRTEE), which increases the difficulty of managing software projects. Therefore, machine learning (ML) has increasingly been used to develop more accurate SRTEEs. The estimation process of a software project comprises inputs, the model, and outputs. This present study examines the quality of estimation inputs and the model required to deliver accurate estimation outputs. An SRTEE that uses the stacking ensemble model (StackSRTEE) was developed to increase the precision of SRTEE. It consisted of the three most common ML methods, namely neural networks, support vector regression, and decision tree regression. The grid search (GS) technique was then used to tune the hyperparameters of the StackSRTEE before it was trained and tested using a dataset from the International Software Benchmarking Standards Group (ISBSG) repository. The size of the functional change; specifically, enhancement; was used as the primary independent variable to improve the inputs of the StackSRTEE model. With the appropriate features; such as the functional change size of an enhancement; (1) the proposed StackSRTEE model yielded higher accuracy than the three individual ML methods on their own, (2) using GS to tune and set the individual ML methods increased the precision of the SRTEE outputs, and (3) the StackSRTEE-based GS tuning yielded estimations that were more precise. © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.|Grid search tuning technique; Machine learning techniques; Software regression test effort estimation; Software regression testing; Stacking ensemble model|Decision trees; Support vector regression; Effort Estimation; Ensemble models; Grid search; Grid search tuning technique; Machine learning techniques; Regression testing; Software regression test effort estimation; Software regression testing; Software regression tests; Stacking ensemble model; Stackings; Test efforts; Software testing|Article|Final||Scopus|2-s2.0-85158111910
scopus|Shukla S.K.; Jain P.; Rana S.; Pandey P.; Gupta V.K.; Mohana R.|Shukla, Surendra Kumar (57578527100); Jain, Paras (57659447500); Rana, Shweta (59423756000); Pandey, Priyank (57191287279); Gupta, Vishan Kumar (56973059300); Mohana, Rajini (59983876200)|57578527100; 57659447500; 59423756000; 57191287279; 56973059300; 59983876200|A Comprehensive Overview of Software Quality Assurance for Computer Gaming|2024|International Conference on Parallel, Distributed and Grid Computing, PDGC||2024||749|754|5|0|10.1109/PDGC64653.2024.10984084|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105010231745&doi=10.1109%2fPDGC64653.2024.10984084&partnerID=40&md5=f1dae104153f42ef6a6089e62184d5d0|In the video game industry, game testing, often known as quality assurance (QA) testing, is a software testing procedure used for video game quality control. Finding and documenting software flaws is the main purpose of game testing. One of the critical aspects in computer games development is software quality assurance as it is responsible for the final product, where all product requirements regarding functionality, performance, and perceived quality are achieved. As a review paper, its aims to give a more detailed overview of today's state of practice of SQA in the specific field of computer gaming, including testing strategies, tools, and techniques used to detect and eradicate faults, compatibility problems, and performance inefficiencies. To a lesser extent, it looks at the issues involved in game development and the methods used to solve these problems. Moreover, this paper also discusses various current prospects with respect to use of smart technologies for SQA for computer games, including artificial intelligence and its evolution of machine learning as having points to drastically alter the testing and quality assurance of games. © 2024 IEEE.|computer games; quality assurance; Software quality assurance; SQA practices|Artificial intelligence; Computer games; Computer software selection and evaluation; Interactive computer graphics; Learning systems; Quality control; Software design; Software quality; Software testing; Computer game development; Computer gaming; Game testing; Quality assurance testing; Software quality assurance; Software testings; SQA practice; Testing procedure; Video game industry; Video-games; Quality assurance|Conference paper|Final||Scopus|2-s2.0-105010231745
scopus|Wang C.; Xu J.; Yao L.; Chen J.|Wang, Cong (57190091581); Xu, Jingwen (59453746700); Yao, Liqiang (57734675500); Chen, Jiayi (57196111184)|57190091581; 59453746700; 57734675500; 57196111184|Research on Mirror Shape Testing Technology Based on Deep Learning|2024|Proceedings of SPIE - The International Society for Optical Engineering|13280||132800R||||0|10.1117/12.3047644|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210863965&doi=10.1117%2f12.3047644&partnerID=40&md5=44258d72c2c7b93ea69a5d954b7998c5|Research on reinforcement learning multi degree of freedom control system for shape testing of space camera mirror. Based on the optimization design of the perception control execution closed-loop intelligent testing system, reinforcement learning pose joint control training and testing are carried out based on the position information of the laser tracker and the misalignment information data of the laser interferometer. Complete automated testing experiments and validation. Improve the accuracy and efficiency of the testing process, reduce labor costs, and enhance the automation level of space camera installation and inspection. © 2024 SPIE.||Automatic testing; Closed loop control systems; Deep reinforcement learning; Laser mirrors; Closed-loop; Intelligent testing; Mirror shape; Multi degree-of-freedom; Optimization design; Reinforcement learnings; Shape testing; Space cameras; Technology-based; Testing technology; Degrees of freedom (mechanics)|Conference paper|Final||Scopus|2-s2.0-85210863965
scopus|Ji Y.; Mak S.; Lekivetz R.; Morgan J.|Ji, Yi (59793338700); Mak, Simon (57191475562); Lekivetz, Ryan (49561542200); Morgan, Joseph (57203198945)|59793338700; 57191475562; 49561542200; 57203198945|MaLT: Machine-Learning-Guided Test Case Design and Fault Localization of Complex Software Systems|2024|Proceedings - 2024 22nd ACM-IEEE International Symposium on Formal Methods and Models for System Design, MEMOCODE 2024||||58|62|4|0|10.1109/MEMOCODE63347.2024.00011|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211941910&doi=10.1109%2fMEMOCODE63347.2024.00011&partnerID=40&md5=2eb2bcaa49306d39531664cca8e987bb|Software testing is essential for the reliable and robust development of complex software systems. This is particularly critical for cyber-physical systems (CPS), which require rigorous testing prior to deployment. The complexity of these systems limits the use of formal verification methods. Furthermore, testing and fault localization can be very costly. To mitigate this cost, we outline in this work a holistic machine-learning-guided test case design and fault localization (MaLT) framework, which leverages recent probabilistic machine learning methods to accelerate the testing of complex software systems. MaLT consists of three steps: (i) the construction of a suite of test cases using a covering array for initial testing, (ii) the investigation of posterior root cause probabilities via a Bayesian fault localization procedure, then (iii) the use of such Bayesian analysis to guide selection of subsequent test cases via active learning. The proposed MaLT framework can thus facilitate efficient identification and subsequent diagnosis of software faults with limited test runs. This framework has potential for integration with an assertion-based test oracle approach, which may prove to be an efficient and cost-effective way of integrating light-weight formal methods with testing. © 2024 IEEE.|Active learning; Bayesian modeling; Combinatorial testing; Fault localization; Probabilistic machine learning|Computer software selection and evaluation; Contrastive Learning; Formal verification; Integration testing; Markov processes; Model checking; Active Learning; Bayesian modelling; Combinatorial testing; Complex software systems; Fault localization; Machine-learning; Probabilistic machine learning; Probabilistic machines; Test case; Test case designs; Active learning|Conference paper|Final||Scopus|2-s2.0-85211941910
scopus|Moubayed A.; Alhindawi N.; Alsakran J.; Injadat M.; Kanan M.|Moubayed, Abdallah (55332411800); Alhindawi, Nouh (55943468000); Alsakran, Jamal (35147671200); Injadat, MohammadNoor (57191710339); Kanan, Mohammad (57215079719)|55332411800; 55943468000; 35147671200; 57191710339; 57215079719|A Data-Driven Approach Towards Software Regression Testing Quality Optimization|2024|2024 25th International Arab Conference on Information Technology, ACIT 2024|||||||0|10.1109/ACIT62805.2024.10877022|https://www.scopus.com/inward/record.uri?eid=2-s2.0-86000004484&doi=10.1109%2fACIT62805.2024.10877022&partnerID=40&md5=d802ce5d2990343e8486bbde39ca5f3a|Software testing is very important in software development to ensure its quality and reliability. As software systems have become more complex, the number of test cases has increased, which presents the challenge of executing all the tests in a limited time frame. Various test case prioritization techniques have been introduced to solve this problem. These methods aim to identify and implement the most critical tests first. In this paper, we propose an implementation of a dynamic test case prioritization strategy to improve software quality by increasing code coverage with special attention to edge case handling. Edge case test prioritization is a technique that improves test efficiency by selecting extreme case scenarios that can reveal critical bugs or unexpected behavior early in development, improving overall software reliability and dependability. In order to prioritize test cases, this paper presents a regression-based method that makes use of machine learning algorithms. The approach leverages previous performance data to optimize regression testing efficiency by examining variables like test time and execution status. Performance evaluations, when compared against industry standards and cutting-edge techniques, show how effective these algorithms are at correctly prioritizing test cases and identifying faults. This study offers simplified yet reliable solutions for regression testing optimization by shedding light on the efficacy of regression algorithms, such as Random Forest and decision trees. © 2024 IEEE.|Machine Learning; Natural Language Processing; Software Testing Optimization|Random forests; Software reliability; Language processing; Machine-learning; Natural language processing; Natural languages; Optimisations; Regression testing; Software testing optimization; Software testings; Test case; Test case prioritization; Software testing|Conference paper|Final||Scopus|2-s2.0-86000004484
scopus|Yin H.; Mohammed H.; Boyapati S.|Yin, Hang (59660684500); Mohammed, Hamza (59661239200); Boyapati, Sai (59976165500)|59660684500; 59661239200; 59976165500|Leveraging Pre-Trained Large Language Models (LLMs) for On-Premises Comprehensive Automated Test Case Generation: An Empirical Study|2024|International Conference on Intelligent Informatics and BioMedical Sciences, ICIIBMS||2024||597|607|10|0|10.1109/ICIIBMS62405.2024.10792720|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85219213235&doi=10.1109%2fICIIBMS62405.2024.10792720&partnerID=40&md5=f5d77ac352a91eb15692d0a8fe74cb0c|The rapidly evolving field of Artificial Intelligence (AI)-assisted software testing has predominantly focused on automated test code generation, with limited research exploring the realm of automated test case generation from user stories requirements. This paper presents a comprehensive empirical study on harnessing pre-trained Large Language Models (LLMs) for generating concrete test cases from natural language requirements given in user stories. We investigate the efficacy of various prompting and alignment techniques, including prompt chaining, few-shot instructions, and agency-based approaches, to facilitate secure on-premises deployment. By integrating our learnings with an on-premises model setup, wherein we deploy a RoPE scaled 4-bit quantized LLaMA 3 70B Instruct model, optionally augmented with LoRA adapters trained on QA datasets, we demonstrate that this approach yields more accurate and consistent test cases despite video random-access memory (VRAM) constraints, thereby maintaining the security benefits of an on-premises deployment.  © 2024 IEEE.|AI-Assisted Testing; Artificial Intelligence (AI); Data Security and Privacy; Deep Learning; Intelligent Systems; Large Language Models (LLMs); Machine Learning (ML); Natural Language Processing (NLP); Neural Networks; On-Premises Deployment; Onpremises Deployment; Pre-trained LLMs; Prompting and Alignment Techniques; Quality Assurance (QA); Software Development and Testing; Software Testing; Test Case Generation|Automatic test pattern generation; Computer software selection and evaluation; Deep learning; Model checking; Alignment technique; Artificial intelligence; Artificial intelligence-assisted testing; Data security and privacy; Deep learning; Development and testing; Language model; Language processing; Large language model; Machine learning; Machine-learning; Natural language processing; Natural languages; Neural-networks; On-premise deployment; Onpremise deployment; Pre-trained large language model; Prompting and alignment technique; Quality assurance; Software testings; Test case generation; Software testing|Conference paper|Final||Scopus|2-s2.0-85219213235
scopus|Zen T.V.|Zen, Tushar Vardhan (58848266100)|58848266100|VLSI Implementation of an 8051 Microcontroller Using VHDL and Re-Corrective Measure Using AI|2024|Studies in Computational Intelligence|1117|||293|303|10|0|10.1007/978-3-031-43009-1_24|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183360338&doi=10.1007%2f978-3-031-43009-1_24&partnerID=40&md5=168c3219dbc1581480a6c95184120d46|The VLSI (Very Large-Scale Integration) implementation of microcontrollers plays a crucial role in the design and development of modern electronic systems. This paper presents a comprehensive study on the VLSI implementation of an 8051-microcontroller using VHDL (Very High-Speed Integrated Circuit Hardware Description Language). The 8051 microcontroller is a widely used and well-established architecture known for its versatility, reliability, and ease of integration into various applications. The proposed VLSI implementation involves translating the functionalities and behavior of the 8051 microcontrollers into VHDL code, which can be synthesized into hardware. The VHDL code captures the essential features of the 8051 architectures, including the CPU, instruction set, memory organization, I/O ports, and interrupt handling mechanism. By leveraging the flexibility and power of VHDL, the design can be customized and optimized to meet specific system requirements. The design flow for the VLSI implementation consists of several stages, including architectural design, register transfer level (RTL) design, functional verification, synthesis, place and route, and physical design. Each stage involves specific design considerations and methodologies to ensure the successful translation of the 8051 microcontrollers into a VLSI implementation. This research paper presents the implementation of an 8051-microcontroller using VHDL. VHDL is a hardware description language that is used to describe digital circuits and systems. The 8051 microcontroller is a widely used microcontroller in embedded systems. The implementation of 8051 microcontroller using VHDL allows for the creation of customized microcontrollers with specific functionalities. Further this paper also provides a concise scope of the VLSI implementation of an 8051-microcontroller using VHDL and the integration of AI for re-correction measures. This article further explored the use of AI techniques at different stages, including design optimization, bug detection and correction, performance prediction, intelligent place and route, automated testing and debugging, and adaptive optimization, to improve the microcontroller's performance, power consumption, and design quality. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.|8051 microcontrollers; Artificial Intelligence (AI); FPGA; iMPACT; ISE; VHDL; VLSI; Xilinx||Book chapter|Final||Scopus|2-s2.0-85183360338
scopus||||IMCIC 2024 - 15th International Multi-Conference on Complexity, Informatics and Cybernetics, Proceedings|2024|Proceedings IMCIC - International Multi-Conference on Complexity, Informatics and Cybernetics|2024-March|||||317|0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192526141&partnerID=40&md5=7f65a3570e4e5a136d00e2362d005677|The proceedings contain 50 papers. The topics discussed include: analyzing spatiotemporal congestion value on urban road networks based on taxi GPS data; a passive assessment of homecare need with a Rasch model; advancements in digital twin application in the metalforming industry: state of the art and challenges; mobile augmented reality application for digital storytelling in high school education; face authentication by constructing a 3D face image from 2D face images, and encoding a unique identification; benefits of effective root cause analysis in software testing; identifying the features of graduated students of the computer science degree of the national university of Asuncion; applying intelligent system to sandplay psychological status detection – transdisciplinary collaboration; and deep learning for predicting cerebral metabolism changes along the Alzheimer’s disease continuum.|||Conference review|Final||Scopus|2-s2.0-85192526141
scopus|Pang A.X.Q.; Lin J.J.; Ong C.H.; Chen Y.; Chong G.X.; Baharudin S.N.; Teo Y.S.; Oh K.S.L.|Pang, Ashton Xue Qun (59260144200); Lin, Jiaxing Jansen (59259688000); Ong, Chin Hee (59259798100); Chen, Yongquan (59259798200); Chong, Ga Xiang (59259459200); Baharudin, Siti Nuruljannah (59259578300); Teo, Yon Shin (57471311000); Oh, Kevin Seng Loong (59259459300)|59260144200; 59259688000; 59259798100; 59259798200; 59259459200; 59259578300; 57471311000; 59259459300|Deep Learning Based Layout Recognition Approach for HMI Software Validation|2024|Proceedings - 2024 IEEE Conference on Artificial Intelligence, CAI 2024||||429|437|8|0|10.1109/CAI59869.2024.00085|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201198727&doi=10.1109%2fCAI59869.2024.00085&partnerID=40&md5=d3372f3978939c16692b07f250fdc757|Human machine interface (HMI) software testing in the automotive industry is a laborious and time consuming process, as testers are required to compare every screen downloaded from the dashboard display cluster against the reference design specified in the requirements. The current industry standard allows for efficient validation of the content of display texts and graphics. However, validating layout information such as the relative positions, alignments, sizes and types of each visual asset on the screen remains a difficult task, as the differences between layouts are not homogeneous. At first glance, some user interfaces may appear to be rather similar but in fact fall under different layouts, due to slight variances in the region or activation conditions. In this work, we propose a two-stage deep learning based framework for efficient layout recognition, which can be applied in general HMI user interface validation tasks. First, we train an object detection model to produce bounding boxes around visual assets within the specified region of interest in the pre-processed input images, along with the object class label. Next, we match the extracted structural information of the test image against the ground truth reference layout designs via two different strategies: a self-supervised learning method (BYOL) and a custom IoU-based layout matching algorithm. While the IoU-based method slightly outperforms BYOL in terms of accuracy, BYOL boasts faster inference speed and can be generalized easily to unseen input images and layouts. Our approach is language agnostic and allows thorough validation of HMI screens in a holistic way. © 2024 IEEE.|Automotive HMI Software; Layout Validation; Self-supervised Learning; Software Testing|Automotive industry; Deep learning; Image segmentation; Learning systems; Object detection; User interfaces; Automotive human machine interface software; Automotives; Human Machine Interface; Input image; Interface software; Layout validation; Reference designs; Self-supervised learning; Software testings; Software validation; Software testing|Conference paper|Final||Scopus|2-s2.0-85201198727
scopus|Tsumoto S.; Kawana F.; Horie K.; Masaki M.; Nishida K.; Miyanishi K.; Seol J.; Tominaga M.; Amemiya T.; Hiei T.; Tani A.; Matsubara M.; Morishima A.; Kitagawa H.; Yanagisawa M.|Tsumoto, Saki (58758011700); Kawana, Fusae (15136117600); Horie, Kazumasa (57191756223); Masaki, Minori (57425943100); Nishida, Kei (59324082500); Miyanishi, Kazuya (57038412600); Seol, Jaehoon (57198452275); Tominaga, Morie (57220150996); Amemiya, Takashi (58757422300); Hiei, Tetsuro (58749025300); Tani, Akihiro (58750396000); Matsubara, Masaki (55608696000); Morishima, Atsuyuki (36829985300); Kitagawa, Hiroyuki (7402625746); Yanagisawa, Masashi (56040458200)|58758011700; 15136117600; 57191756223; 57425943100; 59324082500; 57038412600; 57198452275; 57220150996; 58757422300; 58749025300; 58750396000; 55608696000; 36829985300; 7402625746; 56040458200|Automated Generation of Narrative Sleep Reports Utilizing Portable Electroencephalogram Data Through ChatGPT|2024|Proceedings - 2024 IEEE 12th International Conference on Healthcare Informatics, ICHI 2024||||376|385|9|0|10.1109/ICHI61247.2024.00055|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203709650&doi=10.1109%2fICHI61247.2024.00055&partnerID=40&md5=73d114fba1c0db65807fbaeee65b8a93|Sleep is a very important activity, but many people do not know their own sleep conditions. A sleep test personalizes sleep quality assessment and detects potential sleep disorders by measuring biological signals. The rise in sleep-related issues has necessitated the development of automated testing methods. Machine learning plays a pivotal role in interpreting sleep data and determining sleep stages. However, the generation of detailed reports and tailored recommendations still demands expert intervention. Automating the report generation to provide personalized sleep insights is a crucial and desired step for the future of sleep healthcare. Recently emerged Generative AI, such as ChatGPT, has attracted considerable attention in recent years. It can generate new sentences and images from input data. In this study, we investigate the practicality and applicability of using ChatGPT to generate narrative sleep reports for sleep test. In our proposed method, GPT-4 receives the information about the sleep habits of the participants and the sleep assessment automatically summarized by the rule-based algorithm. In the evaluation, we used in-home sleep EEG data obtained from 100 subjects by S'UIMIN inc. The generated reports were evaluated by experienced technicians and physicians on a 5- point scale for medical correctness and appropriateness as informative reports. The results of the evaluation showed that 60 % of the reports were the acceptable or above range in both aspects. While more than half of the results were judged to be above the acceptable range, differences between the generative AI and humans were also identified. Whereas humans comment on semantically weighted important findings such as medication and subjective insomnia, ChatGPT tends to make broad, shallow and flat comments on the input data. These facts suggest that although practical report generation only using generative AI is at present not easy, generative AI is a promising tool for improving the efficiency of physicians and technicians work. © 2024 IEEE.|ChatGPT; clinical reports; medical reports; sleep|Electroencephalography; Electrotherapeutics; Input output programs; Personalized medicine; Automated generation; ChatGPT; Clinical report; Condition; Medical report; Quality assessment; Report generation; Sleep; Sleep quality; Sleep test; Sleep research|Conference paper|Final||Scopus|2-s2.0-85203709650
scopus|Zhao G.; Georgiou S.; Zou Y.; Hassan S.; Truong D.; Corbin T.|Zhao, Guoliang (57207733236); Georgiou, Stefanos (56988937100); Zou, Ying (8354376000); Hassan, Safwat (57189989013); Truong, Derek (57223360243); Corbin, Toby (57223370751)|57207733236; 56988937100; 8354376000; 57189989013; 57223360243; 57223370751|Enhancing Performance Bug Prediction Using Performance Code Metrics|2024|Proceedings - 2024 IEEE/ACM 21st International Conference on Mining Software Repositories, MSR 2024||||50|62|12|1|10.1145/3643991.3644920|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197437007&doi=10.1145%2f3643991.3644920&partnerID=40&md5=e1fb1f50465d3e35f160e340b576026e|Performance bugs are non-functional defects that can significantly reduce the performance of an application (e.g., software hanging or freezing) and lead to poor user experience. Prior studies found that each type of performance bugs follows a unique code-based performance anti-pattern and proposed different approaches to detect such anti-patterns by analyzing the source code of a program. However, each approach can only recognize one performance anti-pattern. Different approaches need to be applied separately to identify different performance anti-patterns. To predict a large variety of performance bug types using a unified approach, we propose an approach that predicts performance bugs by leveraging various historical data (e.g., source code and code change history). We collect performance bugs from 80 popular Java projects. Next, we propose performance code metrics to capture the code characteristics of performance bugs. We build performance bug predictors using machine learning models, such as Random Forest, eXtreme Gradient Boosting, and Linear Regressions. We observe that: (1) Random Forest and eXtreme Gradient Boosting are the best algorithms for predicting performance bugs at a file level with a median of 0.84 AUC, 0.21 PR-AUC, and 0.38 MCC; (2) The proposed performance code metrics have the most significant impact on the performance of our models compared to code and process metrics. In particular, the median AUC, PR-AUC, and MCC of the studied machine learning models drop by 7.7%, 25.4%, and 20.2% without using the proposed performance code metrics; and (3) Our approach can predict additional performance bugs that are not covered by the anti-patterns proposed in the prior studies.CCS CONCEPTS•Software and its engineering Software testing and debugging; Software testing and debugging  © 2024 ACM.|Performance anti-patterns; Performance bug prediction; Performance bugs; Performance code metrics|Adaptive boosting; Application programs; Machine learning; Program debugging; Random forests; Software testing; Anti-patterns; Bug predictions; Code metrics; Performance; Performance anti-pattern; Performance bug prediction; Performance bugs; Performance code; Performance code metric; Forecasting|Conference paper|Final||Scopus|2-s2.0-85197437007
scopus|Schütz M.; Plösch R.|Schütz, Martin (57190805248); Plösch, Reinhold (6506322162)|57190805248; 6506322162|A Practical Failure Prediction Model based on Code Smells and Software Development Metrics|2023|ACM International Conference Proceeding Series||||14|22|8|3|10.1145/3651640.3651644|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198756910&doi=10.1145%2f3651640.3651644&partnerID=40&md5=b2a7d612452236e97a101aa57828c813|Making errors during software development is unavoidable. Developers inevitably make errors that take additional time to fix later. Consequently, efforts for bug fixing compete with implementing new features. Typically, the later bugs are found, the higher the cost for remediation. To address this concern, software testing should start as early as possible in software development lifecycle. For this purpose, static analysis is proposed, but typically shows too many findings and hence do not support development teams appropriately. So, it would be a benefit to premature detect those findings in static analysis that will result in failures to reduce subsequent efforts notably. The purpose of the paper is to analyze failure data from issue tracking systems that are correlated to findings from static analysis. Thereupon an artificial intelligence-based approach is used to train practicable models for business environment that enables effective prediction of software faults. The results from static analysis show that predefined complexity measures encompassed the most defects. While there are commonalities in relevant defect findings in static analysis reports, meaningful prediction models cannot be expected based solely on this data. In addition to the findings of the static analysis, metrics like code changes in a time period or number of authors involved in code changes were considered for building the prediction models. Two of the developed prediction models have a high accuracy and excellent utility rate. These resulting prediction models are currently used at Raiffeisen Software GmbH for a long-term study on failure prediction based on code smells. © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.|change metrics and failure prediction; failure prediction; machine learning for failure prediction; static analysis; technical debt|Codes (symbols); Defects; Failure (mechanical); Forecasting; Life cycle; Machine learning; Odors; Software design; Software testing; Change metric and failure prediction; Code changes; Code smell; Failures prediction; Machine learning for failure prediction; Machine-learning; Prediction modelling; Technical debts; Static analysis|Conference paper|Final||Scopus|2-s2.0-85198756910
scopus|Cai Q.; Yin B.; Shi J.-A.|Cai, Qing (59285775700); Yin, Beibei (16242881200); Shi, Jing-Ao (59419024500)|59285775700; 16242881200; 59419024500|CGFuzz: A Dynamic Test Case Generation Method for DL Framework Based on Function Coverage|2024|Proceedings - 2024 IEEE 24th International Conference on Software Quality, Reliability and Security Companion, QRS-C 2024||||507|516|9|0|10.1109/QRS-C63300.2024.00070|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209819409&doi=10.1109%2fQRS-C63300.2024.00070&partnerID=40&md5=75868e295fd0783508a12592ae658414|Deep neural networks have gradually become the cornerstone technology to promote progress in various security fields, and deep learning frameworks are the basis for constructing neural networks. Even minor flaws in a deep learning framework as few as a few lines of code can lead to widespread failures in the model, posing a significant threat to the security of the system. Software testing is an effective means to mine the defects of deep learning framework. The defects originating from the underlying functions of the framework's source code can precipitate problems across all APIs that invoke these functions. This study directs its focus towards the examination of low-level function coverage and proposes an efficient API test case generation technique predicated on the guidance of the coverage. We define the number of low-level functions covered by the execution procedure as a test adequacy metric. At the same time, the method for tracing low-level functions correlated with APIs is proposed, so as to calculate the coverage metric. Based on the completely random generation of API test cases, the coverage is used to guide the seed weight update, so as to optimize the test case selection strategy. Besides, the fuzzy rule selection strategy will be adjusted to perform targeted fuzzy mutation on the selected test cases, leading to efficient test cases which cover more low-level functions. Experimental results underscore the efficacy of our method in generating test cases with enhanced coverage effects, thereby introducing novel methods and concepts for the quality assurance of deep learning frameworks. © 2024 IEEE.|API; coverage; deep learning framework; dynamic strategy; low-level function; test case generation|Deep neural networks; Fuzzy inference; Fuzzy rules; Z transforms; API; Coverage; Deep learning framework; Dynamic strategies; Function coverage; Learning frameworks; Low-level function; Neural-networks; Test case; Test case generation; Software testing|Conference paper|Final||Scopus|2-s2.0-85209819409
scopus|Guilherme V.; Vincenzi A.|Guilherme, Vitor (58674427900); Vincenzi, Auri (57205344487)|58674427900; 57205344487|An initial investigation of ChatGPT unit test generation capability|2023|ACM International Conference Proceeding Series||||15|24|9|28|10.1145/3624032.3624035|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175402712&doi=10.1145%2f3624032.3624035&partnerID=40&md5=0da49ce7768de4a4644f8660ecd2ff0d|Context: Software testing ensures software quality, but developers often disregard it. The use of automated testing generation is pursued to reduce the consequences of overlooked test cases in a software project. Problem: In the context of Java programs, several tools can completely automate generating unit test sets. Additionally, studies are conducted to offer evidence regarding the quality of the generated test sets. However, it is worth noting that these tools rely on machine learning and other AI algorithms rather than incorporating the latest advancements in Large Language Models (LLMs). Solution: This work aims to evaluate the quality of Java unit tests generated by an OpenAI LLM algorithm, using metrics like code coverage and mutation test score. Method: For this study, 33 programs used by other researchers in the field of automated test generation were selected. This approach was employed to establish a baseline for comparison purposes. For each program, 33 unit test sets were generated automatically, without human interference, by changing Open AI API parameters. After executing each test set, metrics such as code line coverage, mutation score, and success rate of test execution were collected to evaluate the efficiency and effectiveness of each set. Summary of Results: Our findings revealed that the OpenAI LLM test set demonstrated similar performance across all evaluated aspects compared to traditional automated Java test generation tools used in the previous research. These results are particularly remarkable considering the simplicity of the experiment and the fact that the generated test code did not undergo human analysis.  © 2023 ACM.|automated test generation; coverage testing; experimental software engineering; mutation testing; software testing; testing tools|Automation; Computer software selection and evaluation; Java programming language; Machine learning; Quality control; Automated test generations; Coverage testing; Experimental software engineering; Language model; Mutation testing; Software testings; Test sets; Testing tools; Unit test generations; Unit tests; Software testing|Conference paper|Final||Scopus|2-s2.0-85175402712
scopus|Takeda T.; Masuda S.|Takeda, Tomohiro (57209654762); Masuda, Satoshi (36803608600)|57209654762; 36803608600|Software Bug Prediction Model using Graph Neural Network|2024|Proceedings - 2024 IEEE International Conference on Software Testing, Verification and Validation Workshops, ICSTW 2024||||122|127|5|0|10.1109/ICSTW60967.2024.00035|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205945814&doi=10.1109%2fICSTW60967.2024.00035&partnerID=40&md5=864c5697d2648557a57b553ef19330f0|To ensure the quality of software source code, numerous software testing approaches have been studied. Software is now integral to numerous devices, enterprise services, and public services. Although the demand for software quality has increased, Software Science has yet to provide a definitive solution for bug prediction methodologies. In this study, we propose a novel bug prediction methodology for software testing using Graph Neural Network (GNN) techniques. We attempt to apply the machine learning technique of Graph Convolutional Neural Networks (GCN) to Control Flow Graphs (CFG) generated from the tri-address information of the test target source code. In the CFG, multiple graph centrality values are utilized as graph feature for bug prediction. Hence, our bug prediction model based on graph neural network (BP-GNN) exhibits a better result with an accuracy value of 82%. This result represents an 15% improvement compared to the outcomes of previous study using Akaike Information Criterion (AIC) with graph centrality annotation for same CFG data.  © 2024 IEEE.|Graph Analytics; Software testing; Static Testing; Test Metrics|Graph neural networks; Software quality; Bug predictions; Control-flow graphs; Graph centralities; Graph neural networks; Graph-analytic; Prediction methodology; Prediction modelling; Software testings; Static testing; Test metrics; Prediction models|Conference paper|Final||Scopus|2-s2.0-85205945814
scopus|Matsunaga S.; Yoshimura G.|Matsunaga, Saori (57221329433); Yoshimura, Genta (59715516700)|57221329433; 59715516700|Efficient and High-Quality Formal Verification for Decision Tree Ensembles|2024|IEEE International Conference on Data Mining Workshops, ICDMW||||51|58|7|0|10.1109/ICDMW65004.2024.00013|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001322672&doi=10.1109%2fICDMW65004.2024.00013&partnerID=40&md5=55e65ed8a446b0347afefab392022cae|Given that the inference of machine learning models is inductive and typically operates as a complex black box, applying conventional software testing methods proves challenging. However, formal testing methods are essential for ensuring the quality of machine learning software. This study proposes a formal verification framework specially designed for decision-tree-based ensemble models, which rigorously verifies whether a model satisfies the expected verification properties and summarizes the verification results. The proposed method exhaustively enumerates verification violations by efficiently searching the input space corresponding to the verification properties and summarizes the violation regions, allowing for the appropriate addressing of discovered violations. Experimental results on four datasets across three tasks confirm that the proposed method completes the verification more efficiently than existing methods, with one case demonstrating a reduction in verification time by approximately 1000 times. Additionally, by introducing a metric to quantify the quality of violation regions, we verified that the proposed method presents violation regions more accurately than existing approaches. Furthermore, we conducted an experiment to illustrate that the proposed method can identify unexpected hazardous behaviors in the model. © 2024 IEEE.|formal verification; plausibility of range; reliability; robustness; tree ensembles|Adversarial machine learning; Computer software selection and evaluation; Contrastive Learning; Decision trees; Federated learning; Formal verification; Machine learning; Software quality; Software reliability; Black boxes; Formal testing methods; High quality; Machine learning models; Plausibility of range; Robustness; Software testings; Testing method; Tree ensembles; Verification properties; Black-box testing|Conference paper|Final||Scopus|2-s2.0-105001322672
scopus|Xia X.; Jin Z.; Aiello M.; Zhang D.; Liang G.; Hu X.|Xia, Xin (59594305200); Jin, Zhi (8961795500); Aiello, Marco (8563998100); Zhang, Dongmei (55717568500); Liang, Guangtai (59437426300); Hu, Xing (57191413796)|59594305200; 8961795500; 8563998100; 55717568500; 59437426300; 57191413796|Software Service Engineering in the Era of Large Language Models|2024|Proceedings - 2024 IEEE International Conference on Software Services Engineering, SSE 2024||||XXIII|||1|10.1109/SSE62657.2024.00026|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205550746&doi=10.1109%2fSSE62657.2024.00026&partnerID=40&md5=a7390984dcd0431627c4d68f971cc0c4|Large Language Models (LLMs) such as GPT-4, trained on massive amounts of natural language and source code data, have exhibited remarkable proficiency in automating many aspects of software development and maintenance. As a result, these models have been extensively applied to various Software Service Engineering (SSE) tasks, including software requirement analysis, software coding, software testing, and Artificial Intelligence for IT Operations (AIOps). Despite their widespread adoption, numerous challenges persist in fully utilizing LLMs for SSE, such as the need for integrating domain-specific knowledge to generate project-level code or patches effectively. Furthermore, there remains a lack of clarity on how traditional SSE practices can adapt to support the full lifecycle of LLMs, from the initial training and fine-tuning with domain-specific data to the ongoing inference, application, and maintenance (i.e., LLMOps). Effective LLMOps require new methodologies and tools to manage the unique demands of LLMs, including data handling, model updates, performance monitoring, and scalability. These challenges underscore the need for innovative approaches to manage the integration of LLM capabilities within established SSE frameworks.  © 2024 IEEE.||Application programs; Computer aided software engineering; Computer software maintenance; EXAPT (programming language); Natural language processing systems; Requirements engineering; Software design; Analysis softwares; Engineering tasks; Language model; Natural languages; Natural sources; Services engineering; Software development and maintenances; Software requirements analysis; Software services; Source codes; Software testing|Conference paper|Final||Scopus|2-s2.0-85205550746
scopus|Ye G.; Hu T.; Tang Z.; Fan Z.; Tan S.H.; Zhang B.; Qian W.; Wang Z.|Ye, Guixin (57193613039); Hu, Tianmin (58778333400); Tang, Zhanyong (15822992800); Fan, Zhenye (58778459600); Tan, Shin Hwei (42162322300); Zhang, Bo (57876045200); Qian, Wenxiang (58778435400); Wang, Zheng (35111811300)|57193613039; 58778333400; 15822992800; 58778459600; 42162322300; 57876045200; 58778435400; 35111811300|A Generative and Mutational Approach for Synthesizing Bug-Exposing Test Cases to Guide Compiler Fuzzing|2023|ESEC/FSE 2023 - Proceedings of the 31st ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering||||1127|1139|12|5|10.1145/3611643.3616332|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180553593&doi=10.1145%2f3611643.3616332&partnerID=40&md5=e245d9ebf7fa27a7bf361dd6af62bf06|Random test case generation, or fuzzing, is a viable means for uncovering compiler bugs. Unfortunately, compiler fuzzing can be time-consuming and inefficient with purely randomly generated test cases due to the complexity of modern compilers. We present COMFUZZ, a focused compiler fuzzing framework. COMFUZZ aims to improve compiler fuzzing efficiency by focusing on testing components and language features that are likely to trigger compiler bugs. Our key insight is human developers tend to make common and repeat errors across compiler implementations; hence, we can leverage the previously reported buggy-exposing test cases of a programming language to test a new compiler implementation. To this end, COMFUZZ employs deep learning to learn a test program generator from open-source projects hosted on GitHub. With the machine-generated test programs in place, COMFUZZ then leverages a set of carefully designed mutation rules to improve the coverage and bug-exposing capabilities of the test cases. We evaluate COMFUZZ on 11 compilers for JS and Java programming languages. Within 260 hours of automated testing runs, we discovered 33 unique bugs across nine compilers, of which 29 have been confirmed and 22, including an API documentation defect, have already been fixed by the developers. We also compared COMFUZZ to eight prior fuzzers on four evaluation metrics. In a 24-hour comparative test, COMFUZZ uncovers at least 1.5× more bugs than the state-of-the-art baselines. © 2023 ACM.|Compiler; Deep learning; Fuzzing; Guided testing; Historical bug|Computer programming languages; Deep learning; Open source software; Program compilers; Compiler; Compiler implementation; Deep learning; Fuzzing; Guided testing; Historical bug; Random tests; Test case; Test case generation; Test projects; Software testing|Conference paper|Final|All Open Access; Green Open Access|Scopus|2-s2.0-85180553593
scopus|Gong Z.-H.; Chen Y.-Z.; Chen J.-J.; Hao D.|Gong, Zhi-Hao (59137546800); Chen, Yi-Zhou (59137704900); Chen, Jun-Jie (57145642900); Hao, Dan (23388889700)|59137546800; 59137704900; 57145642900; 23388889700|Comparison Research on Rule-based and Learning-based Mutation Techniques; [基于规则与学习的变异技术对比研究]|2024|Ruan Jian Xue Bao/Journal of Software|35|7||3093|3114|21|0|10.13328/j.cnki.jos.007113|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198002581&doi=10.13328%2fj.cnki.jos.007113&partnerID=40&md5=e062299f3b13b599a80c5290780ce45d|Mutation testing is an effective software testing technique. It helps improve the defect detection capability of an existing test suite by generating mutants that simulate software defects. The quality of mutants has a significant impact on the effectiveness of mutation testing. The traditional mutation testing approach typically employs manually designed syntactic rule-based mutation operators to generate mutants, and has achieved some academic success. In recent years, many studies have started to incorporate deep learning techniques to generate mutants by learning historical code from open source projects. This new approach has achieved preliminary progress in mutant generation. A comprehensive comparison of the two mutation techniques, i.e. rule-based and learning-based, which have different mechanisms but both aim to improve the defect detection capability of the test suite by mutation, is crucial for mutation testing and its downstream tasks. To handle the problem, this study designs and implements an empirical study of rule-based and learning-based mutation techniques, aiming to understand the performance of mutation techniques with different mechanisms on the task of mutation testing, as well as the variability of the generated mutants in terms of program semantics. Specifically, this study uses the Defect4J v1.2.0 dataset to compare the syntactic rule-based mutation techniques represented by MAJOR and PIT with the deep learning-based mutation techniques represented by DeepMutation, μBERT, and LEAM. The experimental results show that both rule-based and learning-based mutation techniques can effectively support mutation testing practices, but MAJOR has the best testing performance and is able to detect 85.4% of real defects. In terms of semantic representation, MAJOR has the strongest semantic representation capability, and its constructed test suite is able to kill more than 95% of the mutants generated by other mutation techniques. In terms of defect representation, both types of techniques are unique. © 2024 Chinese Academy of Sciences. All rights reserved.|defect detection; empirical study; mutation analysis; mutation testing|Deep learning; Learning systems; Open source software; Open systems; Semantics; Software testing; Syntactics; Well testing; Defect detection; Detection capability; Different mechanisms; Empirical studies; Mutation analysis; Mutation testing; Rule based; Rule learning; Semantic representation; Syntactic rules; Defects|Article|Final||Scopus|2-s2.0-85198002581
scopus|Panichella A.; Olsthoorn M.|Panichella, Annibale (35095519000); Olsthoorn, Mitchell (57210556113)|35095519000; 57210556113|Higher Fault Detection Through Novel Density Estimators in Unit Test Generation|2024|Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)|14767 LNCS|||18|32|14|0|10.1007/978-3-031-64573-0_2|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200203826&doi=10.1007%2f978-3-031-64573-0_2&partnerID=40&md5=46b54634201ff74a30dd371deeecfbb5|Many-objective evolutionary algorithms (MOEAs) have been applied in the software testing literature to automate the generation of test cases. While previous studies confirmed the superiority of MOEAs over other algorithms, one of the open challenges is maintaining a strong selective pressure considering the large number of objectives to optimize (coverage targets). This paper investigates four density estimators as a substitute for the traditional crowding distance. In particular, we consider two estimators previously proposed in the evolutionary computation community, namely the subvector-dominance assignment (SD) and the epsilon-dominance assignment (ED). We further propose two novel density estimators specific to test case generation, namely the token-based density estimator (TDE) and the path-based density estimator (PDE). Based on the CodeBERT model tokenizer, TDE uses natural language processing to measure the semantic distance between test cases. PDE, on the other hand, considers the distance between the source-code paths executed by the test cases. We evaluate these density estimators within EvoSuite on 100 non-trivial Java classes from the SF110 benchmark. Our results show that the proposed path-based density estimator (PDE) outperforms all other density estimators in enhancing mutation scores. It increases mutation scores by 4.26 % on average (with a max of over 60%) to the traditional crowding distance. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.|density estimators; search-based software engineering; software testing; test case generation|Evolutionary algorithms; Fault detection; Natural language processing systems; Semantics; Crowding distance; Density estimator; Faults detection; Mutation score; Path-based; Search-based; Search-based software engineering; Software testings; Test case; Test case generation; Software testing|Conference paper|Final||Scopus|2-s2.0-85200203826
scopus|Ussatova O.; Karyukin V.; Zhumabekova A.; Begimbayeva Y.; Ussatov N.|Ussatova, Olga (57204581062); Karyukin, Vladislav (57218952479); Zhumabekova, Aidana (57218949802); Begimbayeva, Yenlik (57191071133); Ussatov, Nikita (57695196800)|57204581062; 57218952479; 57218949802; 57191071133; 57695196800|Designing a vulnerability threat detection scanner with the use of machine learning models|2023|ACM International Conference Proceeding Series|||16||||1|10.1145/3628454.3629997|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180742651&doi=10.1145%2f3628454.3629997&partnerID=40&md5=d200bb3ffc0114fabe060c94c5234b59|Vulnerabilities are a serious threat to operational systems, networks, and applications. Identifying them in web services is crucial for organizations aiming to safeguard their intellectual property and data. This process involves automated scans to detect underlying software issues that could lead to data corruption, loss, or system compromise. Advanced technologies, including vulnerability scanners based on automated testing tools, are employed to detect attacks on web resources. This research focuses on developing an effective vulnerability scanner and analyzing its functionality to ensure information system security. Vulnerability scanners employ various threat detection approaches, including signature detection, behavioral analysis, heuristics, data flow analysis, and machine learning models. Experiments in this work are devoted to the detection of SQL injection threats. The steps, such as data preprocessing, cleaning, normalization, feature extraction, and classification with machine learning algorithms (Naïve Bayes, Logistic Regression, Decision Tree, Random Forest, and XGBoost), were implemented to train machine learning models. The trained models showed impressive classification scores of 0.95 and above for Accuracy, Precision, Recall, and F1-score metrics. These results prove the effectiveness of utilizing a machine-learning approach for SQL injection identification scanners.  © 2023 ACM.|Decision Tree; Logistic Regression; machine learning; Naïve Bayes; Random Forest; SQL injection; Threat detection; Vulnerability scanner; XGBoost|Data flow analysis; Feature extraction; Logistic regression; Random forests; Web services; Logistics regressions; Machine learning models; Machine-learning; Naive bayes; Operational network; Random forests; SQL injection; Threat detection; Vulnerability scanner; Xgboost; Decision trees|Conference paper|Final||Scopus|2-s2.0-85180742651
scopus|Cao J.; Lu Y.; Wen M.; Cheung S.-C.|Cao, Jialun (57203572215); Lu, Yaojie (57198799378); Wen, Ming (56111949000); Cheung, Shing-Chi (7202472792)|57203572215; 57198799378; 56111949000; 7202472792|Testing Coreference Resolution Systems without Labeled Test Sets|2023|ESEC/FSE 2023 - Proceedings of the 31st ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering||||107|119|12|1|10.1145/3611643.3616258|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180553077&doi=10.1145%2f3611643.3616258&partnerID=40&md5=05686db39d8a85b4031cbaca9a29f665|Coreference resolution (CR) is a task to resolve different expressions (e.g., named entities, pronouns) that refer to the same real-world en- tity/event. It is a core natural language processing (NLP) component that underlies and empowers major downstream NLP applications such as machine translation, chatbots, and question-answering. De- spite its broad impact, the problem of testing CR systems has rarely been studied. A major difficulty is the shortage of a labeled dataset for testing. While it is possible to feed arbitrary sentences as test inputs to a CR system, a test oracle that captures their expected test outputs (coreference relations) is hard to define automatically. To address the challenge, we propose Crest, an automated testing methodology for CR systems. Crest uses constituency and depen- dency relations to construct pairs of test inputs subject to the same coreference. These relations can be leveraged to define the meta- morphic relation for metamorphic testing. We compare Crest with five state-of-the-art test generation baselines on two popular CR systems, and apply them to generate tests from 1,000 sentences randomly sampled from CoNLL-2012, a popular dataset for corefer- ence resolution. Experimental results show that Crest outperforms baselines significantly. The issues reported by Crest are all true positives (i.e., 100% precision), compared with 63% to 75% achieved by the baselines. © 2023 ACM.|Coreference resolution testing; Metamorphic testing; SE4AI|Computational linguistics; Natural language processing systems; Coreference; Coreference resolution; Coreference resolution testing; Metamorphic testing; Named entities; Real-world; Resolution systems; SE4AI; Test inputs; Test sets; Statistical tests|Conference paper|Final||Scopus|2-s2.0-85180553077
scopus|Ali A.; Xia Y.; Navid Q.; Khan Z.A.; Khan J.A.; Aldakheel E.A.; Khafaga D.|Ali, Asif (58730610200); Xia, Yuanqing (55916672500); Navid, Qamar (57210110368); Khan, Zohaib Ahmad (57196196028); Khan, Javed Ali (57209631963); Aldakheel, Eman Abdullah (55336815600); Khafaga, Doaa (58088844800)|58730610200; 55916672500; 57210110368; 57196196028; 57209631963; 55336815600; 58088844800|Mobile-UI-Repair: a deep learning based UI smell detection technique for mobile user interface|2024|PeerJ Computer Science|10||e2028||||3|10.7717/PEERJ-CS.2028|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195060445&doi=10.7717%2fPEERJ-CS.2028&partnerID=40&md5=503b27d9a6c6453a942a30abf6129578|The graphical user interface (GUI) in mobile applications plays a crucial role in connecting users with mobile applications. GUIs often receive many UI design smells, bugs, or feature enhancement requests. The design smells include text overlap, component occlusion, blur screens, null values, and missing images. It also provides for the behavior of mobile applications during their usage. Manual testing of mobile applications (app as short in the rest of the document) is essential to ensuring app quality, especially for identifying usability and accessibility that may be missed during automated testing. However, it is time-consuming and inefficient due to the need for testers to perform actions repeatedly and the possibility of missing some functionalities. Although several approaches have been proposed, they require significant performance improvement. In addition, the key challenges of these approaches are incorporating the design guidelines and rules necessary to follow during app development and combine the syntactical and semantic information available on the development forums. In this study, we proposed a UI bug identification and localization approach called Mobile-UI- Repair (M-UI-R). M-UI-R is capable of recognizing graphical user interfaces (GUIs) display issues and accurately identifying the specific location of the bug within the GUI. M-UI-R is trained and tested on the history data and also validated on real-time data. The evaluation shows that the average precision is 87.7% and the average recall is 86.5% achieved in the detection of UI display issues. M-UI-R also achieved an average precision of 71.5% and an average recall of 70.7% in the localization of UI design smell. Moreover, a survey involving eight developers demonstrates that the proposed approach provides valuable support for enhancing the user interface of mobile applications. This aids developers in their efforts to fix bugs. © (2024), 2024 Ali et al.|Deep learning; Machine learning; Mobile app reviews; Mobile application; Smell detection; Software engineering; UI bugs; UI esthetics; UI smell detection; User feedback|Application programs; Deep learning; E-learning; Graphical user interfaces; Learning systems; Mobile computing; Program debugging; Semantics; Deep learning; Machine-learning; Mobile app; Mobile app review; Mobile applications; Smell detection; UI bug; UI esthetic; UI smell detection; User feedback; Repair|Article|Final|All Open Access; Gold Open Access; Green Open Access|Scopus|2-s2.0-85195060445
scopus||||2024 IEEE Microelectronics Design and Test Symposium, MDTS 2024|2024|2024 IEEE Microelectronics Design and Test Symposium, MDTS 2024||||||40|0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198051819&partnerID=40&md5=7238e6a0ec51d1cfe1aefd2a2fe39617|The proceedings contain 8 papers. The topics discussed include: within-chip bridged-pattern short detection using spatially distributed kerf test structures in 7nm FinFET technology; high-speed receiver transient modeling with generative adversarial networks; gate resistance test structures bounded by local layout density to characterize metal gate height variation in 7nm FinFET technology; co-design of a novel CMOS highly parallel, low-power, multi-chip neural network accelerator; design of an OTA circuit for low voltage applications; harmonic tag with probe-fed patch antennas; and machine learning infused software testing for mobile device development.|||Conference review|Final||Scopus|2-s2.0-85198051819
scopus|Hou L.; Shang X.; Ma C.; Xia L.; Liu L.; Zhang Y.; Su Y.; Liu X.; Qiu L.|Hou, Li'an (56605778900); Shang, Xuesong (57972644900); Ma, Chaochao (57202254208); Xia, Liangyu (39763147700); Liu, Li (56799405500); Zhang, Ying (59648167200); Su, Yujun (58753145600); Liu, Xin (56176853700); Qiu, Ling (54380540000)|56605778900; 57972644900; 57202254208; 39763147700; 56799405500; 59648167200; 58753145600; 56176853700; 54380540000|Evaluation and application of automated quality control of automatic pipeline in clinical biochemical and immunological detection; [流水线自动质控在临床生化免疫检验中的评估与应用]|2024|Chinese Journal of Laboratory Medicine|47|1||86|93|7|0|10.3760/cma.j.cn114452-20231102-00253|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185808249&doi=10.3760%2fcma.j.cn114452-20231102-00253&partnerID=40&md5=30c35828c33088c4ad9d1208adfe9735|Objective To assess the applicability of fully automatic pipeline automated testing for internal quality control (automated quality control). Methods Stability, assay efficiency and implementation costs of 18 biochemical tests, 5 immunoturbidimetric tests and 11 chemical illuminescent tests in the Department of Laboratory Medicine of Peking Union Hospital from January 2019 to July 2022 were evaluated using automated quality control implementation methods. The detailed method is as follows: quality control materials for biochemical, immunoturbidimetric and chemiluminescent tests were stored in the refrigerator in the pipeline which was controlled by the intermediate software, and were automatically retrieved and tested as pre‑set followed by documenting and storing. The quality control setup for the biochemical tests included refreshing quality control materials daily and weekly,both of which were paralleled for 3 months. The on‑line storage stability of quality control materials in the pipeline was evaluated by comparing the coefficients of variation (CV) of the quality control results between the two patterns. Effect of automated quality control application was evaluated using 6 indicators, including the results′ variation of automatically performed and manually performed quality controls, the out‑of‑controlled rate, the consumption of quality control materials, the change of staff workload, the impact on the testing time of the first sample, and the failure rate of automated quality control. Results (1) Storage stability of quality control materials in the pipeline: under the pattern of weekly refresh of the biochemical quality control materials, except for total carbon dioxide (TCO2) (the CVs of low and high level quality control were respectively 20.24% and 21.82%) and sodium (the CV of low level quality control was 1.51%) that were greater than the allowable variation set by the laboratory, the CVs of the rest tests meet the lab requirements on the allowable variations. (2) The results′ variation of quality control in automatically performed and manually performed control patterns: in the patterns of daily refresh of biochemical quality control materials and weekly refresh of immunoturbidimetric and chemiluminescent quality control materials, the CVs of both low and high levels of quality control were lower in the automatically performed control pattern than that in manually performed pattern for 8 chemiluminescent items of dehydroepiandrosterone sulfate, estradiol, follicle stimulating hormone, luteinizing hormone, serum ferritin, serum folic acid, vitamin B12 and testosterone, 3 immunologic items of complement 3, C reactive protein and immunoglobulin G, and 10 biochemical items of alkaline phosphatase, glucose, calcium, chloride, potassium, lactate dehydrogenase, sodium, urea, low density lipoprotein cholesterol, and adenosine deaminase. The out‑of‑control rates of biochemistry, immunoturbidimetric and chemiluminescence tests in both quality control patterns conformed with the clinical routine work requirements. (3) Comparison of quality control materials′ consumption: compared with manually performed quality control, weekly consumption of automatically performed chemiluminescent quality control materials decreased 37.5% (from 8 ml to 5 ml); weekly consumption of automatically performed immunoturbidimetric quality control materials decreased 33.3% (from 3 ml to 2 ml). (4)Comparison of staff workload and first sample testing time: compared with manually performed quality control, automatical quality control reduced manual work by about 156 steps per week, and the daily initial testing time was earlier by 15 min on average. The failure rate was 54.5% (37/64) during the early‑stage application of the automated quality control which dropped to 10.2% (13/128) in the late‑stage. Conclusion The results of automated quality control detected in the pipeline system meet the quality indicators′ requirements of the laboratory, and the application of automated quality control can improve the quality control, save costs, reduce workload, and improve work efficiency. © 2024 Chinese Medical Journals Publishing House Co.Ltd. All rights reserved.|Allowable variation; Coefficient of variation; Quality control; Stability|adenosine deaminase; alkaline phosphatase; C reactive protein; calcium; carbon dioxide; chloride; complement component C3; cyanocobalamin; estradiol; ferritin; folic acid; follitropin; glucose; immunoglobulin G; lactate dehydrogenase; low density lipoprotein cholesterol; luteinizing hormone; potassium; prasterone sulfate; sodium; testosterone; urea; Article; biochemical analysis; chemiluminescence immunoassay; cost; immunological procedures; immunoturbidimetry; quality control; workload|Article|Final||Scopus|2-s2.0-85185808249
scopus|Shu J.; Miu B.-J.; Chang E.; Gao J.; Liu J.|Shu, Jing (59368642700); Miu, Bing-Jiun (59367680700); Chang, Eugene (59368643700); Gao, Jerry (7404475003); Liu, Jun (59359160500)|59368642700; 59367680700; 59368643700; 7404475003; 59359160500|Computer Vision Intelligence Test Modeling and Generation: A Case Study on Smart OCR|2024|Proceedings - 6th IEEE International Conference on Artificial Intelligence Testing, AITest 2024||||21|28|7|3|10.1109/AITest62860.2024.00011|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205888666&doi=10.1109%2fAITest62860.2024.00011&partnerID=40&md5=ac5caa04a471ee1b29fc76ecc4066db5|AI-based systems possess distinctive characteristics and introduce challenges in quality evaluation at the same time. Consequently, ensuring and validating AI software quality is of critical importance. In this paper, we present an effective AI software functional testing model to address this challenge. Specifically, we first present a comprehensive literature review of previous work, covering key facets of AI software testing processes. We then introduce a 3D classification model to systematically evaluate the image-based text extraction AI function, as well as test coverage criteria and complexity. To evaluate the performance of our proposed AI software quality test, we propose four evaluation metrics to cover different aspects. Finally, based on the proposed framework and defined metrics, a mobile Optical Character Recognition (OCR) case study is presented to demonstrate the framework's effectiveness and capability in assessing AI function quality. © 2024 IEEE.|AI software testing; Artificial Intelligence; computer vision; optical character recognition; quality assurance|Computer software selection and evaluation; AI software testing; Case-studies; Functional testing; Intelligence tests; Optical-; Quality evaluation; Software Quality; Software testings; Test generations; Test models; Software quality|Conference paper|Final|All Open Access; Green Open Access|Scopus|2-s2.0-85205888666
scopus|Crandall A.S.; Fischer B.J.; Crandall J.L.|Crandall, Aaron S. (24558976200); Fischer, Bryan J. (59703151800); Crandall, Johannah L. (57219854018)|24558976200; 59703151800; 57219854018|WIP: ARTful Insights from a Pilot Study on GPT-Based Automatic Code Reviews in Undergraduate Computer Science Programs|2024|Proceedings - Frontiers in Education Conference, FIE|||||||1|10.1109/FIE61694.2024.10893407|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000713326&doi=10.1109%2fFIE61694.2024.10893407&partnerID=40&md5=0ecdf0af0629ceb3943cf1aa7b14e14d|This work in progress research paper describes a pilot study using a Large Language Model (LLM) Generative Pre-Trained Transformer-based (GPT) system that generates industry-style code reviews for student feedback on software development projects in Computer Science 2nd, 3rd, and 4th+ semester classes (CS2, CS3, CS4+) at an ABET accredited baccalaureate institution. Code reviews are a valuable, but work-intensive, component of the software engineering process and provide important training to undergraduate students in the form of mentor-peer knowledge transfer. Participants in this study engaged in iterative experiential learning using the Automatic Review Tool (ART), an artificial intelligence tool to support software engineering as an Automatic Static Analysis Tool in the Continuous Integration pipeline alongside software testing harnesses and code style checkers. This pilot study was based on earlier results from a full computer science second semester (CS2) class (n=74) to develop an ART-generated code review intervention pilot study with a small group of students in CS2 / 3 and CS4. The project underway uses an experiential learning and iterative feedback process to answer research questions including 'Does ART provide accurate and actionable code reviews for students' and 'Which levels of students are best prepared to receive and use ART-based code reviews?' During this pilot study, the project used a mixed methods research approach with a series of surveys, code review interventions, and numerical analysis of the code reviews' accuracy. Results showed a reasonable degree of code review accuracy by ART and the students learned code review skills from interaction with the ART-based reviews they received. Ongoing work includes increasing the scale of data collection, using this work to refine and focus the ART-based reviews onto the categories of feedback that students find the most valuable, and building out a more modular tool for wider release in the academic community. © 2024 IEEE.|Adaptive computer learning; Code Reviews; Computer science; Mixed methods research; Qualitative; Software Engineering Education|Automatic programming; Automatic testing; C++ (programming language); Computer aided software engineering; Computer software selection and evaluation; Curricula; Electric transformer testing; Engineering education; Integration testing; Personnel training; Pipeline codes; Program processors; Software design; Adaptive computer learning; Automatic codes; Code review; Computer learning; Computer science programs; Experiential learning; Mixed-methods research; Pilot studies; Qualitative; Software engineering education; Students|Conference paper|Final||Scopus|2-s2.0-105000713326
scopus|Pillai T.K.; Mccoy C.; Chakravarty S.|Pillai, Tilak Kesava (59211824500); Mccoy, Clinton (59211824600); Chakravarty, Sunder (59211754000)|59211824500; 59211824600; 59211754000|Machine Learning Infused Software Testing for Mobile Device Development|2024|2024 IEEE Microelectronics Design and Test Symposium, MDTS 2024|||||||0|10.1109/MDTS61600.2024.10570142|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198035115&doi=10.1109%2fMDTS61600.2024.10570142&partnerID=40&md5=d49ddc4ff9379bb5dbf5321caf1c8b59|Automated test systems execute a large set of test cases across mobile devices that are distributed throughout the global test labs. The test cases generate a huge amount of data which consists of various logs that are captured from the mobile devices under teat and the automated test systems. The logs that are associated with the failed test cases are typically manually analyzed to determine if the failure is a true product failure or an issue with the test environment. This binary classification is performed for each test failure. The failures classified as test environment failures are further classified into subcategories. The outcome of this analysis helps ensure the test case failures are properly triaged and the respective team can take the appropriate action.Our study demonstrates the potential application of data mining techniques to automatically categorize failed test cases using the test logs. These logs contain explicit details such as time stamps, log levels, the tested module, error codes, and test outcomes. Moreover, they also have implicit information such as line velocity, error velocity, test duration, and sentiment profile. We utilize heuristics to extract both the explicit and implicit information as features. These features are associated to training labels using a subset of the logs. Our experimentation involved multiple models, including Naïve Bayes, Random Forest, Decision Tree, and Decision Table.We show that with an initial one-time labeling effort, the best models for binary classification achieve around 90% accuracy for binary classification. We further show that multiclass classification achieves around 85% accuracy for most of the classes. © 2024 IEEE.||Binary trees; Data mining; Decision trees; Software testing; Automated test systems; Binary classification; Classifieds; Device development; Implicit informations; Machine-learning; Product failures; Software testings; Test case; Test Environment; Decision tables|Conference paper|Final||Scopus|2-s2.0-85198035115
scopus|Luu Q.; Liu H.; Chen T.Y.; Vu H.L.|Luu, Quang-Hung (56034214700); Liu, Huai (19640635500); Chen, Tsong Yueh (13104290200); Vu, Hai L. (7004453179)|56034214700; 19640635500; 13104290200; 7004453179|A Sequential Metamorphic Testing Framework for Understanding Autonomous Vehicle&#x0027;s Decisions|2024|IEEE Transactions on Intelligent Vehicles||||1|13|12|8|10.1109/TIV.2024.3370740|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186987033&doi=10.1109%2fTIV.2024.3370740&partnerID=40&md5=25eee0244f24e03e8bf768c62440f3f8|Being an indispensable part of future autonomous transportation systems, autonomous vehicles (AVs) are expected to drive safely with minimal human inputs. In addition to safety, their acceptance by the society highly depends on the level of understanding, trustworthiness and transparency in their decisions. It remains an open problem to judge whether their decision is correct or not, and how to verify it systematically. In this paper, a Sequential MetAmoRphic Testing (SMART) framework is proposed based on a highly-successful metamorphic testing approach in the software testing discipline to tackle this problem. The framework makes use of sequences of metamorphic groups of test cases to determine the correctness of AV&#x0027;s decisions. To demonstrate its effectiveness, the framework is applied to test three existing deep learning models that were developed to steer an AV in different scenarios with another car either leading in front or approaching in the opposite direction, as well as under different weather conditions. Our experiments reveal a large number of undesirable behaviors in these autonomous driving models and identify critical factors affecting their decisions. We further demonstrate the applicability of the proposed framework in revealing undesirable behaviors of Autoware, a well-known and accepted open-source automated driving system, in a typical hazardous scenario. These results show that our framework can be used to provide a comprehensive understanding of AV&#x0027;s decisions without the need of ground-truth datasets. IEEE|Accidents; Autonomous vehicles; Autonomous vehicles; Behavioral sciences; metamorphic testing; Meteorology; Safety; sequential metamorphic groups; Task analysis; Testing; verification and validation|Accidents; Autonomous vehicles; Behavioral research; Deep learning; Meteorology; Open source software; Open systems; Safety testing; Autonomous transportation system; Autonomous Vehicles; Behavioral science; Metamorphic testing; Sequential metamorphic group; Software testings; Task analysis; Testing framework; Verification-and-validation; Accident prevention|Article|Article in press||Scopus|2-s2.0-85186987033
scopus|Anderson C.L.; Willner M.R.; Patsolic H.G.; Brem L.; Aboye G.; Smolyak D.; Crowley K.|Anderson, Catherine L. (59921474300); Willner, Marjorie R. (59921086500); Patsolic, Heather G. (57204316599); Brem, Larry (59922242600); Aboye, Gelila (59921086600); Smolyak, Daniel (57202645806); Crowley, Kenyon (7006521009)|59921474300; 59921086500; 57204316599; 59922242600; 59921086600; 57202645806; 7006521009|A Comparison of LLMs for Use in Generating Synthetic Test Data for Automated Testing of a Patient-Focused, Survey-Based System|2024|AMIA ... Annual Symposium proceedings. AMIA Symposium|2024|||142|151|9|0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-105006857050&partnerID=40&md5=66b745901940121f93e753d579317951|In the context of a patient-focused, survey-based system, we demonstrated the potential of generative AI to create custom synthetic data using 2 different large language models (GPT 3.5 and Flan T5-XL) in AWS and Azure environments. While we improved test effectiveness and efficiency by synthetically generating many test cases, the experience included technical and communication challenges as well as complexities associated with balancing the desire for high utility and realism in the data with the available testing resources. Recommendations range from defining and gaining consensus on evaluation metrics early in the process as it influences technical questions like persona creation and prompt-engineering to encouraging test teams to build flexible frameworks from the start. ©2024 AMIA - All rights reserved.||Artificial Intelligence; Humans; Natural Language Processing; Patient-Centered Care; Programming Languages; Surveys and Questionnaires; artificial intelligence; comparative study; computer language; human; natural language processing; person centered care; questionnaire|Article|Final||Scopus|2-s2.0-105006857050
scopus|Marijan D.|Marijan, Dusica (34872942800)|34872942800|Comparative study of machine learning test case prioritization for continuous integration testing|2023|Software Quality Journal|31|4||1415|1438|23|10|10.1007/s11219-023-09646-0|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165962440&doi=10.1007%2fs11219-023-09646-0&partnerID=40&md5=15b4d48c5e12154d61a7d4749f96984a|There is a growing body of research indicating the potential of machine learning to tackle complex software testing challenges. One such challenge pertains to continuous integration testing, which is highly time-constrained, and generates a large amount of data coming from iterative code commits and test runs. In such a setting, we can use plentiful test data for training machine learning predictors to identify test cases able to speed up the detection of regression bugs introduced during code integration. However, different machine learning models can have different fault prediction performance depending on the context and the parameters of continuous integration testing, for example, variable time budget available for continuous integration cycles, or the size of test execution history used for learning to prioritize failing test cases. Existing studies on test case prioritization rarely study both of these factors, which are essential for the continuous integration practice. In this study, we perform a comprehensive comparison of the fault prediction performance of machine learning approaches that have shown the best performance on test case prioritization tasks in the literature. We evaluate the accuracy of the classifiers in predicting fault-detecting tests for different values of the continuous integration time budget and with different lengths of test history used for training the classifiers. In evaluation, we use real-world and augmented industrial datasets from a continuous integration practice. The results show that different machine learning models have different performance for different size of test history used for model training and for different time budgets available for test case execution. Our results imply that machine learning approaches for test prioritization in continuous integration testing should be carefully configured to achieve optimal performance. © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.|Continuous integration; Gradient boosting; Learning to rank; Machine learning; Neural networks; Regression testing; Software testing; Support vector regression; Test optimization; Test prioritization; Test selection|Adaptive boosting; Codes (symbols); Forecasting; Integration; Integration testing; Learning systems; Machine learning; Regression analysis; Continuous integrations; Gradient boosting; Machine-learning; Neural-networks; Regression testing; Software testings; Support vector regressions; Test optimization; Test prioritization; Test selection; Budget control|Article|Final|All Open Access|Scopus|2-s2.0-85165962440
scopus|Parashar B.B.; Chandra M.; Malhotra S.|Parashar, Bhanu Bhushan (59254739500); Chandra, Munesh (55807106100); Malhotra, Sachin (57615334800)|59254739500; 55807106100; 57615334800|Optimizing Brain Tumor Classification Accuracy Through Transfer Learning and Internet of Things Integration|2024|Journal of Intelligent Systems and Internet of Things|13|1||151|165|14|1|10.54216/JISIoT.130112|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200835972&doi=10.54216%2fJISIoT.130112&partnerID=40&md5=d629fd397e84c57d874f50726d7b8e44|Brain tumor classification using medical images is crucial for identification and therapy. However, brain tumors are complex and vary, making grouping them difficult. This work demonstrates a novel transfer learning method for brain tumor classification. We employ trained Convolutional Neural Networks (CNNs) models and data enrichment approaches to extract meaningful information from medical images. We want to fine-tune the models built on our dataset to uncover hierarchical patterns that distinguish tumor types. Through data enrichment, the training sample becomes more diverse and richer, making the model more generic and robust. Our team's extensive testing and research have shown that the suggested procedure can identify brain tumors. Our machine-learning approach performs better than others in terms of accuracy, sensitivity, specificity, and precision. Our technique improves brain tumor categorization and assures accurate clinical diagnosis. Automated testing systems are one way for physicians to assist patients in selecting the best course of treatment. Researchers may improve classification performance by incorporating modern imaging technology or topic-specific data. The Internet of Things, or IoT, is helping to drive the development of complex real-time data collection, processing, and sharing systems. These technological advancements have transformed medical imaging. This graphic depicts a cutting-edge transfer learning system that may be able to identify brain cancer from medical photos. This technology has the potential to enhance data collection and processing via the Internet of Things. Data augmentation and pre-trained convolutional neural networks may help to extract interpretable medical images. The Internet of Things improved the model's flexibility, resilience, and utility. We achieved this by expanding the training data set. Rapid categorization advancements have made clinical diagnosis more efficient. Classification, deep learning, medical imaging, machine learning, transfer learning, tumor detection, and image analysis all relate to this topic. © 2024, American Scientific Publishing Group (ASPG). All rights reserved.|Classification; Convolutional Neural Networks; Data Augmentation; Deep Learning; Image Analysis; Internet of Things, Machine Learning; Medical Imaging; Transfer Learning; Tumor Classification; Tumor Detection||Article|Final||Scopus|2-s2.0-85200835972
scopus|Li Q.; Zhou W.; Zhang X.; Li H.; Li M.; Liang H.|Li, Qingxu (57211855924); Zhou, Wanhuai (55372887800); Zhang, Xuedong (55900088500); Li, Hao (57215302258); Li, Mingjie (58871219200); Liang, Houjun (23389442700)|57211855924; 55372887800; 55900088500; 57215302258; 58871219200; 23389442700|Cotton-Net: efficient and accurate rapid detection of impurity content in machine-picked seed cotton using near-infrared spectroscopy|2024|Frontiers in Plant Science|15||1334961||||5|10.3389/fpls.2024.1334961|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184461629&doi=10.3389%2ffpls.2024.1334961&partnerID=40&md5=679feea49b5c3534c93c80d3ec291248|Widespread adoption of machine-picked cotton in China, the impurity content of seed cotton has increased significantly. This impurity content holds direct implications for the valuation of seed cotton and exerts a consequential influence on the ensuing quality of processed lint and textiles. Presently, the primary approach for assessing impurity content in seed cotton primarily depends on semi-automated testing instruments, exhibiting suboptimal detection efficiency and not well-suited for the impurity detection requirements during the purchase of seed cotton. To address this challenge, this study introduces a seed cotton near-infrared spectral (NIRS) data acquisition system, facilitating the rapid collection of seed cotton spectral data. Three pretreatment algorithms, namely SG (Savitzky-Golay convolutional smoothing), SNV (Standard Normal Variate Transformation), and Normalization, were applied to preprocess the seed cotton spectral data. Cotton-Net, a one-dimensional convolutional neural network aligned with the distinctive characteristics of the seed cotton spectral data, was developed in order to improve the prediction accuracy of seed cotton impurity content. Ablation experiments were performed, utilizing SELU, ReLU, and Sigmoid functions as activation functions. The experimental outcomes revealed that after normalization, employing SELU as the activation function led to the optimal performance of Cotton-Net, displaying a correlation coefficient of 0.9063 and an RMSE (Root Mean Square Error) of 0.0546. In the context of machine learning modeling, the LSSVM model, developed after Normalization and Random Frog algorithm processing, demonstrated superior performance, achieving a correlation coefficient of 0.8662 and an RMSE of 0.0622. In comparison, the correlation coefficient of Cotton-Net increased by 4.01%. This approach holds significant potential to underpin the subsequent development of rapid detection instruments targeting seed cotton impurities. Copyright © 2024 Li, Zhou, Zhang, Li, Li and Liang.|cotton-net; impurity; near-infrared spectroscopy; rapid detection; seed cotton||Article|Final|All Open Access; Gold Open Access; Green Open Access|Scopus|2-s2.0-85184461629
scopus|Hu J.; Xi Z.; Xu G.; Li Z.; Liu X.|Hu, Jinwei (58687553100); Xi, Zhenghao (56365481300); Xu, Guozhong (7404263994); Li, Zhongfeng (57212591140); Liu, Xiang (57192258973)|58687553100; 56365481300; 7404263994; 57212591140; 57192258973|An improved automated testing model for maceral groups in coals based on DeeplabV3+; [基于 DeeplabV3+改进的煤岩显微组分组自动化测试模型]|2023|Meitiandizhi Yu Kantan/Coal Geology and Exploration|51|10||27|36|9|3|10.12363/issn.1001-1986.23.01.0013|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176238618&doi=10.12363%2fissn.1001-1986.23.01.0013&partnerID=40&md5=9385715eea2adb9c69e58608bffa2eda|The identification of maceral groups in coals plays a critical role in analyzing the chemical properties of coals. However, manual identification is laborious and requires high expertise. Existing computer-assisted identification methods, mostly adopting deep learning-based semantic segmentation models, fail to accurately identify maceral groups in coals due to complex compositions of microscopic coal images and the presence of transitional components. Therefore, this study proposed an improved DeeplabV3+ semantic segmentation model integrating the Swin Transformer backbone network and the SkNet. First, to deal with the challenge of feature extraction caused by the intertwined maceral groups and the presence of transitional components in microscopic coal images, the Swin Transformer backbone network was used as the basic feature extraction network to enhance the feature extraction ability of the model for various maceral groups and to enable the information interaction between features of the segmentation network. Second, to improve the feature utilization rate of the Atrous Spatial Pyramid Pooling (ASPP) module in the model, the SkNet network was integrated into the ASPP to enable the ASPP to extract important features and suppress unnecessary features that interfere with the final prediction results. Finally, the improved DeeplabV3+ model was compared with existing advanced algorithms through experiments. As indicated by the comparison results, the improved model yielded pixel accuracy of 92.06% on the test set of microscopic coal images, which was 9.48%, 6.90%, and 3.40% higher than that of the random forest method, the U-Net semantic segmentation model, and the DeeplabV3+ semantic segmentation model, respectively. Furthermore, the improved model showed results similar to the manual point measurement method. Therefore, the improved model, outperforming the existing automatic identification models for coal maceral groups, can serve as a powerful method for the computer-assisted manual identification of maceral groups in coals. © 2023 Science Press. All Rights Reserved.|automated testing; maceral group; microscopic coal image; semantic segmentation model; SkNet; Swin Transformer|Automation; Computer aided instruction; Deep learning; Electric transformer testing; Extraction; Feature extraction; Image enhancement; Semantic Segmentation; Semantics; Automated testing; Features extraction; Maceral groups; Microscopic coal image; Segmentation models; Semantic segmentation; Semantic segmentation model; Sknet; Spatial pyramids; Swin transformer; Coal|Article|Final||Scopus|2-s2.0-85176238618
scopus|Li R.|Li, Rongrong (59000096400)|59000096400|Software Quality Testing Framework based on Machine Learning Analysis|2024|Proceedings - 2024 5th International Conference on Mobile Computing and Sustainable Informatics, ICMCSI 2024||||396|401|5|1|10.1109/ICMCSI61536.2024.00063|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191225766&doi=10.1109%2fICMCSI61536.2024.00063&partnerID=40&md5=f1919920c9759ad2c072354aaf6c359a|This research work presents a software quality testing framework based on machine learning analysis. The framework utilizes dynamic symbol technology and integration testing methods to analyze different execution paths, thereby establishing a comprehensive integration testing framework. Technologies such as robot framework, exploration-driven test data generation, and software reliability coupling measurement are employed to improve testing efficiency and ensure thorough verification of software functions and performance. The research demonstrates the application of reinforcement learning to test case sequencing, using Q-learning to optimize API functional test case generation. The proposed methodology involves the integration of machine learning analysis into three aspects: information handling, procedure formulation, and execution flow. The paper explores regression testing, test case prioritization technology (TCP), and reinforcement learning for efficient test case ordering. A comprehensive simulation of 500 software reliability testing use cases shows significant improvements in test efficiency by reducing redundant instances. The research concludes with a discussion of the application of Q-Learning in continuous integration testing, emphasizing the need for flexible memory representations to handle complex states and action sets. The proposed framework effectively addresses the challenges posed by scale expansion in software development, thereby improving the accuracy and efficiency of software testing. © 2024 IEEE.|Machine learning analysis; robustness testing; software quality; testing framework|Computer software selection and evaluation; Efficiency; Integration; Learning systems; Quality control; Reinforcement learning; Software design; Software reliability; Verification; Machine learning analyse; Machine-learning; On-machines; Q-learning; Quality testing; Reinforcement learnings; Robustness testing; Software Quality; Test case; Testing framework; Integration testing|Conference paper|Final||Scopus|2-s2.0-85191225766
scopus|Gillberg J.|Gillberg, Jonas (58509344400)|58509344400|Bots for Testing|2024|Game AI Uncovered: Volume One|1|||158|167|9|0|10.1201/9781003324102-17|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186673004&doi=10.1201%2f9781003324102-17&partnerID=40&md5=91134ea5c84a63f03a7918fe5885fc0a|Games have grown tremendously in scope over the years. To meet EA’s testing requirements, extensive test automation systems were developed, and autonomous bots were used to provide highly scalable test coverage. There is a fundamental difference between bots for testing and bots for gameplay. Bots for testing need to provide functionality to cover specific test cases and provide good stability, performance, and other data/telemetry. This chapter highlights some good use cases for test bots, demonstrates just how minimal the AI can be to get started, and suggests areas to explore if you want to go further. © 2024 selection and editorial matter, Paul Roberts; individual chapters, the contributors.||Automation; Automation systems; Data telemetry; Gameplay; Good stability; Stability performance; Test Automation; Test case; Test-coverage; Testing requirements; Botnet|Book chapter|Final||Scopus|2-s2.0-85186673004
scopus|Gajbhiye D.; Shete R.; Shah P.; Debory P.; Vora B.|Gajbhiye, Darshana (59410102200); Shete, Ritesh (59410478100); Shah, Param (59411043200); Debory, Pratik (59411418000); Vora, Bhavya (59411043300)|59410102200; 59410478100; 59411043200; 59411418000; 59411043300|Software Defect Sentry using Ensemble Learning|2024|15th International Conference on Advances in Computing, Control, and Telecommunication Technologies, ACT 2024|2|||477|482|5|0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209143093&partnerID=40&md5=3c7697699acb13f1e0983954a989cece|These days, software is ingrained in every part of our life, so it's highly likely to be flawed. Software Defect Prediction (SDP) predicts both front-end and back-end flaws, among other technical problems. To predict bugs, all we have to do is use various Ensemble Learning techniques. Software Defect Prediction (SDP) is one of the most helpful techniques in the Testing Phase of the Software Development Life Cycle (SDLC). It identifies the modules that require testing because of their error- prone nature. This allows for efficient use of the testing resources without going above permitted limits. In the rapidly evolving world of software development, making sure a software system is of high quality is essential. Program testing is one of the most important techniques for guaranteeing program quality. It was found that the cost of testing accounted for almost half of the project's overall expenses. Effective and efficient software testing makes use of the least amount of software resources. Designing a procedure that may effectively carry out testing while also utilizing the fewest resources feasible for the project is therefore essential. Software Defect Sentry was thus developed. The goal of our Sentry is to find as many software bugs as it can. The world is always moving toward making important judgments based on facts. Therefore, we will do machine learning analysis on datasets that are made publicly available in this project in order to achieve the best level of accuracy feasible. The primary objective of the study is to apply several machine learning algorithms to the datasets and identify which methods produce the best outcomes. To be more precise, we demonstrated an ensemble learning model and compared the performance of KNN, Decision tree, SVM, and Naive Bayes on multiple datasets with the Ensemble technique. We also measured F1-score, accuracy, precision, and recall. © Grenze Scientific Society, 2024.|Accuracy; Comparative analysis; Ensemble learning; KNN; Machine Learning; Naive Bayes; Quality assurance; Software testing; SVM|Adversarial machine learning; Computer software selection and evaluation; Decision trees; Federated learning; Software testing; Accuracy; Comparative analyzes; Ensemble learning; KNN; Machine-learning; Naive bayes; Software defect prediction; Software defects; Software testings; SVM; Contrastive Learning|Conference paper|Final||Scopus|2-s2.0-85209143093
scopus|Lowandy K.; Kelliher S.; Le D.; Molinari C.; Harris I.; Unger L.; Fink R.; Shemelya C.; Robinette P.|Lowandy, K. (59454151200); Kelliher, S. (59378537200); Le, D. (59454020400); Molinari, C. (59377969600); Harris, I. (59454020500); Unger, L. (59378137100); Fink, R. (59453492300); Shemelya, C. (36603424200); Robinette, P. (25823528900)|59454151200; 59378537200; 59454020400; 59377969600; 59454020500; 59378137100; 59453492300; 36603424200; 25823528900|Convolutional Neural Networks for Engineering Design Validation|2024|Proceedings of SPIE - The International Society for Optical Engineering|13138||131380H||||0|10.1117/12.3027869|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210855973&doi=10.1117%2f12.3027869&partnerID=40&md5=20d8cd4103af766784fc9f2d26c0c95b|The growth of artificial intelligence has led to the widespread use of convolutional neural networks (CNNs) for computer vision applications, traditionally for binary and categorical classification tasks. However, there remains untapped potential for advancing computer vision through deep learning in regression tasks. Design engineers across many disciplines use computer-aided design software to model their designs. These computer-integrated designs often require machinery for construction or fabrication. For many engineering designs, precision and tolerancing is essential for the proper function and performance of the design. The engineering process typically involves manual testing and parameter measurements to ensure the proper function of the design before it is marketed. However, training a neural network to automate these tests and provide accurate numeric estimates of system parameters without manual intervention can significantly increase efficiency and decrease the time to market for many products. This shift from manual to automated testing allows for a heightened focus on innovation and project development while minimizing the time and resource dedication for validation. This article outlines the implementation of CNN models designed to enhance the efficiency of manually validating engineered projects. Our approach involves utilizing computer-aided design simulation image captures as training data for our pipeline. We integrate a real-time color-filtering and fiducial rotation scaling normalization process on any fabricated design image. Through these pre-processing methods, our algorithm can perceive these images in a consistent manner with simulation images from the model training. Our current model is trained with only 1020 simulation images and achieves a 1.99% average training prediction error on this dataset after training. Before, our errors were a 10.51% average error in our initial model implementation and 3.63% in our second implementation. On our test set, consisting of six captured and preprocessed sample fabricated design images, our model achieves a 3.40% average prediction error. The performance of a regression label neural network of this nature depends largely on the amount and range of data and simulation scenarios considered. As we continue to expand our training dataset through an optimized pipeline, we anticipate a significant improvement in model performance. © 2024 SPIE.|Computer Vision; Convolutional Neural Network (CNN); Deep Learning; Engineering Design; Fabrication; Simulation; Validation|Automatic testing; Deep neural networks; Design for testability; Integrated circuit design; Machine design; Structural dynamics; Convolutional neural network; Deep learning; Design validation; Engineering design; Neural-networks; Performance; Simulation; Simulation images; Validation; Precision engineering|Conference paper|Final||Scopus|2-s2.0-85210855973
scopus|Yu B.; Hu Y.; Mang Q.; Hu W.; He P.|Yu, Boxi (57199407951); Hu, Yiyan (58558501200); Mang, Qiuyang (58558501300); Hu, Wenhan (58558501400); He, Pinjia (56241158600)|57199407951; 58558501200; 58558501300; 58558501400; 56241158600|Automated Testing and Improvement of Named Entity Recognition Systems|2023|ESEC/FSE 2023 - Proceedings of the 31st ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering||||883|894|11|2|10.1145/3611643.3616295|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174884125&doi=10.1145%2f3611643.3616295&partnerID=40&md5=8a9d5adcdb3536c64d654b68d3c7065e|Named entity recognition (NER) systems have seen rapid progress in recent years due to the development of deep neural networks. These systems are widely used in various natural language processing applications, such as information extraction, question answering, and sentiment analysis. However, the complexity and intractability of deep neural networks can make NER systems unreliable in certain circumstances, resulting in incorrect predictions. For example, NER systems may misidentify female names as chemicals or fail to recognize the names of minority groups, leading to user dissatisfaction. To tackle this problem, we introduce TIN, a novel, widely applicable approach for automatically testing and repairing various NER systems. The key idea for automated testing is that the NER predictions of the same named entities under similar contexts should be identical. The core idea for automated repairing is that similar named entities should have the same NER prediction under the same context. We use TIN to test two SOTA NER models and two commercial NER APIs, i.e., Azure NER and AWS NER. We manually verify 784 of the suspicious issues reported by TIN and find that 702 are erroneous issues, leading to high precision (85.0%-93.4%) across four categories of NER errors: omission, over-labeling, incorrect category, and range error. For automated repairing, TIN achieves a high error reduction rate (26.8%-50.6%) over the four systems under test, which successfully repairs 1,056 out of the 1,877 reported NER errors. © 2023 ACM.|AI software; Metamorphic testing; named entity recognition; software repairing|Automation; Errors; Forecasting; Repair; Sentiment analysis; Software testing; AI software; Automated testing; Metamorphic testing; Named entities; Named entity recognition; Natural language processing applications; Question Answering; Recognition error; Recognition systems; Software repairing; Deep neural networks|Conference paper|Final|All Open Access; Green Open Access|Scopus|2-s2.0-85174884125
scopus|Pakshad P.; Shameli-Sendi A.; Khalaji Emamzadeh Abbasi B.|Pakshad, Puya (58107947700); Shameli-Sendi, Alireza (55308191100); Khalaji Emamzadeh Abbasi, Behzad (58107831700)|58107947700; 55308191100; 58107831700|A security vulnerability predictor based on source code metrics|2023|Journal of Computer Virology and Hacking Techniques|19|4||615|633|18|8|10.1007/s11416-023-00469-y|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148378492&doi=10.1007%2fs11416-023-00469-y&partnerID=40&md5=b89a02f62a03d44b332f48c520ff0c11|Detecting security vulnerabilities in the source code of software systems is one of the most important challenges in the field of software security. We need an effective solution to discover and patch vulnerabilities before our valuable information is compromised. Security testing is a type of software testing that checks whether software is vulnerable to cyber attacks. This study aimed to pursue three main objectives: (1) The first goal is to identify the vulnerable functions of a C/C++ software program based on code metrics. This can reduce the cost of software security testing and also redirect the related activities to identified vulnerable functions rather than to the entire software, (2) The second goal is to identify the type of attack related to the vulnerability function, and (3) Finally, the ultimate goal is to analyze the relationship between code metrics and the vulnerabilities. This goal can help us understand which code structure is most likely to contain vulnerable code. This paper first aimed to create a comprehensive view of the source code of the target software using graph concepts. Second, a set of source code metrics and calculated by crawling on the related graph using the static analysis approach. Finally, the vulnerability prediction model presented in this paper is based on machine learning technique applied on metrics extracted from program source code. Compared to previous work, new achievements have been made in this paper. One of the most important ones is the very high accuracy detection of the proposed model in detecting the type of vulnerability. Moreover, 15 code metrics are used to predict vulnerabilities. Our analysis on feature importance indicates that what structure the software program code has, most likely, it will be vulnerable. Experimental results in 10 real projects (OpenSSL, SQLite, FreeType, LibTiff, Libxslt, Binutils, FFmpeg, ImageMagick, OpenSC, and rdesktop) indicated that the security testing predictor proposed in this paper could predict on average 89% of the really vulnerable functions of the source code and 86% of the vulnerability type of the detected functions correctly. © 2023, The Author(s), under exclusive licence to Springer-Verlag France SAS, part of Springer Nature.|Code property graph; Program metric; Security testing; Vulnerability detection|C++ (programming language); Codes (symbols); Cybersecurity; Forecasting; Learning systems; Network security; Software testing; Code metrics; Code property graph; Program metric; Property; Security testing; Security vulnerabilities; Software project; Source code metrics; Source codes; Vulnerability detection; Static analysis|Article|Final||Scopus|2-s2.0-85148378492
scopus|Qian Z.-S.; Yu Q.-Y.; Zhang D.; Yao C.-S.; Qin L.-Y.; Cheng Y.-W.|Qian, Zhong-Sheng (56213912500); Yu, Qing-Yuan (57228349100); Zhang, Ding (58000743300); Yao, Chang-Sen (58549238400); Qin, Lang-Yue (58549148100); Cheng, Yi-Wei (57886334000)|56213912500; 57228349100; 58000743300; 58549238400; 58549148100; 57886334000|Multi-path Coverage Test Case Generation Combining Chained SVM and XGBoost; [结合 SVM 与 XGBoost 的链式多路径覆盖测试用例生成]|2024|Ruan Jian Xue Bao/Journal of Software|35|6||2795|2820|25|1|10.13328/j.cnki.jos.006905|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190120405&doi=10.13328%2fj.cnki.jos.006905&partnerID=40&md5=b4463f8f50cae88756894e7e5380d354|Machine learning methods can be well combined with software testing to enhance test effect, but few scholars have applied it to test data generation. In order to further improve the efficiency of test data generation, a chained model combining support vector machine (SVM) and extreme gradient boosting (XGBoost) is proposed, and multi-path test data generation is realized by a genetic algorithm based on the chained model. Firstly, this study uses certain samples to train several sub-models (i.e., SVM and XGBoost) for predicting the state of path nodes, filters the optimal sub-models based on the prediction accuracy value of the sub-models, and links the optimal sub-models in sequence according to the order of the path nodes, so as to form a chained model, namely chained SVM and XGBoost (C-SVMXGBoost). When using the genetic algorithm to generate test cases, the study makes use of the chained model that is trained instead of the instrumentation method to obtain the test data coverage path (i.e., predicted path), finds the path set with the predicted path similar to the target path, performs instrumentation verification on the predicted path with similar path sets, obtains accurate paths, and calculates fitness values. In the crossover and mutation process, excellent test cases with a large path level depth in the sample set are introduced for reuse to generate test data covering the target path. Finally, individuals with higher fitness during the evolutionary generation are saved, and C-SVMXGBoost is updated, so as to further improve the test efficiency. Experiments show that C-SVMXGBoost is more suitable for solving the path prediction problem and improving the test efficiency than other chained models. Moreover, compared with the existing classical methods, the proposed method can increase the coverage rate by up to 15%. The mean evolutionary algebra is also reduced, and the reduction percentage can reach 65% on programs of large size. © 2024 Chinese Academy of Sciences. All rights reserved.|chained model; extreme gradient boosting (XGBoost); multi-path coverage; support vector machine (SVM); test case|Efficiency; Forecasting; Genetic algorithms; Learning systems; Software testing; Well testing; Chained model; Extreme gradient boosting (xgboost); Gradient boosting; Multi-path coverage; Multipath; Path coverage; Submodels; Support vector machine; Support vectors machine; Test case; Support vector machines|Article|Final||Scopus|2-s2.0-85190120405
scopus|Liu Z.; Yan M.; Gao Z.; Li D.; Zhang X.; Yang D.|Liu, Zhipeng (59201703400); Yan, Meng (56230838000); Gao, Zhipeng (57215134215); Li, Dong (59443909400); Zhang, Xiaohong (55276997400); Yang, Dan (8568055400)|59201703400; 56230838000; 57215134215; 59443909400; 55276997400; 8568055400|AW4C: A Commit-Aware C Dataset for Actionable Warning Identification|2024|Proceedings - 2024 IEEE/ACM 21st International Conference on Mining Software Repositories, MSR 2024||||133|137|4|0|10.1145/3643991.3644885|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197419135&doi=10.1145%2f3643991.3644885&partnerID=40&md5=8160fd5a824e8a9792994cc021ebc39b|Excessive non-actionable warnings generated by static program analysis tools can hinder developers from utilizing these tools effectively. Leveraging learning-based approaches for actionable warning identification has demonstrated promise in boosting developer productivity, minimizing the risk of bugs, and reducing code smells. However, the small sizes of existing datasets have limited the model choices for machine learning researchers, and the lack of aligned fix commits limits the scope of the dataset for research. In this paper, we present AW4C, an actionable warning C dataset that contains 38,134 actionable warnings mined from more than 500 repositories on GitHub. These warnings are generated via Cppcheck, and most importantly, each warning is precisely mapped to the commit where the corrective action occurred. To the best of our knowledge, this is the largest publicly available actionable warning dataset for C programming language to date. The dataset is suited for use in machine/deep learning models and can support a wide range of tasks, such as actionable warning identification and vulnerability detection. Furthermore, we have released our dataset1 and a general framework for collecting actionable warnings on GitHub2 to facilitate other researchers to replicate our work and validate their innovative ideas.CCS Concepts• Software and its engineering → Software maintenance tools; Software creation and management; Software testing and debugging;• Mathematics of computing → Data mining.  © 2024 ACM.|Actionable warning identification; Static program analysis|C (programming language); Data mining; Learning systems; Program debugging; Actionable warning identification; Analysis tools; C++ programming; Code smell; Corrective actions; Learning models; Learning-based approach; Machine-learning; Model choice; Static program analysis; Software testing|Conference paper|Final||Scopus|2-s2.0-85197419135
scopus|Dedek C.; Azadgoleh M.A.; Prescott S.A.|Dedek, Christopher (57221742349); Azadgoleh, Mehdi A. (58288195100); Prescott, Steven A. (36606735000)|57221742349; 58288195100; 36606735000|Reproducible and fully automated testing of nocifensive behavior in mice|2023|Cell Reports Methods|3|12|100650||||5|10.1016/j.crmeth.2023.100650|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179801114&doi=10.1016%2fj.crmeth.2023.100650&partnerID=40&md5=a0962af22df1acfb4d8a7570314ce503|Pain in rodents is often inferred from their withdrawal from noxious stimulation. Threshold stimulus intensity or response latency is used to quantify pain sensitivity. This usually involves applying stimuli by hand and measuring responses by eye, which limits reproducibility and throughput. We describe a device that standardizes and automates pain testing by providing computer-controlled aiming, stimulation, and response measurement. Optogenetic and thermal stimuli are applied using blue and infrared light, respectively. Precise mechanical stimulation is also demonstrated. Reflectance of red light is used to measure paw withdrawal with millisecond precision. We show that consistent stimulus delivery is crucial for resolving stimulus-dependent variations in withdrawal and for testing with sustained stimuli. Moreover, substage video reveals “spontaneous” behaviors for consideration alongside withdrawal metrics to better assess the pain experience. The entire process was automated using machine learning. RAMalgo (reproducible automated multimodal algometry) improves the standardization, comprehensiveness, and throughput of preclinical pain testing. © 2023 The Authors|artificial intelligence; automation; behavior; CP: neuroscience; machine learning; nociception; optogenetics; pain; reproducibility; sensitivity; somatosensory|Animals; Behavior, Animal; Mice; Pain; Pain Measurement; Pain Threshold; Reproducibility of Results; accuracy; algometry; animal behavior; animal experiment; animal model; Article; automation; clinical research; controlled study; female; hand stimulation; infrared radiation; machine learning; male; mechanical stimulation; mouse; nocifensive behavior; nonhuman; optogenetics; pain; paw withdrawal latency; photostimulation; reflectometry; reflex; reproducibility; software; standardization; stimulation; stimulus response; thermal stimulation; animal; animal behavior; pain; pain measurement; pain threshold; physiology; reproducibility|Article|Final|All Open Access; Green Open Access|Scopus|2-s2.0-85179801114
scopus|Silveira B.; Durelli V.; Santos S.; Durelli R.; Delamaro M.; Souza S.|Silveira, Beatriz (57316550000); Durelli, Vinicius (37022886400); Santos, Sebastião (57212496613); Durelli, Rafael (36184908100); Delamaro, Marcio (6602659678); Souza, Simone (36899404000)|57316550000; 37022886400; 57212496613; 36184908100; 6602659678; 36899404000|Test Data Selection Based on Applying Mutation Testing to Decision Tree Models|2023|ACM International Conference Proceeding Series||||38|46|8|1|10.1145/3624032.3624038|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175401484&doi=10.1145%2f3624032.3624038&partnerID=40&md5=c5ee16c8b5d199a901d2f9a7eb69aa7d|Software testing is crucial to ensure software quality, verifying that it behaves as expected. This activity plays a crucial role in identifying defects from the early stages of the development process. Software testing is especially essential in complex or critical systems, such as those using Machine Learning (ML) techniques, since the models can present uncertainties and errors that affect their reliability. This work investigates the use of mutation testing to support the validation of ML applications. Our approach involves applying mutation analysis to the decision tree structure. The resulting mutated trees are a reference for selecting a test dataset that can effectively identify incorrect classifications in machine learning models. Preliminary results suggest that the proposed approach can successfully improve the test data selection for ML applications.  © 2023 ACM.|Decision Tree; Machine Learning; Mutation Testing; Software Testing|Classification (of information); Computer software selection and evaluation; Data reduction; Machine learning; Software reliability; Software testing; Statistical tests; Data Selection; Decision-tree model; Development process; Machine learning applications; Machine-learning; Mutation testing; Selection based; Software Quality; Software testings; Test data; Decision trees|Conference paper|Final||Scopus|2-s2.0-85175401484
scopus|Matey-Sanz M.; Gonzalez-Perez A.; Casteleyn S.; Granell C.|Matey-Sanz, Miguel (57210556658); Gonzalez-Perez, Alberto (57194053428); Casteleyn, Sven (7801625436); Granell, Carlos (8833951100)|57210556658; 57194053428; 7801625436; 8833951100|Implementing and Evaluating the Timed Up and Go Test Automation Using Smartphones and Smartwatches|2024|IEEE Journal of Biomedical and Health Informatics|28|11||6594|6605|11|0|10.1109/JBHI.2024.3456169|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203793675&doi=10.1109%2fJBHI.2024.3456169&partnerID=40&md5=05e11a720ef6d9dba190a4fd72c2da3e|Physical performance tests aim to assess the physical abilities and mobility skills of individuals for various healthcare purposes. They are often driven by experts and usually performed at their practice, and therefore they are resource-intensive and time-demanding. For tests based on objective measurements (e.g., duration, repetitions), technology can be used to automate them, allowing the patients to perform the test themselves, more frequently and anywhere, while alleviating the expert from supervising the test. The well-known Timed Up and Go (TUG) test, typically used for mobility assessment, is an ideal candidate for automation, as inertial sensors (among others) can be deployed to detect the various movements constituting the test without expert supervision. To move from expert-led testing to self-administered testing, we present a mHealth system capable of automating the TUG test using a pocket-sized smartphone or a wrist smartwatch paired with a smartphone, where data from inertial sensors are used to detect the activities carried out by the patient while performing the test and compute their results in real time. All processing (i.e., data processing, machine learning-based activity inference, results calculation) takes place on the smartphone. The use of both devices to automate the TUG test was evaluated (w.r.t. accuracy, reliability and battery consumption) and mutually compared, and set off with a reference method, obtaining excellent Bland-Altman agreement results and Intraclass Correlation Coefficient reliability. Results also suggest that the smartwatch-based system performs better than the smartphone-based system. © 2013 IEEE.|mHealth; smartphone; smartwatch; Timed Up and Go|Adult; Aged; Female; Humans; Male; Middle Aged; Smartphone; Telemedicine; Wearable Electronic Devices; mHealth; Inertial sensor; Mobility assessments; Mobility skills; Objective measurement; Performance tests; Physical performance; Smart phones; Smartwatch; Test Automation; Timed up and go; adult; aged; aging; Article; automation; clinical article; correlation coefficient; data processing; disease severity; energy consumption; fall risk assessment; female; fitness; gyroscope sensor; health care facility; heart rate; human; machine learning; male; normal human; Parkinson disease; physical capacity; physical performance; risk assessment; sitting; standing; timed up and go test; turnover rate; walk test; walking; wrist; devices; middle aged; smartphone; telemedicine; wearable computer|Article|Final|All Open Access; Hybrid Gold Open Access|Scopus|2-s2.0-85203793675
scopus|Lima R.F., Jr.; Presta L.F.P.B.; Borborema L.S.; Silva V.N.; Dahia M.L.M.; Santos A.|Lima, Roberto F. (58781726000); Presta, Luiz Fernando P.B. (59296447000); Borborema, Lucca S. (58782824100); Silva, Vanderson N. (58782160200); Dahia, Marcio L.M. (36616965900); Santos, Anderson (59158037400)|58781726000; 59296447000; 58782824100; 58782160200; 36616965900; 59158037400|A Case Study on Test Case Construction with Large Language Models: Unveiling Practical Insights and Challenges|2024|27th Ibero-American Conference on Software Engineering, CIbSE 2024||||388|395|7|2||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201957632&partnerID=40&md5=82eea4f4cafd1142e63291f9952377ef|This study delves into the integration of Large Language Models (LLMs) in test case construction within software engineering, exploring their potential to enhance efficiency and effectiveness in test generation. Leveraging LLMs, known for their sophisticated natural language processing abilities, this research conducts a detailed case study on a representative software application to evaluate the practicality of LLMs in creating detailed and accurate test scenarios. The investigation focuses on the challenges and advantages of LLMs in test case development, assessing their impact on test comprehensiveness, accuracy, and the formulation process. By providing a nuanced understanding of LLMs' role in software testing, this paper aims to inform practitioners and researchers about their potential and limitations, offering insights into their application in real-world testing environments and their contribution to advancing software testing methodologies. © 2024 27th Ibero-American Conference on Software Engineering, CIbSE 2024. All rights reserved.||Computer software selection and evaluation; Integration testing; Case-studies; Language model; Language processing; Natural languages; Processing ability; Software applications; Software testings; Test case; Test generations; Test scenario; Application programs|Conference paper|Final||Scopus|2-s2.0-85201957632
scopus|Pham V.-H.; Thi Thu Hien D.; Phuc Chuong N.; Thanh Thai P.; The Duy P.|Pham, Van-Hau (59157724400); Thi Thu Hien, Do (59158512300); Phuc Chuong, Nguyen (59367438200); Thanh Thai, Pham (59367353700); The Duy, Phan (57202751987)|59157724400; 59158512300; 59367438200; 59367353700; 57202751987|A Coverage-Guided Fuzzing Method for Automatic Software Vulnerability Detection Using Reinforcement Learning-Enabled Multi-Level Input Mutation|2024|IEEE Access|12|||129064|129080|16|1|10.1109/ACCESS.2024.3421989|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197516277&doi=10.1109%2fACCESS.2024.3421989&partnerID=40&md5=86e8890767f61bc3bfdae08b8a0f34da|Fuzzing is a popular and effective software testing technique that automatically generates or modifies inputs to test the stability and vulnerabilities of a software system, which has been widely applied and improved by security researchers and experts. The goal of fuzzing is to uncover potential weaknesses in software by providing unexpected and invalid inputs to the target program to monitor its behavior and identify errors or unintended outcomes. Recently, researchers have also integrated promising machine learning algorithms, such as reinforcement learning, to enhance the fuzzing process. Reinforcement learning (RL) has been proven to be able to improve the effectiveness of fuzzing by selecting and prioritizing transformation actions with higher coverage, which reduces the required effort to uncover vulnerabilities. However, RL-based fuzzing models also encounter certain limitations, including an imbalance between exploitation and exploration. In this study, we propose a coverage-guided RL-based fuzzing model that enhances grey-box fuzzing, in which we leverage deep Q-learning to predict and select input variations to maximize code coverage and use code coverage as a reward signal. This model is complemented by simple input selection and scheduling algorithms that promote a more balanced approach to exploiting and exploring software. Furthermore, we introduce a multi-level input mutation model combined with RL to create a sequence of actions for comprehensive input variation. The proposed model is compared to other fuzzing tools in testing various real-world programs, where the results indicate a notable enhancement in terms of code coverage, discovered paths, and execution speed of our solution. © 2024 The Authors. This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License.|coverage fuzzing; fuzzing; Reinforcement learning; vulnerability detection|Codes (symbols); Deep learning; Fault detection; Learning algorithms; Scheduling algorithms; Software testing; Code; Coverage fuzzing; Faults diagnosis; Fuzzing; Q-learning; Reinforcement learnings; Software; Source-coding; Vulnerability detection; Reinforcement learning|Article|Final|All Open Access; Gold Open Access|Scopus|2-s2.0-85197516277
scopus|Marques J.P.; Lima M.; Souza B.; Miranda E.; Santos A.; Collins E.|Marques, João Paulo (58573478300); Lima, Mônica (58674375900); Souza, Bruno (57192257094); Miranda, Eloise (58674394700); Santos, André (58715238000); Collins, Eliane (55319962600)|58573478300; 58674375900; 57192257094; 58674394700; 58715238000; 55319962600|SelectNLTest - Selection and natural language rewriting of test cases generated by the DRL-MOBTEST tool|2023|ACM International Conference Proceeding Series||||77|85|8|0|10.1145/3624032.3624043|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175398330&doi=10.1145%2f3624032.3624043&partnerID=40&md5=60140ae7cf6b9b53f61a0dda3ca5a675|The software testing process is important to ensure quality, especially in mobile applications that have characteristics such as platform diversity, hardware limitations, portability, frequent updates, among others. Software companies need to deliver quickly with increasingly complex functionalities; therefore, the testing process must be efficient and avoid bottlenecks, such as the creation of test cases. Among the solutions found in the literature, the state-of-the-art tool DRL-MOBTEST aims to assist in the automatic generation of test cases for mobile applications using deep reinforcement learning. The experiments show promising results; however, the tool has some limitations, such as generating duplicate and less readable tests. In this article, we present SelectNLTest, a module developed to identify and remove similar test scripts and transcribe the test cases generated by the tool using Natural Language Processing techniques. This allows for the removal of similar tests and improves the readability and understanding of the generated test cases for professionals in the field. The results of the experiments showed that, in 10 Android applications used in the comparative analysis, the proposed module reduced the number of test cases by 58.3% while maintaining code coverage and application functionality.  © 2023 ACM.|automatic test generation; coverage analysis; deep reinforcement learning; natural language|Application programs; Computer software portability; Computer software selection and evaluation; Deep learning; Learning algorithms; Mobile computing; Natural language processing systems; Software testing; Automatic test generation; Coverage analysis; Deep reinforcement learning; Mobile applications; Natural languages; Platform diversity; Reinforcement learnings; Software testings; Test case; Testing process; Reinforcement learning|Conference paper|Final||Scopus|2-s2.0-85175398330
scopus|Sun W.; Xue X.; Lu Y.; Zhao J.; Sun M.|Sun, Weidi (57210751517); Xue, Xiaoyong (58036695700); Lu, Yuteng (57204726686); Zhao, Jia (58734466800); Sun, Meng (53983437100)|57210751517; 58036695700; 57204726686; 58734466800; 53983437100|HashC: Making deep learning coverage testing finer and faster|2023|Journal of Systems Architecture|144||102999||||1|10.1016/j.sysarc.2023.102999|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173528733&doi=10.1016%2fj.sysarc.2023.102999&partnerID=40&md5=09c06986ee103ccb74876e3891d369a3|Though Deep Neural Networks (DNNs) have been widely deployed and achieved great success in many domains, they have severe safety and reliability concerns. To provide testing evidence for DNNs’ reliable behaviors, various coverage testing techniques inspired by traditional software testing have been proposed. However, the coverage criteria in these techniques are either not fine enough to capture subtle behaviors of DNNs, or too time-consuming to be applied on large-scale DNNs. In this paper, we propose a coverage testing framework named HashC, which makes mainstream coverage criteria (e.g., NC and KMNC) much finer. Meanwhile, HashC reduces the time complexity of combinatorial coverage testing from polynomial time to linear time. We also develop the corresponding test sample selection method. Our experiments show that, (1) the existing mainstream coverage criteria are becoming finer after being equipped with HashC, (2) HashC greatly accelerates combinatorial coverage testing and can handle the testing of large-scale DNNs. © 2023 Elsevier B.V.|Coverage criteria; HashC; Neural networks; Testing|Consumer behavior; Polynomial approximation; Software testing; Coverage criteria; Coverage testing; Hashc; Large-scales; Neural-networks; Polynomial-time; Software testings; Testing framework; Testing technique; Time complexity; Deep neural networks|Article|Final||Scopus|2-s2.0-85173528733
scopus|Nasra P.|Nasra, Parul (58928907700)|58928907700|Lung Cancer Classification using ResNet50|2024|2nd International Conference on Intelligent Cyber Physical Systems and Internet of Things, ICoICI 2024 - Proceedings||||1201|1205|4|0|10.1109/ICoICI62503.2024.10696405|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207181442&doi=10.1109%2fICoICI62503.2024.10696405&partnerID=40&md5=3b470760686d3c53e21bc1e1255869d0|Lung cancer is still the most often occurring and lethal form of cancer globally, contributing significantly to the annual death from cancer. With the use of efficient and automated testing technologies, the project seeks to lower mortality rates and improve early detection accuracy. Improving survival rates requires early diagnosis, but because current diagnostic techniques such as imaging and biopsies rely so much on clinical presentation, they frequently lead to late diagnoses. One of the most efficient deep learning architectures for applications involving image recognition is Convolutional Neural Networks. A version of the ResNet (Residual Networks) architecture known as ResNet50 has become well-known for its capacity to lessen the vanishing gradient issue and make intense network training possible. ResNet50, which has been pre-trained on ImageNet, is used in this study as a feature extractor to detect lung cancer. The outcomes of the experiments indicate that the ResNet50-based model is highly accurate in differentiating between malignant lung tissues and those that are not. In addition to Accuracy, the model's efficiency in managing and analyzing images offers significant advantages over traditional diagnostic methods. The application of ResNet50 to the diagnosis of lung cancer demonstrates the Deep learning transformative potential models in the field of cancer diagnostics. This study provides a reliable, accurate, and valuable diagnostic tool, which contributes to the ongoing efforts to improve the early identification and treatment outcomes for patients with lung cancer. Lung tumor identification and diagnosis have greatly benefited from the use of deep learning and convolutional neural networks. These technologies improve the precision and effectiveness of medical imaging analysis by utilizing advanced image processing and pattern recognition capabilities. © 2024 IEEE.|Convolutional Neural Network; Deep Learning; Image Classification; Lung Cancer; ResNet50; Transfer Learning|Diseases; Automated testing; Cancer classification; Convolutional neural network; Deep learning; Images classification; Lung Cancer; Mortality rate; Resnet50; Testing technology; Transfer learning; Lung cancer|Conference paper|Final||Scopus|2-s2.0-85207181442
scopus|Yusupova S.B.; Davletboyev S.Z.; Ishmetov B.Y.|Yusupova, Shohida B. (57463407900); Davletboyev, Sardorbek Z. (58810626200); Ishmetov, Bahrom Y. (57462606100)|57463407900; 58810626200; 57462606100|Development of a Flexible Student Training System Using the Moodle LMS|2024|Proceedings of the IEEE 3rd International Conference on Problems of Informatics, Electronics and Radio Engineering, PIERE 2024||||1450|1453|3|1|10.1109/PIERE62470.2024.10804952|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216550838&doi=10.1109%2fPIERE62470.2024.10804952&partnerID=40&md5=6359de1808a3e68791dd763d8f4786d9|In today's era of extensive information flow and the rise of distance education, there is a growing need for innovative educational technologies that can support personalized learning paths. This article explores the development of an adaptive learning system within the Moodle LMS, focusing on the implementation of individual educational trajectories based on automated testing and neural network models. The system enables the delivery of educational materials at varying levels of complexity, combined with adaptive tests that adjust based on student performance. Through machine learning, neural networks evaluate students' knowledge and generate customized training courses tailored to their needs. The proposed system addresses the limitations of traditional assessment methods, such as subjectivity in grading, by offering a more objective, data-driven approach. The use of adaptive testing and neural networks enhances the accuracy of knowledge assessment and fosters independent learning, ultimately contributing to improved educational outcomes in a distance learning environment. © 2024 IEEE.|Adaptive tests; assessment; expert system; fuzzy algorithm; LMS Moodle; neural network; preceptor; test bank|Adaptive algorithms; Contrastive Learning; Distance education; Educational technology; Federated learning; Fuzzy inference; Fuzzy neural networks; Neural network models; Self-supervised learning; Students; Adaptive tests; Assessment; Fuzzy algorithms; Information flows; LMS moodle; Neural-networks; Preceptor; Student training; Test bank; Training Systems; Adversarial machine learning|Conference paper|Final||Scopus|2-s2.0-85216550838
scopus|Hassan M.N.H.B.; Halim S.B.A.; Hassan R.B.|Hassan, Mohamad Nur Hafizhan Bin (58696054800); Halim, Shahliza Binti Abd (57196449329); Hassan, Rohayanti Binti (35310505600)|58696054800; 57196449329; 35310505600|The implementation of clustering algorithm in mutation testing|2023|AIP Conference Proceedings|2827|1|30027||||0|10.1063/5.0165124|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176757869&doi=10.1063%2f5.0165124&partnerID=40&md5=9de6e946266463f27afeb6c0838eeab1|Software testing phase is one of the most significant phases within the System Development Life Cycle (SDLC) since software bugs can be costly and traumatic. Originally, the implementation of software testing was done manually where the test cases are executed manually without any support from scripts or tools and then multiples of tools were introduced to help the implementation where automated testing taking place throughout the process where test cases are executed using the scripts, tools and software to provide the level of product's quality. Now with the widely known Artificial Intelligence (AI) technologies gaining place in industry, it is transforming the software testing in ways that could not have been dreamt of a decade ago including reducing the need for test maintenance, simplifying test creation, and driving new ways to assess the results. Machine learning is one of the branches in AI that happen to be a new dominated technology in industry. The use of machine learning in software testing's process is rarely implemented in the market, machine learning focus on the use of data and algorithms to imitate the way that humans learn, gradually improve its accuracy and it is an important component of the growing field of data science. In machine learning there are multiple algorithms to be use as an approach that can help to improve the way to manage and understand the results produced from the testing. The use of machine learning in this area theoretically able to provide a faster and easier test creation, make the test analysis much simpler and reducing the needs of test maintenance. In this study will be focusing on using clustering which is one of algorithm in machine learning as an approach to increase the mutation score of mutation testing which is one of the software testing methods on fault-based testing. © 2023 Author(s).|||Conference paper|Final||Scopus|2-s2.0-85176757869
scopus|Yadav A.B.; Udaykumar M.|Yadav, Aniruddh Bahadur (55838644700); Udaykumar, Mudigonda (59340851200)|55838644700; 59340851200|Scan and Automated Test Pattern Generation in VLSI|2024|Proceedings - 2024 5th International Conference on Image Processing and Capsule Networks, ICIPCN 2024||||424|429|5|0|10.1109/ICIPCN63822.2024.00075|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204767343&doi=10.1109%2fICIPCN63822.2024.00075&partnerID=40&md5=2404c1941ce77722bee604a7cfa877b0|Integrated circuits (ICs) are becoming more and more complicated, which makes it difficult to guarantee their functioning and dependability. Automated testing techniques are crucial for identifying and resolving this issue by identifying and diagnosing IC problems. Among these approaches, test pattern generation and scan-based testing are essential for quickly locating and analyzing flaws. The creation of an automated system for test pattern generation and scan-based testing in the context of ICs is the main goal of this study. The suggested solution makes use of cutting-edge algorithms and methodologies to improve the efficacy and efficiency of the testing procedure. The system's initial component entails incorporating scan chains into the IC design. Scan chains offer observable and adjustable places in the circuit, making it possible to apply test patterns and track responses. This integration makes it possible to isolate and analyze particular IC portions, which enables thorough testing. The system's second part deals with the automatic creation of test patterns. Given the complexity of current ICs, traditional approaches for generating test patterns may be both time-consuming and not the best. The suggested method creates test patterns intelligently by utilizing sophisticated algorithms, including machine learning and artificial intelligence. These algorithms create effective and high-coverage test patterns by examining the circuit's architecture, functioning, and past test data. Moreover, the system integrates self-learning techniques to adjust to changing fault models and integrated circuit designs. Because of its flexibility, testing can continue to be efficient even with increasingly complex IC architectures. The suggested system's efficacy in terms of fault coverage, test time reduction, and adaptation to different IC designs is demonstrated by the experimental evaluation. The outcomes show a notable improvement over conventional testing methods, underscoring the automated scan and test pattern generation system's potential to raise the effectiveness and dependability of IC testing.  © 2024 IEEE.|Automated Testing; Integrated circuits (ICs); Machine Learning (ML) and Artificial Intelligence (AI)|Automatic test pattern generation; Integrated circuit design; Integrated circuit manufacture; Integrated circuit testing; Integration testing; Machine learning; Automated testing; Circuit architectures; Circuit designs; Integrated circuit; Machine learning  and artificial intelligence; Machine-learning; Scan chain; Scan-based testing; Test Pattern; Test pattern generations; Chains|Conference paper|Final||Scopus|2-s2.0-85204767343
scopus|Laaber C.; Yue T.; Ali S.; Schwitalla T.; Nygård J.|Laaber, Christoph (57194171758); Yue, Tao (25651096400); Ali, Shaukat (56962801700); Schwitalla, Thomas (57193757105); Nygård, Jan (7003875061)|57194171758; 25651096400; 56962801700; 57193757105; 7003875061|Automated Test Generation for Medical Rules Web Services: A Case Study at the Cancer Registry of Norway|2023|ESEC/FSE 2023 - Proceedings of the 31st ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering||||1937|1948|11|5|10.1145/3611643.3613882|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172431647&doi=10.1145%2f3611643.3613882&partnerID=40&md5=3ca247bd1bfb5730356b1ded32efd778|The Cancer Registry of Norway (CRN) collects, curates, and manages data related to cancer patients in Norway, supported by an interactive, human-in-the-loop, socio-technical decision support software system. Automated software testing of this software system is inevitable; however, currently, it is limited in CRN's practice. To this end, we present an industrial case study to evaluate an AI-based system-level testing tool, i.e., EvoMaster, in terms of its effectiveness in testing CRN's software system. In particular, we focus on GURI, CRN's medical rule engine, which is a key component at the CRN. We test GURI with EvoMaster's black-box and white-box tools and study their test effectiveness regarding code coverage, errors found, and domain-specific rule coverage. The results show that all EvoMaster tools achieve a similar code coverage; i.e., around 19% line, 13% branch, and 20% method; and find a similar number of errors; i.e., 1 in GURI's code. Concerning domain-specific coverage, EvoMaster's black-box tool is the most effective in generating tests that lead to applied rules; i.e., 100% of the aggregation rules and between 12.86% and 25.81% of the validation rules; and to diverse rule execution results; i.e., 86.84% to 89.95% of the aggregation rules and 0.93% to 1.72% of the validation rules pass, and 1.70% to 3.12% of the aggregation rules and 1.58% to 3.74% of the validation rules fail. We further observe that the results are consistent across 10 versions of the rules. Based on these results, we recommend using EvoMaster's black-box tool to test GURI since it provides good results and advances the current state of practice at the CRN. Nonetheless, EvoMaster needs to be extended to employ domain-specific optimization objectives to improve test effectiveness further. Finally, we conclude with lessons learned and potential research directions, which we believe are applicable in a general context. © 2023 ACM.|automated software testing; cancer registry; electronic health records; REST APIs; rule engine; test generation|Automation; Decision support systems; Diseases; Engines; Software testing; Automated software testing; Black boxes; Cancer registries; Electronic health; Electronic health record; Health records; REST API; Rule engine; Software-systems; Test generations; Web services|Conference paper|Final|All Open Access; Green Open Access|Scopus|2-s2.0-85172431647
scopus|Asaad J.; Avksentieva E.|Asaad, Jameleh (58744629900); Avksentieva, Elena (57204910364)|58744629900; 57204910364|Review of ways to apply machine learning methods in software engineering|2023|E3S Web of Conferences|449||7018||||2|10.1051/e3sconf/202344907018|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178611846&doi=10.1051%2fe3sconf%2f202344907018&partnerID=40&md5=3860ddd6411e090ca8f071b063df3e81|This article reviews the integration of machine learning (ML) techniques into Software Engineering (SE) across various phases of the software development life cycle (SDLC). The purpose is to investigate the applications of ML in SE, analyze its methodologies, present findings, and draw conclusions regarding its impact. The study categorized ML applications in SE and assessed the performance of various ML algorithms. Authors identified ML applications in SDLC phases, including requirements analysis, design, implementation, testing, and maintenance. ML algorithms, such as supervised and unsupervised learning, are employed for tasks like software requirement identification, design pattern recognition, code generation, and automated testing. In summary, we find that ML-based techniques are experiencing a substantial surge in adoption within the field of software engineering. Nevertheless, it is evident that substantial endeavors are needed to establish thorough comparisons and synergies among these approaches, perform meaningful evaluations grounded in detailed real-world implementations that are applicable to industrial software development. Therefore, our key takeaway is the necessity for a shift in focus towards reproducible research, prioritizing this over isolated novel concepts. Failure to do so may result in the limited practical implementation of these promising applications. © 2023 EDP Sciences. All rights reserved.|||Conference paper|Final|All Open Access; Gold Open Access; Green Open Access|Scopus|2-s2.0-85178611846
scopus|Zhang F.; Wu Q.; Xuan B.; Chen Y.; Lin W.; Poskitt C.M.; Sun J.; Chen B.|Zhang, Fan (56469982000); Wu, Qianmei (57827457500); Xuan, Bohan (57218364669); Chen, Yuqi (57192062465); Lin, Wei (58553361300); Poskitt, Christopher M. (36698287200); Sun, Jun (56153273100); Chen, Binbin (56367849500)|56469982000; 57827457500; 57218364669; 57192062465; 58553361300; 36698287200; 56153273100; 56367849500|Constructing Cyber-Physical System Testing Suites Using Active Sensor Fuzzing|2023|IEEE Transactions on Software Engineering|49|11||4829|4845|16|0|10.1109/TSE.2023.3309330|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176375223&doi=10.1109%2fTSE.2023.3309330&partnerID=40&md5=b60bb9ac8b858ede91e30d0793d977bd|Cyber-physical systems (CPSs) automating critical public infrastructure face a pervasive threat of attack, motivating research into different types of countermeasures. Assessing the effectiveness of these countermeasures is challenging, however, as benchmarks are difficult to construct manually, existing automated testing solutions often make unrealistic assumptions, and blindly fuzzing is ineffective at finding attacks due to the enormous search spaces and resource requirements. In this work, we propose active sensor fuzzing, a fully automated approach for building test suites without requiring any a prior knowledge about a CPS. Our approach employs active learning techniques. Applied to a real-world water treatment system, our approach manages to find attacks that drive the system into 15 different unsafe states involving water flow, pressure, and tank levels, including nine that were not covered by an established attack benchmark. Furthermore, we successfully generate targeted multi-point attacks which have been long suspected to be possible. We reveal that active sensor fuzzing successfully extends the attack benchmarks generated by our previous work, an ML-guided fuzzing tool, with two more kinds of attacks. Finally, we investigate the impact of active learning on models and the reason that the model trained with active learning is able to discover more attacks.  © 1976-2012 IEEE.|Cyber-physical systems; fuzzing; machine learning; metaheuristic optimisation; testing|Digital storage; Embedded systems; Flow of water; Learning systems; Machine learning; Software testing; Space research; Water treatment; Active sensor; Benchmark testing; Cybe-physical systems; Cyber-physical systems; Fuzzing; Machine-learning; Metaheuristic optimization; Predictive models; Space explorations; Cyber Physical System|Article|Final|All Open Access; Green Open Access|Scopus|2-s2.0-85176375223
scopus|Porter A.A.; Karr A.F.|Porter, Adam A. (7202005069); Karr, Alan F. (7006443279)|7202005069; 7006443279|Active Model Learning for Software Interrogation and Diagnosis|2024|Proceedings - 2024 IEEE International Conference on Software Testing, Verification and Validation Workshops, ICSTW 2024||||93|100|7|0|10.1109/ICSTW60967.2024.00026|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205985396&doi=10.1109%2fICSTW60967.2024.00026&partnerID=40&md5=cd77ccab8ea28171ac7fd243971ece3a|We propose extension of the concept of software correctness, and the associated task of software testing, to include interrogation and diagnosis, whereby actionable knowledge about the limitations and performance of the software is gleaned. The new paradigm is especially relevant for AI-based systems such as classifiers and large language models (LLMs) that involve interactions among complex software, underlying training/reference data and the analysis/input data. In this context, the need for both interrogation-to identify problematic outputs when there may be no measure of correctness-and diagnosisto determine where the problem lies-is evident. To make our rhetoric concrete, we present two case studies. Classifier boundaries enable characterization of robustness of classifier output and fragility of inputs. Cliques in metagenomic assembly provide novel insight into the software as well as the potential for performance improvement.  © 2024 IEEE.|classifier; DNA reads; metagenomic assembly; uncertainty|Adversarial machine learning; Contrastive Learning; Input output programs; Software testing; Active models; DNA read; Language model; Metagenomic assembly; Metagenomics; Model learning; Performance; Software correctness; Software testings; Uncertainty; Active learning|Conference paper|Final||Scopus|2-s2.0-85205985396
scopus||||SQAMIA 2024 - Proceedings of the 11th Workshop on Software Quality Analysis, Monitoring, Improvement, and Applications|2024|CEUR Workshop Proceedings|3845|||||254|0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211935377&partnerID=40&md5=57f60cb587b5ff5d99388c06f244cfd3|The proceedings contain 23 papers. The topics discussed include: a structural approach to program similarity analysis; exploring legacy software quality by a metrics tool: an experience report; forecasting cryptocurrency prices using advanced machine learning techniques; enhancing SEO compliance of JavaScript web frameworks through automated testing inside CI/CD pipelines; machine learning optimizations of BioMeld-Voxelyze simulator; smart system for real-time monitoring of vital parameters; prospects of explainability in the hugging face hub landscape; empowering connected healthcare: addressing challenges and evolutions in a distributed centralized medical information system; detecting and ranking atom creation related bottlenecks; and continuous source code rejuvenation in continuous integration pipelines.|||Conference review|Final||Scopus|2-s2.0-85211935377
scopus|Wang Y.; Huang S.; Xu Y.; Zhang H.|Wang, Yuqi (59378246800); Huang, Shuwen (59378546500); Xu, Yuhan (59378103700); Zhang, Hongwei (59378175200)|59378246800; 59378546500; 59378103700; 59378175200|Research on Software Defects Prediction and Peformance Analysis based on Machine Learning|2024|2024 7th International Conference on Computer Information Science and Application Technology, CISAT 2024||||774|777|3|1|10.1109/CISAT62382.2024.10695196|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207086578&doi=10.1109%2fCISAT62382.2024.10695196&partnerID=40&md5=6babd8c558e01cd5d72db032ae907e86|With the rapid increase in the number of various types of software, the importance of software quality has become increasingly prominent, and software testing has become an indispensable part of the software development process. With the increasing demand for software testing, various emerging technologies have been introduced into the testing field, among which machine learning has gradually become the mainstream technology in software defect prediction due to its predictive model and scalability. In this work, we utilize XGBoost model for training and prediction. Specifically, data preprocessing including missing value processing and data standardization, followed by feature selection through statistical analysis and algorithmic methods to extract the most representative features. During the model training phase, grid search is used to optimize XGBoost's hyperparameters, such as the number of trees, depth, and learning rate. During training, XGBoost improves prediction performance by gradually building a decision tree and minimizing the loss function. Finally, cross-validation and confusion matrix are used to evaluate the performance of the model to ensure high prediction accuracy and stability. Experimental analysis shows that the XGBoost model has excellent performance in prediction accuracy and performance, which effectively improves the efficiency and accuracy of software defect detection. © 2024 IEEE.|Machine learning; Performance analysis; Software defects prediction; XGBoost Model|Adversarial machine learning; Computer software selection and evaluation; Contrastive Learning; Software quality; Software testing; Machine-learning; On-machines; Peformance analysis; Performances analysis; Prediction accuracy; Prediction performance; Software defect prediction; Software testings; Xgboost model; Prediction models|Conference paper|Final||Scopus|2-s2.0-85207086578
scopus|Machado R.; Zelindro A.; Farias G.; Adamatti D.; Gonçalves E.|Machado, Ricardo (57211168489); Zelindro, Arthur (59247687900); Farias, Giovani (54918115500); Adamatti, Diana (25929020300); Gonçalves, Eder (26667621000)|57211168489; 59247687900; 54918115500; 25929020300; 26667621000|MAMTCPN: Moise+ Automated Mapping to Colored Petri Net|2024|Lecture Notes in Networks and Systems|1067 LNNS|||24|37|13|1|10.1007/978-3-031-66431-1_2|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201121229&doi=10.1007%2f978-3-031-66431-1_2&partnerID=40&md5=aa82c3d635c14f3fe52d577feb9bad95|The demand for systems with artificial intelligence, such as multi-agent systems, is continuously growing. At the same time, there is a need for the development of tools for helping this area, ensuring better fault tolerance for the project, since these systems have characteristics that make the system non-deterministic and increase the difficulty in carrying out tests. To try to solve this problem, a mapping tool was developed that automatically generates a graphical model that can be used to identify test paths for a given multi-agent system. This tool takes as input an XML file from Moise+, an organizational model for multi-agent systems, mapping it into a colored Petri net, a graphical and mathematical modeling tool. The resulting mapping is used to generate test cases, necessary for validating the Moise+ model, being used as a guide when carrying out system tests. Automation makes the process faster and eliminates the possibility of human error. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.|Mapping; Moise; Multi-agent; Petri Net; Tests; Tool|Fault tolerance; Mapping; Petri nets; Automated mapping; Colored Petri Nets; Deterministics; GraphicaL model; Mapping tools; Moise; Multi agent; Organizational models; Test; XML files; Multi agent systems|Conference paper|Final||Scopus|2-s2.0-85201121229
scopus|Al-Qudah R.A.; Suen C.Y.|Al-Qudah, Rabiah A. (57203465725); Suen, Ching Y. (7102317250)|57203465725; 7102317250|A Data-Centric Approach to Investigate the Feasibility of Utilizing Animal Medical Data as a Solution for Human Medical Data Scarcity|2024|IEEE Access|12|||163326|163337|11|0|10.1109/ACCESS.2024.3487851|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208230872&doi=10.1109%2fACCESS.2024.3487851&partnerID=40&md5=bf700dab64d3d17102dd18e24d126831|Reticulocyte count is a routine blood test that can be an essential source of knowledge for medical doctors to diagnose and assess patients' health condition. In fact, the automation of this blood test will reduce cost and time, in addition to protecting laboratorians' lives, especially during pandemics and outbreaks. However, human reticulocyte data scarcity is a main challenge that slows the pace of the test automation. In this paper, a novel method that assesses the feasibility of using animal reticulocyte cells as a solution to compensate for the scarcity of human reticulocyte data is investigated. The integration of animal cells will be implemented by utilizing a data-centric artificial intelligence approach, in addition to employing multiple deep classifiers that utilize transfer learning in different experimental setups in a procedure that mimics the protocol followed in experimental medical labs. Moreover, to evaluate the effectiveness of the proposed method, three evaluation criteria have been proposed, namely, the pretraining boost, the dataset similarity boost, and the dataset size boost measures. All the experiments of this work were conducted on a public human reticulocyte dataset and the best performing model achieved 98.9%, 98.9%, 98.6% average accuracy, average macro precision, and average macro F-score respectively. Moreover, the results showed that using animals medical data holds a promising solution for human medical data scarcity, as utilizing weights that were pretrained on a medium size feline reticulocyte dataset outperformed the model that utilized weights that were pretrained on the large scale ImageNet dataset. ©2024 The Authors.|Automated blood smear analysis; computer aided diagnosis; data centric artificial intelligence; data scarcity; deep learning; reticulocyte|Data accuracy; Automated blood smear analyze; Blood smears; Blood test; Computer-aided; Data centric; Data centric artificial intelligence; Data scarcity; Deep learning; Medical data; Reticulocyte; Macroinvertebrates|Article|Final|All Open Access; Gold Open Access|Scopus|2-s2.0-85208230872
scopus|Scott J.; Pan G.; Jha P.; Khalil E.B.; Ganesh V.|Scott, Joseph (57197623960); Pan, Guanting (57886159400); Jha, Piyush (57205557861); Khalil, Elias B. (58904984100); Ganesh, Vijay (36018364100)|57197623960; 57886159400; 57205557861; 58904984100; 36018364100|Pierce: A Testing Tool for Neural Network Verification Solvers|2024|Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)|14095 LNCS|||31|43|12|1|10.1007/978-3-031-66064-1_3|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200725939&doi=10.1007%2f978-3-031-66064-1_3&partnerID=40&md5=ccebf979bff494794198b30afd7ce3fb|We introduce Pierce, a versatile and extensible testing tool aimed at solvers for the neural network verification (NNV) problem. At its core, Pierce implements a fuzzing engine over the Open Neural Network Exchange (ONNX) – a standardized model format for deep learning and classical machine learning, and VNN-LIB – a specification standard over the input-output behavior of machine learning systems. Pierce supports the entirety of the VNN-LIB and most of ONNX v18. The API of Pierce is designed to enable users to create a variety of software testing tools, such as performance and mutation fuzzers, as well as delta debuggers, with relative ease. For example, Pierce provides a rich generator for computation graphs and specifications that allows users to easily specify a wide variety of configurations, as well as mutators that ensure that mutated computation graphs are well-formed. Using Pierce we build a reinforcement learning (RL) driven relative performance fuzzer. Using this fuzzer, we expose performance issues in four state-of-the-art solvers, such as Marabou, ERAN, MIPVerify, and nnenum, observing up to a 13.3x times slowdown in cumulative PAR-2 score in the target solvers relative to reference solvers. Further, we leverage Pierce to create a diverse benchmark suite with 10,000 competition-grade NNV instances for the community. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.|AI Testing; Fuzzing; Neural Network Verification|Deep learning; Learning systems; Neural networks; Program debugging; Reinforcement learning; Software testing; Well testing; AI testing; Fuzzing; Input/output behaviors; Machine-learning; Modeling format; Neural network verification; Neural-networks; Standardized models; Testing tools; Verification problems; Specifications|Conference paper|Final||Scopus|2-s2.0-85200725939
scopus|Grube N.; Massah M.; Tebbe M.; Wancura P.; Wiesbrock H.-W.; Grossmann J.; Kharma S.|Grube, Nicolas (58160824800); Massah, Mozhdeh (57191346989); Tebbe, Michael (57222901473); Wancura, Paul (59368643900); Wiesbrock, Hans-Werner (57203618671); Grossmann, Jurgen (24080428700); Kharma, Sami (58160779600)|58160824800; 57191346989; 57222901473; 59368643900; 57203618671; 24080428700; 58160779600|On a Systematic Test of ML-Based Systems: Experiments on Test Statistics|2024|Proceedings - 6th IEEE International Conference on Artificial Intelligence Testing, AITest 2024||||11|20|9|1|10.1109/AITest62860.2024.00010|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198992829&doi=10.1109%2fAITest62860.2024.00010&partnerID=40&md5=2b91ccc87fbc31a1a30faebe918a531f|Machine learning (ML)-based systems are becoming increasingly ubiquitous even in safety critical environments. The strength of ML systems, to solve complex problems with a stochastic model, leads to challenges in the testing domain. This motivates us to introduce a rigorous testing method for ML-models and their application environment akin to classical software testing, which is independent of the training process and considers the probabilistic nature of ML. The approach is based on the concept of the Probabilistically Extended ONtology (PEON). In brief, PEON is a an ontology modeling the designated Operational Design Domain (ODD), which is extended by assigning probability distributions to classes and their individual attributes, as well as probabilistic dependencies between these attributes. The relevant statistical key figures like accuracy depend not only on the ML-based model but also strongly on the statistics of the test data set, which we refer to by quality assurance (QA) data set, to emphasize its independence from the test data set in the training process. This implies that we have to consider the statistical properties of the QA data in order to evaluate an ML-based system. In this paper we present first experimental results comparing established test selection methods e.g. N-wise, with a new approach the PEON. Our findings strongly suggest, that the underlying statistical properties of the QA data significantly influence the test results of ML-based systems. In this respect, careful attention must be paid to the statistical independence and balance of the QA data. The PEON provides a good basis for the composition of QA data sets, which are not only independent of the development process but also statistically representative and balanced with respect to the modeled ODD. © 2024 IEEE.|Black Box Test for AI Systems; Probabilistic Modeling; Systematic Evaluation of Training data sets; Testing AI Systems|Stochastic models; AI systems; Black box test; Black box test for AI system; Machine-learning; Probabilistic models; Systematic evaluation; Systematic evaluation of training data set; Testing AI system; Training dataset; Black-box testing|Conference paper|Final||Scopus|2-s2.0-85198992829
scopus|Halaweh M.; Refae G.E.|Halaweh, Mohanad (25960639300); Refae, Ghaleb El (15026385900)|25960639300; 15026385900|Examining the Accuracy of AI Detection Software Tools in Education|2024|2024 5th International Conference on Intelligent Data Science Technologies and Applications, IDSTA 2024||||186|190|4|1|10.1109/IDSTA62194.2024.10747004|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211939290&doi=10.1109%2fIDSTA62194.2024.10747004&partnerID=40&md5=df3f46488e0fb6939f9b6dced0e55b10|Educators have raised concerns about the utilization of ChatGPT in generating unoriginal text and the possibility of plagiarism. To address these concerns, various AI text detection software tools have been developed to evaluate whether a text is AI generated or human generated. The aim of this research is to empirically examine the accuracy of AI detection tools in identifying AI-generated texts. An experiment was conducted using textual data generated by ChatGPT, which was assessed using Turnitin and four other AI detection tools. Through multiple iterations and interventions, the text was paraphrased by ChatGPT until it appeared original and could not be detected as AI-generated by Turnitin's AI detection tool. The findings revealed that all the AI detection software tools that were examined failed to detect the AI-generated text by ChatGPT in the final iteration. The findings provide valuable insights that have implications for various stakeholders, including educators, researchers, and AI text detection software developers. Based on the tools examined, educators and researchers do not need to set a specific threshold or percentage, including 0%, to determine what qualifies as acceptable AI-generated text. This is because establishing such a threshold can be misleading, considering the current limitations in the algorithms of these tools. Furthermore, the data generated in this paper can provide a solid basis for replicated research or software testing and assessment. It can be utilized to evaluate the accuracy of alternative AI detection tools and any future advancements in the tools mentioned in this investigation. © 2024 IEEE.|AI Detection Tools; Artificial Intelligence; ChatGPT; Education; Generative AI; Turnitin|AI detection; AI detection tool; ChatGPT; Detection software; Detection tools; Generative AI; Software-tools; Text detection; Textual data; Turnitin|Conference paper|Final||Scopus|2-s2.0-85211939290
scopus|Komar M.; Fedorovych V.; Poidych V.; Taborovskyi A.|Komar, Myroslav (35366491300); Fedorovych, Viktor (59220549100); Poidych, Vladyslav (59220440000); Taborovskyi, Andrii (59220655500)|35366491300; 59220549100; 59220440000; 59220655500|Intelligent System For Visual Testing Of Software Products|2024|CEUR Workshop Proceedings|3716|||9|18|9|0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198655776&partnerID=40&md5=be4d0739d34afd5a1cd9dc3f299e942d|This article presents an innovative approach to software product testing through the development of an intelligent system for visual testing, leveraging artificial intelligence to automate and enhance the process. The paper outlines the creation of an integrated system designed to monitor and analyze visual changes in software graphical interfaces. By addressing the limitations of traditional visual snapshot testing, which struggles with the variability of web browsers' versions and types, this system uses a blend of Python and PHP programming languages, Selenium WebDriver testing framework, and ImageMagick library to offer a more robust solution for web interfaces testing. The study emphasizes the growing importance of visual testing in software development, particularly for web and mobile applications, where user interface correctness and usability are critical for market success. It introduces an AI-based method for visual comparison, aiming to streamline the testing process, reduce error detection times, and improve overall product quality. The proposed solution is designed to overcome the challenges of traditional methods by enabling more accurate and efficient testing across different browsers and devices without the need for extensive manual coding or model training. This contribution to the field of software testing and AI application in software development not only provides a practical solution to a common industry challenge but also opens avenues for further research and development in automated visual testing systems. © 2024 Copyright for this paper by its authors.|artificial intelligence; automated testing; graphical interface; Machine learning; pixel comparator; visual element; visual testing|Application programs; Comparators (optical); Machine learning; Software design; Software testing; User interfaces; Visual languages; Web browsers; Automated testing; Graphical interface; Innovative approaches; Integrated systems; Machine-learning; Pixel comparator; Product testing; Software products; Visual elements; Visual testing; Intelligent systems|Conference paper|Final||Scopus|2-s2.0-85198655776
scopus|Azizul Hakim S.M.; Rafiq R.I.; Lingg M.|Azizul Hakim, S.M. (59235428600); Rafiq, Rahat Ibn (56032493700); Lingg, Michael (57204184995)|59235428600; 56032493700; 57204184995|Visualizing Software Test Requirements Using NLP and HITL Approach|2024|Communications in Computer and Information Science|2142 CCIS|||288|298|10|0|10.1007/978-3-031-63616-5_22|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199661879&doi=10.1007%2f978-3-031-63616-5_22&partnerID=40&md5=a9be664550e63264eb48426947d9235d|This research paper presents an innovative approach for capturing and representing system specifications through structured requirements and their visualization using knowledge graphs. We introduce a formalized syntax and structure to define system behavior, conditions, and actions to achieve precision and eliminate ambiguities. The proposed solution encompasses a multi-panel web application featuring a knowledge graph panel, a semistructured requirements panel, a structured requirements panel, and a feedback panel. Users can conveniently edit and save requirements in the semistructured panel, automatically propagating changes to the other panels. Additionally, we fine-tune the CodeT5 language model to effectively convert semistructured requirements into structured ones, facilitating the regeneration of the knowledge graph. This process significantly enhances the intuitive visualization of required dependencies among system components. This methodology enables effective collaboration, validation, and refinement of requirements, thereby substantially improving the quality and accuracy of the software testing process. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.|Human-In-Tha-Loop; Knowledge Graph; NLP; Software Test Generation|Knowledge graph; Software testing; Specifications; Visualization; Human-in-tha-loop; Innovative approaches; Knowledge graphs; Research papers; Semi-structured; Software test generation; System behaviors; Systems specification; Test generations; Test requirements; Natural language processing systems|Conference paper|Final||Scopus|2-s2.0-85199661879
scopus|Fan Y.-L.; Hsu F.-R.; Wang Y.; Liao L.-D.|Fan, Yi-Ling (58527908900); Hsu, Fang-Rong (7202881024); Wang, Yuhling (57212035932); Liao, Lun-De (15065570200)|58527908900; 7202881024; 57212035932; 15065570200|Unlocking the Potential of Zebrafish Research with Artificial Intelligence: Advancements in Tracking, Processing, and Visualization|2023|Medical and Biological Engineering and Computing|61|11||2797|2814|17|12|10.1007/s11517-023-02903-1|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167357922&doi=10.1007%2fs11517-023-02903-1&partnerID=40&md5=787ca397ca516e4a31ff080eb82fd176|Zebrafish have become a widely accepted model organism for biomedical research due to their strong cortisol stress response, behavioral strain differences, and sensitivity to both drug treatments and predators. However, experimental zebrafish studies generate substantial data that must be analyzed through objective, accurate, and repeatable analysis methods. Recently, advancements in artificial intelligence (AI) have enabled automated tracking, image recognition, and data analysis, leading to more efficient and insightful investigations. In this review, we examine key AI applications in zebrafish research, including behavior analysis, genomics, and neuroscience. With the development of deep learning technology, AI algorithms have been used to precisely analyze and identify images of zebrafish, enabling automated testing and analysis. By applying AI algorithms in genomics research, researchers have elucidated the relationship between genes and biology, providing a better basis for the development of disease treatments and gene therapies. Additionally, the development of more effective neuroscience tools could help researchers better understand the complex neural networks in the zebrafish brain. In the future, further advancements in AI technology are expected to enable more extensive and in-depth medical research applications in zebrafish, improving our understanding of this important animal model. This review highlights the potential of AI technology in achieving the full potential of zebrafish research by enabling researchers to efficiently track, process, and visualize the outcomes of their experiments. Graphical Abstract: [Figure not available: see fulltext.] © 2023, International Federation for Medical and Biological Engineering.|Data analysis; Deep learning; Image recognition; Machine learning; Trajectory tracking; Zebrafish|Behavioral research; Data handling; Data visualization; Deep learning; Disease control; Image analysis; Information analysis; Learning systems; Neurology; Analysis method; Artificial intelligence algorithms; Artificial intelligence technologies; Biomedical research; Deep learning; Machine-learning; Model organisms; Stresses response; Trajectory-tracking; Zebrafish; animal behavior; artificial intelligence; automation; behavioral science; cell motion; deep learning; genomics; image processing; large scale production; learning algorithm; machine learning; medical research; microinjection; movement (physiology); neuroscience; nonhuman; Review; zebra fish; Image recognition|Review|Final||Scopus|2-s2.0-85167357922
scopus|Nayab S.; Wotawa F.|Nayab, Shahzad (59419108100); Wotawa, Franz (6603677377)|59419108100; 6603677377|Testing and Reinforcement Learning - A Structured Literature Review|2024|Proceedings - 2024 IEEE 24th International Conference on Software Quality, Reliability and Security Companion, QRS-C 2024||||326|335|9|0|10.1109/QRS-C63300.2024.00049|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209794672&doi=10.1109%2fQRS-C63300.2024.00049&partnerID=40&md5=41e6c618d91ea4ae9ccb3a5c10f989ec|Reinforcement Learning has gained much attention in the last decade, leading to substantial progress in Artificial Intelligence and its applications, especially in games and other areas where agents interact to learn and adapt to complex environments successfully. In this paper, we focus on reinforcement learning in the context of software and system testing. Specifically, we want to review the use of reinforcement learning in testing particularly test automation and testing approaches used for assuring the quality of reinforcement learning implementations. For this purpose, we carried out a structured literature review that considered Scopus, the digital libraries of IEEE and ACM. Using exclusion and inclusion criteria, we finally obtained 79 scientific articles. We categorized these articles according to various criteria, like the testing methods used or the application of testing, e.g., for obtaining security vulnerabilities, for automated game testing devoid of human competitive intelligence aid, for exploring GUI actions and states, etc. Hence, most papers focus on applying reinforcement learning for testing, but there is little work on testing implementations of reinforcement learning. © 2024 IEEE.|reinforcement learning in testing; test automation; testing reinforcement learning applications|Reinforcement learning; Complex environments; ITS applications; Learn+; Literature reviews; Reinforcement learning in testing; Reinforcement learnings; Software testings; Test Automation; Testing reinforcement learning application; Adversarial machine learning|Conference paper|Final||Scopus|2-s2.0-85209794672
scopus|Le N.-B.-V.; Thai H.-D.; Yoon C.-W.; Huh J.-H.|Le, Ngoc-Bao-Van (57290400500); Thai, Hong-Danh (57223974996); Yoon, Chang-Won (59320840200); Huh, Jun-Ho (56438784800)|57290400500; 57223974996; 59320840200; 56438784800|Recent Development of Drone Technology Software Engineering: A Systematic Survey|2024|IEEE Access|12|||128729|128751|22|3|10.1109/ACCESS.2024.3454546|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203496684&doi=10.1109%2fACCESS.2024.3454546&partnerID=40&md5=a83e86576ef88e89c864449f10fede31|The drone technology field has received attention and witnessed numerous impressive advancements that heralded substantial changes and opened new possibilities in different industries. Several advanced technologies, such as artificial intelligence, computer science, object avoidance technology, and others, have been collaboratively developed to empower drone operations. Drone technology software engineering overview can assist in identifying and prioritizing research gaps that require attention in future research. The main contribution is to investigate the recent development of drone technology by applying the literature review methodology. Our research involves a comprehensive literature review of drone technology software engineering, including worldwide journal papers and reviews published from 2010 to the present. To achieve this goal, we will first research the evolution of drone technology software engineering research trends. Second, we investigate approaches to ensuring the reliability, safety, and security of drone software systems. After that, software testing and validation methodologies have emerged to ensure the robustness and trustworthiness of drone systems are investigated. Finally, the potential of integration of AI/ML capabilities into drone software that has been progressing to enhance autonomous decision-making and adaptation in drone technology is described. As a result, summarized features of a drone system and its increasingly expanding variety of applications are discussed. After that, an analysis to identify the emerging trends, promising research directions, and ongoing challenges in the domain of drone software engineering is presented. These findings are expected to become a valuable reference in this research field. © 2013 IEEE.|algorithms; Drone; landing site; landing technology; literature review; unmanned aerial vehicles (UAVs)|Aircraft landing; Application programs; Computer software selection and evaluation; Engineering research; Integration testing; Safety testing; Advanced technology; Aerial vehicle; Avoidance technology; Drone system; Landing site; Landing technology; Literature reviews; Research gaps; Technology fields; Unmanned aerial vehicle; Drones|Article|Final|All Open Access; Gold Open Access|Scopus|2-s2.0-85203496684
scopus||||Proceedings of the 9th International Conference on Internet of Things, Big Data and Security, IoTBDS 2024|2024|International Conference on Internet of Things, Big Data and Security, IoTBDS - Proceedings||||||369|0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193951973&partnerID=40&md5=ac7366d553e12146311043a9e3fc595e|The proceedings contain 37 papers. The topics discussed include: a systematic mapping study in security software testing for mobile devices; automation of smart homes with multiple rule sources; advancements in household data mining: fine-tuning of usage pattern inference pipeline; need for speed: leveraging the power of functional encryption for resource-constrained devices; ransomware reconnaissance: interrogating certificates towards proactive threat mitigation; privacy sensitive building monitoring through generative sensors; optimizing data processing in industrial settings: a comparative evaluation of dimensionality reduction approaches; a systematic mapping study on techniques for generating test cases from requirements; data sets for cyber security machine learning models: a methodological approach; and hybrid statistical modeling for anomaly detection in multi-key stores based on access patterns.|||Conference review|Final||Scopus|2-s2.0-85193951973
scopus|Salman Z.D.S.D.; Al-Absy M.S.M.|Salman, Zahra Dawood Salman Dawood (59171577600); Al-Absy, Mujeeb Saif Mohsen (57191668511)|59171577600; 57191668511|Artificial Intelligent Impact on Accounting Professionals in Bahrain|2024|Studies in Systems, Decision and Control|524|||133|141|8|0|10.1007/978-3-031-54379-1_11|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195964578&doi=10.1007%2f978-3-031-54379-1_11&partnerID=40&md5=5c9dc5faecc727a224b1f9b50fc86605|The purpose of this study is to examine the effect of artificial intelligent (AI) on accounting profession in Bahrain. The study uses three dimensions for AI, namely, test automation, anomalous error, predictive and forecasting solutions. For accounting profession, the study used three measurements which are reporting accuracy, data analytics, and transparent reporting. Questionnaire will be distributed to accountants in the sector of Banks and financial institutions in Bahrain. The study expects a significant positive impact of test automation, anomalous error, predictive and forecasting solutions on accounting profession measured by reporting accuracy, data analytics, and transparent reporting. The study has provided insights for developing strategies to enhance accountant’s skills through training programs and adapting accounting education accordingly. Additionally, it will help policymakers create measures that allow professionals to benefit from increased productivity brought about by AI while minimizing any job displacement risks. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.|Audit fees; Audit firm’s size; Audit quality; Competency; Tuner||Book chapter|Final||Scopus|2-s2.0-85195964578
scopus|Fariha A.; Azim A.; Liscano R.|Fariha, Asma (58813137100); Azim, Akramul (36023296200); Liscano, Ramiro (56086121100)|58813137100; 36023296200; 56086121100|Replay-Based Continual Learning for Test Case Prioritization|2024|Proceedings - 2024 IEEE International Conference on Software Testing, Verification and Validation Workshops, ICSTW 2024||||106|107|1|0|10.1109/ICSTW60967.2024.00031|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206011625&doi=10.1109%2fICSTW60967.2024.00031&partnerID=40&md5=2f90d33357d49dfbd1cda71cb1e0b3c6|In a large-scale Continuous Integration (CI) environment, regression testing can encounter high time and resource demands in ad hoc execution. Therefore, Test Case Prioritization (TCP) is crucial for enhancing the regression testing efficiency of CI. TCP methods aim to optimize regression testing by ordering test cases to effectively cover new code changes and their potential side effects and to maximize early fault detection. Traditional prioritization processes use diverse data sources, including code coverage analysis, test execution history, and domain-specific features. Heuristic-based or code-coverage-driven prioritization techniques may not be sufficient for accurate results in a rapidly changing environment. For this reason, there has been a significant shift towards employing Machine Learning (ML) techniques in TCP in recent years to harness the vast and complex datasets generated by CI practices. ML-based TCP approaches integrate multifaceted test case features from various sources to enhance the accuracy of test case prioritization. This trend reflects a broader movement towards data-driven decisionmaking in software testing, offering the potential to significantly reduce the regression testing burden by tailoring test suites more effectively to the needs of each software build, thereby saving time and resources while maintaining or improving the software quality. Recent studies have shown that the ML-based methods used in TCP can be categorized into four groups: Supervised Learning, Unsupervised Learning, Reinforcement Learning, and Natural Language Processing. Codebases for software projects can be changed rapidly by introducing new feature distributions into the CI systems. We analyzed a Java application's CI and version control system (VCS) history data received from the International Business Machines Corporation (IBM) [1], [6], [7]. The frequent inclusion of new test suites introduced new patterns into the dataset properties. To keep up with these changes, ML models require frequent re-training on old and new datasets to maintain high accuracy on new data. The volume of the dataset tends to increase with time as more data becomes available. Frequent re-training of ML models on the entire dataset is computationally costly and requires extensive storage. Reinforcement Learning focuses on finding the best solution through reward maximization [2] and restricts the learning goal. Learning incrementally from new non-stationary data without requiring an old dataset to solve this TCP problem. Continual Learning (CL) or life-long learning/ incremental learning adapts to changes without needing old training samples. While CL has recently been studied in several works for different domains, we could not find effective research on implementing CL in the TCP domain. Given the dynamic environment of software testing, we apply CL in industrial test case prioritization is critical for maintaining the efficiency and effectiveness of software testing processes in dynamic environments. However, modifying ML models on new datasets may introduce other problems, such as catastrophic forgetting. This can occur when the model is trained on a new distribution, and the model weights change drastically. Different strategies have been suggested to solve the problem of catastrophic forgetting in CL. This abstract discusses the integration of pre-training and replay-based continual learning methods to enhance test case prioritization. Pre-trainingbased continual learning leverages the strong representation of pre-training models on a large dataset. This approach helps initialize the model with a broad understanding, which can be further incrementally trained to accommodate new tasks without significant performance loss on previous tasks. The dataset we obtained from IBM has a few years of test execution data for the CI and VCS. The model can be trained using a large volume of data for the pre-training method. Replay-based continual learning, however, involves retaining a small buffer of old training samples. This strategy includes a small fraction of old samples with a new dataset while incrementally training the model, enabling it to maintain its performance on older tasks by reinforcing the previous learning. Integrating pre-training and replay-based methods is most effective in the literature [3]. Pre-training provides a solid foundation for generic knowledge; replay-based methods complement this by continuously reinforcing past learning, ensuring that the adaptation to new tasks does not come at the expense of previously acquired knowledge. Several design choices leverage the benefits of this combined method. The frequency of incremental training on new datasets is an important design decision. This frequency can be timedriven or property-driven. Experimental work will guide the decision on incremental training frequency. Next, in replay-based approaches, the memory buffer size, number of old samples, and criteria for old sample selection are some of the decision parameters. In addition, a small buffer memory requires effective management in terms of data-retaining strategies. The empirical evidence supports the effectiveness of this integrated approach. Hu et al. [4] introduced prioritized experience replay in continual learning, emphasizing the selection of representative experiences to alleviate catastrophic forgetting. Similarly, Merlin et al. [5] provided practical recommendations for replay-based continual learning methods, highlighting the importance of memory size and data augmentation in enhancing the performance. We will conduct detailed investigations to determine the optimal values for these decision parameters. For time-based frequency, we will experiment at different intervals, such as weekly, every ten or 15 days, monthly, three months, and six months of incremental training. Property-based choices can be new test suite additions, significant changes in test suites, and an increase or decrease in the test case failure rate. Similarly, for the replay-based method, samples can be selected from each incremental training dataset; the selection can be random or property-based. For example, an even distribution of passed or failed samples could be selected to avoid overfitting. In conclusion, integrating pretraining and replay-based continual learning methods presents a promising research direction for enhancing large-scale test case prioritization in CI. Future research should explore different strategies to maximize the benefits of continual learning in test case prioritization.  © 2024 IEEE.|catastrophic forgetting; continual learning; experience replay; pretraining; test case prioritization|Computer software selection and evaluation; Integration testing; Java programming language; Negative bias temperature instability; Problem oriented languages; Unsupervised learning; Catastrophic forgetting; Continual learning; Continuous integrations; Experience replay; Incremental training; Pre-training; Regression testing; Software testings; Test case; Test case prioritization; Reinforcement learning|Conference paper|Final||Scopus|2-s2.0-85206011625
scopus|Wang F.; Tao C.; Gao J.|Wang, Fengyu (59815380300); Tao, Chuanqi (36086787600); Gao, Jerry (7404475003)|59815380300; 36086787600; 7404475003|REDQT: a method for automated mobile application GUI testing based on deep reinforcement learning algorithms|2024|Service Oriented Computing and Applications|||||||1|10.1007/s11761-024-00413-y|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197227980&doi=10.1007%2fs11761-024-00413-y&partnerID=40&md5=db3ef5db9dfb19ecde5eb59cc4ae8d1e|As mobile applications become increasingly prevalent in daily life, the demand for their functionality and reliability continues to grow. Traditional mobile application testing methods, particularly graphical user interface (GUI) testing, face challenges of limited automation and adaptability.Despite the application of various machine learning approaches to GUI testing, enhancing the utilization of limited component samples in complex mobile application environments remains an overlooked issue in many automated testing methods. This study introduces a mobile application testing method based on deep reinforcement learning, aimed at improving performance and adaptability during the testing process. By integrating the feature recognition capabilities of deep learning with the decision-making mechanisms of reinforcement learning, our method can effectively simulate user operations and identify potential application pitfalls. Initially, the study analyzes the limitations of traditional mobile application testing methods and explores the advantages of deep reinforcement learning in handling complex tasks. Subsequently, we present RedqT: an automated mobile application GUI testing method based on a deep reinforcement learning algorithm (REDQ), aimed at enhancing the utilization of application information through the characteristics of the REDQ algorithm. A study testing 18 open-source Android applications on GitHub demonstrated that our method shows promising performance in terms of code coverage and testing speed. © The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature 2024.|Deep reinforcement learning; Machine learning; Mobile application testing||Note|Article in press||Scopus|2-s2.0-85197227980
scopus|Wang J.; Lei Y.; Li M.; Ren G.; Xie H.; Jin S.; Li J.; Hu J.|Wang, Jiaguo (58725379900); Lei, Yan (55541448200); Li, Maojin (58725379800); Ren, Guanyu (58776042500); Xie, Huan (57223967907); Jin, Shifeng (58744689400); Li, Junchao (37100878400); Hu, Jian (57198193889)|58725379900; 55541448200; 58725379800; 58776042500; 57223967907; 58744689400; 37100878400; 57198193889|Flakyrank: Predicting Flaky Tests Using Augmented Learning to Rank|2024|Proceedings - 2024 IEEE International Conference on Software Analysis, Evolution and Reengineering, SANER 2024||||872|883|11|1|10.1109/SANER60148.2024.00095|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199758344&doi=10.1109%2fSANER60148.2024.00095&partnerID=40&md5=e3303c96d07a530e1df9dad052d7c118|The ideal principle of software testing is that test results ought to be deterministic: a test failure indicates the presence of a software bug, while a test success suggests the absence of a bug. Nevertheless, flaky tests break the principle. Flaky tests yield inconsistent results when executed repeatedly under the same conditions. The most straightforward approach runs the tests multiple times to predict flaky tests whereas it is highly time-consuming. Many researchers have proposed efficient approaches to reduce the cost, e.g., recent approaches leverage machine learning techniques for the prediction of flaky tests. However, traditional machine learning primarily focuses on predicting specific instances, which is not conducive to identify flaky tests across an entire project. Therefore, we propose Flakyrank, a ranking framework based on augmented learning to rank to predict flaky tests. The insight is that learning to rank, as compared with traditional machine learning, not only concentrates on individual samples but also optimizes the overall ranking. Since flaky tests constitute a small proportion of the dataset (i.e., approximately 3.6% of the total tests), we utilize generative adversarial networks to generate some synthetic flaky tests to augment the dataset. Based on the augmented dataset, FLAKYRANK treats predicting flaky tests as an information retrieval task, where newly detected flaky tests and test cases serve as queries and documents, respectively. For each newly detected flaky test (i.e., query), FLAKYRANK combines multiple relevant features into a learning to rank model to predict flaky tests candidate tests. We conduct large-scale experiments on different learning to rank models, and the results show that FLAKYRANK with the LambdaMART algorithm yields the best performance. In addition, the experimental results on 23 benchmark projects show that FLAKYRANK outperforms the state-of-the-art predictors.  © 2024 IEEE.|flaky tests; generative adversarial networks; learning to rank; Software testing|Forecasting; Generative adversarial networks; Statistical tests; Condition; Deterministics; Flaky test; Machine learning techniques; Machine-learning; Rank modeling; Software bug; Software testings; Test case; Test failure; Software testing|Conference paper|Final||Scopus|2-s2.0-85199758344
scopus|Ngaruiya N.; Donner J.; Baru J.K.; Chege B.W.|Ngaruiya, Njeri (56951226100); Donner, Jonathan (23090160800); Baru, Joshua Kinuthia (58869880700); Chege, Babra Wanjiku (58869921200)|56951226100; 23090160800; 58869880700; 58869921200|The domestication of AI by Kenyan digital creators: This note documents the use of AI by digital creators in Kenya, using the lens of domestication theory|2023|ACM International Conference Proceeding Series||||71|75|4|4|10.1145/3628096.3628753|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184372206&doi=10.1145%2f3628096.3628753&partnerID=40&md5=22d10500e3f8c6cc23c780546a70e088|This note explores the adoption and use of artificial intelligence (AI) in Kenya's digital creative sectors. Guided by a lens of domestication theory, and informed by interviews with 21 practitioners, the study documents ways in which AI is transforming traditional workflows, job roles, and skill requirements, enabling increased efficiency, automation, and creativity possibilities. Digital marketers leverage AI-powered analytics tools for data-driven insights and personalized marketing campaigns. Coders utilize AI algorithms to optimize code development, enhance software testing, and streamline debugging processes. Graphic designers incorporate AI tools for image recognition, automated design generation, and enhanced visual effects. Ghostwriters embrace AI-based writing assistants for generating content, improving productivity, and meeting client demands. Importantly, the study identifies concerns among professionals regarding job security, ethical implications, and the need for upskilling to effectively collaborate with AI technologies. © 2023 Owner/Author.|AI; Domestication; ICT4D; Livelihoods|Commerce; Employment; Image enhancement; Philosophical aspects; Program debugging; Software testing; Analytic tools; Creatives; Data driven; Domestication; ICT4D; Livelihood; Marketing campaign; Personalized marketings; Skill requirements; Work-flows; Marketing|Conference paper|Final|All Open Access; Hybrid Gold Open Access|Scopus|2-s2.0-85184372206
scopus|Deepashree N.; Sahina Parveen M.|Deepashree, N. (59247321700); Sahina Parveen, M. (59247162000)|59247321700; 59247162000|Software Testing Using Cuckoo Search Algorithm with Machine Learning Techniques|2024|Journal of Intelligent Systems and Internet of Things|13|2||150|165|15|0|10.54216/JISIoT.130212|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200450728&doi=10.54216%2fJISIoT.130212&partnerID=40&md5=948b3be0e607a71c9b360cbab560ce6a|Software testing are any errors, flaws, bugs, mistakes, failures in a piece of software that might cause the programme to produce incorrect or unexpected results. Testing in software almost always increase both the time and money needed to finish a project. And finding bugs and fixing them is a laborious and expensive software process in and of itself. While it's unrealistic to expect to completely eradicate all testing from a project, their severity may be mitigated. It is possible to predict where bugs may appear in software using a method known as software defect prediction (SDP). The goal of each software development project should be to provide a bug-free product. Predicting where bugs may appear in code, often known as software defect prediction (SDP), is an important part of fixing software. Software of a high calibre should have few bugs. A software metric is a quantitative or qualitative evaluation of some aspect of the programme or its requirements. One of the more recent population-based algorithms, Cuckoo Search (CS) was inspired by the flight patterns of some cuckoo species as well as the Lévy flying patterns of other birds and fruit flies. The needs for international convergence are met by CS. KNN is a significant non-parameter supervised learning technique. This paper presents an overview of Stochastic Diffusion Search (SDS) in the form of a social metaphor to illustrate the processes by which SDS allots resources. The best-fit pattern identification and matching difficulties were addressed by SDS using a novel probabilistic method. As a multiagent population-based global search and optimization method, SDS is a distributed model of computing that makes use of interaction amongst basic agents. The behaviour of SDS is described by studying its resource allocation, convergence to global optimum, resilience, minimum convergence criterion, and linear time complexity within a rigorous mathematical framework, setting it apart from many nature-inspired search algorithms. This paper proposes a hybrid optimization strategy based on CS-SDS techniques. By using the global search strategy solution of the SDS algorithm, this hybridization idea aims to enhance the cuckoo bird's search strategy for the optimum host nest. To that end, the SDS method would be used to place the cuckoo egg in the most advantageous location. When compared to other classifiers, PC2's improved performance may be attributed to its higher recall values. When compared to the Naive Bayes and Radial Bias Neural Network classifiers, the KNN performs 7.64% and 2.20% better, respectively. © 2024, American Scientific Publishing Group (ASPG). All rights reserved.|Cuckoo Search; K Nearest Neighbor; Naïve Bayes; Radial Bias Neural Network; Software Defect Prediction; Stochastic Diffusion Search||Article|Final||Scopus|2-s2.0-85200450728
scopus|Anju A.J.; Judith J.E.|Anju, A.J. (57215216025); Judith, J.E. (52663657800)|57215216025; 52663657800|A reliable impact factor for feature SELECTION|2023|AIP Conference Proceedings|2904|1|20004||||0|10.1063/5.0170391|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177602742&doi=10.1063%2f5.0170391&partnerID=40&md5=2f3e67055f6de80988d3fb664d1415f4|Feature selection enables faster, more economical, and more accurate classifiers various academic areas that focus on data mining and machine learning have taken an interest in it. By concentrating on defect module, the precise forecast of a software module's propensity for defects can assist with software testing effort, lower costs, and improve the software testing process. Data mining, machine learning, and mixed algorithms, which were based on software matrix associated with the software, have also been used to predict software defect. Various software metrics, such as cyclometric complexity and line of code, have been calculated effectively used for this purpose. In this study, it is explored how feature selection affects the accuracy of NaveBayes, logistic regression, One-r, Random forest and J48 decision tree classifiers. 5 real datasets that have undergone feature selection pre-processing are utilised to compare these classifiers. Naive Bayes seems to be the classifier that responds to feature selection the best, with classification accuracy improvements of up to high percent.  © 2023 Author(s).|Classification; Data set description; Defect Prediction; Feature selection||Conference paper|Final||Scopus|2-s2.0-85177602742
scopus|Zivkovic T.; Nikolic B.; Simic V.; Pamucar D.; Bacanin N.|Zivkovic, Tamara (6701358907); Nikolic, Bosko (7006055343); Simic, Vladimir (7005545253); Pamucar, Dragan (54080216100); Bacanin, Nebojsa (37028223900)|6701358907; 7006055343; 7005545253; 54080216100; 37028223900|Software defects prediction by metaheuristics tuned extreme gradient boosting and analysis based on Shapley Additive Explanations|2023|Applied Soft Computing|146||110659||||52|10.1016/j.asoc.2023.110659|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167436767&doi=10.1016%2fj.asoc.2023.110659&partnerID=40&md5=89c419a568f152f6211a5a1a0099d7ff|Software testing represents a crucial component of software development, and it is usually making the difference between successful and failed projects. Although it is extremely important, due to the fast pace and short deadlines of contemporary projects it is often neglected or not detailed enough due to the lack of available time, leading to the potential loss of reputation, private users’ data, money, and even lives in some circumstances. In such situations, it would be vital to have the option to predict what modules are error-prone according to the collection of software metrics, and to focus testing on them, and that task is a typical classification task. Machine learning models have been frequently employed within a wide range of classification problems with significant success, and this paper proposes eXtreme gradient boosting (XGBoost) model to execute the defect prediction task. A modified variant of the well-known reptile search optimization algorithm has been suggested to carry out the calibrating of the XGBoost hyperparameters. The enhanced algorithm was named HARSA and evaluated on the collection of challenging CEC2019 benchmark functions, where it exhibited excellent performance. Later, the introduced XGBoost model that uses the proposed algorithm has been evaluated on two benchmark software testing datasets, and the simulation outcomes have been compared to other powerful swarm intelligence metaheuristics that were used in the identical experimental environment, where the proposed approach attained superior classification accuracy on both datasets. Finally, Shapley Additive Explanations analysis was conducted to discover the impact of various software metrics on the classification results. © 2023 Elsevier B.V.|Metaheuristics optimization; Reptile search algorithm; Software defect prediction; Software testing; XGBoost|Adaptive boosting; Additives; Benchmarking; Classification (of information); Defects; Forecasting; Heuristic algorithms; Optimization; Software design; Gradient boosting; Metaheuristic; Metaheuristic optimization; Reptile search algorithm; Search Algorithms; Shapley; Software defect prediction; Software metrics; Software testings; Xgboost; Software testing|Article|Final||Scopus|2-s2.0-85167436767
scopus|Baz A.; Gligoric M.; Shi A.|Baz, Abdelrahman (59325794500); Gligoric, Milos (26221765900); Shi, August (56453975300)|59325794500; 26221765900; 56453975300|Impact of JVM Configurations on Test Runtime|2024|Proceedings - 2024 IEEE International Conference on Software Maintenance and Evolution, ICSME 2024||||249|261|12|0|10.1109/ICSME58944.2024.00032|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215529089&doi=10.1109%2fICSME58944.2024.00032&partnerID=40&md5=fbe170b09cd699ebcbe6315ff5d43c21|JVM provides dozens of configuration flags, with many flags intended for tuning application performance. We empirically study the impact of JVM configuration flags on software testing runtime. We focus on an extensive study that shows not only the great impact of JVM configurations on test runtime (up to 43.89% reduction in runtime when using certain configurations) but also shows that those configurations that reduce runtime are rare and thus hard to find. Modern techniques based on machine learning or combinatorial testing that search through combinations of configuration flags are still not as effective at finding the best configurations for test runtime. Finally, we show that JVM configurations that provide good speedup retain this power over a number of commits. We believe that this paper provides strong motivation for further work on finding the best JVM configurations to optimize test runtime.  © 2024 IEEE.|JVM configurations; performance; regression testing|Application programs; Program debugging; % reductions; Application performance; JVM configuration; Machine-learning; Modern techniques; On-machines; Performance; Regression testing; Runtimes; Software testings; Software testing|Conference paper|Final||Scopus|2-s2.0-85215529089
scopus|Mündler N.; Müller M.N.; He J.; Vechev M.|Mündler, Niels (57219590946); Müller, Mark Niklas (57222420533); He, Jingxuan (57204734521); Vechev, Martin (8876227900)|57219590946; 57222420533; 57204734521; 8876227900|SWT-Bench: Testing and Validating Real-World Bug-Fixes with Code Agents|2024|Advances in Neural Information Processing Systems|37||||||1||https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000529637&partnerID=40&md5=64830080c1fd8ab3a15e5f855dd9811b|Rigorous software testing is crucial for developing and maintaining high-quality code, making automated test generation a promising avenue for both improving software quality and boosting the effectiveness of code generation methods. However, while code generation with Large Language Models (LLMs) is an extraordinarily active research area, test generation remains relatively unexplored. We address this gap and investigate the capability of LLM-based Code Agents to formalize user issues into test cases. To this end, we propose a novel benchmark based on popular GitHub repositories, containing real-world issues, ground-truth bug-fixes, and golden tests. We find that LLMs generally perform surprisingly well at generating relevant test cases, with Code Agents designed for code repair exceeding the performance of systems designed specifically for test generation. Further, as test generation is a similar but more structured task than code generation, it allows for a more fine-grained analysis using issue reproduction rate and coverage changes, providing a dual metric for analyzing systems designed for code repair. Finally, we find that generated tests are an effective filter for proposed code fixes, doubling the precision of SWE-AGENT. We release all data and code at github.com/logic-star-ai/SWT-Bench. © 2024 Neural information processing systems foundation. All rights reserved.|||Conference paper|Final||Scopus|2-s2.0-105000529637
scopus|Yang B.; Wang X.; Liu H.|Yang, Bo (57721912200); Wang, Xu (59831190800); Liu, Huai (19640635500)|57721912200; 59831190800; 19640635500|MRTCNN: A Lightweight Approach for Predicting Metamorphic Relations|2024|Proceedings - Asia-Pacific Software Engineering Conference, APSEC||||519|520|1|0|10.1109/APSEC65559.2024.00072|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105004727279&doi=10.1109%2fAPSEC65559.2024.00072&partnerID=40&md5=654844af46bbee1833f9ef9e14a3c28b|Metamorphic testing is a software testing technique that provides both a test case generation strategy and a test result verification mechanism. Its foundation is a set of metamorphic relations, which are basically the necessary properties of the software under test, represented in the form of relationships among multiple inputs and corresponding expected outputs. As the core element of metamorphic testing, metamorphic relations have attracted lots of research interests from different perspectives, among which one major direction is to identify metamorphic relations suitable for certain types of programs. In order to reduce the manual work in the identification process, machine learning techniques have been leveraged to predict valid metamorphic relations for scientific software. In this paper, we present a new approach for predicting metamorphic relations based on the deep learning of the program documentation. In particular, we make use of the text convolutional neural networks in the prediction and validation of proper metamorphic relations. Empirical studies have also been conducted to evaluate the applicability and performance of our approach. The experimental results demonstrate its effectiveness in predicting appropriate metamorphic relations for the testing of various Java programs. Compared with the existing baseline techniques, our approach improves the precision and accuracy of the metamorphic relation prediction process. This study also reveals potential research opportunities for advancing the performance of metamorphic testing.  © 2024 IEEE.|deep learning; metamorphic relation; metamorphic testing; text mining; word embedding|Model checking; System program documentation; Deep learning; Embeddings; Metamorphic relations; Metamorphic testing; Performance; Result verifications; Software testing techniques; Test case generation; Text-mining; Word embedding; Testbeds|Conference paper|Final||Scopus|2-s2.0-105004727279
scopus|Sakhrawi Z.; Labidi T.; Sellami A.; Bouassida N.|Sakhrawi, Zaineb (57211166983); Labidi, Taher (56487826900); Sellami, Asma (35189535000); Bouassida, Nadia (6506761943)|57211166983; 56487826900; 35189535000; 6506761943|Automotive User Interface Based on LSTM-Grid Search Deep Learning Model for IoT Security Change Request Classification|2024|Lecture Notes on Data Engineering and Communications Technologies|200|||476|486|10|0|10.1007/978-3-031-57853-3_40|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191329445&doi=10.1007%2f978-3-031-57853-3_40&partnerID=40&md5=e141c8fdad70f54ace1eef35a53c647e|The field of the Internet of Things (IoT) is rapidly growing in significance, with roughly fifty billion devices being used in technology for computing by the end of 2020. However, the interdependence of IoT devices, as well as the variety of components used in their implementation, has caused a variety of issues, such as insufficient testing of change requests (CR) that affect security requirements. One way to address these security issues is to provide a deeper classification of security requirements that have an impact on the overall software process, such as software testing. Thus, the primary goal of this study is to assist software testers in prioritizing changes requested to enhance software security on IoT-based devices. Therefore, a deep learning-based approach to security CR classification is proposed. In this study, the Long Short Term Memory (LSTM) model is used and enhanced through the grid search tuning method. The LSTM-based grid search deep learning classifier identifies the class (i.e., sub-characteristics defined by the ISO 25010 quality model) of a given security CR from IoT-based devices with an average classification accuracy of 79%. Finally, to validate the robustness of our proposed research methodology, we developed an automated classification user interface for software testers. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.|Grid Search tuning method; IoT-based devices; LSTM deep learning; Security change request; software regression testing|Cryptography; Learning systems; Long short-term memory; Software testing; User interfaces; Well testing; Grid search; Grid search tuning method; Internet of thing-based device; Long short term memory deep learning; Regression testing; Security change request; Security changes; Security requirements; Software regression testing; Tuning method; Internet of things|Book chapter|Final||Scopus|2-s2.0-85191329445
scopus|Yang G.; Li Z.; Wang P.; Shi Y.; Meng L.|Yang, Guang (57189524128); Li, Zhiwen (59207444400); Wang, Pengqi (57221916244); Shi, Yuan (57221905906); Meng, Lingzhong (55574233424)|57189524128; 59207444400; 57221916244; 57221905906; 55574233424|A Testing and Evaluation Framework for the Quality of DNN Models|2024|Proceedings - 2024 10th International Symposium on System Security, Safety, and Reliability, ISSSR 2024||||224|231|7|0|10.1109/ISSSR61934.2024.00034|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197704024&doi=10.1109%2fISSSR61934.2024.00034&partnerID=40&md5=7c6392d7efe834b82881acd341ba827b|Recently, the application of advanced AI algorithms represented by deep neural network (DNN) in various fields of human society has shown explosive growth. These powerful AI tools have not only revolutionized the traditional working mode of the technology industry, but also deeply penetrated into people's daily life. However, since AI algorithms generally have problems such as uncertain capability boundaries and difficult interpretability, failing to adequately and accurately measure their quality will bring about great hidden dangers. Traditional software testing and evaluation methods can hardly meet the need of comprehensively measuring the quality of DNN models. To solve this problem, we propose a testing and evaluation framework for the quality of DNN models. Experiments demonstrate that our proposed framework can comprehensively test and evaluate the quality of DNN models, as well as improve the adequacy and accuracy of testing and evaluation through dataset quality analysis and test adequacy analysis.  © 2024 IEEE.|dataset quality analysis; deep neural network; quality of models; test adequacy analysis; testing and evaluation framework|Neural network models; Petroleum reservoir evaluation; Quality control; Software testing; Statistical tests; Well testing; AI algorithms; Dataset quality analyse; Evaluation framework; Human society; Neural network model; Quality of model; Test adequacies; Test adequacy analyse; Testing and evaluation; Testing framework; Deep neural networks|Conference paper|Final||Scopus|2-s2.0-85197704024
scopus|de Andrade S.A.; Nunes F.L.S.; Delamaro M.E.|de Andrade, Stevão Alves (57202432308); Nunes, Fatima L. S. (7102392843); Delamaro, Márcio Eduardo (6602659678)|57202432308; 7102392843; 6602659678|Exploiting deep reinforcement learning and metamorphic testing to automatically test virtual reality applications|2023|Software Testing Verification and Reliability|33|8|e1863||||5|10.1002/stvr.1863|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171430281&doi=10.1002%2fstvr.1863&partnerID=40&md5=c948e9bf2135ac5251e5426859d38b52|Despite the rapid growth and popularization of virtual reality (VR) applications, which have enabled new concepts for handling and solving existing problems through VR in various domains, practices related to software engineering have not kept up with this growth. Recent studies indicate that one of the topics that is still little explored in this area is software testing, as VR applications can be built for practically any type of purpose, making it difficult to generalize knowledge to be applied. In this paper, we present an approach that combines metamorphic testing, agent-based testing and machine learning to test VR applications, focusing on finding collision and camera-related faults. Our approach proposes the use of metamorphic relations to detect faults in collision and camera components in VR applications, as well as the use of intelligent agents for the automatic generation of test data. To evaluate the proposed approach, we conducted an experimental study on four VR applications, and the results showed an (Formula presented.) of the solution ranging from 93% to 69%, depending on the complexity of the application tested. We also discussed the feasibility of extending the approach to identify other types of faults in VR applications. In conclusion, we discussed important trends and opportunities that can benefit both academics and practitioners. © 2023 John Wiley & Sons Ltd.|metamorphic testing; software testing; virtual reality|Application programs; Cameras; Computer aided instruction; Deep learning; E-learning; Intelligent agents; Learning algorithms; Reinforcement learning; Virtual reality; Agent-based testing; Automatically test; Existing problems; Machine-learning; Metamorphic relations; Metamorphic testing; Rapid growth; Reinforcement learnings; Software testings; Testing agents; Software testing|Article|Final|All Open Access; Bronze Open Access|Scopus|2-s2.0-85171430281
scopus|Auer T.; Haller-Seeber S.; Gatterer T.|Auer, Thomas (57219222257); Haller-Seeber, Simon (56640964800); Gatterer, Thomas (57604707300)|57219222257; 56640964800; 57604707300|User Experience design of further training on Test automation of an AI self-driving robotic car powered by a Raspberry Pi|2023|IEEE Global Engineering Education Conference, EDUCON|2023-May||||||0|10.1109/EDUCON54358.2023.10125176|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162637665&doi=10.1109%2fEDUCON54358.2023.10125176&partnerID=40&md5=fc4b14614c074b9db49a8618bcfd76ae|In this study, the implementation of interactive continuing training in test automation of autonomous vehicles (AV) is discussed. Therefore, the most important characteristic is that the training should be appropriate for introducing new project members to an existing project within that domain. User experience (UX) tests with professionals in software engineering, software quality assurance, IT education, and similar fields, have been conducted. All potential stakeholders, such as lecturers, subject matter experts, developers, or testing and quality assurance experts must be incorporated from the very beginning of the implementation of the continuing training. The UX test focuses as well on the proposed curriculum of the training as a whole, as also on two lectures on the basics of a Raspberry Pi and the installation of the Raspberry Pi operating system on Windows, which will be provided as an optional lecture for persons with no or only a few experiences in microcontroller boards, and finally on the main part of the course, a group assignment on implementation of a test automation suite for testing of the autonomous robotic vehicle. The UX test conducted aims to adapt the interactive training to the individual needs of professionals to enable rapid familiarization with autonomous vehicle test automation.  © 2023 IEEE.|autonomous driving; curriculum design; Raspberry Pi; robotic vehicle; test automation; user experience (UX) testing|Autonomous vehicles; Computer software selection and evaluation; Personnel training; Quality assurance; Software testing; Autonomous driving; Autonomous Vehicles; Curricula design; Further trainings; Raspberry pi; Robotic vehicles; Test Automation; User experience (UX) testing; User experience design; Users' experiences; Curricula|Conference paper|Final||Scopus|2-s2.0-85162637665
scopus|Verma I.; Kumar D.; Goel R.|Verma, Isha (58250480500); Kumar, Deepak (59936812700); Goel, Rajni (56264149600)|58250480500; 59936812700; 56264149600|Implementation and Comparison of Artificial Intelligence Techniques in Software Testing|2023|2023 6th International Conference on Information Systems and Computer Networks, ISCON 2023|||||||2|10.1109/ISCON57294.2023.10112041|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159496149&doi=10.1109%2fISCON57294.2023.10112041&partnerID=40&md5=09e482d490f5606556a256e34e547a73|AI is a prominent innovation of the current digital world. It powers most of the cutting-edge digital devices. It is a blend of unique technologies from machine learning (ML) to mixed reality (MR), and more. AI has significantly touched many sectors including healthcare, life sciences, manufacturing, retail, and agriculture. AI, as many expect, is going to be the future of the computing world. Artificial Intelligence has been a boon to the software industry as well. The software testing area has been highly touched by AI. Any applications that are built, need to be tested before providing it to the client. It becomes tedious if it's a complex timebound application. Manual testing in those scenarios doesn't seem to be a feasible solution. Although test automation has been incorporated in many companies, they aren't efficient in all cases. AI, on the other hand, helps test the applications effectively. Machine learning and deep learning technologies of AI are playing a crucial role in training and inferring massive amounts of data resulting in faster testing of the application. In this paper, we discuss the implementation and comparison of machine learning and deep learning techniques in Software Testing. . © 2023 IEEE.|Artificial Intelligence; Deep Learning; Machine Learning; Software Testing; Test Automation|Deep learning; Digital devices; Learning systems; Mixed reality; 'current; Artificial intelligence techniques; Cutting edges; Deep learning; Digital world; IT Power; Machine-learning; Mixed reality; Software testings; Test Automation; Software testing|Conference paper|Final||Scopus|2-s2.0-85159496149
scopus|Kumar V.; Ghosh D.; Srivastava S.|Kumar, Vimal (58728480000); Ghosh, Debjani (57209128678); Srivastava, Shivom (58973409600)|58728480000; 57209128678; 58973409600|Efficient MLOps Pipeline for Transfer Learning and Reuse of Pre-Trained ML Models|2023|International Symposium on Advanced Networks and Telecommunication Systems, ANTS|||||||0|10.1109/ANTS59832.2023.10468932|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189631641&doi=10.1109%2fANTS59832.2023.10468932&partnerID=40&md5=052305d71e86a95c158c64ca41738e99|This research paper aims to develop an MLOps pipeline for transfer learning to improve the efficiency and accuracy of machine learning models. The commencement of addressing a related undertaking in deep learning, frequently involves applying the oft-used practice of utilizing pre-established models as footing. However, setting up an efficient transfer learning pipeline can be challenging due to issues like data preprocessing, model selection, and deployment. The proposed pipeline addresses these issues by incorporating best practices in MLOps, including version control, continuous integration and deployment, and automated testing. In an effort to assess the proficiency of the pipeline, numerous experiments were conducted on diverse datasets and then juxtaposed against other established methodologies. The findings unveil that our conduit vastly enhances the efficacy and precision of the transfer learning. This inquiry holds momentous implications for the AI society, as it furnishes a detailed blueprint to construct efficient pipelines in this realm. Furthermore, it is feasible to expand our methodology effortlessly towards diverse fields of machine learning. This enables scholars and specialists alike to optimize the evolution of models successfully. On the whole, our investigation underscores the significance of incorporating MLOps methodologies into machine learning model creation and the conceivable advantages it can furnish regarding capability to grow, reproducibility and overlying performance.  © 2023 IEEE.|Continuous Integration; Deployment; Machine Learning Operations; Pipeline; Transfer Learning|Deep learning; Integration testing; Learning systems; Continuous integrations; Data preprocessing; Deployment; Machine learning models; Machine learning operation; Machine-learning; Model Selection; Research papers; Reuse; Transfer learning; Pipelines|Conference paper|Final||Scopus|2-s2.0-85189631641
scopus|Nath P.; Mushahary J.R.; Roy U.; Brahma M.; Singh P.K.|Nath, Panchanan (58078774700); Mushahary, Jaya Rani (58079782900); Roy, Ujjal (58079783000); Brahma, Maharaj (57211136765); Singh, Pranav Kumar (57200581293)|58078774700; 58079782900; 58079783000; 57211136765; 57200581293|AI and Blockchain-based source code vulnerability detection and prevention system for multiparty software development|2023|Computers and Electrical Engineering|106||108607||||16|10.1016/j.compeleceng.2023.108607|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146839664&doi=10.1016%2fj.compeleceng.2023.108607&partnerID=40&md5=669b50c5757cd9a70d7547050d21611f|With the growing demand for application software, there is a race among industries to develop software as quickly as possible. However, maintaining pace and ensuring bug-free software has become increasingly challenging in a work-from-home arrangement as software developers are not under constant supervision. It increases the possibility of buggy products, and traditional testing techniques fail to provide optimal performance. We propose an Artificial Intelligence (AI) and blockchain-based novel decentralized software testing system. The proposed system aims to detect and prevent vulnerable code by synergizing deep learning capabilities and smart-contract-powered blockchain. The vulnerability detection is performed automatically without relying on manually written rules. We propose a non-vulnerability score range map to classify the source code. Furthermore, we integrate an InterPlanetary File System (IPFS) to ensure efficient storage over the blockchain. We conduct a testbed-based experiment to demonstrate the effectiveness of AI and blockchain integration for secure code development and testing. © 2023 Elsevier Ltd|Blockchain; Deep learning; IPFS; Smart contract; Software development; Software testing|Application programs; Blockchain; Codes (symbols); Deep learning; Integration testing; Software design; Block-chain; Deep learning; Detection system; Filesystem; Interplanetary file system; Prevention systems; Software testings; Source codes; Vulnerability detection; Vulnerability prevention; Smart contract|Article|Final||Scopus|2-s2.0-85146839664
scopus|Dell’Anna D.; Aydemir F.B.; Dalpiaz F.|Dell’Anna, Davide (57201642596); Aydemir, Fatma Başak (55880322200); Dalpiaz, Fabiano (24400635100)|57201642596; 55880322200; 24400635100|Evaluating classifiers in SE research: the ECSER pipeline and two replication studies|2023|Empirical Software Engineering|28|1|3||||19|10.1007/s10664-022-10243-1|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141580631&doi=10.1007%2fs10664-022-10243-1&partnerID=40&md5=e10994c893935ff76d1cc2b0982d6ad3|Context: Automated classifiers, often based on machine learning (ML), are increasingly used in software engineering (SE) for labelling previously unseen SE data. Researchers have proposed automated classifiers that predict if a code chunk is a clone, if a requirement is functional or non-functional, if the outcome of a test case is non-deterministic, etc. Objective: The lack of guidelines for applying and reporting classification techniques for SE research leads to studies in which important research steps may be skipped, key findings might not be identified and shared, and the readers may find reported results (e.g., precision or recall above 90%) that are not a credible representation of the performance in operational contexts. The goal of this paper is to advance ML4SE research by proposing rigorous ways of conducting and reporting research. Results: We introduce the ECSER (Evaluating Classifiers in Software Engineering Research) pipeline, which includes a series of steps for conducting and evaluating automated classification research in SE. Then, we conduct two replication studies where we apply ECSER to recent research in requirements engineering and in software testing. Conclusions: In addition to demonstrating the applicability of the pipeline, the replication studies demonstrate ECSER’s usefulness: not only do we confirm and strengthen some findings identified by the original authors, but we also discover additional ones. Some of these findings contradict the original ones. © 2022, The Author(s).|Automated classification; Machine learning; Replication study; Software engineering|Automation; Machine learning; Software testing; Automated classification; Automated classifiers; Labelings; Machine-learning; Non-functional; On-machines; Replication study; Software engineering data; Software engineering research; Test case; Pipelines|Article|Final|All Open Access; Green Open Access; Hybrid Gold Open Access|Scopus|2-s2.0-85141580631
scopus|Garg A.; Sharma D.|Garg, Anshumaan (58978517500); Sharma, Dolly (57219994156)|58978517500; 57219994156|Generative AI for Software Test Modelling with a focus on ERP Software|2023|2023 International Conference on Advances in Computation, Communication and Information Technology, ICAICCIT 2023||||187|193|6|3|10.1109/ICAICCIT60255.2023.10466102|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189913438&doi=10.1109%2fICAICCIT60255.2023.10466102&partnerID=40&md5=bbd4cff707a16e04204f96778f0cbe85|Generative AI in this context refers to the type of artificial intelligence that can generate content or give new information based on patterns it has learned. In the case of software testing, it refers to the use of generative AI to model or for the creation of test scenarios, test cases or objects for ERP (Enterprise Resource Planning) software. The special focus on ERP software means that generative AI-based techniques have been particularly designed and optimized for the purpose of software testing. It does take into account the unique features and complexity of the ERP systems which allows for more effective and accurate testing. The problem with the existing chatbots is that they are not integrated with generative AI and the training is either not properly done or the data used for training is biased. The objective of this work is to develop a chatbot integrated with the generative AI-based framework and develop training data to cater to user needs. Methods and tools used in this approach are the OpenAI's API used for integrating chatbot with the generative AI-based software, Postman API has also been used to send and receive API requests and prompts and completions to be generated using Python code. The result of this approach is that a chatbot has been developed which develops test cases and scenarios, requests sent and received successfully and prompts and completions have been successfully generated using Python code. To state it simply, generative AI for software test modelling with a focus on ERP software means creating test cases and scenarios using AI and generating them automatically which helps testers ensure that the software is working correctly and meets the needs of the business operations. © 2023 IEEE.||Codes (symbols); High level languages; Software testing; Chatbots; Enterprise resource planning systems; Enterprise resources planning; Python code; Software testings; Test case; Test models; Test object; Test scenario; Unique features; Enterprise resource planning|Conference paper|Final||Scopus|2-s2.0-85189913438
scopus|Schrettenbrunner M.B.|Schrettenbrunner, Manfred Bernhard (58401859600)|58401859600|Artificial-Intelligence-Driven Management: Autonomous Real-Time Trading and Testing of Portfolio or Inventory Strategies|2023|IEEE Engineering Management Review|51|3||65|76|11|12|10.1109/EMR.2023.3288609|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163566233&doi=10.1109%2fEMR.2023.3288609&partnerID=40&md5=bdbb19e188242b93448b4df3b6c3ce40|Artificial-intelligence-driven management (AIDM) replaces the deming cycle with the artificial intelligence-assisted plan-predict-act cycle. Collaborative LeanBots for an industrial base and Trading- or StockExBots for trading or financial institutions and their clients, use this paradigm shift to perform cyber-secure, sophisticated decision-making processes (transactions) autonomously and in real-time at large scale, at low cost, and with minimal energy consumption. Recursively utilized gains reinforce and accelerate growth. Expanding on modern portfolio management, autonomous TradingBots diversify portfolios like inventories not only in terms of asset weighting, but also with respect to holding periods and moreover, do so in real-time. TradingBots can also be deployed to test automation, collaboration, portfolio, and inventory strategies. Metrics from modern portfolio management used show that StockExBots are able to outperform high-ranking index and actively managed funds. Five use cases are presented for leveraging the properties of StockExBots commercially. TradingBots can be deployed with a wide range of nonproprietary and proprietary (IoT or IIoT) devices or as software services, supporting decentralized, redundant, and localized transaction processes in proprietary (e.g., financial or trading institutions) and nonproprietary smart (home) environments. Linking both environments improves the scalability of proprietary ones and enables the migration and dispersion of complex real-time decision-making processes for mutual benefit.  © 1973-2011 IEEE.|Artificial-intelligence-driven management (AIDM); automation; autonomous; collaborative; decision-making; equity; growth; IIoT; industrial base; inventory; IoT; logistic; Plan-Do-Check-Act (PDCA); portfolio; recursive; trading|Artificial intelligence; Commerce; Decision making; Energy utilization; Financial data processing; Interactive computer systems; Internet of things; Investments; Artificial-intelligence-driven management; Autonomous; Collaboration; Collaborative; Decisions makings; Equity; IIoT; Industrial basis; Inventory; IoT; PDCA; Portfolio; Real - Time system; Recursive; Trading; Real time systems|Article|Final||Scopus|2-s2.0-85163566233
scopus|Raneri S.; Lecron F.; Hermans J.; Fouss F.|Raneri, Santo (57656404900); Lecron, Fabian (36466621100); Hermans, Julie (36617243000); Fouss, François (8685481800)|57656404900; 36466621100; 36617243000; 8685481800|Predictions through Lean startup? Harnessing AI-based predictions under uncertainty|2023|International Journal of Entrepreneurial Behaviour and Research|29|4||886|912|26|17|10.1108/IJEBR-07-2021-0566|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129138236&doi=10.1108%2fIJEBR-07-2021-0566&partnerID=40&md5=3e27fe804122a7635a45ceb0a145aa5f|Purpose: Artificial intelligence (AI) has started to receive attention in the field of digital entrepreneurship. However, few studies propose AI-based models aimed at assisting entrepreneurs in their day-to-day operations. In addition, extant models from the product design literature, while technically promising, fail to propose methods suitable for opportunity development with high level of uncertainty. This study develops and tests a predictive model that provides entrepreneurs with a digital infrastructure for automated testing. Such an approach aims at harnessing AI-based predictive technologies while keeping the ability to respond to the unexpected. Design/methodology/approach: Based on effectuation theory, this study identifies an AI-based, predictive phase in the “build-measure-learn” loop of Lean startup. The predictive component, based on recommendation algorithm techniques, is integrated into a framework that considers both prediction (causal) and controlled (effectual) logics of action. The performance of the so-called active learning build-measure-predict-learn algorithm is evaluated on a data set collected from a case study. Findings: The results show that the algorithm can predict the desirability level of newly implemented product design decisions (PDDs) in the context of a digital product. The main advantages, in addition to the prediction performance, are the ability to detect cases where predictions are likely to be less precise and an easy-to-assess indicator for product design desirability. The model is found to deal with uncertainty in a threefold way: epistemological expansion through accelerated data gathering, ontological reduction of uncertainty by revealing prior “unknown unknowns” and methodological scaffolding, as the framework accommodates both predictive (causal) and controlled (effectual) practices. Originality/value: Research about using AI in entrepreneurship is still in a nascent stage. This paper can serve as a starting point for new research on predictive techniques and AI-based infrastructures aiming to support digital entrepreneurs in their day-to-day operations. This work can also encourage theoretical developments, building on effectuation and causation, to better understand Lean startup practices, especially when supported by digital infrastructures accelerating the entrepreneurial process. © 2022, Santo Raneri, Fabian Lecron, Julie Hermans and François Fouss.|Artificial intelligence; Causation; Digital entrepreneurship; Effectuation; Lean startup; Uncertainty||Article|Final|All Open Access; Hybrid Gold Open Access|Scopus|2-s2.0-85129138236
scopus|García de la Barrera A.; García-Rodríguez de Guzmán I.; Polo M.; Piattini M.|García de la Barrera, Antonio (59454976500); García-Rodríguez de Guzmán, Ignacio (6602985950); Polo, Macario (7005519744); Piattini, Mario (7004203473)|59454976500; 6602985950; 7005519744; 7004203473|Quantum software testing: State of the art|2023|Journal of Software: Evolution and Process|35|4|e2419||||46|10.1002/smr.2419|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121582526&doi=10.1002%2fsmr.2419&partnerID=40&md5=3124e629e7b4711f63a17373a0a6bbf1|Quantum computing is expected to exponentially outperform classic computing on a broad set of problems, including encryption, machine learning, and simulations. It has an impact yet to explore on all software lifecycle's processes and techniques. Testing quantum software raises a significant number of challenges due to the unique properties of quantum physics—such as superposition and entanglementand the stochastic behavior of quantum systems. It is, therefore, an open research issue. In this work, we offer a systematic mapping study of quantum software testing engineering, presenting a comprehensive view of the current state of the art. The main identified trends in testing techniques are (1) the statistic approaches based on repeated measurements and (2) the use of Hoare-like logics to reason about software correctness. Another relevant line of research is reversible circuit testing, which is partially applicable to quantum software unitary testing. Finally, we have observed a flourishing of secondary studies and frameworks supporting testing processes from 2018 onwards. © 2021 The Authors. Journal of Software: Evolution and Process published by John Wiley & Sons Ltd.||Computation theory; Cryptography; Life cycle; Quantum optics; Stochastic systems; Testing; Life-cycle process; Machine simulation; Machine-learning; Property; Quantum Computing; Software Evolution; Software life cycles; Software process; Software testings; State of the art; Software testing|Review|Final||Scopus|2-s2.0-85121582526
scopus|Abboush M.; Knieke C.; Rausch A.|Abboush, Mohammad (57206905108); Knieke, Christoph (24802237700); Rausch, Andreas (8586021000)|57206905108; 24802237700; 8586021000|GRU-Based Denoising Autoencoder for Detection and Clustering of Unknown Single and Concurrent Faults during System Integration Testing of Automotive Software Systems|2023|Sensors|23|14|6606||||8|10.3390/s23146606|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165966955&doi=10.3390%2fs23146606&partnerID=40&md5=3b2b94c64c1eb05a58c916d00a6218ae|Recently, remarkable successes have been achieved in the quality assurance of automotive software systems (ASSs) through the utilization of real-time hardware-in-the-loop (HIL) simulation. Based on the HIL platform, safe, flexible and reliable realistic simulation during the system development process can be enabled. However, notwithstanding the test automation capability, large amounts of recordings data are generated as a result of HIL test executions. Expert knowledge-based approaches to analyze the generated recordings, with the aim of detecting and identifying the faults, are costly in terms of time, effort and difficulty. Therefore, in this study, a novel deep learning-based methodology is proposed so that the faults of automotive sensor signals can be efficiently and automatically detected and identified without human intervention. Concretely, a hybrid GRU-based denoising autoencoder (GRU-based DAE) model with the k-means algorithm is developed for the fault-detection and clustering problem in sequential data. By doing so, based on the real-time historical data, not only individual faults but also unknown simultaneous faults under noisy conditions can be accurately detected and clustered. The applicability and advantages of the proposed method for the HIL testing process are demonstrated by two automotive case studies. To be specific, a high-fidelity gasoline engine and vehicle dynamic system along with an entire vehicle model are considered to verify the performance of the proposed model. The superiority of the proposed architecture compared to other autoencoder variants is presented in the results in terms of reconstruction error under several noise levels. The validation results indicate that the proposed model can perform high detection and clustering accuracy of unknown faults compared to stand-alone techniques. © 2023 by the authors.|automotive software systems development; deep learning; fault detection and clustering; GRU-based denoising autoencoder; hardware-in-the-loop (HIL); k-means; real-time validation; system integration testing|Deep learning; Fault detection; Hardware-in-the-loop simulation; Knowledge based systems; Learning systems; Quality assurance; Real time systems; Simulation platform; Software design; Synthetic apertures; Auto encoders; Automotive software system development; Automotive software systems; Clusterings; De-noising; Deep learning; Fault detection and clustering; Faults detection; GRU-based denoising autoencoder; Hardware in the loops; Hardware-in-the-loop; K-means; Real-time validation; Software systems development; System integration; System integration testing; Integration testing|Article|Final|All Open Access; Gold Open Access; Green Open Access|Scopus|2-s2.0-85165966955
scopus|Alsaedi S.A.; Noaman A.Y.; Gad-Elrab A.A.A.; Eassa F.E.|Alsaedi, Shatha Abed (58349483500); Noaman, Amin Yousef (6506736298); Gad-Elrab, Ahmed A. A. (57200038453); Eassa, Fathy Elbouraey (6506548846)|58349483500; 6506736298; 57200038453; 6506548846|Nature-Based Prediction Model of Bug Reports Based on Ensemble Machine Learning Model|2023|IEEE Access|11|||63916|63931|15|13|10.1109/ACCESS.2023.3288156|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162891630&doi=10.1109%2fACCESS.2023.3288156&partnerID=40&md5=d9a3f34ed8d43633a18f286632088a7c|In software development systems, the maintenance process of software systems attracted the attention of researchers due to its importance in fixing the defects discovered in the software testing by using bug reports (BRs) which include detailed information like description, status, reporter, assignee, priority, and severity of the bug and other information. The main problem in this process is how to analyze these BRs to discover all defects in the system, which is a tedious and time-consuming task if done manually because the number of BRs increases dramatically. Thus, the automated solution is the best. Most of the current research focuses on automating this process from different aspects, such as detecting the severity or priority of the bug. However, they did not consider the nature of the bug, which is a multi-class classification problem. This paper solves this problem by proposing a new prediction model to analyze BRs and predict the nature of the bug. The proposed model constructs an ensemble machine learning algorithm using natural language processing (NLP) and machine learning techniques. We simulate the proposed model by using a publicly available dataset for two online software bug repositories (Mozilla and Eclipse), which includes six classes: Program Anomaly, GUI, Network or Security, Configuration, Performance, and Test-Code. The simulation results show that the proposed model can achieve better accuracy than most existing models, namely, 90.42% without text augmentation and 96.72% with text augmentation.  © 2013 IEEE.|bug reports; ensemble machine learning algorithm; machine learning; natural language processing; nature classification; Software maintenance|Classification (of information); Computer software maintenance; Defects; Forecasting; Learning systems; Natural language processing systems; Program debugging; Software design; Software testing; Support vector machines; Bug reports; Computer bugs; Ensemble machine learning algorithm; Language processing; Machine learning algorithms; Machine-learning; Natural language processing; Natural languages; Nature classification; Predictive models; Software; Support vectors machine; Learning algorithms|Article|Final|All Open Access; Gold Open Access|Scopus|2-s2.0-85162891630
scopus|Stradowski S.; Madeyski L.|Stradowski, Szymon (57899636200); Madeyski, Lech (14045220900)|57899636200; 14045220900|Industrial applications of software defect prediction using machine learning: A business-driven systematic literature review|2023|Information and Software Technology|159||107192||||18|10.1016/j.infsof.2023.107192|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150041533&doi=10.1016%2fj.infsof.2023.107192&partnerID=40&md5=adef39458fbdf72dbe9232624eef7f22|Context: Machine learning software defect prediction is a promising field of software engineering, attracting a great deal of attention from the research community; however, its industry application tents to lag behind academic achievements. Objective: This study is part of a larger project focused on improving the quality and minimising the cost of software testing of the 5G system at Nokia, and aims to evaluate the business applicability of machine learning software defect prediction and gather lessons learnt. Methods: The systematic literature review was conducted on journal and conference papers published between 2015 and 2022 in popular online databases (ACM, IEEE, Springer, Scopus, Science Direct, and Google Scholar). A quasi-gold standard procedure was used to validate the search, and SEGRESS guidelines were used for transparency, reporting, and replicability. Results: We have selected and analysed 32 publications out of 397 found by our automatic search (and seven by snowballing). We have identified highly relevant evidence of methods, features, frameworks, and datasets used. However, we found a minimal emphasis on practical lessons learnt and cost consciousness — both vital from a business perspective. Conclusion: Even though the number of machine learning software defect prediction studies validated in the industry is increasing (and we were able to identify several excellent papers on studies performed in vivo), there is still not enough practical focus on the business aspects of the effort that would help bridge the gap between the needs of the industry and academic research. © 2023 The Authors|Effort and cost minimisation; Industry; Machine learning; Real-world; Software defect prediction; Systematic literature review|5G mobile communication systems; Application programs; Costs; Defects; Forecasting; Software testing; Cost minimization; Effort and cost minimization; Industry applications; Lesson learnt; Machine learning software; Machine-learning; Real-world; Research communities; Software defect prediction; Systematic literature review; Machine learning|Review|Final|All Open Access; Green Open Access; Hybrid Gold Open Access|Scopus|2-s2.0-85150041533
scopus|Tsai W.-T.; Zhang L.; Hu S.; Fan Z.; Wang Q.|Tsai, Wei-Tek (7402907369); Zhang, Li (57218408896); Hu, Shufeng (57542273100); Fan, Zizheng (57963252500); Wang, Qianyu (58442433300)|7402907369; 57218408896; 57542273100; 57963252500; 58442433300|Crowdtesting Practices and Models: An Empirical Approach|2023|Information and Software Technology|154||107103||||3|10.1016/j.infsof.2022.107103|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141810795&doi=10.1016%2fj.infsof.2022.107103&partnerID=40&md5=6026d56d06283997af93d185054d8cff|Context: Crowdsourced software testing (CST) has received significant attention. After these years, CST has made new progress and changes. Objective: While current literature lists many CST challenges, this paper analyzes industrial CST practices, finds that many challenges already have practical solutions, summarizes their commonalities, and comes up with new CST models and processes. Method: We look for well-known CST websites to participate in and take a secret and unobtrusive approach where customers, platform managers, and fellow workers do not know that we are mainly interested in CST research. We then register at selected CST websites, collect any public documents such as whitepapers, open rules, and public training materials, and join as many test tasks as possible. Results: We analyze the confrontation and collaboration among clients, platforms, and workers in the CST sessions. Clients want to get as much bug information as possible for a small amount of pay, but workers want to get paid as much as possible for a small amount of bug information. We also study the process and method of selecting suitable CST workers. Based on these, this paper proposes three future research directions. Conclusion: Data security and privacy at CST are paramount. If this problem can be overcome, CST will have wider applications. Additionally, the integration of workers, internal workers, software automation, and artificial intelligence will be major drivers for CST. It is also critical to develop a standardized CST structure and processes, and this will push the field to grow significantly. © 2022 Elsevier B.V.|Crowdsourced software development (CSD); Crowdsourced software testing (CST)|Crowdsourcing; Human resource management; Security of data; Software design; Websites; 'current; Crowdsourced software development; Crowdsourced software testing; Empirical approach; Paper analysis; Practical solutions; Software testings; Testing models; Testing process; Workers'; Software testing|Article|Final||Scopus|2-s2.0-85141810795
scopus|Bayri V.; Demirel E.|Bayri, Vahit (58876481200); Demirel, Ece (58876587400)|58876481200; 58876587400|AI-Powered Software Testing: The Impact of Large Language Models on Testing Methodologies|2023|4th International Informatics and Software Engineering Conference - Symposium Program, IISEC 2023|||||||6|10.1109/IISEC59749.2023.10391027|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184666280&doi=10.1109%2fIISEC59749.2023.10391027&partnerID=40&md5=1c637f44d6823b5411ca85f1d7021577|Software testing is a crucial aspect of the software development lifecycle, ensuring the delivery of high-quality, reliable, and secure software systems. With the advancements in Artificial Intelligence (AI) and Natural Language Processing (NLP), Large Language Models (LLMs) have emerged as powerful tools capable of understanding and processing natural language texts easly. This article investigates the application of AI-based software testing, with a specific focus on the impact of LLMs in traditional testing methodologies. Through a comprehensive review of relevant literature and SeturDigital's 25 year testing experience, this article explores the potential benefits, challenges, and prospects of integrating LLMs into software testing.  © 2023 IEEE.|artificial intelligence; large language model; software testing; software testing life cycle|Application programs; Artificial intelligence; Computational linguistics; Integration testing; Natural language processing systems; Software design; High-quality software; Language model; Large language model; Secure software; Software development life-cycle; Software testing life cycle; Software testings; Software-systems; Testing methodology; Life cycle|Conference paper|Final||Scopus|2-s2.0-85184666280
scopus|Cico O.; Cico B.; Cico A.|Cico, Orges (56429596800); Cico, Betim (35811883100); Cico, Andja (58489550300)|56429596800; 35811883100; 58489550300|AI-assisted Software Engineering: A tertiary study|2023|12th Mediterranean Conference on Embedded Computing, MECO 2023|||||||1|10.1109/MECO58584.2023.10154972|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164974144&doi=10.1109%2fMECO58584.2023.10154972&partnerID=40&md5=ffda87a5b543333dfe2e89b113000b2c|The research in Artificial Intelligence (AI) and its applications across the software engineering (SE) domain has progressed significantly in the last decade, evidenced by an increase in systematic literature reviews. Our study aims to provide an overview of existing systematic reviews within this research area and synthesize the findings related to AI subfields (Machine Learning, Search-based, Evolutionary Computation, Vision, Robotics, Expert Systems, Speech Processing, Natural Language Processing, and Planning) supporting the five main SE processes: requirements, design, development, testing, and maintenance. For our tertiary study, we used the methodology based on Kitchenham's guidelines. We selected 11 reviews published between 2000 and 2021, including results from 513 primary studies. The selected reviews cover the AI subfields across the five main SE processes. Studies have covered Machine Learning, Natural Language Processing, and Evolutionary Computations as AI subfields assisting SE processes. We have found that reviews in AI-assisted software testing are the most common, followed by software maintenance and development. Our study can help researchers identify missing reviews on AI-assisted SE topics to help further consolidate this research area.  © 2023 IEEE.|Artificial Intelligence; Software Engineering; Tertiary Study|Application programs; Expert systems; Learning algorithms; Machine learning; Natural language processing systems; Robot programming; ITS applications; Language processing; Machine-learning; Natural languages; Research areas; Software engineering domain; Software engineering process; Subfields; Systematic literature review; Tertiary study; Software testing|Conference paper|Final||Scopus|2-s2.0-85164974144
scopus|Anand K.; Jena A.K.|Anand, Kunal (58002037700); Jena, Ajay Kumar (36620382800)|58002037700; 36620382800|Software Defect Prediction: An ML Approach-Based Comprehensive Study|2023|Lecture Notes in Networks and Systems|493|||497|512|15|8|10.1007/978-981-19-4990-6_46|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144488452&doi=10.1007%2f978-981-19-4990-6_46&partnerID=40&md5=8ca1060c14c8a896300428deb2189faa|Software testing is a vital phase in the software development life cycle. Testing validates a developed software against the input test cases by identifying the defects present in the system. The phenomenon of testing is not only time-consuming but also a costly affair. Although there are automated tools available that reduce the effort of testing up to some extent, the high maintenance cost of these tools only increases the cost. Earlier defect prediction in software significantly reduces the effort and cost without affecting the constraints. It identifies the defect-prone modules that require more rigorous testing. A practical and effective defect prediction mechanism is the need of the hour due to the challenges, namely dimensionality reduction and class imbalance, present in software defect prediction. Lately, machine learning (ML) has emerged as a powerful decision-making approach in this regard. This research work aims to do an extensive study on the implementation of ML techniques in software defect prediction. This comprehensive report is based on two different aspects named feature selection/reduction techniques and ensemble learning methods that have been used in software defect prediction. This study has also discussed the widely used software and performance measure metrics used in software defect prediction. This concise work would guide future researchers in this emerging research area. Further, this paper also emphasizes the need to identify a suitable feature selection approach that could enhance the model's predictive performance when applied with ensemble learning. © 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.|Ensemble modelling; Feature selection; Machine learning; Software defect prediction; Software testing||Conference paper|Final||Scopus|2-s2.0-85144488452
scopus|Navaei M.; Tabrizi N.|Navaei, Maryam (57948939900); Tabrizi, Nasseh (53364389900)|57948939900; 53364389900|Impact of Machine Learning on Software Development Life Cycle|2023|International Conference on Evaluation of Novel Approaches to Software Engineering, ENASE - Proceedings|2023-April|||718|726|8|1|10.5220/0011997200003464|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160560764&doi=10.5220%2f0011997200003464&partnerID=40&md5=0e25b7b57d2acad51e499888892cb95d|This research concludes an overall summary of the publications so far on the applied Machine Learning (ML) techniques in different phases of Software Development Life Cycle (SDLC) that includes Requirement Analysis, Design, Implementation, Testing, and Maintenance. We have performed a systematic review of the research studies published from 2015-2023 and revealed that Software Requirements Analysis phase has the least number of papers published; in contrast, Software Testing is the phase with the greatest number of papers published. Copyright © 2023 by SCITEPRESS - Science and Technology Publications, Lda. Under CC license (CC BY-NC-ND 4.0)|Artificial Intelligence; Machine Learning; Machine Learning Algorithms; Software Development Life Cycle; Software Engineering|Application programs; Learning algorithms; Life cycle; Publishing; Requirements engineering; Software design; Software testing; Analysis/design; Applied machine learning; Design implementation; Implementation testing; Machine learning algorithms; Machine learning techniques; Machine-learning; Requirement analysis; Software development life-cycle; Testing and maintenance; Machine learning|Conference paper|Final|All Open Access; Hybrid Gold Open Access|Scopus|2-s2.0-85160560764
scopus|Laaber C.; Yue T.; Ali S.; Schwitalla T.; Nygard J.F.|Laaber, Christoph (57194171758); Yue, Tao (25651096400); Ali, Shaukat (56962801700); Schwitalla, Thomas (57193757105); Nygard, Jan F. (7003875061)|57194171758; 25651096400; 56962801700; 57193757105; 7003875061|Challenges of Testing an Evolving Cancer Registration Support System in Practice|2023|Proceedings - International Conference on Software Engineering||||355|359|4|4|10.1109/ICSE-Companion58688.2023.00102|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171358088&doi=10.1109%2fICSE-Companion58688.2023.00102&partnerID=40&md5=20dac898b1aabfa1d9022386b11753e1|The Cancer Registry of Norway (CRN) is a public body responsible for capturing and curating cancer patient data histories to provide a unified access to research data and statistics for doctors, patients, and policymakers. For this purpose, CRN develops and operates a complex, constantly-evolving, and socio-technical software system. Recently, machine learning (ML) algorithms have been introduced into this system to augment the manual decisions made by humans with automated decision support from learned models. To ensure that the system is correct and robust and cancer patients' data are properly handled and do not violate privacy concerns, automated testing solutions are being developed. In this paper, we share the challenges that we identified when developing automated testing solutions at CRN. Such testing potentially impacts the quality of cancer data for years to come, which is also used by the system's stakeholders to make critical decisions. The challenges identified are not specific to CRN but are also valid in the context of other healthcare registries. We also provide some details on initial solutions that we are investigating to solve the identified challenges. © 2023 IEEE.|cancer registry; evolution; healthcare; research challenges; software testing|Automation; Decision support systems; Diseases; Health care; Hospital data processing; Machine learning; Access to research; Automated testing; Cancer patients; Cancer registries; Evolution; Healthcare; Patient data; Research challenges; Software testings; Support systems; Software testing|Conference paper|Final|All Open Access; Green Open Access|Scopus|2-s2.0-85171358088
scopus|Krichen M.|Krichen, Moez (8973115500)|8973115500|How Artificial Intelligence Can Revolutionize Software Testing Techniques|2023|Lecture Notes in Networks and Systems|649 LNNS|||189|198|9|6|10.1007/978-3-031-27499-2_18|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152565736&doi=10.1007%2f978-3-031-27499-2_18&partnerID=40&md5=2bc9127f1e51c7b242b37b1a68fcfdab|Since the end of the 2000s, connected objects, applications and other innovative digital tools have abounded and continued to grow. However, if the digital evolution makes it possible to reach a large audience, bugs can become a real threat to the sustainability of large companies. In this article, we will provide a brief review of the many strategies for testing software as well as the various approaches to artificial intelligence. In addition, we provide a rundown of the primary benefits that derive from employing artificial methods during the software testing process. In addition, we provide a few examples of artificial intelligence-driven tools that have been specifically developed for the purpose of testing software. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.|Advantages; Artificial intelligence; Software testing; Tools|Artificial intelligence; Digital devices; Well testing; Advantage; Digital evolution; Digital tools; Large companies; Software testing techniques; Software testings; Testing process; Testing software; Software testing|Conference paper|Final||Scopus|2-s2.0-85152565736
scopus|Park S.; Kim D.-H.|Park, Sunggyun (57216947436); Kim, Do-Hoon (56972838700)|57216947436; 56972838700|Evaluation of SARS-CoV-2 Detection Systems Using Clinical Samples and Standard Material: A Comparative Study|2023|Diagnostics|13|12|2046||||0|10.3390/diagnostics13122046|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163933680&doi=10.3390%2fdiagnostics13122046&partnerID=40&md5=e0033b9ff817c6194b677d7928d8f8d1|Due to the decreasing trends in daily confirmed COVID-19 cases and daily confirmed tests, there is a need for a new testing system capable of quickly and efficiently testing small amounts of samples. Therefore, we compared and evaluated the testing performance of the Aptima SARS-CoV-2 assay, an automated testing system that allows continuous loading of samples, and the Real-Q Direct SARS-CoV-2 detection kit that is currently being used in our laboratory. We compared the results of the two testing systems using 259 residual individual nasopharyngeal specimens and 91 residual pooled nasopharyngeal specimens that were submitted for COVID-19 testing in January and February 2023. The 95% limit of detection (LoD) for the Aptima SARS-CoV-2 assay determined using reference material for SARS-CoV-2 nucleic acid was confirmed to be 17.793 copies/mL, while the LoD for the Real-Q Direct SARS-CoV-2 detection kit was determined to be 131.842 copies/mL for the RdRP gene and 241.77 copies/mL for the E gene. The comparative study using clinical specimens showed almost perfect agreement. Our data showed that the Aptima SARS-CoV-2 assay has a very low LoD. In addition, the Aptima SARS-CoV-2 assay and Real-Q Direct detection kit have comparable clinical performance for SARS-CoV-2 for individual and pooled samples. © 2023 by the authors.|COVID-19; limit of detection; SARS-CoV-2|nucleic acid; Article; comparative study; controlled study; coronavirus disease 2019; COVID-19 testing; human; human tissue; limit of detection; major clinical study; nasopharyngeal swab; virus detection|Article|Final|All Open Access; Gold Open Access; Green Open Access|Scopus|2-s2.0-85163933680
scopus|Kim M.; Corradini D.; Sinha S.; Orso A.; Pasqua M.; Tzoref-Brill R.; Ceccato M.|Kim, Myeongsoo (57219538205); Corradini, Davide (57212489683); Sinha, Saurabh (55636320325); Orso, Alessandro (6603901617); Pasqua, Michele (57193643550); Tzoref-Brill, Rachel (35185578400); Ceccato, Mariano (8216098200)|57219538205; 57212489683; 55636320325; 6603901617; 57193643550; 35185578400; 8216098200|Enhancing REST API Testing with NLP Techniques|2023|ISSTA 2023 - Proceedings of the 32nd ACM SIGSOFT International Symposium on Software Testing and Analysis||||1232|1243|11|25|10.1145/3597926.3598131|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167737439&doi=10.1145%2f3597926.3598131&partnerID=40&md5=5e61097c2f8d4abe58541df1208d0209|RESTful services are commonly documented using OpenAPI specifications. Although numerous automated testing techniques have been proposed that leverage the machine-readable part of these specifications to guide test generation, their human-readable part has been mostly neglected. This is a missed opportunity, as natural language descriptions in the specifications often contain relevant information, including example values and inter-parameter dependencies, that can be used to improve test generation. In this spirit, we propose NLPtoREST, an automated approach that applies natural language processing techniques to assist REST API testing. Given an API and its specification, NLPtoREST extracts additional OpenAPI rules from the human-readable part of the specification. It then enhances the original specification by adding these rules to it. Testing tools can transparently use the enhanced specification to perform better test case generation. Because rule extraction can be inaccurate, due to either the intrinsic ambiguity of natural language or mismatches between documentation and implementation, NLPtoREST also incorporates a validation step aimed at eliminating spurious rules. We performed studies to assess the effectiveness of our rule extraction and validation approach, and the impact of enhanced specifications on the performance of eight state-of-the-art REST API testing tools. Our results are encouraging and show that NLPtoREST can extract many relevant rules with high accuracy, which can in turn significantly improve testing tools' performance.  © 2023 ACM.|Automated REST API Testing; Natural Language Processing for Testing; OpenAPI Specification Analysis|Application programming interfaces (API); Automation; Extraction; Natural language processing systems; Automated REST API testing; Human-readable; Language processing; Natural language processing for testing; Natural languages; OpenAPI specification analyse; RESTful Services; Rules extraction; Test generations; Testing tools; Specifications|Conference paper|Final||Scopus|2-s2.0-85167737439
scopus|Zulkifli Z.; Gaol F.L.; Trisetyarso A.; Budiharto W.|Zulkifli, Zulkifli (58493910400); Gaol, Ford Lumban (24536664300); Trisetyarso, Agung (36337949500); Budiharto, Widodo (36069151100)|58493910400; 24536664300; 36337949500; 36069151100|Software Testing Integration-Based Model (I-BM) Framework for Recognizing Measure Fault Output Accuracy Using Machine Learning Approach|2023|International Journal of Software Engineering and Knowledge Engineering|33|8||1149|1168|19|4|10.1142/S0218194023300026|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165162280&doi=10.1142%2fS0218194023300026&partnerID=40&md5=9a8185e91aaa111facf848ff4f94f69b|In software development, the software testing phase is an important process in determining the quality level of the software. Software testing is a process of executing a program aimed at finding errors in module access, units, and involves the execution of the system being tested on a number of test inputs, and determining whether the output produced is correct. In this study, a model-based testing (MBT) called integration-based model (I-BM) framework will be developed. This I-BM framework integrates testing variables from several software testing methods, namely black-box testing, white-box testing, unit testing, system testing, and acceptance testing. The integrated variables are function, interface, structure, performance, requirement, documentation, positives, and negatives. Then, this framework will document software errors to form a dataset, which will be measured for the level of accuracy of expected manual fault output using neural network algorithm and support vector machine. From the experiment results, it shows that the accuracy level of predicting fault output values from the I-BM framework using the neural network algorithm is on average 80%, and it produces a superior SVM architecture model in predicting I-BM framework output errors with an accuracy value of 0.99, precision of 0.99, recall of 0.99, and F1-score of 0.99. Compared to other MBT, the IBM framework has the advantage of being a more comprehensive software testing model because it starts from the identification of problems, analysis, design, documentation of software testing, and recommendations for each fault output found. Thus, software errors can be classified systematically in the form of a dataset, and not only focus on software testing for product lines and module mappings.  © 2023 World Scientific Publishing Company.|Integration-based model (I-BM); model-based testing (MBT); neural networks algorithms; support vector machines|Acceptance tests; Black-box testing; Errors; Integration; Integration testing; Software design; Statistical tests; Integration-based model; Machine learning approaches; Model based testing; Model-based testing; Modelling framework; Neural networks algorithms; Output accuracy; Software errors; Software testings; Support vectors machine; Support vector machines|Review|Final||Scopus|2-s2.0-85165162280
scopus|Akila V.; Vasuki A.; Christaline J.A.; Sathiya R.; Rishi P.; Edward A.S.|Akila, V. (57194531772); Vasuki, A. (58246044600); Christaline, J.Anita (57220053761); Sathiya, R. (57210402766); Rishi, Priti (57933651600); Edward, A.Shirly (59454715400)|57194531772; 58246044600; 57220053761; 57210402766; 57933651600; 59454715400|Enhancing Software Testing with Machine Learning Techniques|2023|2nd International Conference on Sustainable Computing and Data Communication Systems, ICSCDS 2023 - Proceedings||||329|333|4|0|10.1109/ICSCDS56580.2023.10105028|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159110178&doi=10.1109%2fICSCDS56580.2023.10105028&partnerID=40&md5=e368bc43d06e8da28a54697ae3c82465|Software testing is a crucial component of software development that helps ensure the quality and reliability of a software system. By performing tests, developers can identify potential bugs and malfunctions and correct them before the final product is released to the market. The use of machine learning algorithms in software testing not only improves efficiency and accuracy but also helps reduce manual testing efforts. The algorithms analyze patterns and use statistical methods to identify areas that need to be tested. This results in a more comprehensive and thorough testing process, making it possible to deliver high-quality software systems to customers.  © 2023 IEEE.|decision tree; Machine Learning; Random forest; Regression; Software testing|Decision trees; Machine learning; Random forests; Software design; Software reliability; Algorithm analysis; Machine learning algorithms; Machine learning techniques; Machine-learning; Manual testing; Random forests; Regression; Software testings; Software-systems; Testing effort; Software testing|Conference paper|Final||Scopus|2-s2.0-85159110178
scopus|Arcuri A.; Zhang M.; Belhadi A.; Marculescu B.; Golmohammadi A.; Galeotti J.P.; Seran S.|Arcuri, Andrea (23097099900); Zhang, Man (56990520700); Belhadi, Asma (56820083800); Marculescu, Bogdan (56131469600); Golmohammadi, Amid (58068753800); Galeotti, Juan Pablo (12646413700); Seran, Susruthan (58126435600)|23097099900; 56990520700; 56820083800; 56131469600; 58068753800; 12646413700; 58126435600|Building an open-source system test generation tool: lessons learned and empirical analyses with EvoMaster|2023|Software Quality Journal|31|3||947|990|43|9|10.1007/s11219-023-09620-w|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149316084&doi=10.1007%2fs11219-023-09620-w&partnerID=40&md5=2e4c102b04c5ae8e7f34f9c7172e947a|Research in software testing often involves the development of software prototypes. Like any piece of software, there are challenges in the development, use and verification of such tools. However, some challenges are rather specific to this problem domain. For example, often these tools are developed by PhD students straight out of bachelor/master degrees, possibly lacking any industrial experience in software development. Prototype tools are used to carry out empirical studies, possibly studying different parameters of novel designed algorithms. Software scaffolding is needed to run large sets of experiments efficiently. Furthermore, when using AI-based techniques like evolutionary algorithms, care needs to be taken to deal with their randomness, which further complicates their verification. The aforementioned represent some of the challenges we have identified for this domain. In this paper, we report on our experience in building the open-source EvoMaster tool, which aims at system-level test case generation for enterprise applications. Many of the challenges we faced would be common to any researcher needing to build software testing tool prototypes. Therefore, one goal is that our shared experience here will boost the research community, by providing concrete solutions to many development challenges in the building of such kind of research prototypes. Ultimately, this will lead to increase the impact of scientific research on industrial practice. © 2023, The Author(s).|Experimentation; Fuzzing; SBST; Software testing; Tool|Industrial research; Open source software; Open systems; Scaffolds; Software design; Software prototyping; Verification; Empirical analysis; Experimentation; Fuzzing; Generation tools; Open source system; Problem domain; SBST; Software testings; System test; Test generations; Software testing|Article|Final|All Open Access; Green Open Access; Hybrid Gold Open Access|Scopus|2-s2.0-85149316084
scopus|Boukhlif M.; Hanine M.; Kharmoum N.|Boukhlif, Mohamed (58247381400); Hanine, Mohamed (57219370936); Kharmoum, Nassim (57210745538)|58247381400; 57219370936; 57210745538|A Decade of Intelligent Software Testing Research: A Bibliometric Analysis|2023|Electronics (Switzerland)|12|9|2109||||22|10.3390/electronics12092109|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159213053&doi=10.3390%2felectronics12092109&partnerID=40&md5=41df76c8c4ae2e1641d6cad959517f58|It gets harder and harder to guarantee the quality of software systems due to their increasing complexity and fast development. Because it helps spot errors and gaps during the first phases of software development, software testing is one of the most crucial stages of software engineering. Software testing used to be done manually, which is a time-consuming, imprecise procedure that comes with errors and gaps and costs money, time, and effort. Currently, testing professionals routinely automate testing to obtain trustworthy results while saving time, cost, and labor. We’ve also moved the starting point of the software cycle to the developer, and made write tests before even writing code, or what’s known as TDD (Test Driven Development). The use of new artificial intelligence techniques will enable the generation of smart test cases to improve test quality and provide better coverage and accurate results. In this study, we used the Web of Science database to acquire bibliometric data about intelligent software testing papers which were conducted between 2012 and 2022, and we used Biblioshiny from the R bibliomerix package, alongside with VOSViewer in order to analyze the data and extract insights and answer research questions about the authors, articles, journals, organizations, and countries publishing in the field of intelligent software testing. The focus of this study is on scientific progress and collaborative trends in scholarly research, providing a blueprint for showcasing worldwide developments in the realm of intelligent software testing. By gaining a comprehensive understanding of the present state of research on the application of artificial intelligence in software testing, this study can offer valuable insights to software engineers, architects, and researchers in the field. © 2023 by the authors.|artificial intelligence; bibliometrics; bibliometrix package; biblioshiny application; R; software testing; VOSviewer||Review|Final|All Open Access; Gold Open Access|Scopus|2-s2.0-85159213053
scopus|Khaliq Z.; Khan D.A.; Farooq S.U.|Khaliq, Zubair (57423387800); Khan, Dawood Ashraf (35761464100); Farooq, Sheikh Umar (55259943800)|57423387800; 35761464100; 55259943800|Using deep learning for selenium web UI functional tests: A case-study with e-commerce applications|2023|Engineering Applications of Artificial Intelligence|117||105446||||8|10.1016/j.engappai.2022.105446|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140333270&doi=10.1016%2fj.engappai.2022.105446&partnerID=40&md5=c4acf18f071716ddcd77f66983c4e1a3|The application of test cases for detecting the faults within the software is called software testing. Manual testing is laborious and time-consuming hence automation tools to test software were introduced. Despite the use of automation tools at the User Interface (UI) level of the test pyramid, the limitations of current automation tools like automated test case generation and automated repairing of fragile tests still force us to carry out a large amount of manual testing. In this paper, we propose a novel method using AI to address the given challenges. With our proposed method test cases are automatically generated from the structure of the UI using a pipelined architecture of object detection, text detection and NLP models. We show that the test cases generated by the proposed framework can be translated into executable test scripts using a simple parser. The proposed method generates an average of 98.8% correct executable test cases for the applications under study. We also show the capability of the proposed method in generating new tests automatically when the application is modified. The proposed method generates an average of 98.605% correct executable test cases when the UI is modified for the applications under study. We also empirically prove that a GPU implementation of the proposed framework results in just an additional average runtime of 0.92 seconds per test case which is significantly low given the benefits of automated generation of test scripts and automated repairing of fragile tests. © 2022 Elsevier Ltd|Automated testing; Deep learning; Software testing; Transformers; UI functional testing|Application programs; Automation; Deep learning; Electric transformer testing; Object detection; Repair; Selenium; Selenium compounds; User interfaces; Automated testing; Automation tools; Deep learning; Executables; Functional testing; Manual testing; Software testings; Test case; Transformer; User interface functional testing; Software testing|Article|Final||Scopus|2-s2.0-85140333270
scopus|Alshahwan N.; Harman M.; Marginean A.|Alshahwan, Nadia (24821603800); Harman, Mark (7006379048); Marginean, Alexandru (56311537300)|24821603800; 7006379048; 56311537300|Software Testing Research Challenges: An Industrial Perspective|2023|Proceedings - 2023 IEEE 16th International Conference on Software Testing, Verification and Validation, ICST 2023||||1|10|9|15|10.1109/ICST57152.2023.00008|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161898000&doi=10.1109%2fICST57152.2023.00008&partnerID=40&md5=1d3e066d49cf0d1adbddebd59727ba72|There have been rapid recent developments in automated software test design, repair and program improvement. Advances in artificial intelligence also have great potential impact to tackle software testing research problems. In this paper we highlight open research problems and challenges from an industrial perspective. This perspective draws on our experience at Meta Platforms, which has been actively involved in software testing research and development for approximately a decade. As we set out here, there are many exciting opportunities for software testing research to achieve the widest and deepest impact on software practice. With this overview of the research landscape from an industrial perspective, we aim to stimulate further interest in the deployment of software testing research. We hope to be able to collaborate with the scientific community on some of these research challenges.  © 2023 IEEE.|Artificial Intelligence; Automated Program Repair; Automated Remediation; Automated Software Engineering; Genetic Improvement; Software Testing|Artificial intelligence; Automation; Industrial research; Repair; Automated program repair; Automated remediation; Automated software engineering; Genetic improvements; Research challenges; Research problems; Software testings; Test designs; Test projects; Test repair; Software testing|Conference paper|Final||Scopus|2-s2.0-85161898000
scopus|Sharma S.; Chande S.V.|Sharma, Sheetal (57939398700); Chande, Swati V. (36571448300)|57939398700; 36571448300|Optimizing test case prioritization using machine learning algorithms|2023|Journal of Autonomous Intelligence|6|2|661||||0|10.32629/jai.v6i2.661|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166210466&doi=10.32629%2fjai.v6i2.661&partnerID=40&md5=5f6e277fabae2d3e4a48c20dee144fd5|Software testing is an important aspect of software development to ensure the quality and reliability of the software. With the increasing complexity of software systems, the number of test cases has also increased significantly, making it challenging to execute all the test cases in a limited amount of time. Test case prioritization techniques have been proposed to tackle this problem by identifying and executing the most important test cases first. In this research paper, we propose the use of machine learning algorithms for prioritization of test cases. We explore different machine learning algorithms, including decision trees, random forests, and neural networks, and compare their performance with traditional prioritization techniques such as code coverage-based and risk-based prioritization. We evaluate the effectiveness of these algorithms on various datasets and metrics such as the number of test cases executed, the fault detection rate, and the execution time. Our experimental results demonstrate that machine learning algorithms can effectively prioritize test cases and outperform traditional techniques in terms of reducing the number of test cases executed while maintaining high fault detection rates. Furthermore, we discuss the potential limitations and future research directions of using machine learning algorithms for test case prioritization. Our research findings contribute to the development of more efficient and effective software testing techniques that can improve the quality and reliability of software systems. © 2023 by author(s).|bugs; decision tree; machine learning; open source; random forest||Article|Final|All Open Access; Gold Open Access|Scopus|2-s2.0-85166210466
scopus|Andrade R.; Mascarenhas A.P.F.M.; Simoes M.A.|Andrade, Renato (58788742500); Mascarenhas, Ana Patricia Fontes Magalhaes (24476405800); Simoes, Marco Antonio (57197880779)|58788742500; 24476405800; 57197880779|GOBEAT: Towards a Methodology to Support MAS Test Case Definition|2023|Proceedings - 2023 Latin American Robotics Symposium, 2023 Brazilian Symposium on Robotics, and 2023 Workshop of Robotics in Education, LARS/SBR/WRE 2023||||218|223|5|0|10.1109/LARS/SBR/WRE59448.2023.10332953|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181115298&doi=10.1109%2fLARS%2fSBR%2fWRE59448.2023.10332953&partnerID=40&md5=a1d05563bc8e29248f1a82a6a3ae0cc0|Multi-Agent Systems (MAS) is a branch of Artificial Intelligence (AI) that works with distributed systems whose components are autonomous entities called agents. The soccer game has been used as a test bed to stimulate research in the MAS. A soccer team, i.e., a MAS, is composed of a group of players, i.e., agents, who should coordinate their actions towards a goal. The testing process in MASs has proven to be challenging. Autonomous agents are programmed to learn during their execution. So, running the same test scenario successively can lead to different results. It makes difficult the application of conventional software testing techniques. This paper proposes the Goal Behavioral Agent Testing (GoBeAT) methodology to assist in specifying the MAS test suite applied to the robot soccer domain. GoBeAT was tested in a case study by a robot soccer team of the Robotic World Cup (RoboCup) and showed positive results in the definition of a test suit.  © 2023 IEEE.|MAS; Robot Soccer; Software Testing|Application programs; Autonomous agents; Intelligent robots; Software testing; Sports; Autonomous entities; Behavioral agents; Distributed systems; Robot soccer; Soccer games; Soccer team; Software testings; Test bed; Test case; Testing process; Multi agent systems|Conference paper|Final||Scopus|2-s2.0-85181115298
scopus|Zimmermann D.; Koziolek A.|Zimmermann, Daniel (57192928414); Koziolek, Anne (55094731500)|57192928414; 55094731500|GUI-Based Software Testing: An Automated Approach Using GPT-4 and Selenium WebDriver|2023|Proceedings - 2023 38th IEEE/ACM International Conference on Automated Software Engineering Workshops, ASEW 2023||||171|174|3|10|10.1109/ASEW60602.2023.00028|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178510464&doi=10.1109%2fASEW60602.2023.00028&partnerID=40&md5=5905b7e1c08650949819f9e27ae8cd39|This paper presents a novel method for GUI testing in web applications that largely automates the process by integrating the advanced language model GPT-4 with Selenium, a popular web application testing framework. Unlike traditional deep learning approaches, which require extensive training data, GPT-4 is pre-trained on a large corpus, giving it significant generalisation and inference capabilities. These capabilities allow testing without the need for recorded data from human testers, significantly reducing the time and effort required for the testing process. We also compare the efficiency of our integrated GPT-4 approach with monkey testing, a widely used technique for automated GUI testing where user input is randomly generated. To evaluate our approach, we implemented a web calculator with an integrated code coverage system. The results show that our integrated GPT-4 approach provides significantly better branch coverage compared to monkey testing. These results highlight the significant potential of integrating specific AI models such as GPT-4 and automated testing tools to improve the accuracy and efficiency of GUI testing in web applications.  © 2023 IEEE.|GPT-4; Language Models; Test Automation; UI Testing|Automation; Computational linguistics; Deep learning; Graphical user interfaces; Integration testing; Selenium; Automated approach; GPT-4; GUI testing; Language model; Novel methods; Software testings; Test Automation; UI testing; WEB application; Web applications; Efficiency|Conference paper|Final||Scopus|2-s2.0-85178510464
scopus|ElGhondakly R.; Moussa S.M.; Badr N.|ElGhondakly, Roaa (57189381918); Moussa, Sherin M. (35759116600); Badr, Nagwa (6602448188)|57189381918; 35759116600; 6602448188|Service-oriented model-based fault prediction and localization for service compositions testing using deep learning techniques|2023|Applied Soft Computing|143||110430||||4|10.1016/j.asoc.2023.110430|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162193918&doi=10.1016%2fj.asoc.2023.110430&partnerID=40&md5=8dac80b6dcc847ef57112f7705c9f54e|As service-oriented computing systems become more buoyant and complex, the occurrence of faults dramatically increases. Fault prediction plays a crucial role in the service-oriented computing paradigm, aiming to reduce testing cost while maximizing testing quality to utilize testing resources effectively and increase the reliability of service compositions. Although various fault prediction techniques were considered in software testing, service-oriented systems were less fortunate, in which most of the studies have focused on single web services testing rather than service compositions. Moreover, mainly the detection of faulty/non-faulty services was addressed, ignoring the estimate of faults count, their severity, as well as predicting when and where such faults would occur. In this paper, a multilateral model-based fault prediction and localization approach is proposed using deep learning techniques for web service compositions testing rather than single web service testing, which uniquely predicts not only faulty services, but also their count and severity level, location of faults, and time at which faults would occur. Three deep learning models are investigated: Convolutional Neural Networks (CNNs), Recurrent Neural Networks (RNNs) and a proposed hybrid model based on both CNN and RNN. The proposed approach is language-independent, as it adopts process metrics rather than code metrics to overcome the code unavailability concern of services. The experimental analysis adopted main performance metrics on multiple public datasets to evaluate its efficiency and effectiveness. The results indicated that the hybrid CNN_RNN model achieves an average accuracy range of 84%–95.7%, where the RNN and CNN models individually achieve 75%–90% and 70%-79.3% respectively. Thus, the hybrid model increases the accuracy level by 5%–10% and 15%–20%, while achieving the least mean square error of 30% and 60% compared to the RNN and CNN models respectively. In terms of time, the RNN model consumes less average time as of 30–50 ms for the different datasets of variant sizes compared to the CNN and hybrid CNN_RNN models that consume 79–102 and 177–224 ms respectively. Thus, RNN model consumes around 50%–80% less time than those of the CNN and hybrid models respectively. © 2023 Elsevier B.V.|Deep learning techniques; Dependency graph; Fault localization; Fault prediction; Service oriented architecture; Service-oriented computing; Web service composition|Codes (symbols); Forecasting; Information services; Learning algorithms; Learning systems; Long short-term memory; Service oriented architecture (SOA); Software testing; Web services; Websites; Convolutional neural network; Deep learning technique; Dependency graphs; Fault localization; Fault prediction; Learning techniques; Recurrent neural network model; Service oriented computing; Soa (serviceoriented architecture); Web service composition; Mean square error|Article|Final||Scopus|2-s2.0-85162193918
scopus|Wong W.E.; Tse T.H.|Wong, W. Eric (7403972316); Tse, T.H. (7005496974)|7403972316; 7005496974|Handbook of software fault localization: Foundations and advances|2023|Handbook of Software Fault Localization: Foundations and Advances||||1|590|589|7|10.1002/9781119880929|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161163363&doi=10.1002%2f9781119880929&partnerID=40&md5=49bce25b3a5aa2cf5fa75c6af8ca9f00|Handbook of Software Fault Localization A comprehensive analysis of fault localization techniques and strategies In Handbook of Software Fault Localization: Foundations and Advances, distinguished computer scientists Prof. W. Eric Wong and Prof. T.H. Tse deliver a robust treatment of up-to-date techniques, tools, and essential issues in software fault localization. The authors offer collective discussions of fault localization strategies with an emphasis on the most important features of each approach. The book also explores critical aspects of software fault localization, like multiple bugs, successful and failed test cases, coincidental correctness, faults introduced by missing code, the combination of several fault localization techniques, ties within fault localization rankings, concurrency bugs, spreadsheet fault localization, and theoretical studies on fault localization. Readers will benefit from the authors' straightforward discussions of how to apply cost-effective techniques to a variety of specific environments common in the real world. They will also enjoy the in-depth explorations of recent research directions on this topic. Handbook of Software Fault Localization also includes: • A thorough introduction to the concepts of software testing and debugging, their importance, typical challenges, and the consequences of poor efforts • Comprehensive explorations of traditional fault localization techniques, including program logging, assertions, and breakpoints • Practical discussions of slicing-based, program spectrum-based, and statistics-based techniques • In-depth examinations of machine learning-, data mining-, and model-based techniques for software fault localization • Perfect for researchers, professors, and students studying and working in the field, Handbook of Software Fault Localization: Foundations and Advances is also an indispensable resource for software engineers, managers, and software project decision makers responsible for schedule and budget control. © 2023 by the IEEE Computer Society. All rights reserved.|||Book|Final||Scopus|2-s2.0-85161163363
scopus||||2023 6th International Conference on Information Systems and Computer Networks, ISCON 2023|2023|2023 6th International Conference on Information Systems and Computer Networks, ISCON 2023||||||1410|0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159427271&partnerID=40&md5=71ab9a2cc67b711c005954c66a79d5f7|The proceedings contain 246 papers. The topics discussed include: estimation of recall values and accuracy of gender identification for the different age groups based on voice signals; deep learning and data mining techniques for cardiovascular disease prediction: a survey; impact of telepresence of hotel websites on behavioral intention of Indian consumers: a select study; improving the quality of monocular depth estimation using ensemble learning; post-processing deblocking technique for reduction of blocking artifacts; cloud base intrusion detection system using convolutional and supervised machine learning; implementation and comparison of artificial intelligence techniques in software testing; and an overview of bio-inspired and deep learning model for extraction of land use pattern.|||Conference review|Final||Scopus|2-s2.0-85159427271
scopus|Srivastava J.; Malik A.; Bhushan B.; Parihar V.; Nair S.|Srivastava, Jaya (57485012100); Malik, Ayasha (57215216191); Bhushan, Bharat (57205917596); Parihar, Veena (58258347100); Nair, Shyam (58491570400)|57485012100; 57215216191; 57205917596; 58258347100; 58491570400|Genetic Algorithm: An Approach for Software Testing Based on a Given Source Code|2023|Lecture Notes in Networks and Systems|617 LNNS|||543|554|11|0|10.1007/978-981-19-9512-5_49|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165066790&doi=10.1007%2f978-981-19-9512-5_49&partnerID=40&md5=a2fdf6d643ed377b6816e3acaf164304|In the progression of computer-based structures and products, software has turned out to be a vital element. Software testing is an utmost effort of an intense segment in the software development life cycle. In the same manner, everyone like to minimalize the struggle and distinguish the most of the number of errors. Automatic test case production helps to minimize the price and time effort. Worldwide a single or most significant method of automatic test case production is a crucial issue in software testing and a warm problem in the study of software testing. The paper proposed a genetic algorithm (GA) to improve the test case and the submission of the artificial intelligence (AI) approaches that is applied in software testing for automatic software testing. The data of test cases are produced randomly by put on the conditional coverage on the source code and creating the control flow graph (CFG) of the source code and then applying GA test cases that are automatically generated. GA makes the test cases optimized and outperforms which is produced by a type of testing named random testing (RT). It is an effective technique for enhancing test cases by applying GA and conditional coverage as well that implemented in MATLAB. Automated test case production improves the software testing approaches and advances the quality of software. Like this automated test, case production decreases the complete cost of software development for software-based systems. © 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.|Genetic algorithm; SDLC; Software; Software testing; Source code; STLC; Test cases|Codes (symbols); Data flow analysis; Flow graphs; Life cycle; MATLAB; Software design; Software testing; Automated test; Control-flow graphs; Product software; SDLC; Software; Software development life-cycle; Software testings; Source codes; STLC; Test case; Genetic algorithms|Conference paper|Final||Scopus|2-s2.0-85165066790
scopus|Landin C.; Liu J.; Katsarou K.; Tahvili S.|Landin, Cristina (59662944300); Liu, Jie (59878723700); Katsarou, Katerina (55876918100); Tahvili, Sahar (37093975500)|59662944300; 59878723700; 55876918100; 37093975500|Time Series Anomaly Detection using Convolutional Neural Networks in the Manufacturing Process of RAN|2023|Proceedings - 5th IEEE International Conference on Artificial Intelligence Testing, AITest 2023||||90|98|8|6|10.1109/AITest58265.2023.00023|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172254244&doi=10.1109%2fAITest58265.2023.00023&partnerID=40&md5=50092b842c5759a9a099e5f95daeee26|The traditional approach of categorizing test results as 'Pass' or 'Fail' based on fixed thresholds can be labor-intensive and lead to dropping test data. This paper presents a framework to enhance the semi-automated software testing process by detecting deviations in executed data and alerting when anomalous inputs fall outside data-driven thresholds. In detail, the proposed solution utilizes classification with convolutional neural networks and prediction modeling using linear regression, Ridge regression, Lasso regression, and XGBoost. The study also explores transfer learning in a highly correlated use case. Empirical evaluation at a leading Telecom company validates the effectiveness of the approach, showcasing its potential to improve testing efficiency and accuracy. Despite its significance, limitations include the need for further research in different domains and industries to generalize the findings, as well as the potential biases introduced by the selected machine learning models. Overall, this study contributes to the field of semi-automated software testing and highlights the benefits of leveraging data-driven thresholds and machine learning techniques for enhanced software quality assurance processes.  © 2023 IEEE.|Imbalanced Learning; Machine Learning; Moving Block Bootstrap; Software Testing; Test Optimization|Anomaly detection; Automation; Computer software selection and evaluation; Convolution; Learning systems; Logistic regression; Quality assurance; Software testing; Transfer learning; Anomaly detection; Automated software testing; Convolutional neural network; Data driven; Imbalanced Learning; Machine-learning; Moving blocks bootstrap; Software testings; Test optimization; Times series; Convolutional neural networks|Conference paper|Final||Scopus|2-s2.0-85172254244
scopus|Birchler C.; Khatiri S.; Bosshard B.; Gambi A.; Panichella S.|Birchler, Christian (57226328214); Khatiri, Sajad (57226343814); Bosshard, Bill (57348787500); Gambi, Alessio (23466827200); Panichella, Sebastiano (35095375100)|57226328214; 57226343814; 57348787500; 23466827200; 35095375100|Machine learning-based test selection for simulation-based testing of self-driving cars software|2023|Empirical Software Engineering|28|3|71||||32|10.1007/s10664-023-10286-y|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85156160993&doi=10.1007%2fs10664-023-10286-y&partnerID=40&md5=b539b1778df00f857199f8e068f3b8b8|Simulation platforms facilitate the development of emerging Cyber-Physical Systems (CPS) like self-driving cars (SDC) because they are more efficient and less dangerous than field operational test cases. Despite this, thoroughly testing SDCs in simulated environments remains challenging because SDCs must be tested in a sheer amount of long-running test cases. Past results on software testing optimization have shown that not all the test cases contribute equally to establishing confidence in test subjects’ quality and reliability, and the execution of “safe and uninformative” test cases can be skipped to reduce testing effort. However, this problem is only partially addressed in the context of SDC simulation platforms. In this paper, we investigate test selection strategies to increase the cost-effectiveness of simulation-based testing in the context of SDCs. We propose an approach called SDC-Scissor (SDC coS t-effeC tI ve teS t S electOR) that leverages Machine Learning (ML) strategies to identify and skip test cases that are unlikely to detect faults in SDCs before executing them. Our evaluation shows that SDC-Scissor outperforms the baselines. With the Logistic model, we achieve an accuracy of 70%, a precision of 65%, and a recall of 80% in selecting tests leading to a fault and improved testing cost-effectiveness. Specifically, SDC-Scissor avoided the execution of 50% of unnecessary tests as well as outperformed two baseline strategies. Complementary to existing work, we also integrated SDC-Scissor into the context of an industrial organization in the automotive domain to demonstrate how it can be used in industrial settings. © 2023, The Author(s).|Industrial integration; Regression testing; Self-driving cars; Software simulation; Test case selection|Autonomous vehicles; Embedded systems; Integration testing; Machine learning; Simulation platform; Software reliability; Tools; Cybe-physical systems; Cyber-physical systems; Industrial integration; Machine-learning; Regression testing; Simulation platform; Software simulation; Test case; Test case selection; Test selection; Cost effectiveness|Article|Final|All Open Access; Hybrid Gold Open Access|Scopus|2-s2.0-85156160993
scopus|Lipp S.; Elsner D.; Kacianka S.; Pretschner A.; Böhme M.; Banescu S.|Lipp, Stephan (57754702800); Elsner, Daniel (57224771491); Kacianka, Severin (56875422100); Pretschner, Alexander (12645083400); Böhme, Marcel (55321057200); Banescu, Sebastian (35147584400)|57754702800; 57224771491; 56875422100; 12645083400; 55321057200; 35147584400|Green Fuzzing: A Saturation-Based Stopping Criterion using Vulnerability Prediction|2023|ISSTA 2023 - Proceedings of the 32nd ACM SIGSOFT International Symposium on Software Testing and Analysis||||127|139|12|1|10.1145/3597926.3598043|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167700795&doi=10.1145%2f3597926.3598043&partnerID=40&md5=70b55b6a73a4064351fb9d9993e46c62|Fuzzing is a widely used automated testing technique that uses random inputs to provoke program crashes indicating security breaches. A difficult but important question is when to stop a fuzzing campaign. Usually, a campaign is terminated when the number of crashes and/or covered code elements has not increased over a certain period of time. To avoid premature termination when a ramp-up time is needed before vulnerabilities are reached, code coverage is often preferred over crash count to decide when to terminate a campaign. However, a campaign might only increase the coverage on non-security-critical code or repeatedly trigger the same crashes. For these reasons, both code coverage and crash count tend to overestimate the fuzzing effectiveness, unnecessarily increasing the duration and thus the cost of the testing process. The present paper explores the tradeoff between the amount of saved fuzzing time and number of missed bugs when stopping campaigns based on the saturation of covered, potentially vulnerable functions rather than triggered crashes or regular function coverage. In a large-scale empirical evaluation of 30 open-source C programs with a total of 240 security bugs and 1,280 fuzzing campaigns, we first show that binary classification models trained on software with known vulnerabilities (CVEs), using lightweight machine learning features derived from findings of static application security testing tools and proven software metrics, can reliably predict (potentially) vulnerable functions. Second, we show that our proposed stopping criterion terminates 24-hour fuzzing campaigns 6-12 hours earlier than the saturation of crashes and regular function coverage while missing (on average) fewer than 0.5 out of 12.5 contained bugs.  © 2023 ACM.|empirical study; fuzzing; stopping criterion|Application programs; C (programming language); Open source software; Program debugging; Automated testing; Code coverage; Empirical studies; Function coverage; Fuzzing; Random input; Regular function; Security breaches; Stopping criterion; Testing technique; Software testing|Conference paper|Final|All Open Access; Green Open Access|Scopus|2-s2.0-85167700795
scopus|Salahirad A.; Gay G.; Mohammadi E.|Salahirad, Alireza (57195625290); Gay, Gregory (25723089800); Mohammadi, Ehsan (54965851600)|57195625290; 25723089800; 54965851600|Mapping the structure and evolution of software testing research over the past three decades|2023|Journal of Systems and Software|195||111518||||12|10.1016/j.jss.2022.111518|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139315300&doi=10.1016%2fj.jss.2022.111518&partnerID=40&md5=33d44ca39355c546c4dbfbec699af11f|Background: The field of software testing is growing and rapidly-evolving. Aims: Based on keywords assigned to publications, we seek to identify predominant research topics and understand how they are connected and have evolved. Methods: We apply co-word analysis to map the topology of testing research as a network where author-assigned keywords are connected by edges indicating co-occurrence in publications. Keywords are clustered based on edge density and frequency of connection. We examine the most popular keywords, summarize clusters into high-level research topics examine how topics connect, and examine how the field is changing. Results: Testing research can be divided into 16 high-level topics and 18 subtopics. Creation guidance, automated test generation, evolution and maintenance, and test oracles have particularly strong connections to other topics, highlighting their multidisciplinary nature. Emerging keywords relate to web and mobile apps, machine learning, energy consumption, automated program repair and test generation, while emerging connections have formed between web apps, test oracles, and machine learning with many topics. Random and requirements-based testing show potential decline. Conclusions: Our observations, advice, and map data offer a deeper understanding of the field and inspiration regarding challenges and connections to explore. Editor's note: Open Science material was validated by the Journal of Systems and Software Open Science Board. © 2022 The Author(s)|Bibliometrics; Co-word analysis; Software testing|Energy utilization; Machine learning; Bibliometric; Co-occurrence; Co-word analysis; Edge densities; Machine-learning; Open science; Research topics; Software testings; Test oracles; Web App; Software testing|Article|Final|All Open Access; Green Open Access; Hybrid Gold Open Access|Scopus|2-s2.0-85139315300
scopus||||ISSTA 2023 - Proceedings of the 32nd ACM SIGSOFT International Symposium on Software Testing and Analysis|2023|ISSTA 2023 - Proceedings of the 32nd ACM SIGSOFT International Symposium on Software Testing and Analysis||||||1557|0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167730866&partnerID=40&md5=95f261c022768550f1cc09bbb5ff6465|The proceedings contain 138 papers. The topics discussed include: improving bit-blasting for nonlinear integer constraints; CONCORD: clone-aware contrastive learning for source code; towards efficient fine-tuning of pre-trained code models: an experimental study and beyond; understanding and tackling label errors in deep learning-based vulnerability detection; fine-grained code clone detection with block-based splitting of abstract syntax tree; reducing the memory footprint of IFDS-based data-flow analyses using fine-grained garbage collection; hybrid inlining: a framework for compositional and context-sensitive static analysis; green fuzzing: a saturation-based stopping criterion using vulnerability prediction; testing graph database engines via query partitioning; loop invariant inference through SMT solving enhanced reinforcement learning; dependency-aware metamorphic testing of datalog engines; and detecting state inconsistency bugs in DApps via on-chain transaction replay and fuzzing.|||Conference review|Final||Scopus|2-s2.0-85167730866
scopus||||2nd International Conference on Artificial Intelligence, Robotics, and Communication, ICAIRC 2022|2023|Lecture Notes in Electrical Engineering|1063 LNEE|||||307|0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174525108&partnerID=40&md5=82612376f7e70f9059f2e03dcd2c2d66|The proceedings contain 27 papers. The special focus in this conference is on International Conference on Artificial Intelligence, Robotics, and Communication. The topics include: Pilot Design for Compressed Sensing Based OFDM Channel Estimation; a Review of the Development of Artificial Intelligence Electronic Circuit Technology; Stock’s Closing Price Prediction Based on GRU Neural Network; random Forest Algorithm for Forest Fire Prediction; underwater Image Clearing Algorithm Based on the Laplacian Edge Detection Operator; multi-models Study on the Influence of Space–Time Factors on the Shared Bike Usage; application of Collaborative Robot in Cigarette Production Line for Automatic Distribution of Packaging Materials; comparison of Data Processing Performance of Hadoop and Spark Based on Huawei Cloud and Serverless; structured Model of “Three Flows in One” Emergency Preplan Based on Knowledge Graph; the Advance and Performance Analysis of MapReduce; an Efficient Model for Dorsal Hand Vein Recognition Based on Combination of Squeeze-and-Excitation Block and Vanilla ResNet; design and Implementation of Online Book Sale System; review of Tobacco Planting Area Estimation Based on Machine Learning and Multi-source Remote Sensing Data; an Innovative Information System for Health and Nutrition Guidance; Research on Energy Saving Scene of 5G Base Stations Based on SOM + K-Means Two-Stage Clustering Algorithm; Smart Substation Synthetical Smart Prevent Mishandling System Based on Topology Model and Intelligent IOT; fresh Products Application Information Management System; a Novel Action Recognition Method Based on Attention Enhancement and Relative Entropy; Application of Combinatorics Based on Discrete Analysis in WCET Embedded Software Testing Technology.|||Conference review|Final||Scopus|2-s2.0-85174525108
scopus|Islam M.; Khan F.; Alam S.; Hasan M.|Islam, Mahmudul (57714193400); Khan, Farhan (58293996700); Alam, Sabrina (57384365300); Hasan, Mahady (35105055600)|57714193400; 58293996700; 57384365300; 35105055600|Artificial Intelligence in Software Testing: A Systematic Review|2023|IEEE Region 10 Annual International Conference, Proceedings/TENCON||||524|529|5|10|10.1109/TENCON58879.2023.10322349|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179519029&doi=10.1109%2fTENCON58879.2023.10322349&partnerID=40&md5=abb546b355e1bc26872e94cb3427f664|Software testing is a crucial component of software development. With the increasing complexity of software systems, traditional manual testing methods are becoming less feasible. Artificial Intelligence (AI) has emerged as a promising approach to software testing in recent years. This review paper aims to provide an in-depth understanding of the current state of software testing using AI. The review will examine the various approaches, techniques, and tools used in this area and assess their effectiveness. The selected articles for this study have been extracted from different research databases using the advanced search string strategy. Initially, 40 articles have been extracted from different research libraries. After gradual filtering finally, 20 articles have been selected for the study. After studying all the selected papers, we find that various testing tasks can be automated successfully using AI (Machine Learning and Deep Learning) such as Test Case Generation, Defect Prediction, Test Case Prioritization Metamorphic Testing, Android Testing, Test Case Validation, and White Box Testing. This study also finds that the integration of AI in software testing is making software testing activities easier along with better performance. This literature review paper provides a thorough analysis of the impact AI can have on the software testing process.  © 2023 IEEE.|Artificial Intelligence; Software Testing; Systematic Literature Review; Test Automation|Integration testing; Libraries; Software design; 'current; In-depth understanding; Manual testing; Review papers; Software testings; Software-systems; Systematic literature review; Systematic Review; Test Automation; Testing method; Deep learning|Conference paper|Final||Scopus|2-s2.0-85179519029
scopus|Gu S.; Liu Z.; Liang Q.; Deng Z.; Xiao X.|Gu, Siqi (58167412500); Liu, Zhibiao (58920426000); Liang, Qiaoqing (58920584300); Deng, Zhimin (58920458000); Xiao, Xiangyu (58920458100)|58167412500; 58920426000; 58920584300; 58920458000; 58920458100|Test Case Reuse Method Based on Deep Semantic Matching|2023|Proceedings - 2023 IEEE 23rd International Conference on Software Quality, Reliability, and Security Companion, QRS-C 2023||||593|599|6|0|10.1109/QRS-C60940.2023.00022|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186744202&doi=10.1109%2fQRS-C60940.2023.00022&partnerID=40&md5=7911cc44db24f6dfe255f688c133b529|Software testing is a crucial means to ensure the quality and reliability of software, playing an indispensable role in the software development process. The design of test cases is a pivotal process within software testing. Well-designed test cases are a prerequisite for effective software testing, as the quality of test code determines the overall testing quality and effectiveness. With continuous software version iterations, a rich history of test cases accumulates during the testing process. As the functionality of the system grows, the number of required test cases and lines of code also increases, leading to reduced efficiency and longer testing cycles for testers. Test case reuse involves utilizing accumulated historical test cases and related materials for new testing tasks. Leveraging historical test cases effectively to enhance new testing tasks and improve tester efficiency is a significant challenge. In response to the aforementioned issues, this paper proposes and implements a test case reuse method based on deep semantic matching. The method employs natural language processing techniques to extract textual information and vectorize key fields of test cases, establishing a quick retrieval index. Upon receiving a user input describing the testing functionality, the method utilizes deep semantic matching technology to recommend suitable historical test cases. We improve the test case reuse method based on a deep semantic matching model and adopt the negative sampling method to increase the robustness of the model. The method's effectiveness is tested using three datasets from the text matching domain, with the Spearman coefficient as the evaluation metric, demonstrating superior matching performance compared to other baseline algorithms. © 2023 IEEE.|case reuse; semantic matching; software testing|Computer software reusability; Efficiency; Natural language processing systems; Semantics; Software design; Software reliability; Well testing; Case reuse; Semantic matching; Software development process; Software testings; Software versions; Test case; Test case reuse; Test code; Test-lines; Testing process; Software testing|Conference paper|Final||Scopus|2-s2.0-85186744202
scopus||||2023 Innovations in Intelligent Systems and Applications Conference, ASYU 2023|2023|2023 Innovations in Intelligent Systems and Applications Conference, ASYU 2023||||||936|0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178271991&partnerID=40&md5=c779057ab77ec2ea9396d3540c219eed|The proceedings contain 169 papers. The topics discussed include: a novel mobile malware detection model based on ensemble learning; fine-tuning Wav2Vec2 for classification of Turkish broadcast news and advertisement jingles; dynamic data masking by two-step encryption; a hybrid CNN-LSTM framework for unsupervised anomaly detection in water distribution plant; a new deep learning model for early stage of diabetes disease prediction; time-minimum motion handling of open liquid-filled objects using sparse sequential quadratic programming; advancements in optical character recognition for Bangla scripts; development of cloud and artificial intelligence based software testing platform (ChArIoT); non-destructive defect detection on PCB boards using a metamaterial-based circular patch antenna; and automatic fake news detection in social networks.|||Conference review|Final||Scopus|2-s2.0-85178271991
scopus|Shah H.; Kamuni N.|Shah, Hardik (57209562296); Kamuni, Navin (58864877300)|57209562296; 58864877300|DesignSystemsJS - Building a Design Systems API for aiding standardization and AI integration|2023|Proceedings - 2023 International Conference on Computing, Networking, Telecommunications and Engineering Sciences Applications, CoNTESA 2023||||83|89|6|2|10.1109/CoNTESA61248.2023.10384889|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184122054&doi=10.1109%2fCoNTESA61248.2023.10384889&partnerID=40&md5=d09f00987984f43813c1afc5c6906ffe|In the rapidly evolving landscape of software development, Design Systems have emerged as crucial frameworks that enforce consistency and efficiency in user interface (UI) and user experience (UX) design. However, the implementation of these systems varies significantly across teams, leading to discrepancies in understanding and applying design requirements. This inconsistency often results in divergent costs, efforts, and timelines in software projects. Our research introduces 'DesignSystemsJS,' a novel JavaScript library, to address these challenges. Leveraging the widespread popularity and flexibility of JavaScript, widely recognized as a dominant programming language in both client and server-side web applications, DesignSystemsJS aims to standardize Design Systems requirements. It does so by enforcing a JSON format specification for defining the Design System, based on a meticulously researched checklist. This standardization is crucial in a domain where software reuse and the evolution of JavaScript applications often pose challenges related to third-party dependencies. Furthermore, DesignSystemsJS aims to support Artificial Intelligence (AI) integration, reflecting the ongoing paradigm shift in the software development industry towards generative AI assistants. AI integration in software testing and development has seen significant advancements, offering various approaches and tools to enhance efficiency and effectiveness. Our library taps into these advancements, utilizing AI techniques like data mining and machine learning to promote automated software reuse, a key aspect of modern software development. DesignSystemsJS's architecture and API facilitate a more unified and streamlined approach to designing and implementing Design Systems, potentially revolutionizing how design consistency is maintained across different platforms and tools. This research paper details the methodology behind DesignSystemsJS, its features, and the potential impact it holds for the future of Design Systems development and AI integration. © 2023 IEEE.|Design Systems; Design Systems AI integration; Design Systems API; DesignSystemsJS|Application programming interfaces (API); Application programs; Artificial intelligence; Computer software reusability; Data integration; Data mining; Efficiency; High level languages; Integration; Integration testing; Interoperability; Software design; User interfaces; Design system API; Design system artificial intelligence integration; Design systems; Designsystemsjs; Development designs; Intelligence integration; Javascript; Software-reuse; Standardization|Conference paper|Final||Scopus|2-s2.0-85184122054
scopus||||Proceedings - 2023 IEEE/ACM International Conference on Software and System Processes, ICSSP 2023|2023|Proceedings - 2023 IEEE/ACM International Conference on Software and System Processes, ICSSP 2023||||||109|0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166269845&partnerID=40&md5=7b6fe53586e476a61a81db88d4583ec4|The proceedings contain 10 papers. The topics discussed include: achieving business success - a framework for software delivery of emerging technologies; adding generic role- and process-based behaviors to smart contracts using dynamic condition response graphs; an experience report on assessing software engineer’s outputs in practice; automatically generating dockerfiles via deep-learning: challenges and promises; characterizing the impact of culture on agile methods: the MoCA model; improve software and system process of cloud serverless architectures through automated testing with AI; measuring the benefits of CI/CD practices for database application development; towards better code reviews: using mutation testing to improve reviewer attention; towards sustainable software for public sector information systems; and using GUI test videos to obtain stakeholders’ feedback.|||Conference review|Final||Scopus|2-s2.0-85166269845
scopus|Hooda S.; Sood V.M.; Singh Y.; Dalal S.; Sood M.|Hooda, Susheela (57224091581); Sood, Vandana Mohindru (59000392600); Singh, Yashwant (57210010055); Dalal, Sandeep (57188767010); Sood, Manu (7006559768)|57224091581; 59000392600; 57210010055; 57188767010; 7006559768|Agile Software Development: Trends, Challenges and Applications|2023|Agile Software Development: Trends, Challenges and Applications||||1|365|364|7|10.1002/9781119896838|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152319031&doi=10.1002%2f9781119896838&partnerID=40&md5=96d57d8772b2d3799df5a636218054a7|A unique title tat introduces the whole range of agile software development processes from the fundamental concepts to the highest levels of applications such as requirement analysis, software testing, quality assurance, and risk management. Agile Software Development (ASD) has become a popular technology because its methods apply to any programming paradigm. It is important in the software development process because it emphasizes incremental delivery, team collaboration, continuous planning, and learning over delivering everything at once near the end. Agile has gained popularity as a result of its use of various frameworks, methods, and techniques to improve software quality. Scrum is a major agile framework that has been widely adopted by the software development community. Metaheuristic techniques have been used in the agile software development process to improve software quality and reliability. These techniques not only improve quality and reliability but also test cases, resulting in cost-effective and time-effective software. However, many significant research challenges must be addressed to put such ASD capabilities into practice. With the use of diverse techniques, guiding principles, artificial intelligence, soft computing, and machine learning, this book seeks to study theoretical and technological research findings on all facets of ASD. Also, it sheds light on the latest trends, challenges, and applications in the area of ASD. This book explores the theoretical as well as the technical research outcomes on all the aspects of Agile Software Development by using various methods, principles, artificial intelligence, soft computing, and machine learning. © 2023 Scrivener Publishing LLC.|||Book|Final||Scopus|2-s2.0-85152319031
scopus|Radliński Ł.|Radliński, Łukasz (15769924100)|15769924100|The Impact of Data Quality on Software Testing Effort Prediction|2023|Electronics (Switzerland)|12|7|1656||||4|10.3390/electronics12071656|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152780841&doi=10.3390%2felectronics12071656&partnerID=40&md5=c2d7d66d713b365fa8b3af2b04b43e72|Background: This paper investigates the impact of data quality on the performance of models predicting effort on software testing. Data quality was reflected by training data filtering strategies (data variants) covering combinations of Data Quality Rating, UFP Rating, and a threshold of valid cases. Methods: The experiment used the ISBSG dataset and 16 machine learning models. A process of three-fold cross-validation repeated 20 times was used to train and evaluate each model with each data variant. Model performance was assessed using absolute errors of prediction. A ‘win–tie–loss’ procedure, based on the Wilcoxon signed-rank test, was applied to identify the best models and data variants. Results: Most models, especially the most accurate, performed the best on a complete dataset, even though it contained cases with low data ratings. The detailed results include the rankings of the following: (1) models for particular data variants, (2) data variants for particular models, and (3) the best-performing combinations of models and data variants. Conclusions: Arbitrary and restrictive data selection to only projects with Data Quality Rating and UFP Rating of ‘A’ or ‘B’, commonly used in the literature, does not seem justified. It is recommended not to exclude cases with low data ratings to achieve better accuracy of most predictive models for testing effort prediction. © 2023 by the author.|data quality; effort prediction; ISBSG; machine learning; software testing||Article|Final|All Open Access; Gold Open Access|Scopus|2-s2.0-85152780841
scopus|Kalita P.P.; Sarma M.P.; Saikia A.P.|Kalita, Partha Pratim (58754938600); Sarma, Manash Pratim (57197875463); Saikia, Ankur Pan (58187952200)|58754938600; 57197875463; 58187952200|Artificial Intelligence and Robots in Individuals’ Lives: How to Align Technological Possibilities and Ethical Issues|2023|Ethical Issues in AI for Bioinformatics and Chemoinformatics||||119|135|16|2|10.1201/9781003353751-9|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179291733&doi=10.1201%2f9781003353751-9&partnerID=40&md5=b490f5755664d13e41f1ed65ac983fe9|This chapter investigates the ethical dilemmas posed by ethical algorithms, pre-existing or acquired values, and Artificial intelligence (AI)-related ethical issues. In general, the chapter will make readers aware of AI safety as a related area of research and provide a brief analysis of the concerns as well as potential solutions to the ethical issues that are presented. The Council on the Responsible Use of AI aims to address ethical and policy issues to help businesses and their leaders adapt to the interface between humans and machines, which is rapidly changing. A few examples of the kinds of jobs that can be effectively completed by robots include assembly line work, software testing, financial reports, and other documents compiled based on data. When developing the algorithms that are embedded in robots, the data that has been learned from human experts, such as a group of physical therapists, is frequently utilized. © 2024 selection and editorial matter, Yashwant Pathak, Surovi Saikia, Sarvadaman Pathak, Jayvadan Patel and Jigna Prajapati; individual chapters, the contributors.|||Book chapter|Final||Scopus|2-s2.0-85179291733
scopus|Zhang Y.; Chen S.; Wang Y.; Li J.; Xu K.; Chen J.; Zhao J.|Zhang, Ying (57673509800); Chen, Shijie (59113581300); Wang, Yuling (57807937900); Li, Jingjing (57194789845); Xu, Kai (59105642200); Chen, Jyhcheng (24390547400); Zhao, Jie (57193394354)|57673509800; 59113581300; 57807937900; 57194789845; 59105642200; 24390547400; 57193394354|Deep learning-based methods for classification of microsatellite instability in endometrial cancer from HE-stained pathological images|2023|Journal of Cancer Research and Clinical Oncology|149|11||8877|8888|11|10|10.1007/s00432-023-04838-4|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85158117511&doi=10.1007%2fs00432-023-04838-4&partnerID=40&md5=e1a60cf880aa8679f7e85a8366211304|Background: Microsatellite instability (MSI) is one of the essential tumor biomarkers for cancer treatment and prognosis. The presence of more significant PD-L1 expression on the surface of tumor cells in endometrial cancer with MSI suggests that MSI may be a promising biomarker for anti-PD-1/PD-L1 immunotherapy. However, the conventional testing methods are labor-intensive and expensive for patients. Methods: Inspired by classifiers for MSI based on fast and low-cost deep-learning methods in previous investigations, a new architecture for MSI classification based on an attention module is proposed to extract features from pathological images. Especially, slide-level microsatellite status will be obtained by the bag of words method to aggregate probabilities predicted by the proposed model. The H&E-stained whole slide images (WSIs) from The Cancer Genome Atlas endometrial cohort are collected as the dataset. The performances of the proposed model were primarily evaluated by the area under the receiver-operating characteristic curve, accuracy, sensitivity, and F1-Score. Results: On the randomly divided test dataset, the proposed model achieved an accuracy of 0.80, a sensitivity of 0.857, a F1-Score of 0.826, and an AUROC of 0.799. We then visualize the results of the microsatellite status classification to capture more specific morphological features, helping pathologists better understand how deep learning performs the classification. Conclusions: This study implements the prediction of microsatellite status in endometrial cancer cases using deep-learning methods directly from H&E-stained WSIs. The proposed architecture can help the model capture more valuable features for classification. In contrast to current laboratory testing methods, the proposed model creates a more convenient screening tool for rapid automated testing for patients. This method can potentially be a clinical method for detecting the microsatellite status of endometrial cancer. © 2023, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.|Attention; Deep learning; Endometrial cancer; Microsatellite instability; Whole slide image|B7-H1 Antigen; Deep Learning; Endometrial Neoplasms; Female; Humans; Microsatellite Instability; Microsatellite Repeats; microsatellite DNA; programmed death 1 ligand 1; adult; Article; attention; controlled study; deep learning; endometrium cancer; human; human tissue; laboratory test; male; microsatellite instability; randomized controlled trial; receiver operating characteristic; sensitivity and specificity; endometrium tumor; female; genetics; metabolism; microsatellite instability; pathology|Article|Final||Scopus|2-s2.0-85158117511
scopus|Bhat M.I.; Yaqoob S.I.; Imran M.|Bhat, Mohammad Idrees (57192540881); Yaqoob, Syed Irfan (58494923600); Imran, Mohammad (59857572700)|57192540881; 58494923600; 59857572700|Engineering Challenges in the Development of Artificial Intelligence and Machine Learning Software Systems|2023|System Reliability and Security: Techniques and Methodologies||||133|142|9|3|10.1201/9781032624983-7|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179277659&doi=10.1201%2f9781032624983-7&partnerID=40&md5=8d4c838a9eb34b83f7f86e0841ed7615|In this chapter, we first introduce artificial intelligence and machine learning (AI/ML) as state-of-the-art in engineering software and then outline the major differences between AI/ML and traditional software development. In particular, we categorize AI/ML engineering challenges in different phases. Eventually, different challenges are generalized and categorized. Finally, we observe that software testing, quality assurance, and management of the data are the most challenging issues that engineers/developers are currently facing. © 2024 Taylor & Francis Group, LLC.|||Book chapter|Final||Scopus|2-s2.0-85179277659
scopus|Shankar S.P.; Pushp D.; Makadia N.; Dubey R.; Nayak A.; Shashikant Chaudhari S.|Shankar, Sahana P. (57216108507); Pushp, Divyansh (58674337100); Makadia, Nemi (58674370700); Dubey, Raghav (58674388300); Nayak, Anusha (58674388400); Shashikant Chaudhari, Shilpa (56177436200)|57216108507; 58674337100; 58674370700; 58674388300; 58674388400; 56177436200|Software Defect Predictor and Classifier Tool Using Machine Learning Techniques|2023|2023 International Conference on Network, Multimedia and Information Technology, NMITCON 2023|||||||3|10.1109/NMITCON58196.2023.10275871|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175399400&doi=10.1109%2fNMITCON58196.2023.10275871&partnerID=40&md5=7e41235dffafcfdd5c9859f47c8c3c1d|The Software testing is critical for ensuring the quality of software, but it can consume more than half of a software project's total expenses. This research can help software development teams identify potential bugs early on, leading to efficient and effective software creation. To improve the efficiency of software testing, this report presents research on software defect prediction using a hybrid machine learning algorithm that combines supervised and unsupervised learning techniques. The study used publicly available datasets to train and evaluate various machine learning models, including an ensemble learning model. A comparative analysis was conducted among KNN, Random Forest, Adaboost, Multilayer Perceptron, CNN, and Gaussian Naïve Bayes on different datasets. Feature selection was performed using various methods, including Recurrent Feature Elimination (RFE), SelectKBest, and Correlation, implemented by a tool created to select any feature selection algorithm and compare the results for various combinations with the above mentioned classifiers. The results achieved by the model are showed in detail for each of the algorithms on the selected datasets. The main objectives of the research are to create a tool to apply various machine learning techniques to the datasets and determine the most effective ones, as well as to explore different feature selection methods for improving the accuracy of defect prediction.  © 2023 IEEE.|Accuracy; Clustering; Ensemble Learning; Precision; Software Testing; Supervised Learning; Unsupervised Learning|Adaptive boosting; Defects; Feature Selection; Forestry; Learning systems; Program debugging; Software design; Supervised learning; Unsupervised learning; Accuracy; Clusterings; Ensemble learning; Machine learning techniques; Precision; Quality of softwares; Software defects; Software development teams; Software project; Software testings; Software testing|Conference paper|Final||Scopus|2-s2.0-85175399400
scopus|Mustaqeem M.; Siddiqui T.; Khan N.A.; Kumar D.|Mustaqeem, Mohd (57223112377); Siddiqui, Tamanna (35186530000); Khan, Najeeb Ahmad (57216272434); Kumar, Deepak (59936812700)|57223112377; 35186530000; 57216272434; 59936812700|In-Depth Analysis of Various Artificial Intelligence Techniques in Software Engineering: Experimental Study|2023|Journal of Information Technology Management|15|3||162|181|19|5|10.22059/jitm.2023.93632|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174685569&doi=10.22059%2fjitm.2023.93632&partnerID=40&md5=512c32d3544aac4fd9d7a81f7dee11d6|In this paper, we have extended our literature survey with experimental implementation. Analyzing numerous Artificial Intelligence (AI) techniques in software engineering (SE) can help understand the field better; the outcomes will be more effective when used with it. Our manuscript shows various AI-based algorithms that include Machine learning techniques (ML), Artificial Neural Networks (ANN), Deep Neural Networks (DNN) and Convolutional Neural Networks (CNN), Natural Language Processing (NLP), Genetic Algorithms (GA) applications. Software testing using Ant Colony Optimization (ACO) approach, predicting software maintainability with Group Method of Data Handling (GMDH), Probabilistic Neural Network (PNN), and Software production with time series analysis technique. Furthermore, data is the fuel for AI-based model testing and validation techniques. We have also used NASA dataset promise repository in our script. There are various applications of AI in SE, and we have experimentally demonstrated one among them, i.e., software defect prediction using AI-based techniques. Moreover, the expected future trends have also been mentioned; these are some significant contributions to the research. © 2023 University of Tehran. All rights reserved.|ANN; Artificial Intelligence; CNN; Defects Prediction; DNN; ML; Software Engineering||Article|Final||Scopus|2-s2.0-85174685569
scopus|Altiero F.; Corazza A.; Martino S.D.; Peron A.; Lucio Starace L.L.|Altiero, Francesco (57220897571); Corazza, Anna (6701582907); Martino, Sergio Di (9640416000); Peron, Adriano (7003391555); Lucio Starace, Luigi Libero (57211982059)|57220897571; 6701582907; 9640416000; 7003391555; 57211982059|Tree Kernels to Support Formal Methods-Based Testing of Evolving Specifications|2023|CEUR Workshop Proceedings|3629|||31|36|5|0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184519495&partnerID=40&md5=12fde308a5e5d4a91a4a676a3b1339e1|Tree Kernels (TKs) are a family of functions measuring the similarity between two tree-structured objects. TKs have been successfully employed in several fields of AI, including Natural Language Processing and Software Engineering (e.g.: software testing and code clone detection). A recent research line has proved that the information about source code changes captured by TKs can fruitfully be applied to select and prioritize test cases in Regression Testing, a crucial activity in modern software development processes. We suggest that a similar approach can be adopted also in the field of formal specification of safety-critical systems, whenever a structured language (e.g., a variant of Statecharts, hierarchical automata or the Promela description language) is adopted for the specification task and test cases are (semi-)automatically generated from the specifications. In evolutionary approaches to specification development, the information on changes between two consecutive versions of the specification can aid in focusing the activity of test generation and their execution on the specification modules that were mainly affected by the specification changes. © 2023 CEUR-WS. All rights reserved.|AI; Change-driven testing; Formal Verification; Tree Kernels|Formal verification; Hierarchical systems; Natural language processing systems; Safety engineering; Software design; Software testing; Change-driven testing; Code clone detection; Language processing; Natural languages; Recent researches; Software codes; Software testings; Test case; Tree kernels; Tree-structured; Formal specification|Conference paper|Final||Scopus|2-s2.0-85184519495
scopus|Ehresmann M.; Beyer J.; Fasoulas S.; Schorfmann M.; Brudna T.; Schoolmann I.; Brüggmann J.; Hönle A.; Gerlich R.; Gerlich R.|Ehresmann, Manfred (57193312261); Beyer, Julian (22959903400); Fasoulas, Stefanos (6603089546); Schorfmann, Martin (58943273700); Brudna, Timon (58943648500); Schoolmann, Ingo (58943402300); Brüggmann, Jörg (56426904800); Hönle, Alfred (6504103939); Gerlich, Ralf (23012124500); Gerlich, Rainer (8925653600)|57193312261; 22959903400; 6603089546; 58943273700; 58943648500; 58943402300; 56426904800; 6504103939; 23012124500; 8925653600|ExANT: Exploring NLP AI Systems for Requirements Development|2023|Proceedings of the International Astronautical Congress, IAC|2023-October||||||0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187973356&partnerID=40&md5=8dac101f592154d45463cb5fdbaf79b8|In spacecraft development, initial customer requirements are refined through subsequent engineering phases to meet specific subsystem and operational needs. However, the dynamic nature of requirements, influenced by evolving engineering processes and customer demands, poses challenges. Ensuring requirement quality, interpreting changes, and tracking them can be demanding, especially in larger teams or multi-organization projects. This can lead to prolonged development times, escalated costs, and the risk of incorrect implementations. The ExANT (Extraction of Requirements from Natural Language Texts) project employs natural language processing (NLP) and artificial intelligence (AI) to automate requirement development. The goal is to create an AI system that can automatically analyse requirement texts, assess quality, and suggest enhancements and in the long run enable automated testing of software requirements. This paper updates the project's progress, comparing commercially available tools like IBM Watson with open-source alternatives such as spaCy for processing software requirements. The project focuses on spacecraft-related software requirements, aiming to narrow the domain knowledge needed for NLP AI training. Real-world requirements provided by OHB System, a European large system integrator, and artificially generated requirements using OpenAI's ChatGPT to enrich the dataset are explored. Human annotation is essential for processing software requirement texts, enabling supervised training for named entity recognition (NER). Collaboratively developed entity types and annotation guidelines enables consistent NER training. An AI system, aided by annotated data, becomes skilled at recognizing entities in similar texts. Patterns, quantities, and entity relationships contribute to an assessment pipeline for requirement quality. The ExANT project, involving GSSE, OHB System AG, OHB Digital Services GmbH, and the Institute of Space Systems at the University of Stuttgart, aims to enhance spacecraft software requirement engineering development through collaborative efforts by utilizing NLP technology. Copyright © 2023 by Institute of Space Systems, University of Stuttgart.|Artificial Intelligence; Natural Language Processing; Requirements Engineering|Domain Knowledge; Information services; Large datasets; Natural language processing systems; Open source software; Open systems; Software testing; Artificial intelligence systems; Language processing; Named entity recognition; Natural language processing; Natural languages; Processing software; Requirement development; Requirement engineering; Software requirements; Spacecraft development; Requirements engineering|Conference paper|Final||Scopus|2-s2.0-85187973356
scopus|Parsa S.|Parsa, Saeed (8407441400)|8407441400|Software Testing Automation: Testability Evaluation, Refactoring, Test Data Generation and Fault Localization|2023|Software Testing Automation: Testability Evaluation, Refactoring, Test Data Generation and Fault Localization||||1|580|579|3|10.1007/978-3-031-22057-9|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168564144&doi=10.1007%2f978-3-031-22057-9&partnerID=40&md5=614d2e693b96a6878bf802a3cba256e8|This book is about the design and development of tools for software testing. It intends to get the reader involved in software testing rather than simply memorizing the concepts. The source codes are downloadable from the book website. The book has three parts: software testability, fault localization, and test data generation. Part I describes unit and acceptance tests and proposes a new method called testability-driven development (TsDD) in support of TDD and BDD. TsDD uses a machine learning model to measure testability before and after refactoring. The reader will learn how to develop the testability prediction model and write software tools for automatic refactoring. Part II focuses on developing tools for automatic fault localization. This part shows the reader how to use a compiler generator to instrument source code, create control flow graphs, identify prime paths, and slice the source code. On top of these tools, a software tool, Diagnoser, is offered to facilitate experimenting with and developing new fault localization algorithms. Diagnoser takes a source code and its test suite as input and reports the coverage provided by the test cases and the suspiciousness score for each statement. Part III proposes using software testing as a prominent part of the cyber-physical system software to uncover and model unknown physical behaviors and the underlying physical rules. The reader will get insights into developing software tools to generate white box test data. © The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer Nature Switzerland AG 2023.|Refactoring; Software Engineering; Software Testing Automation; Test Data generation and Fault Localization; Testability Evaluation||Book|Final||Scopus|2-s2.0-85168564144
scopus|Kim J.; Feldt R.; Yoo S.|Kim, Jinhan (57188764454); Feldt, Robert (24476388300); Yoo, Shin (20435019400)|57188764454; 24476388300; 20435019400|Evaluating Surprise Adequacy for Deep Learning System Testing|2023|ACM Transactions on Software Engineering and Methodology|32|2|42||||14|10.1145/3546947|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153749279&doi=10.1145%2f3546947&partnerID=40&md5=d3a21036604664e827eeaf27fda0b528|The rapid adoption of Deep Learning (DL) systems in safety critical domains such as medical imaging and autonomous driving urgently calls for ways to test their correctness and robustness. Borrowing from the concept of test adequacy in traditional software testing, existing work on testing of DL systems initially investigated DL systems from structural point of view, leading to a number of coverage metrics. Our lack of understanding of the internal mechanism of Deep Neural Networks (DNNs), however, means that coverage metrics defined on the Boolean dichotomy of coverage are hard to intuitively interpret and understand. We propose the degree of out-of-distribution-ness of a given input as its adequacy for testing: the more surprising a given input is to the DNN under test, the more likely the system will show unexpected behavior for the input. We develop the concept of surprise into a test adequacy criterion, called Surprise Adequacy (SA). Intuitively, SA measures the difference in the behavior of the DNN for the given input and its behavior for the training data. We posit that a good test input should be sufficiently, but not overtly, surprising compared to the training dataset. This article evaluates SA using a range of DL systems from simple image classifiers to autonomous driving car platforms, as well as both small and large data benchmarks ranging from MNIST to ImageNet. The results show that the SA value of an input can be a reliable predictor of the correctness of the mode behavior. We also show that SA can be used to detect adversarial examples, and also be efficiently computed against large training dataset such as ImageNet using sampling.  © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.|deep learning systems; Test adequacy|Autonomous vehicles; Large dataset; Learning systems; Medical imaging; Safety engineering; Software testing; Statistical tests; Autonomous driving; Coverage metrics; Deep learning system; Safety-critical domain; Software testings; System testing; Test adequacies; Test adequacy criteria; Training data; Training dataset; Deep neural networks|Article|Final||Scopus|2-s2.0-85153749279
scopus|Oviya G.; Kishore M.; Pradeep S.; Poorani S.; Anitha R.|Oviya, G. (49361665900); Kishore, M. (57219531254); Pradeep, S. (57213212439); Poorani, S. (58093139400); Anitha, R. (57941261600)|49361665900; 57219531254; 57213212439; 58093139400; 57941261600|Advanced Semiconductor Classifiers Using Machine Learning Techniques|2023|Proceedings of the International Conference on Artificial Intelligence and Knowledge Discovery in Concurrent Engineering, ICECONF 2023|||||||1|10.1109/ICECONF57129.2023.10083525|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153117502&doi=10.1109%2fICECONF57129.2023.10083525&partnerID=40&md5=2d4bf4aaab0a9d57bc492dd0835f21a8|Due to the greater dimensional faults that appeared on the wafers earlier in the industry's history, human operators were able to execute inspection activities manually using optical microscopes. The fabrication of semiconductors is a sector that is continually expanding and becoming more significant. The STATISTA website estimates that the worldwide semiconductor sector generated roughly 429 billion USD in revenue in 2019. Testing semiconductors is a crucial step in the production process, especially as the complexity of integrated circuit (IC) designs and the competitive pressure on the market rise. An innovative method to perform advanced semiconductor classification using logistic regression and a random forest classifier is proposed. Semiconductors are found in practically all of the electronics we use on a daily basis. The proposed approach is a unique method in respect of semiconductor testing strategies. Thus, the increased number of test types of devices can significantly increase the cost of manufacturing a single semiconductor chip. This work provides an examination on how to perform automated testing using machine learning techniques. © 2023 IEEE.|ASC Advanced - semiconductor classification; Automation; Exploratory Data Analysis (EDA); Faster testing; Random Forest Classifier; Regression|Classification (of information); Integrated circuits; Semiconductor device manufacture; ASC advanced - semiconductor classification; Exploratory data analyse; Exploratory data analysis; Fast testing; Human operator; Inspection activities; Machine learning techniques; Optical microscopes; Random forest classifier; Regression; Learning algorithms|Conference paper|Final||Scopus|2-s2.0-85153117502
scopus|Chow M.Y.|Chow, Man Yiu (57224983368)|57224983368|Analysis of Embedded System’s Functional Requirement using BERT-based Name Entity Recognition for Extracting IO Entities|2023|Journal of Information Processing|31|||143|153|10|5|10.2197/ipsjjip.31.143|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148464254&doi=10.2197%2fipsjjip.31.143&partnerID=40&md5=728444842a2e652711ee4f63a9c97d5f|The functional testing specification is usually designed based on the IO entities’ recognition from the embedded system’s functional requirement sentences. However, it is hard for the software testing engineers to ably recognize the appropriate IO entities from the functional requirement sentences without clearly indicated entities and much experience with the domain knowledge. The conventional rule-based methods of extracting IO entities are in-applicable when the requirement sentences drafted by humans become too semantically complex. Even though all the sentences keep aligned with the structure, it is still infeasible to manually hard-code each rule when those rules change from time to time without any explicit writing standard. With the successful application of artificial intelligent techniques in natural language processing (NLP), we propose a method that intelligently solves the issue of the entities recognition by using BERT (Bidirectional Encoder Representations from Transformers) based named entity recognition (NER) which is the technique of NLP to recognize the phrases having similar attributes in semantics. In this paper, we specifically focus on the issue of IO entities’ recognition in the embedded systems that implement the in-verter control function such as elevator and hybrid hydraulic excavator systems. Our evaluation result demonstrates that the best model variant fine-tuned on 829 sentences achieves more than 80% F-measure in recognizing the IO en-tities, and the model can provide applicable information for the improvement of industrial productivity in the target industries. Our contribution of this paper is to provide insight into the case whether the IO entities in the target system manages to be interpreted well by exploiting the BERT model with the sole reliance on the small size of exem-plary IO entities data and three existing model variants pre-trained on large corpus open datasets with general language knowledge. © 2023 Information Processing Society of Japan.|BERT; IO entities; named entity recognition; NLP; software requirement||Article|Final|All Open Access; Gold Open Access|Scopus|2-s2.0-85148464254
scopus|Deng X.; Ye W.; Xie R.; Zhang S.-K.|Deng, Xiao (57203413536); Ye, Wei (57202350940); Xie, Rui (57208228261); Zhang, Shi-Kun (7409376421)|57203413536; 57202350940; 57208228261; 7409376421|Survey of Source Code Bug Detection Based on Deep Learning; [基于深度学习的源代码缺陷检测研究综述]|2023|Ruan Jian Xue Bao/Journal of Software|34|2||625|654|29|16|10.13328/j.cnki.jos.006696|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161293722&doi=10.13328%2fj.cnki.jos.006696&partnerID=40&md5=958b708bc4fbe875f699bb83aea10c04|Source code bug (vulnerability) detection is a process of judging whether there are unexpected behaviors in the program code. It is widely used in software engineering tasks such as software testing and software maintenance, and plays a vital role in software functional assurance and application security. Traditional vulnerability detection research is based on program analysis, which usually requires strong domain knowledge and complex calculation rules, and faces the problem of state explosion, resulting in limited detection performance, and there is room for greater improvement in the rate of false positives and false negatives. In recent years, the open source community’s vigorous development has accumulated massive amounts of data with open source code as the core. In this context, the feature learning capabilities of deep learning can automatically learn semantically rich code representations, thereby providing a new way for vulnerability detection. This study collected the latest high-level papers in this field, systematically summarized and explained the current methods from two aspects: vulnerability code dataset and deep learning vulnerability detection model. Finally, it summarizes the main challenges faced by the research in this field, and looks forward to the possible future research focus. © 2023 Chinese Academy of Sciences. All rights reserved.|code representation; deep learning; vulnerability detection|Application programs; Codes (symbols); Deep learning; Domain Knowledge; Open source software; Open systems; Application security; Bug detection; Code representation; Deep learning; Engineering tasks; Program analysis; Program code; Software testings; Source codes; Vulnerability detection; Software testing|Article|Final||Scopus|2-s2.0-85161293722
scopus|Zhang Y.; Guo Z.; Sun T.|Zhang, Yanan (57196202482); Guo, Zhen (58061042200); Sun, Tao (56013027900)|57196202482; 58061042200; 56013027900|A Non-Intrusive Automated Testing System for Internet of Vehicles App Based on Deep Learning|2023|Electronics (Switzerland)|12|13|2873||||0|10.3390/electronics12132873|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164906118&doi=10.3390%2felectronics12132873&partnerID=40&md5=f7294f9a92134b1276d6166f2cc27ef5|In the non-intrusive automated testing system for Internet of Vehicles (IoV) applications, automatic recognition of text and icons on vehicle central control screens is of paramount importance. However, the detection and recognition of content on vehicle central control screens are inherently complex. Additionally, during non-intrusive vehicle central control screen image testing, there is a deficiency of suitable datasets and detection methods. This deficiency renders information within vehicle application images difficult to be accurately extracted by the detection network. To address this problem, this study first constructs a dataset tailored for text detection and recognition on vehicle screens. This dataset encompasses a variety of vehicle central control images, enabling the generic text detection and recognition network to more effectively identify and interpret text within vehicle screens. Subsequently, this research proposes an enhanced Fully Convolutional Networks for Text Detection (FOTS) method for vehicle central control screen text detection and recognition. This method elevates the semantic expression capabilities of features by sharing vehicle central control screen text detection and recognition features. Furthermore, it improves multi-scale feature processing capabilities through the utilization of a feature transformation module. Validation through visual and quantitative experiments demonstrates that the proposed method can effectively accomplish text detection and recognition tasks on vehicle screens. This achievement bears significant implications for the field of automated testing in IoV applications. © 2023 by the authors.|automated testing; deep learning; non-intrusive testing||Article|Final|All Open Access; Gold Open Access|Scopus|2-s2.0-85164906118
scopus|Birihanu E.; Adamu B.; Kefie H.; Beshah T.|Birihanu, Ermiyas (57949339600); Adamu, Birtukan (57982592800); Kefie, Hailemichael (58305333200); Beshah, Tibebe (36553880700)|57949339600; 57982592800; 58305333200; 36553880700|Software Complexity Prediction Model: A Combined Machine Learning Approach|2023|Lecture Notes in Electrical Engineering|1011 LNEE|||681|694|13|0|10.1007/978-981-99-0601-7_53|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161199655&doi=10.1007%2f978-981-99-0601-7_53&partnerID=40&md5=02f6d4ef4880bff0696f2fed5c969c39|The need for computers increased quickly. As a result, the program is utilized in a significant and intricate manner. More complex systems are being developed by software businesses. Additionally, customers expect great quality, but the market requires them to finish their assignment faster. Different measuring methods are employed by software firms. Some of these include customer feedback after it has been given to customers, software testing, and stakeholder input. The objective of this project is to use a combination of machine learning techniques to predict software bug states using the NASA MDP dataset. The research process considered data preprocessing methods and applied singular and combination machine learning algorithms. To create the model, the single classifiers were combined using the voting method. Accuracy, precision, and recall were used to evaluate the model's effectiveness, along with tenfold cross-validation. The promising result was recorded by a combination of J48 and SMO classifiers. Before attempting to test the software product, the researcher retrieved attribute data from the source code; the complexity of the software product will then be ascertained using the constructed model. The main contribution of this study is to improve software quality by incorporating a machine learning framework into the present software development life cycle between implementation and testing. © 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.|Machine learning; Prediction model; Software complexity; Software faults; Software metrics|Computer software selection and evaluation; Forecasting; Learning algorithms; Life cycle; NASA; Sales; Software design; Software testing; Machine learning approaches; Machine-learning; Measuring method; Prediction modelling; Software business; Software complexity; Software fault; Software firms; Software metrics; Software products; Machine learning|Conference paper|Final||Scopus|2-s2.0-85161199655
scopus|Ragel R.K.C.; Balahadia F.F.|Ragel, Ritz Kevin C. (58178784300); Balahadia, Francis F. (57189092165)|58178784300; 57189092165|Visual Test Framework: Enhancing Software Test Automation with Visual Artificial Intelligence and Behavioral Driven Development|2023|2023 IEEE 15th International Conference on Humanoid, Nanotechnology, Information Technology, Communication and Control, Environment, and Management, HNICEM 2023|||||||0|10.1109/HNICEM60674.2023.10589222|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199904654&doi=10.1109%2fHNICEM60674.2023.10589222&partnerID=40&md5=2c6d901cf331b72b873e95961b26b1d9|Software test automation plays a crucial role in today's software needs. Traditional test automation approaches often rely on script-based testing, which can be time-consuming, error-prone, and challenging to maintain. In recent years, Visual AI (Artificial Intelligence) and Behavior Driven Development (BDD) have emerged as valuable approaches to enhance the efficiency and effectiveness of software testing. Visual AI leverages machine learning algorithms to identify visual differences in Graphical User Interfaces (GUI), accelerating the test automation process and improving accuracy. BDD focuses on defining and automating system behavior from the end-user perspective, fostering collaboration between stakeholders and eliminating the need for specialized technical expertise. This paper explores the integration of Visual AI and BDD in software test automation, aiming to evaluate its impact on test creation, execution, and maintenance. The research employs a mixed-methods approach, including surveys and evaluations of the Visual Test Framework integrated with Visual AI tools. The findings provide valuable insights into the benefits and challenges of integrating Visual AI and BDD in software test automation, highlighting their potential to streamline testing processes, improve accuracy, and eliminate technical barriers. This paper recommends the usage of Visual AI with BDD © 2023 IEEE.|Applitools; Behavioral Driven Development (BDD); Framework; Graphical User Interface (GUI); Software Quality; Software Testing; Test Automation; Visual AI|Automatic test pattern generation; Automation; Boolean functions; Computer software selection and evaluation; Integration testing; Learning algorithms; Machine learning; Applitool; Behavioral driven development; Framework; Graphical user interface; Software Quality; Software test automation; Software testings; Test Automation; Test framework; Visual artificial intelligence; Graphical user interfaces|Conference paper|Final||Scopus|2-s2.0-85199904654
scopus|Caglar O.; Taskin F.; Baglum C.; Asik S.; Yayan U.|Caglar, Osman (58735644200); Taskin, Furkan (58735279900); Baglum, Cem (58503905300); Asik, Sergen (58535037800); Yayan, Ugur (46061619200)|58735644200; 58735279900; 58503905300; 58535037800; 46061619200|Development of Cloud and Artificial Intelligence based Software Testing Platform (ChArIoT)|2023|2023 Innovations in Intelligent Systems and Applications Conference, ASYU 2023|||||||1|10.1109/ASYU58738.2023.10296551|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178252559&doi=10.1109%2fASYU58738.2023.10296551&partnerID=40&md5=d7c21efc9a4301e874ae085828c8d16b|In the rapidly evolving field of autonomous systems, the traditional methods of software testing have proven to be time-consuming, resource-intensive, and inadequate in addressing the complex challenges posed by these systems. This highlights a pressing need for more efficient and effective testing methodologies. In response to this, we present ChArIoT, a cloud-based web platform that leverages the power of artificial intelligence (AI) and the MERN Stack architecture to conduct mutation testing on Python codes. ChArIoT provides a scalable and cost-effective solution, offering flexible testing environments, improved test coverage, and enhanced accuracy. By integrating AI into mutation testing, ChArIoT significantly reduces time and resource requirements, thereby advancing the effectiveness and efficiency of the testing process. The system infrastructure has been improved to accommodate various AI models, enhancing customization capabilities based on user requirements. Specifically, the platform can adapt its mutation functionalities to match the abilities of installed models, such as code fixing or code generation. This study underscores the superiority of AI and cloud-based testing over manual methods, emphasizing the value of ChArIoT in ensuring trustworthy operation for autonomous systems. © 2023 IEEE.|AI; autonomous systems; cloud-based testing; mutation testing; safety and security-critical systems; software testing|Acceptance tests; Cost effectiveness; Integration testing; Safety testing; Software design; Software reliability; Autonomous system; Cloud-based; Cloud-based testing; Critical systems; Mutation testing; Safety and securities; Safety and security-critical system; Security-critical; Software testings; Testing platforms; Artificial intelligence|Conference paper|Final||Scopus|2-s2.0-85178252559
scopus|Palanivel S.; Nallasamy V.|Palanivel, Silambarasi (59875042200); Nallasamy, Viswanathan (55764357700)|59875042200; 55764357700|An integrated and automated testing approach on Inception Restnet-V3 based on convolutional neural network for leukocytes image classification|2023|Biomedizinische Technik|68|2||165|174|9|4|10.1515/bmt-2022-0297|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140077364&doi=10.1515%2fbmt-2022-0297&partnerID=40&md5=2ab95bef6d62f0d17e0db7e3ffc9e771|Objectives: The leukocyte is a specialized immune cell that functions as the foundation of the immune system and keeps the body healthy. The WBC classification plays a vital role in diagnosing various disorders in the medical area, including infectious diseases, immune deficiencies, leukemia, and COVID-19. A few decades ago, Machine Learning algorithms classified WBC types required for image segmentation, and the feature extraction stages, but this new approach becomes automatic while existing models can be fine-tuned for specific classifications. Methods: The inception architecture and deep learning model-based Resnet connection are integrated into this article. Our proposed method, inception Resnet-v3, was used to classify WBCs into five categories using 15.7k images. Pathologists made diagnoses of all images so a model could be trained to classify five distinct types of cells. Results: After implementing the proposed architecture on a large dataset of 5 categories of human peripheral white blood cells, it achieved high accuracy than VGG, U-Net and Resnet. We tested our model with WBC images from additional public datasets such as the Kaagel data sets and Raabin data sets of which the accuracy was 98.80% and 98.95%. Conclusions: Considering the large sample sizes, we believe the proposed method can be used for improving the diagnostic performance of clinical blood examinations as well as a promising alternative for machine learning. Test results obtained with the system have been satisfying, with outstanding values for Accuracy, Precision, Recall, Specificity and F1 Score.  © 2022 Walter de Gruyter GmbH, Berlin/Boston.|deep learning; image classification; inception V3; leukocyte; residual network|Algorithms; COVID-19; Humans; Leukocytes; Machine Learning; Neural Networks, Computer; Blood; Convolutional neural networks; Deep learning; Diagnosis; Diseases; Image segmentation; Large dataset; Learning algorithms; Learning systems; Network architecture; Automated testing; Convolutional neural network; Data set; Deep learning; Images classification; Immune cells; Inception v3; Leucocytes; Medical areas; Residual network; algorithm; Article; automation; basophil; comparative study; convolutional neural network; deep learning; deep neural network; diagnostic accuracy; eosinophil; false positive result; gated recurrent unit network; human; human cell; image analysis; image processing; image segmentation; inception resnet v3 network; leukocyte; lymphocyte; monocyte; neutrophil; residual neural network; transfer of learning; vgg network; leukocyte; machine learning; Image classification|Article|Final||Scopus|2-s2.0-85140077364
scopus|Upadhyaya P.S.; Tripathi N.; Gaeddert J.; Reed J.H.|Upadhyaya, Pratheek S. (57216053374); Tripathi, Nishith (7005810196); Gaeddert, Joseph (56618697700); Reed, Jeffrey H. (7403641959)|57216053374; 7005810196; 56618697700; 7403641959|Open AI Cellular (OAIC): An Open Source 5G O-RAN Testbed for Design and Testing of AI-Based RAN Management Algorithms|2023|IEEE Network|37|5||7|15|8|16|10.1109/MNET.2023.3320933|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174838008&doi=10.1109%2fMNET.2023.3320933&partnerID=40&md5=0c5fefbd3405d6095687af42cb913820|Open Radio Access Network (O-RAN), defined by the O-RAN Alliance, is quickly emerging as one of the most critical RAN architectures for designing and deploying future cellular networks. O-RAN aims to use openness and intelligence to solve new research problems that arise from the broad set of services offered by 5G. However, the lack of end-to-end, stable, open-source platforms offering realistic environments has limited progress in developing effective solutions. This paper describes an open-source 3GPP-compliant O-RAN-based 5G testbed being developed at Virginia Tech called Open AI Cellular (OAIC). The OAIC testbed includes the OAIC-Control framework to facilitate the design of AI-based RAN management algorithms and the OAIC-Testing framework to facilitate automated testing of AI-based RAN management algorithms. While O-RAN defines non-Real Time RAN Intelligent Controller (RIC) and near-Real Time RIC, the OAIC testbed introduces a new Real-Time RIC, zApps, and Z1 interface to support new use cases that require latency of less than 10 ms. The current and target capabilities of the OAIC testbed, along with the challenges within the O-RAN framework, are discussed. An example use case (Key Performance Metrics) that utilizes the OAIC testbed is also narrated. The OAIC testbed integrated with CORNET infrastructure is remotely accessible via a portal and is expected to accelerate R&D in academia and the wireless industry.  © 1986-2012 IEEE.|5G; 6G; O-RAN; OAIC; Real-Time RIC; Testbeds; zApps|5G mobile communication systems; Computer architecture; Computer hardware; Interactive computer systems; Network architecture; Open source software; Open systems; Testbeds; 5g; 5g mobile communication; 6g; Cellulars; Hardware; Intelligent controllers; Mobile communications; Open AI cellular; Open radio access network; Radio access networks; Real - Time system; Real- time; Real-time RAN intelligent controller; Software; Zapps; Real time systems|Article|Final||Scopus|2-s2.0-85174838008
scopus|Balasubramanian P.|Balasubramanian, Parasuram (58355307600)|58355307600|Automation in Data Science, Software, and Information Services|2023|Springer Handbooks|Part F674|||989|1014|25|6|10.1007/978-3-030-96729-1_46|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162973079&doi=10.1007%2f978-3-030-96729-1_46&partnerID=40&md5=0b7983eec422c3c54a0ad8cf14789f18|While the data and information services industry dates back to the fifteenth century AD, the information technology (also called as software services) industry is as young as 70 years. Yet the pace at which both have grown is phenomenal, and this is tied to the evolution of computer technology. Networking of computers and people through the Internet has moved into high gear. The decision (or knowledge) sciences arena enveloping the operations research methodologies came into prominence during the Second World War but has had its growth in parallel to the computing technologies till the 1970s. The last two decades have also witnessed a spurt in their development due to advances in expert systems, machine learning, and artificial intelligence (AI) algorithms, all of which are now embedded within the field of data science. These three sectors have given birth to multiple business segments in the process. Delivery of data and information, data and business process outsourcing, analytics, printing and display solutions, and information flow in supply chain management of goods and services are the five segments identified within the information services, while computer-aided software engineering, independent software testing and quality assurance, package and bespoke software implementation and maintenance, network and security management, and hosting and infrastructure management are covered within software services. The data science arena consists of big data, statistical and mathematical techniques, and business domains but covered as one distinct business segment. The automation path of each segment is reviewed in detail. An impact analysis to identify the changing landscape is described. Finally, current trends are traced, followed by predictions for future developments. © 2023, Springer Nature Switzerland AG.|Big data and analytics; Customer relationship management; Data science; Enterprise resource planning; Information technology services; Software services||Book chapter|Final||Scopus|2-s2.0-85162973079
scopus|Gudaparthi H.; Niu N.; Yang Y.; Van Doren M.; Johnson R.|Gudaparthi, Hemanth (57219439856); Niu, Nan (36856329200); Yang, Yilong (57201588421); Van Doren, Matthew (57203717222); Johnson, Reese (36863894500)|57219439856; 36856329200; 57201588421; 57203717222; 36863894500|Deep learning's fitness for purpose: A transformation problem frame's perspective|2023|CAAI Transactions on Intelligence Technology|8|2||343|354|11|3|10.1049/cit2.12237|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161611132&doi=10.1049%2fcit2.12237&partnerID=40&md5=4d4c6d0e05e68f09aa76050ef8304a98|Combined sewer overflows represent significant risks to human health as untreated water is discharged to the environment. Municipalities, such as the Metropolitan Sewer District of Greater Cincinnati (MSDGC), recently began collecting large amounts of water-related data and considering the adoption of deep learning (DL) solutions like recurrent neural network (RNN) for predicting overflow events. Clearly, assessing the DL's fitness for the purpose requires a systematic understanding of the problem context. In this study, we propose a requirements engineering framework that uses the problem frames to identify and structure the stakeholder concerns, analyses the physical situations in which the high-quality data assumptions may not hold, and derives the software testing criteria in the form of metamorphic relations that incorporate both input transformations and output comparisons. Applying our framework to MSDGC's overflow prediction problem enables a principled way to evaluate different RNN solutions in meeting the requirements. © 2023 The Authors. CAAI Transactions on Intelligence Technology published by John Wiley & Sons Ltd on behalf of The Institution of Engineering and Technology and Chongqing University of Technology.|deep learning; deep neural networks; software engineering|Health risks; Recurrent neural networks; Sewers; Software testing; Cincinnati; Combined sewer overflows; Deep learning; Engineering frameworks; Fitness for purpose; High quality data; Large amounts; Problem Frames; Requirement engineering; Risk to human health; Deep neural networks|Article|Final|All Open Access; Gold Open Access|Scopus|2-s2.0-85161611132
scopus||||Proceedings - 2023 IEEE 16th International Conference on Software Testing, Verification and Validation, ICST 2023|2023|Proceedings - 2023 IEEE 16th International Conference on Software Testing, Verification and Validation, ICST 2023||||||516|0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161886052&partnerID=40&md5=13b1fad2438a89da3b2e9fd015132180|The proceedings contain 52 papers. The topics discussed include: software testing research challenges: an industrial perspective; AI is a game-changing technology: how to test and robustify machine-learning software?; a case against coverage-based program spectra; a coverage-driven systematic test approach for simultaneous localization and mapping; android fuzzing: balancing user-inputs and intents; batching non-conflicting mutations for efficient, safe, parallel mutation analysis in rust; constraint-guided automatic side object placement for steering control testing in virtual environment; distributed repair of deep neural networks; embedding context as code dependencies for neural program repair; heap fuzzing: automatic garbage collection testing with expert-guided random events; homo in machina: improving fuzz testing coverage via compartment analysis; and how closely are common mutation operators coupled to real faults?.|||Conference review|Final||Scopus|2-s2.0-85161886052
scopus|Ma H.; Shen Q.; Tian Y.; Chen J.; Cheung S.-C.|Ma, Haoyang (57221462124); Shen, Qingchao (57282978100); Tian, Yongqiang (57210932766); Chen, Junjie (57145642900); Cheung, Shing-Chi (7202472792)|57221462124; 57282978100; 57210932766; 57145642900; 7202472792|Fuzzing Deep Learning Compilers with HirGen|2023|ISSTA 2023 - Proceedings of the 32nd ACM SIGSOFT International Symposium on Software Testing and Analysis||||248|260|12|20|10.1145/3597926.3598053|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167673721&doi=10.1145%2f3597926.3598053&partnerID=40&md5=8590382252be041d17bb0afe7c147f88|Deep Learning (DL) compilers are widely adopted to optimize advanced DL models for efficient deployment on diverse hardware. Their quality has a profound effect on the quality of compiled DL models. A recent bug study shows that the optimization of high-level intermediate representations (IRs) is the most error-prone compilation stage and bugs in this stage account for 44.92% of the whole collected ones. However, existing testing techniques do not consider the features related to high-level optimization (e.g., the high-level IR), and are therefore weak in exposing bugs at this stage. To bridge this gap, we propose HirGen, an automated testing technique that effectively exposes coding mistakes in the optimization of high-level IRs. The design of HirGen includes 1) three coverage criteria to generate diverse and valid computational graphs; 2) the use of the high-level IR's language features to generate diverse IRs; 3) three test oracles of which two are inspired by metamorphic testing and differential testing. HirGen has successfully detected 21 bugs that occur at TVM, with 17 bugs confirmed and 12 fixed. Further, we construct four baselines using state-of-the-art DL compiler fuzzers that can cover the high-level optimization stage. Our experiment results show that HirGen can detect 10 crashes and inconsistencies that cannot be detected by the baselines in 48 hours. We also evaluate the usefulness of our proposed coverage criteria and test oracles.  © 2023 ACM.|Deep Learning Compiler; Software Testing|Deep learning; High level languages; Program compilers; Coverage criteria; Deep learning compiler; Error prones; High-level optimizations; Intermediate representations; Learning models; Optimisations; Software testings; Test oracles; Testing technique; Software testing|Conference paper|Final|All Open Access; Green Open Access|Scopus|2-s2.0-85167673721
scopus|Abdulla H.H.H.A.; Albalooshi F.A.|Abdulla, Hasan Hameed Hasan Ahmed (58916259200); Albalooshi, Fawzi Abdulaziz (6508384856)|58916259200; 6508384856|Automated Testing for DevOps in GitHub Environment: A Comprehensive Analysis|2023|2023 International Conference on Advanced Mechatronics, Intelligent Manufacture and Industrial Automation, ICAMIMIA 2023 - Proceedings||||833|838|5|0|10.1109/ICAMIMIA60881.2023.10427702|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186537388&doi=10.1109%2fICAMIMIA60881.2023.10427702&partnerID=40&md5=a9675a9a3ab4ca1bd8965038611ee9f2|This paper examines automated testing, a vital DevOps practice, within the GitHub development environment. It comprehensively covers various test automation types, including unit, integration, and security testing, analyzing their roles in continuous integration/deployment workflows. A particular focus is given to the advantages and challenges of implementing automated testing for DevOps on the GitHub platform. Through a detailed GitHub-based case study, the paper offers real-world insights into deploying test automation for a large project, highlighting successes and pitfalls. Emerging innovations like AI/ML in testing regarding their potential GitHub applications are also discussed. The goal is to synthesize current knowledge into a holistic overview of automated testing for DevOps on GitHub. It encompasses the significance of test automation, nuances of execution within GitHub, practical implementations, and future directions to advance automated testing in this ecosystem. The paper aims to provide technical depth and applied perspectives on this critical DevOps practice within a leading development environment. © 2023 IEEE.|Automated Testing; DevOps; Github; Testing|Integration testing; Automated testing; Case-studies; Comprehensive analysis; Continuous integrations; Development environment; Github; Security testing; Test Automation; Unit testing; Work-flows; Automation|Conference paper|Final||Scopus|2-s2.0-85186537388
scopus|Tetteh M.; de Lima A.; McEllin J.; Murphy A.; Dias D.M.; Ryan C.|Tetteh, Michael (57224310686); de Lima, Allan (57826381000); McEllin, Jack (57845322500); Murphy, Aidan (57205544623); Dias, Douglas Mota (15055697700); Ryan, Conor (7403275552)|57224310686; 57826381000; 57845322500; 57205544623; 15055697700; 7403275552|Evolving Multi-Output Digital Circuits Using Multi-Genome Grammatical Evolution|2023|Algorithms|16|8|365||||2|10.3390/a16080365|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168759191&doi=10.3390%2fa16080365&partnerID=40&md5=91dab0893b62adb8ac644b3ec580b64c|Grammatical Evolution is a Genetic Programming variant which evolves problems in any arbitrary language that is BNF compliant. Since its inception, Grammatical Evolution has been used to solve real-world problems in different domains such as bio-informatics, architecture design, financial modelling, music, software testing, game artificial intelligence and parallel programming. Multi-output problems deal with predicting numerous output variables simultaneously, a notoriously difficult problem. We present a Multi-Genome Grammatical Evolution better suited for tackling multi-output problems, specifically digital circuits. The Multi-Genome consists of multiple genomes, each evolving a solution to a single unique output variable. Each genome is mapped to create its executable object. The mapping mechanism, genetic, selection, and replacement operators have been adapted to make them well-suited for the Multi-Genome representation and the implementation of a new wrapping operator. Additionally, custom grammar syntax rules and a cyclic dependency-checking algorithm have been presented to facilitate the evolution of inter-output dependencies which may exist in multi-output problems. Multi-Genome Grammatical Evolution is tested on combinational digital circuit benchmark problems. Results show Multi-Genome Grammatical Evolution performs significantly better than standard Grammatical Evolution on these benchmark problems. © 2023 by the authors.|combinational circuits; digital circuit design; Evolvable Hardware; Grammatical Evolution; Hardware Description Languages; Multi-Genome; SystemVerilog|Benchmarking; Computer hardware description languages; Digital circuits; Genes; Genetic algorithms; Parallel programming; Software testing; Timing circuits; Arbitrary languages; Benchmark problems; Digital circuit design; Evolvable hardware; Grammatical evolution; Multi-genome; Multi-output; Output variables; Real-world problem; SystemVerilog; Genetic programming|Article|Final|All Open Access; Gold Open Access; Green Open Access|Scopus|2-s2.0-85168759191
scopus|Ahmed I.; Yadav P.K.|Ahmed, Imtiaz (58281414900); Yadav, Pramod Kumar (56127108100)|58281414900; 56127108100|Artificial Intelligence and Machine Learning Problems and Challenges in Software Testing|2023|System Reliability and Security: Techniques and Methodologies||||194|206|12|1|10.1201/9781032624983-10|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179267470&doi=10.1201%2f9781032624983-10&partnerID=40&md5=fd97eb431ab3f389ef08e60062bb8b23|Machine learning and artificial intelligence have a long history that began in the 1950s. Applications that use AI and ML technologies have grown in prominence over the past few years. An effective AI/ML application must include software testing, just as with conventional development. Nevertheless, the process employed in AI/ML development differs in many ways from conventional development. These variances give rise to a variety of software testing difficulties. Identification is the primary objective of this study, which discusses some of the most significant difficulties that software testers have while working with AI/ML applications. This study has important repercussions for upcoming research. Each issue raised in this paper is perfect for future research and has tremendous potential to illuminate the path to software that is more productive. © 2024 Taylor & Francis Group, LLC.|||Book chapter|Final||Scopus|2-s2.0-85179267470
scopus|Guo X.; Okamura H.; Dohi T.|Guo, Xiujing (57269949900); Okamura, Hiroyuki (35303235000); Dohi, Tadashi (7102430978)|57269949900; 35303235000; 7102430978|Towards High-Quality Test Suite Generation with ML-Based Boundary Value Analysis|2023|Proceedings - 2023 10th International Conference on Dependable Systems and Their Applications, DSA 2023||||75|85|10|1|10.1109/DSA59317.2023.00020|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179524520&doi=10.1109%2fDSA59317.2023.00020&partnerID=40&md5=cb4b6d97067ae3873d321c9ae34bfd8f|In software testing, a protective measure to prevent faults in the code is to ensure that the behavior on the boundary between the sub-domains of the input space is correct. Therefore, designing test cases with boundary value analysis (BVA) can detect more errors and improve test efficiency. This paper presents an ML (machine learning) based approach to automatically generate boundary test cases. Our approach is twofold. First, we train an ML-based discriminator that determines whether a boundary exists between two test inputs. Second, using the outputs of the discriminator, we create test inputs based on Markov Chain Monte Carlo. We conduct experiments to compare the fault detection capabilities of the ML-based approach with concolic testing and manually-performed boundary analysis. Results indicate that the ML-based method outperforms the manually-performed boundary analysis in four of the seven programs tested and concolic testing in three of the seven programs tested.  © 2023 IEEE.|boundary value analysis; Markov chain Monte Carlo; neural network; random testing; software testing|Fault detection; Markov processes; Monte Carlo methods; Neural networks; Quality control; Value engineering; Boundary value analysis; Learning-based approach; Machine-learning; Markov chain Monte Carlo; Markov Chain Monte-Carlo; Neural-networks; Random testing; Software testings; Test case; Test inputs; Software testing|Conference paper|Final||Scopus|2-s2.0-85179524520
scopus|Chetna; Kaur K.|Chetna (58723379100); Kaur, Kamaldeep (57223048873)|58723379100; 57223048873|Empirical Study of Meta-learning-Based Approach for Predictive Mutation Testing|2023|Lecture Notes in Electrical Engineering|1078 LNEE|||623|635|12|0|10.1007/978-981-99-5974-7_50|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177812978&doi=10.1007%2f978-981-99-5974-7_50&partnerID=40&md5=f6567a2b4648ab95c1f4aea4822cdedd|One of the thrust areas in software testing is design of good quality test suites. Mutation testing is a widely acknowledged technique for validating test suites. Mutation testing works by altering the original program so as to introduce faults intentionally. The altered program or mutant is tested against the test suite. If the test suite is able to detect or kill all the intentionally introduced faults, it is considered adequate. The adequacy of test suite is measured in terms of mutation score. However, the cost of executing mutant programs is a big deterrent to adoption of mutation testing in practice. Therefore, research community has proposed a Machine Learning (ML) based strategy called Predictive Mutation Testing (PMT). PMT allows mutation testing outputs to be predicted without actually executing mutant programs. The research objective undertaken in this empirical study is to propose a meta-learning-based approach for PMT. The proposed approach is compared with classical machine learning and other state of art ensemble-based approaches. Analysis of the results based on statistical tests shows that the proposed meta-learning-based approach for PMT outperforms classical machine learning as well as ensemble approaches like XGBoost, CatBoost, and random forests. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd 2023.|Meta-learning; Predictive mutation testing; Statistical tests|Machine learning; Software testing; Empirical studies; IS design; Learning-based approach; Machine-learning; Metalearning; Mutation score; Mutation testing; Predictive mutation testing; Quality test; Software testings; Statistical tests|Conference paper|Final||Scopus|2-s2.0-85177812978
scopus|Krichen M.|Krichen, Moez (8973115500)|8973115500|A Survey on Formal Verification and Validation Techniques for Internet of Things|2023|Applied Sciences (Switzerland)|13|14|8122||||48|10.3390/app13148122|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166181133&doi=10.3390%2fapp13148122&partnerID=40&md5=db224dc684a28fb864b27cf2ae93dad1|The Internet of Things (IoT) has brought about a new era of connected devices and systems, with applications ranging from healthcare to transportation. However, the reliability and security of these systems are critical concerns that must be addressed to ensure their safe and effective operation. This paper presents a survey of formal verification and validation (FV&V) techniques for IoT systems, with a focus on the challenges and open issues in this field. We provide an overview of formal methods and testing techniques for the IoT and discuss the state explosion problem and techniques to address it. We also examined the use of AI in software testing and describe examples of tools that use AI in this context. Finally, we discuss the challenges and open issues in FV&V for the IoT and present possible future directions for research. This survey paper aimed to provide a comprehensive understanding of the current state of FV&V techniques for IoT systems and to highlight areas for further research and development. © 2023 by the author.|formal verification; Internet of Things; testing techniques; validation||Article|Final|All Open Access; Gold Open Access|Scopus|2-s2.0-85166181133
scopus|Oleshchenko L.|Oleshchenko, Liubov (54795717500)|54795717500|Machine Learning Algorithms Comparison for Software Testing Errors Classification Automation|2023|Lecture Notes on Data Engineering and Communications Technologies|181|||615|625|10|1|10.1007/978-3-031-36118-0_55|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169043209&doi=10.1007%2f978-3-031-36118-0_55&partnerID=40&md5=43d401c1fd00cbebc79190defe37406b|Automatic classification of software errors is an important tool for ensuring the quality of software being tested. By automating this process, testers can save time and effort, improve accuracy, gain a better understanding of errors, and improve communication between stakeholders. Software error clustering is an important concept in software testing that involves identifying and analyzing patterns in software errors or defects. The goal of error clustering is to understand the relationships between defects and identify the root causes of software errors, so that they can be prevented or corrected. The article provides a comprehensive survey of various techniques for software error clustering, including clustering algorithms. The author note that many of these techniques require significant expertise in software engineering and data analysis, and that there is a need for more user-friendly tools for software error clustering. This article presents an empirical research of software defect clustering, in which the author analyzes a large dataset of defects from a software development projects to identify several patterns in the defects, including clusters of related defects and common root causes. The proposed software method uses stack traces to cluster data about software testing errors. The method uses a kNN algorithm to analyze test results, allowing the user to assign the text of the software test result to specified categories. The kNN algorithm has a high accuracy rate of 0.98, which is better than other clustering methods like Support Vector and Naive Bayes. The proposed method has several advantages, including a single repository for test results, automatic analysis of software testing results, and the ability to create custom error types and subtypes for error clustering. The developed new software method allows multiple launches to be combined. If there are a large number of test suites, they are divided into smaller groups as they cannot be included in a single run. The test suites can then be combined into a single run to present the data on dashboards and generate reports. The method is integrated into software using a Docker container, which reduces the time and human resources required for error analysis. Overall, the method provides real-time monitoring of project status for managers and customers. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.|automation; clustering; Machine learning algorithms; software defect; software errors classification|Ability testing; Barium compounds; Clustering algorithms; Computer software selection and evaluation; Defects; Large dataset; Learning algorithms; Learning systems; Machine learning; Software design; Statistical tests; Clusterings; Error classification; Machine learning algorithms; Root cause; Software defects; Software error classification; Software errors; Software methods; Software testings; Testing errors; Software testing|Conference paper|Final||Scopus|2-s2.0-85169043209
scopus|Schmid S.; Dürrmeier F.; Grosse C.U.|Schmid, Simon (14018646500); Dürrmeier, Florian (57938977800); Grosse, Christian U. (7005029389)|14018646500; 57938977800; 7005029389|Spatial and Temporal Deep Learning in Air-Coupled Ultrasonic Testing for Enabling NDE 4.0|2023|Journal of Nondestructive Evaluation|42|3|84||||4|10.1007/s10921-023-00993-3|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170385960&doi=10.1007%2fs10921-023-00993-3&partnerID=40&md5=88a9f3dc3177a6bfe0f6147e0125626b|Air-coupled ultrasonic (ACU) testing has been used for several years to detect defects in plate-like structures. Especially, for automated testing procedures, ACU testing is advantageous in comparison to conventional testing. However, the evaluation of the measurement data is usually done in a manual manner, which is an obstruction to the application of ACU testing. The goal of this study is to automate and improve defect characterization and NDE 4.0 accordingly with deep learning. In conventional ACU testing the measurement data contains temporal (A-scans) and spatial (C-scans) information. Both data types are investigated in this study. For the A-scans, which represent time series data, neural network architectures tailored to such data types are applied. In addition, it is evaluated if further adaptions of the training procedure increase the performance. The C-scans are segmented by applying different U-net similar architectures and training strategies. In order to use spatial and temporal information, a further approach is taken. The prediction of the time series models is segmented with image models. The performance of all trained models and training strategies is compared with the F1-score and benchmarked against the conventional evaluation, which is thresholding of the C-scans. As specimens, artificial defects in acrylic and carbon fiber-reinforced polymer plates are investigated. © 2023, The Author(s).|Air-coupled ultrasonic testing; Deep learning; NDE 4.0; Spatial and temporal deep learning|Bridge decks; Carbon fiber reinforced plastics; Deep learning; Defects; Network architecture; Nondestructive examination; Plates (structural components); Time series; Air-coupled ultrasonic; Air-coupled ultrasonic testing; Datatypes; Deep learning; Measurement data; NDE 4.0; Performance; Plate-like structure; Spatial and temporal deep learning; Training strategy; Ultrasonic testing|Article|Final|All Open Access; Green Open Access; Hybrid Gold Open Access|Scopus|2-s2.0-85170385960
scopus|Feng S.; Xie M.; Chen C.|Feng, Sidong (57211802256); Xie, Mulong (57220181228); Chen, Chunyang (57191225906)|57211802256; 57220181228; 57191225906|Efficiency Matters: Speeding Up Automated Testing with GUI Rendering Inference|2023|Proceedings - International Conference on Software Engineering||||906|918|12|12|10.1109/ICSE48619.2023.00084|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168646866&doi=10.1109%2fICSE48619.2023.00084&partnerID=40&md5=a93d68d74ad64df28f5dae6c66251611|Due to the importance of Android app quality assurance, many automated GUI testing tools have been developed. Although the test algorithms have been improved, the impact of GUI rendering has been overlooked. On the one hand, setting a long waiting time to execute events on fully rendered GUIs slows down the testing process. On the other hand, setting a short waiting time will cause the events to execute on partially rendered GUIs, which negatively affects the testing effectiveness. An optimal waiting time should strike a balance between effectiveness and efficiency. We propose AdaT, a lightweight image-based approach to dynamically adjust the inter-event time based on GUI rendering state. Given the real-time streaming on the GUI, AdaT presents a deep learning model to infer the rendering state, and synchronizes with the testing tool to schedule the next event when the GUI is fully rendered. The evaluations demonstrate the accuracy, efficiency, and effectiveness of our approach. We also integrate our approach with the existing automated testing tool to demonstrate the usefulness of AdaT in covering more activities and executing more events on fully rendered GUIs. © 2023 IEEE.|Efficient android GUI testing; GUI rendering; Machine Learning|Android (operating system); Automation; Deep learning; Efficiency; Learning systems; Quality assurance; Rendering (computer graphics); Android apps; Automated testing; Efficient android GUI testing; GUI rendering; GUI testing; Machine-learning; Test algorithms; Testing process; Testing tools; Waiting time; Graphical user interfaces|Conference paper|Final|All Open Access; Green Open Access|Scopus|2-s2.0-85168646866
scopus|Gamal A.; Emad R.; Mohamed T.; Mohamed O.; Hamdy A.; Ali S.|Gamal, Ahmed (58833570700); Emad, Reem (58743316900); Mohamed, Taher (58743635100); Mohamed, Omar (58876421400); Hamdy, Ahmed (6701551000); Ali, Sarah (58175923800)|58833570700; 58743316900; 58743635100; 58876421400; 6701551000; 58175923800|Owl Eye: An AI-Driven Visual Testing Tool|2023|5th Novel Intelligent and Leading Emerging Sciences Conference, NILES 2023 - Proceedings||||312|315|3|1|10.1109/NILES59815.2023.10296575|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178513258&doi=10.1109%2fNILES59815.2023.10296575&partnerID=40&md5=bbe74c93a5c12f0152b9133b3ebc526c|Visual testing is a software testing technique that checks the visual aspects of a Graphical User Interface (GUI). It helps identify visual defects that other GUI testing techniques, such as functional and performance tests, may not detect. While functional testing verifies the correct behavior of applications, it is not effective in catching visual issues. This paper introduces an AI-driven visual tester, a novel approach to visual testing that enhances the detection of visual defects in application interfaces. The tester can effectively test any platform, using screenshots as input. The process begins with object detection in the screenshots, employing two methods: traditional image processing and deep learning. The detected objects are then transformed into a tree data structure for efficient analysis. Object matching is utilized to correlate objects between the reference and updated images. Finally, change analysis and classification are performed to identify and categorize changes in each object, such as translation, scaling, color change, or object removal. © 2023 IEEE.|Classification; GUI; Image Processing; Object Detection; Testing; Visual|Deep learning; Defects; Image classification; Object recognition; Trees (mathematics); Images processing; Interface testings; Objects detection; Screenshots; Software testing techniques; Testing tools; Visual; Visual aspects; Visual defects; Visual testing; Object detection|Conference paper|Final||Scopus|2-s2.0-85178513258
scopus|Zohdinasab T.; Riccio V.; Gambi A.; Tonella P.|Zohdinasab, Tahereh (57226186594); Riccio, Vincenzo (57214054052); Gambi, Alessio (23466827200); Tonella, Paolo (7003489194)|57226186594; 57214054052; 23466827200; 7003489194|DeepHyperion: Exploring the Feature Space of Deep Learning-based Systems through Illumination Search|2023|Lecture Notes in Informatics (LNI), Proceedings - Series of the Gesellschaft fur Informatik (GI)|P-332|||131|132|1|1||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150057352&partnerID=40&md5=5f22f50f9cdb92c05873499e8b238e73|In this extended abstract, we summarize our contributions to automated testing of Deep Learning-based systems published at the ACM SIGSOFT International Symposium on Software Testing and Analysis (ISSTA) in 2021 [Zo21a] and just accepted by the ACM Transactions on Software Engineering and Methodology (TOSEM) in 2022 [Zo22]. Deep Learning-based systems (DL Systems) find applications in safety-critical application domains and thus must be thoroughly tested. Existing DL system testing approaches can generate complex and fault-finding inputs but do not characterize them in a way that enables human interpretation and do not always consider test diversity. Our work addresses these challenges and can find effective and diverse test cases. © 2023 Gesellschaft fur Informatik (GI). All rights reserved.|deep learning; search-based software engineering; self-driving cars; Software testing|Autonomous vehicles; Deep learning; Learning systems; Safety engineering; Safety testing; Automated testing; Deep learning; Extended abstracts; Feature space; Search-based; Search-based software engineering; Software methodologies; Software testing and analysis; Software testings; Transactions on Software Engineering; Software testing|Conference paper|Final||Scopus|2-s2.0-85150057352
scopus|Dias T.; Batista A.; Maia E.; Praça I.|Dias, Tiago (57355096600); Batista, Arthur (58582589000); Maia, Eva (57220280825); Praça, Isabel (22734900800)|57355096600; 58582589000; 57220280825; 22734900800|TestLab: An Intelligent Automated Software Testing Framework|2023|Lecture Notes in Networks and Systems|741 LNNS|||355|364|9|3|10.1007/978-3-031-38318-2_35|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173477776&doi=10.1007%2f978-3-031-38318-2_35&partnerID=40&md5=203ee6d11a70ca36fab2476c1661b171|The prevalence of software systems has become an integral part of modern-day living. Software usage has increased significantly, leading to its growth in both size and complexity. Consequently, software development is becoming a more time-consuming process. In an attempt to accelerate the development cycle, the testing phase is often neglected, leading to the deployment of flawed systems that can have significant implications on the users daily activities. This work presents TestLab, an intelligent automated software testing framework that attempts to gather a set of testing methods and automate them using Artificial Intelligence to allow continuous testing of software systems at multiple levels from different scopes, ranging from developers to end-users. The tool consists of three modules, each serving a distinct purpose. The first two modules aim to identify vulnerabilities from different perspectives, while the third module enhances traditional automated software testing by automatically generating test cases through source code analysis. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.|Artificial Intelligence; Automated Software Testing; Testing Framework|Automation; Computer programming; Software design; Software testing; Automated software testing; Continuous testing; Daily activity; Development cycle; Integral part; Multiple levels; Software-systems; Testing framework; Testing method; Testing phase; Artificial intelligence|Conference paper|Final||Scopus|2-s2.0-85173477776
scopus|Ramesh L.; Radhika S.; Jothi S.|Ramesh, Lilly (37102675100); Radhika, S. (56432602100); Jothi, S. (56418284200)|37102675100; 56432602100; 56418284200|Hybrid support vector machine and K-nearest neighbor-based software testing for educational assistant|2023|Concurrency and Computation: Practice and Experience|35|1|e7433||||5|10.1002/cpe.7433|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142457881&doi=10.1002%2fcpe.7433&partnerID=40&md5=d590d0d799d7b4f8a1e3b650364f1c86|In terms of training students for work in diverse firms, traditional and out-of-date teaching techniques cannot compete with digital teaching methods. To overcome this problem, the teaching approach and content must be changed. An Educational Assistant for Software Testing (EAST) framework is developed in this work to train students to improve their skills in software testing via Computer Assisted Instruction (CAI) built using Natural Language Processing (NLP), Machine learning, and information retrieval techniques. In this paper, a Group Search Optimized two-stage hybrid Support Vector Machine-K-Nearest Neighbor (SVM-KNN) classifier is used to develop a novel approach for analyzing the parameters that introduce bugs in bug reports. To decrease the data sparsity problem, the group search optimization (GSO) algorithm is used to improve the parameter selection process of the two-stage hybrid classifier by generating optimal values for parameters such as k, c, and gamma. Two bug report datasets were used to test the model. The database for our application is built by collecting bug reports from a wide open-source community as well as several mobile application development companies. Based on the extensive experiments conducted via different performance metrics, we can conclude that the EAST framework can improve outdated teaching methodologies. © 2022 John Wiley & Sons, Ltd.|bug report classification; computer-assisted instruction; group search optimization algorithm; hybrid support vector machine-K-nearest neighbor classifier; machine learning; natural language processing|Classification (of information); Computer aided instruction; E-learning; Learning systems; Motion compensation; Natural language processing systems; Nearest neighbor search; Open source software; Program debugging; Software testing; Students; Support vector machines; Text processing; Bug report classification; Bug reports; Computer Assisted Instruction; Group search optimization algorithm; Hybrid support vector machine-K-near neighbor classifier; Hybrid support vector machines; K-nearest neighbors classifiers; Language processing; Machine-learning; Natural language processing; Natural languages; Optimization algorithms; Search optimization; Learning algorithms|Article|Final||Scopus|2-s2.0-85142457881
scopus|Zimmermann D.; Deubel P.; Koziolek A.|Zimmermann, Daniel (57192928414); Deubel, Patrick (57446362000); Koziolek, Anne (55094731500)|57192928414; 57446362000; 55094731500|Evaluating the Effectiveness of Neuroevolution for Automated GUI-Based Software Testing|2023|Proceedings - 2023 38th IEEE/ACM International Conference on Automated Software Engineering Workshops, ASEW 2023||||119|126|7|1|10.1109/ASEW60602.2023.00021|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178521953&doi=10.1109%2fASEW60602.2023.00021&partnerID=40&md5=528108fc14b9e5eb9f14bf711bcd9048|As software systems become increasingly complex, testing has become an essential component of the development process to ensure the quality of the final product. However, manual testing can be costly and time-consuming due to the need for human intervention. This constrains the number of test cases that can be run within a given timeframe and, as a result, limits the ability to detect defects in software in a timely manner. Automated testing, on the other hand, can reduce the cost and time associated with testing, but traditional approaches have limitations. These include the inability to thoroughly explore the entire state space of software or process the high-dimensional input space of graphical user interfaces (GUIs). In this study, we propose a new approach for automated GUI-based software testing utilizing neuroevolution (NE), a branch of machine learning that employs evolutionary algorithms to train artificial neural networks with multiple hidden layers of neurons. NE offers a scalable alternative to established deep reinforcement learning methods and provides higher robustness to parameter influences and improved handling of sparse rewards. The agents are trained to explore software and identify errors while being rewarded for high test coverage. We evaluate our approach using a realistic benchmark software application and compare it to monkey testing, a widely adopted automated software testing method.  © 2023 IEEE.|Deep Learning; Neuroevolution; Test Automation; UI Testing|Application programs; Automation; Benchmarking; Deep learning; Multilayer neural networks; Reinforcement learning; Software agents; Software testing; Complex testing; Deep learning; Development process; Human intervention; Manual testing; Neuro evolutions; Software testings; Software-systems; Test Automation; UI testing; Graphical user interfaces|Conference paper|Final||Scopus|2-s2.0-85178521953
scopus|Stocco A.; Shehory O.; Jahangirova G.; Riccio V.; Barash G.; Farchi E.; Saha D.|Stocco, Andrea (36882807000); Shehory, Onn (7003736526); Jahangirova, Gunel (57190973501); Riccio, Vincenzo (57214054052); Barash, Guy (57201121209); Farchi, Eitan (6602737587); Saha, Diptikalyan (57162370400)|36882807000; 7003736526; 57190973501; 57214054052; 57201121209; 6602737587; 57162370400|Software testing in the machine learning era: Special issue of the empirical Software Engineering (EMSE) journal|2023|Empirical Software Engineering|28|3|74||||1|10.1007/s10664-023-10326-7|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85158009317&doi=10.1007%2fs10664-023-10326-7&partnerID=40&md5=760767324856e0a3d0bbe964a20eaab1|[No abstract available]|||Editorial|Final|All Open Access; Hybrid Gold Open Access|Scopus|2-s2.0-85158009317
scopus|Widodo A.P.; Wibowo A.; Kurniawan K.|Widodo, Aris Puji (57194067937); Wibowo, Adi (57205972690); Kurniawan, Kabul (57218551988)|57194067937; 57205972690; 57218551988|Enhancing Software User Interface Testing Through Few Shot Deep Learning: A Novel Approach for Automated Accuracy and Usability Evaluation|2023|International Journal of Advanced Computer Science and Applications|14|12||578|585|7|1|10.14569/IJACSA.2023.0141260|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183462132&doi=10.14569%2fIJACSA.2023.0141260&partnerID=40&md5=492e9b3b1d6c60a0a0b45b3866ce4b0b|Traditional user interface (UI) testing methods in software development are time-consuming and prone to human error, requiring more efficient and accurate approaches. Moreover, deep learning requires extensive data training to develop accurate automated UI software testing. This paper proposes an efficient and accurate method for automating UI software testing using Deep learning with training data limitations. We propose a novel deep learning-based framework suitable for UI element analysis in data-scarce situations, focusing on Few-shot learning. Our framework initiates with several robust feature extraction modules that employ and compare sophisticated encoder models to be adept at capturing complex patterns from a sparse dataset. The methodology employs the Enrico and UI screen mistake datasets, overcoming training data limitations. Utilizing encoder models, including CNN, VGG-16, ResNet-50, MobileNet-V3, and EfficientNet-B1, the EfficientNet-B1 model excelled in the setting of Few-Shot learning with five-shot with an average accuracy of 76.05%. Our proposed model's accuracy was improved and compared to the state-of-the-art method. Our findings demonstrate the effectiveness of few-shot learning in UI screen classification, setting new benchmarks in software testing and usability evaluation, particularly in limited data scenarios. © (2023), (Science and Information Organization). All Rights Reserved.|Deep learning; efficientnet; few-shot; software testing; UI screen classification|Deep learning; Learning systems; Signal encoding; Software design; User interfaces; Deep learning; Efficientnet; Few-shot; Interface testings; Screen classification; Software testings; Training data; Usability evaluation; User interface screen classification; User interface software; Software testing|Article|Final|All Open Access; Gold Open Access|Scopus|2-s2.0-85183462132
scopus|Alsangari B.; Bircik G.|Alsangari, Baraah (58505126100); Bircik, Goksel (16229388000)|58505126100; 16229388000|Performance Evaluation of various ML techniques for Software Fault Prediction using NASA dataset|2023|HORA 2023 - 2023 5th International Congress on Human-Computer Interaction, Optimization and Robotic Applications, Proceedings|||||||3|10.1109/HORA58378.2023.10156708|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165711023&doi=10.1109%2fHORA58378.2023.10156708&partnerID=40&md5=960c3dbddadb8712d89c36832fe32db5|In order to improve software dependability, Software Fault Prediction (SFP) has become an important research topic in the area of software engineering. To improve program dependability, program defect predictions are being utilized to aid developers in anticipating prospective issues and optimizing testing resources. As a result of this method, the amount of software defects may be forecast, and software testing resources are directed toward the software modules that have the greatest issues, enabling the defects to be fixed as soon as possible. As a result, this paper handles the issue related for SFP based on using a dataset known as JM1 provided by NASA, with 21 features. In this study, several Machine Learning (ML) techniques will be studied, which include Logistic Regression (LR), Random Forest (RF), Naive Bias (NB), Support Vector Machine (SVM), K-Nearest Neighbor (KNN) with three distance metric, Decision Tree (DT). Three cases of normalization will be involved with investigation which are the without sampling, Random over Sample and the SMOTE. Performance evaluation will be based on various parameters such as the ACC, Recall, Precision, and F1-Score. Results obtained indicate that RF achieve the higher ACC with values of 0.81%, 0.92%, and 0.88% respectively. The comprehensive findings of this study may be utilized as a baseline for subsequent studies, allowing any claim of improved prediction using any new approach, model, or framework to be compared and confirmed. In future, the variation of feature number will be involved with performance evaluation in handling SFP. © 2023 IEEE.|KNN; ML; RF; SFP; Software Engineering|Decision trees; Defects; Forecasting; Logistic regression; NASA; Nearest neighbor search; Support vector machines; K-near neighbor; Machine learning techniques; Machine-learning; Nearest-neighbour; Performances evaluation; Random forests; Research topics; Software dependability; Software fault prediction; Testing resources; Software testing|Conference paper|Final||Scopus|2-s2.0-85165711023
scopus|Samir M.; Sherief N.; Abdelmoez W.|Samir, Mina (58517234600); Sherief, Nada (56311059400); Abdelmoez, Walid (8347414700)|58517234600; 56311059400; 8347414700|Improving Bug Assignment and Developer Allocation in Software Engineering through Interpretable Machine Learning Models|2023|Computers|12|7|128||||9|10.3390/computers12070128|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166397867&doi=10.3390%2fcomputers12070128&partnerID=40&md5=675ed7198e8907d10e7ba6091cbfb050|Software engineering is a comprehensive process that requires developers and team members to collaborate across multiple tasks. In software testing, bug triaging is a tedious and time-consuming process. Assigning bugs to the appropriate developers can save time and maintain their motivation. However, without knowledge about a bug’s class, triaging is difficult. Motivated by this challenge, this paper focuses on the problem of assigning a suitable developer to a new bug by analyzing the history of developers’ profiles and analyzing the history of bugs for all developers using machine learning-based recommender systems. Explainable AI (XAI) is AI that humans can understand. It contrasts with “black box” AI, which even its designers cannot explain. By providing appropriate explanations for results, users can better comprehend the underlying insight behind the outcomes, boosting the recommender system’s effectiveness, transparency, and confidence. The trained model is utilized in the recommendation stage to calculate relevance scores for developers based on expertise and past bug handling performance, ultimately presenting the developers with the highest scores as recommendations for new bugs. This approach aims to strike a balance between computational efficiency and accurate predictions, enabling efficient bug assignment while considering developer expertise and historical performance. In this paper, we propose two explainable models for recommendation. The first is an explainable recommender model for personalized developers generated from bug history to know what the preferred type of bug is for each developer. The second model is an explainable recommender model based on bugs to identify the most suitable developer for each bug from bug history. © 2023 by the authors.|bugs; explainability; explainable AI; recommendation; XAI||Article|Final|All Open Access; Gold Open Access; Green Open Access|Scopus|2-s2.0-85166397867
scopus|Borandag E.|Borandag, Emin (57063310500)|57063310500|Software Fault Prediction Using an RNN-Based Deep Learning Approach and Ensemble Machine Learning Techniques|2023|Applied Sciences (Switzerland)|13|3|1639||||35|10.3390/app13031639|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148017033&doi=10.3390%2fapp13031639&partnerID=40&md5=39c0baf9607c52c0128dd3415ff7ecab|Alongside the modern software development life cycle approaches, software testing has gained more importance and has become an area researched actively within the software engineering discipline. In this study, machine learning and deep learning-related software fault predictions were made through a data set named SFP XP-TDD, which was created using three different developed software projects. A data set of five different classifiers widely used in the literature and their Rotation Forest classifier ensemble versions were trained and tested using this data set. Numerous publications in the literature discussed software fault predictions through ML algorithms addressing solutions to different problems. Some of these articles indicated the usage of feature selection algorithms to improve classification performance, while others reported operating ensemble machine learning algorithms for software fault predictions. Besides, a detailed literature review revealed that there were few studies involving software fault prediction with DL algorithms due to the small sample sizes in the data sets and the low success rates in the tests performed on these datasets. As a result, the major contribution of this research was to statistically demonstrate that DL algorithms outperformed ML algorithms in data sets with large sample values via employing three separate software fault prediction datasets. The experimental outcomes of a model that includes a layer of recurrent neural networks (RNNs) were enclosed within this study. Alongside the aforementioned and generated data sets, the study also utilized the Eclipse and Apache Active MQ data sets in to test the effectiveness of the proposed deep learning method. © 2023 by the author.|deep learning; ensemble machine learning; software fault prediction||Article|Final|All Open Access; Gold Open Access|Scopus|2-s2.0-85148017033
scopus|Aleti A.|Aleti, Aldeida (35092219900)|35092219900|Software Testing of Generative AI Systems: Challenges and Opportunities|2023|Proceedings - 2023 IEEE/ACM International Conference on Software Engineering: Future of Software Engineering, ICSE-FoSE 2023||||4|14|10|6|10.1109/ICSE-FoSE59343.2023.00009|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187719451&doi=10.1109%2fICSE-FoSE59343.2023.00009&partnerID=40&md5=bf6e29aa3a9fbc006169b6cb0c831c17|Software Testing is a well-established area in software engineering, encompassing various techniques and methodologies to ensure the quality of software systems. However, with the arrival of generative artificial intelligence (GenAI) systems, new challenges arise in the testing domain. These systems, capable of generating novel and creative outputs, introduce unique complexities that require novel testing approaches. In this paper, I aim to explore the challenges posed by GenAI systems and discuss potential opportunities for future research in the area of testing. I will touch on the specific characteristics of GenAI systems that make traditional testing techniques inadequate or insufficient. By addressing these challenges and pursuing further research, we can enhance our understanding of how to safeguard GenAI and pave the way for improved quality assurance in this rapidly evolving area. © 2023 IEEE.|Generative AI; oracle; Software testing; test suite adequacy|Quality assurance; Verification; Well testing; AI systems; Artificial intelligence systems; Creatives; Generative AI; Novel testing; Oracle; Quality of softwares; Software testings; Software-systems; Test suite adequacy; Software testing|Conference paper|Final|All Open Access; Green Open Access|Scopus|2-s2.0-85187719451
scopus|Andyartha P.K.; Yuhana U.L.; Raharjo A.B.; Purwitasari D.|Andyartha, Putu Krisna (58122038800); Yuhana, Umi Laili (55070783100); Raharjo, Agus Budi (57196345296); Purwitasari, Diana (23493277700)|58122038800; 55070783100; 57196345296; 23493277700|Presenting a Reliability Evaluation Framework for Cloud-Based Machine Learning in Microservices|2023|6th International Seminar on Research of Information Technology and Intelligent Systems, ISRITI 2023 - Proceeding||||95|100|5|1|10.1109/ISRITI60336.2023.10467653|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190064791&doi=10.1109%2fISRITI60336.2023.10467653&partnerID=40&md5=151dc018805d3e1f16b814e5872cf691|Machine learning has seen wide adoptions, although its deployment is resource-intensive and time-consuming with interoperability and performance concerns. Cloud deployment and microservice architecture have been chosen by researchers and practitioners as solutions to these issues. However, the reliability aspects of such systems have yet to be explored. The reliability of any system is important, especially for the end users. To this end, we proposed an evaluation framework to equip practitioners with guidelines that consist of metrics and threshold selection, which can be integrated with a software's testing life cycle. We conducted an analysis of ISO/IEC 25023:2016 standard to study the software reliability requirements. Afterwards, we demonstrated the utility of our framework on a healthcare application that runs two CNN models and multiple services. The evaluation within this work was done for 84 hours and the proposed framework successfully guided the reliability evaluation of the selected case study. This work concluded that the proposed evaluation framework successfully gauged the reliability of cloud-based machine learning in microservices. © 2023 IEEE.|cloud deployment; evaluation framework; machine learning; microservice architecture; reliability|Computer architecture; ISO Standards; Life cycle; Reliability analysis; Software reliability; Software testing; Cloud deployments; Cloud-based; End-users; Evaluation framework; Machine-learning; Metric selections; Microservice architecture; Performance; Reliability Evaluation; Threshold selection; Machine learning|Conference paper|Final||Scopus|2-s2.0-85190064791
scopus|Wan W.X.; Lindenthal T.|Wan, Wayne Xinwei (57222637543); Lindenthal, Thies (55631148000)|57222637543; 55631148000|Testing machine learning systems in real estate|2023|Real Estate Economics|51|3||754|778|24|10|10.1111/1540-6229.12416|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143233595&doi=10.1111%2f1540-6229.12416&partnerID=40&md5=9971ef2ea7a073e20fac46d93b6b4e2c|Uncertainty about the inner workings of machine learning (ML) models holds back the application of ML-enabled systems in real estate markets. How do ML models arrive at their estimates? Given the lack of model transparency, how can practitioners guarantee that ML systems do not run afoul of the law? This article first advocates a dedicated software testing framework for applied ML systems, as commonly found in computer science. Second, it demonstrates how system testing can verify that applied ML models indeed perform as intended. Two system-testing procedures developed for ML image classifiers used in automated valuation models (AVMs) illustrate the approach. © 2022 American Real Estate and Urban Economics Association.|accountability gap; computer vision; explainable machine learning; real estate; system testing||Article|Final|All Open Access; Hybrid Gold Open Access|Scopus|2-s2.0-85143233595
scopus|Ricca F.; Marchetto A.; Stocco A.|Ricca, Filippo (24822686600); Marchetto, Alessandro (23971457800); Stocco, Andrea (36882807000)|24822686600; 23971457800; 36882807000|A Retrospective Analysis of Grey Literature for AI-Supported Test Automation|2023|Communications in Computer and Information Science|1871 CCIS|||90|105|15|4|10.1007/978-3-031-43703-8_7|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172411770&doi=10.1007%2f978-3-031-43703-8_7&partnerID=40&md5=7f7a9cc0ab66d614d22d4424a4e2d68f|This paper provides the results of a retrospective analysis conducted on a survey of the grey literature about the perception of practitioners on the integration of artificial intelligence (AI) algorithms into Test Automation (TA) practices. Our study involved the examination of 231 sources, including blogs, user manuals, and posts. Our primary goals were to: (a) assess the generalizability of existing taxonomies about the usage of AI for TA, (b) investigate and understand the relationships between TA problems and AI-based solutions, and (c) systematically map out the existing AI-based tools that offer AI-enhanced solutions. Our analysis yielded several interesting results. Firstly, we assessed a high degree of generalization of the existing taxonomies. Secondly, we identified TA problems that can be addressed using AI-enhanced solutions integrated into existing tools. Thirdly, we found that some TA problems require broader solutions that involve multiple software testing phases simultaneously, such as test generation and maintenance. Fourthly, we discovered that certain solutions are being investigated but are not supported by existing AI-based tools. Finally, we observed that there are tools that supports different phases of TA and may have a broader outreach. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.|Artificial Intelligence; Grey Literature; Test Automation|Automation; Software testing; Taxonomies; Artificial intelligence algorithms; Generalisation; Grey literature; Retrospective analysis; Software testings; Test Automation; Test generations; Test maintenances; Testing phase; User manual; Artificial intelligence|Conference paper|Final||Scopus|2-s2.0-85172411770
scopus|Fatima S.; Ghaleb T.A.; Briand L.|Fatima, Sakina (57386740700); Ghaleb, Taher A. (55932635300); Briand, Lionel (7006613079)|57386740700; 55932635300; 7006613079|Flakify: A Black-Box, Language Model-Based Predictor for Flaky Tests|2023|IEEE Transactions on Software Engineering|49|4||1912|1927|15|21|10.1109/TSE.2022.3201209|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137568682&doi=10.1109%2fTSE.2022.3201209&partnerID=40&md5=72a0b07c369ed41812cf679e98002f8a|Software testing assures that code changes do not adversely affect existing functionality. However, a test case can be flaky, i.e., passing and failing across executions, even for the same version of the source code. Flaky test cases introduce overhead to software development as they can lead to unnecessary attempts to debug production or testing code. Besides rerunning test cases multiple times, which is time-consuming and computationally expensive, flaky test cases can be predicted using machine learning (ML) models, thus reducing the wasted cost of re-running and debugging these test cases. However, the state-of-the-art ML-based flaky test case predictors rely on pre-defined sets of features that are either project-specific, i.e., inapplicable to other projects, or require access to production code, which is not always available to software test engineers. Moreover, given the non-deterministic behavior of flaky test cases, it can be challenging to determine a complete set of features that could potentially be associated with test flakiness. Therefore, in this article, we propose Flakify, a black-box, language model-based predictor for flaky test cases. Flakify relies exclusively on the source code of test cases, thus not requiring to (a) access to production code (black-box), (b) rerun test cases, (c) pre-define features. To this end, we employed CodeBERT, a pre-trained language model, and fine-tuned it to predict flaky test cases using the source code of test cases. We evaluated Flakify on two publicly available datasets (FlakeFlagger and IDoFT) for flaky test cases and compared our technique with the FlakeFlagger approach, the best state-of-the-art ML-based, white-box predictor for flaky test cases, using two different evaluation procedures: (1) cross-validation and (2) per-project validation, i.e., prediction on new projects. Flakify achieved F1-scores of 79% and 73% on the FlakeFlagger dataset using cross-validation and per-project validation, respectively. Similarly, Flakify achieved F1-scores of 98% and 89% on the IDoFT dataset using the two validation procedures, respectively. Further, Flakify surpassed FlakeFlagger by 10 and 18 percentage points (pp) in terms of precision and recall, respectively, when evaluated on the FlakeFlagger dataset, thus reducing the cost bound to be wasted on unnecessarily debugging test cases and production code by the same percentages (corresponding to reduction rates of 25% and 64%). Flakify also achieved significantly higher prediction results when used to predict test cases on new projects, suggesting better generalizability over FlakeFlagger. Our results further show that a black-box version of FlakeFlagger is not a viable option for predicting flaky test cases.  © 1976-2012 IEEE.|black-box testing; CodeBERT; Flaky tests; natural language processing; software testing|Black-box testing; C (programming language); Codes (symbols); Computational linguistics; Feature extraction; Forecasting; Learning systems; Modeling languages; Natural language processing systems; Object oriented programming; Program debugging; Software design; Testing; Code; CodeBERT; Computational modelling; Features extraction; Flaky test; Language processing; Natural language processing; Natural languages; Predictive models; Software; Software testings; Learning algorithms|Article|Final|All Open Access; Green Open Access|Scopus|2-s2.0-85137568682
scopus||||13th International Conference on Innovations in Bio-Inspired Computing and Applications, IBICA 2022, and 12th World Congress on Information and Communication Technologies, WICT 2022|2023|Lecture Notes in Networks and Systems|649 LNNS|||||931|0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152541297&partnerID=40&md5=6d907d2c5ed790f7ee02e76d8aedff5d|The proceedings contain 86 papers. The special focus in this conference is on Innovations in Bio-Inspired Computing and Applications. The topics include: A Novel Approach to the Two-Dimensional Cargo Load Problem; vehicle Detection from Aerial Imagery Using Principal Component Analysis and Deep Learning; bio-inspired Heterogeneity in Swarm Robots; software Defect Prediction Using Cellular Automata as an Ensemble Strategy to Combine Classification Techniques; a Systematic Literature Review on Home Health Care Management; the Impact of the Size of the Partition in the Performance of Bat Algorithm; automatic Diagnosis Framework for Catheters and Tubes Semantic Segmentation and Placement Errors Detection; how Artificial Intelligence Can Revolutionize Software Testing Techniques; e-Assessment in Medical Education: From Paper to Platform; Evolution of Configuration Data in CGP Format Using Parallel GA on Embryonic Fabric; DeepPRS: A Deep Learning Integrated Pattern Recognition Methodology for Secure Data in Cloud Environment; Automated Depression Diagnosis in MDD (Major Depressive Disorder) Patients Using EEG Signal; an Effective Deep Learning Classification of Diabetes Based Eye Disease Grades: An Retinal Analysis Approach; extracting and Analyzing Terms with the Component ‘Green’ in the Bulgarian Language: A Big Data Approach; Apartments Waste Disposal Location Evaluation Using TOPSIS and Fuzzy TOPSIS Methods; detection of Cracks in Building Facades Using Infrared Thermography; optimizing Pre-processing for Foetal Cardiac Ultra Sound Image Classification; a Review on Dimensionality Reduction for Machine Learning; detecting Depression on Social Platforms Using Machine Learning; impact of Green Hydrogen Production on Energy Pricing; Cross Synergetic Mobilenet-VGG16 for UML Multiclass Diagrams Classification; the Future in Fishfarms: An Ocean of Technologies to Explore; breast Cancer Identification Using Improved DarkNet53 Model; anomaly Detection Framework.|||Conference review|Final||Scopus|2-s2.0-85152541297
scopus||||Proceedings - 2023 International Conference on Advanced Computing and Communication Technologies, ICACCTech 2023|2023|Proceedings - 2023 International Conference on Advanced Computing and Communication Technologies, ICACCTech 2023||||||809|0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187322476&partnerID=40&md5=aaa63b39b60706c140203010ed02e79b|The proceedings contain 120 papers. The topics discussed include: quantum teleportation using artificial wormhole: a mini review; designing and developing a CanSat for environmental monitoring and scientific exploration; a survey on green IoT and its opportunities for future directions; artificial intelligence for portfolio selection: a bibliometric review; face reconstruction from sketch using deep learning; a comprehensive investigation into the dimensions of educational data mining using artificial intelligence; human-computer interaction: a systematic review; possibilities and pitfalls of generative pre-trained transformers in healthcare; unveiling the art of software testing effort estimation: an in-depth study of current techniques and their analysis; advancements in natural language processing: techniques and applications; and securing mobile robots multi-party authentication technique using modified elliptic curve cryptography.|||Conference review|Final||Scopus|2-s2.0-85187322476
scopus|Herbold S.; Tunkel S.|Herbold, Steffen (35226400600); Tunkel, Steffen (57833610300)|35226400600; 57833610300|Differential testing for machine learning: an analysis for classification algorithms beyond deep learning|2023|Empirical Software Engineering|28|2|34||||3|10.1007/s10664-022-10273-9|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146744477&doi=10.1007%2fs10664-022-10273-9&partnerID=40&md5=2fe03eb745b37db39e3ce7566a6ff2ac|Differential testing is a useful approach that uses different implementations of the same algorithms and compares the results for software testing. In recent years, this approach was successfully used for test campaigns of deep learning frameworks. There is little knowledge about the application of differential testing beyond deep learning. Within this article, we want to close this gap for classification algorithms. We conduct a case study using Scikit-learn, Weka, Spark MLlib, and Caret in which we identify the potential of differential testing by considering which algorithms are available in multiple frameworks, the feasibility by identifying pairs of algorithms that should exhibit the same behavior, and the effectiveness by executing tests for the identified pairs and analyzing the deviations. While we found a large potential for popular algorithms, the feasibility seems limited because, often, it is not possible to determine configurations that are the same in other frameworks. The execution of the feasible tests revealed that there is a large number of deviations for the scores and classes. Only a lenient approach based on statistical significance of classes does not lead to a huge amount of test failures. The potential of differential testing beyond deep learning seems limited for research into the quality of machine learning libraries. Practitioners may still use the approach if they have deep knowledge about implementations, especially if a coarse oracle that only considers significant differences of classes is sufficient. © 2023, The Author(s).|Differential testing; Machine learning; Software testing|Deep learning; Case-studies; Classification algorithm; Differential testing; Learn+; Learning frameworks; Machine-learning; Software testings; Statistical significance; Test campaign; Test failure; Software testing|Article|Final|All Open Access; Hybrid Gold Open Access|Scopus|2-s2.0-85146744477
scopus|Manikkannan D.; Babu S.|Manikkannan, D. (58452937200); Babu, S. (57209822555)|58452937200; 57209822555|Automating Software Testing with Multi-Layer Perceptron (MLP): Leveraging Historical Data for Efficient Test Case Generation and Execution|2023|International Journal of Intelligent Systems and Applications in Engineering|11|7s||424|428|4|0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163948624&partnerID=40&md5=881f8efd59ba3a7ed89fe2a5a054c7d6|Software testing is an essential step in the software development process. Defects in software are mostly caused by newer technology, a lack of version control, and the complexity of systems. Because of these issues, the cost of software maintenance rises, as do its consequences. Manual testing necessitates the use of human labour to seek for and analyse data. As software systems get more complicated, automated software testing approaches are becoming increasingly important. Machine Learning approaches have proven extremely beneficial in automating this procedure. Machine learning is also utilised to find essential software testing variables that aid in forecasting software testing cost and time. Predicting testing effort, tracking process expenses, and measuring results all contribute to improve software testing efficiency. Previously, classification trees were used to identify key properties of software testing, and regression approaches were employed to categorise defective data sets. Our framework is useful for automating the software testing process. © 2023, Ismail Saritas. All rights reserved.|automation; efficient testing; ML in software testing; Software testing; test case generation||Article|Final||Scopus|2-s2.0-85163948624
scopus|Li X.; Yu S.; Sun L.; Liu Y.; Fang C.|Li, Xin (57863559400); Yu, Shengcheng (57211404469); Sun, Lifan (58759316500); Liu, Yuexiao (58759096200); Fang, Chunrong (55321130800)|57863559400; 57211404469; 58759316500; 58759096200; 55321130800|Towards Effective Bug Reproduction for Mobile Applications|2023|Proceedings - 2023 10th International Conference on Dependable Systems and Their Applications, DSA 2023||||114|125|11|1|10.1109/DSA59317.2023.00024|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179516500&doi=10.1109%2fDSA59317.2023.00024&partnerID=40&md5=87badd0571e1121f8a7c062c953aecf6|Bug reproduction is a critical task in software testing, as it helps developers to identify and fix bugs in the software. While some automated reproduction tools are designed to assist developers in reproducing bugs detected by automated testing tools, they are not entirely reliable. Thus, manual reproduction remains important. However, automated testing tools often generate testing results that are difficult for non-professional developers to understand, which complicates their efforts to reproduce bugs. In this paper, we propose RepAssistor, an approach that employs an interactive method to assist developers in reproducing bugs based on automated testing logs. RepAssistor is designed for reproducing bugs in mobile applications. It leverages deep learning (DL) and traditional computer vision (CV) techniques to analyze application screenshots, transforming automated testing logs into a graph representation. In this graph, edges represent test events while nodes represent application states. With this graph representation in place, RepAssistor is then able to monitor developers' actions and continuously track which node they are at in this graph in real-time. Based on this understanding, RepAssistor dynamically calculates and updates the optimal path to guide developers to reproduce bugs. This guidance is conveyed to the developers through an interactive method, enabling effective communication and assistance throughout the bug reproduction process. Our experiments demonstrate that RepAssistor improves the performance of developers in bug reproduction tasks.  © 2023 IEEE.|bug reproduction; conversational agent; software testing|Application programs; Automation; Cell proliferation; Deep learning; Graph theory; Mobile computing; Program debugging; Software agents; Automated testing; Automated testing tools; Bug reproduction; Conversational agents; Critical tasks; Graph representation; Interactive methods; Mobile applications; Software testings; Traditional computers; Software testing|Conference paper|Final||Scopus|2-s2.0-85179516500
scopus|Dresia K.; Kurudzija E.; Waxenegger-Wilfing G.; Behler H.; Auer D.; Fröhlke K.; Neumann H.; Frank A.; Laurent J.; Fabreguettes L.|Dresia, Kai (57216629220); Kurudzija, Eldin (58297081600); Waxenegger-Wilfing, Günther (57203383924); Behler, Hendrik (58812938200); Auer, Daniel (58813237900); Fröhlke, Karsten (7801498732); Neumann, Heike (58813022200); Frank, Anja (56176933300); Laurent, Jérôme (58813022300); Fabreguettes, Luce (35781485200)|57216629220; 58297081600; 57203383924; 58812938200; 58813237900; 7801498732; 58813022200; 56176933300; 58813022300; 35781485200|AUTOMATION OF TESTING AND FAULT DETECTION FOR ROCKET ENGINE TEST FACILITIES WITH MACHINE LEARNING|2023|International Journal of Energetic Materials and Chemical Propulsion|22|6||17|33|16|1|10.1615/IntJEnergeticMaterialsChemProp.2023047195|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182392625&doi=10.1615%2fIntJEnergeticMaterialsChemProp.2023047195&partnerID=40&md5=e478a79efa8036ab8bd1d59cdd2814ee|The German Aerospace Center (DLR) Institute of Space Propulsion has unique expertise in op-erating test facilities for rocket engine testing and development in Europe since 1959. However, essential elements of the test site were designed up to half a century ago. In order to ensure a future-proof and intelligent digital test infrastructure, the potential of test automation, advanced control, and monitoring systems is investigated based on machine learning. Such intelligent control systems are expected to reduce engine development and test preparation times, thereby lowering the asso-ciated costs. Additionally, advanced monitoring systems are anticipated to increase the safety and reliability of the test infrastructure. This paper presents the results of two pilot projects: the first project uses reinforcement learning to automatically generate test sequences based on test require-ments, while the second project develops a feed-forward forecasting model to predict deviations from expected behavior in the feed-line of a rocket engine test facility. © 2023 by Begell House, Inc.|anomaly de-tection; digital twin; intelligent control; machine learning; reinforcement learning; rocket engine test facilities|E-learning; Intelligent control; Reinforcement learning; Rocket engines; Rockets; Test facilities; Advanced monitoring; Anomaly de-tection; Engine development; Engine test; Faults detection; German aerospace centers; Machine-learning; Reinforcement learnings; Rocket engine test facility; Test infrastructures; Fault detection|Article|Final||Scopus|2-s2.0-85182392625
scopus|Li J.; Yu H.|Li, Jinfeng (39561308600); Yu, Haihao (56693246300)|39561308600; 56693246300|An effective method for fault localization based on combination of convolution and LSTM|2023|Lecture Notes in Electrical Engineering|1090 LNEE|||815|827|12|0|10.1007/978-981-99-6882-4_66|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175047521&doi=10.1007%2f978-981-99-6882-4_66&partnerID=40&md5=6b481a6e436ad6b5890fb0c1c1a26e78|Software testing takes up a sizeable portion of the overall process of developing software. The process of software testing must always include software fault localization as one of its core components. CNN-LSTM-FL is the name of the effective method for fault localization that we propose in this paper. Deep learning’s convolutional and recurrent neural network serve as the foundation for this model’s deep learning architecture. This method is applied to Siemens programs that are stored in the Software Infrastructure Repository (SIR), and it is contrasted with fault localization techniques using convolutional neural networks (CNN-FL) and fault localization techniques using recurrent neural networks (LSTM-FL). The method that is proposed in this paper is found to be superior to the other two methods in terms of both effectiveness and stability. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2023.|Deep learning; Fault localization; Software testing|Convolution; Learning systems; Long short-term memory; Core components; Deep learning; Fault localization; Learning architectures; Localization technique; Overall process; Siemens; Software fault localization; Software infrastructure; Software testings; Software testing|Conference paper|Final||Scopus|2-s2.0-85175047521
scopus|Xie X.; Li T.; Wang J.; Ma L.; Guo Q.; Juefei-Xu F.; Liu Y.|Xie, Xiaofei (55268560900); Li, Tianlin (57218764226); Wang, Jian (57221358273); Ma, Lei (55479591700); Guo, Qing (57191163500); Juefei-Xu, Felix (54911989900); Liu, Yang (56911879800)|55268560900; 57218764226; 57221358273; 55479591700; 57191163500; 54911989900; 56911879800|NPC: Neuron Path Coverage via Characterizing Decision Logic of Deep Neural Networks|2022|ACM Transactions on Software Engineering and Methodology|31|3|47||||54|10.1145/3490489|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130728492&doi=10.1145%2f3490489&partnerID=40&md5=4a2b36fff06c0dab5095153ffb174652|Deep learning has recently been widely applied to many applications across different domains, e.g., image classification and audio recognition. However, the quality of Deep Neural Networks (DNNs) still raises concerns in the practical operational environment, which calls for systematic testing, especially in safety-critical scenarios. Inspired by software testing, a number of structural coverage criteria are designed and proposed to measure the test adequacy of DNNs. However, due to the blackbox nature of DNN, the existing structural coverage criteria are difficult to interpret, making it hard to understand the underlying principles of these criteria. The relationship between the structural coverage and the decision logic of DNNs is unknown. Moreover, recent studies have further revealed the non-existence of correlation between the structural coverage and DNN defect detection, which further posts concerns on what a suitable DNN testing criterion should be.In this article, we propose the interpretable coverage criteria through constructing the decision structure of a DNN. Mirroring the control flow graph of the traditional program, we first extract a decision graph from a DNN based on its interpretation, where a path of the decision graph represents a decision logic of the DNN. Based on the control flow and data flow of the decision graph, we propose two variants of path coverage to measure the adequacy of the test cases in exercising the decision logic. The higher the path coverage, the more diverse decision logic the DNN is expected to be explored. Our large-scale evaluation results demonstrate that: The path in the decision graph is effective in characterizing the decision of the DNN, and the proposed coverage criteria are also sensitive with errors, including natural errors and adversarial examples, and strongly correlate with the output impartiality.  © 2022 Association for Computing Machinery.|Deep learning testing; model interpretation; testing coverage criteria|Computer circuits; Data flow analysis; Flow graphs; Graphic methods; Safety engineering; Safety testing; Software testing; Audio-recognition; Coverage criteria; Decision graphs; Decision logic; Deep learning testing; Different domains; Images classification; Model interpretations; Path coverage; Testing coverage criterion; Deep neural networks|Article|Final|All Open Access; Bronze Open Access; Green Open Access|Scopus|2-s2.0-85130728492
scopus|Tsimpourlas F.; Rooijackers G.; Rajan A.; Allamanis M.|Tsimpourlas, Foivos (57203224939); Rooijackers, Gwenyth (57706425900); Rajan, Ajitha (16239550300); Allamanis, Miltiadis (39361040300)|57203224939; 57706425900; 16239550300; 39361040300|Embedding and classifying test execution traces using neural networks|2022|IET Software|16|3||301|316|15|4|10.1049/sfw2.12038|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130637519&doi=10.1049%2fsfw2.12038&partnerID=40&md5=63d064fdc629999bd7cb0bc9f05ca39d|Classifying test executions automatically as pass or fail remains a key challenge in software testing and is referred to as the test oracle problem. It is being attempted to solve this problem with supervised learning over test execution traces. A programme is instrumented to gather execution traces as sequences of method invocations. A small fraction of the programme's execution traces is labelled with pass or fail verdicts. Execution traces are then embedded as fixed length vectors and a neural network (NN) component that uses the line-by-line information to classify traces as pass or fail is designed. The classification accuracy of this approach is evaluated using subject programs from different application domains—1. Module from Ethereum Blockchain, 2. Module from PyTorch deep learning framework, 3. Microsoft SEAL encryption library components, 4. Sed stream editor, 5. Nine network protocols from Linux packet identifier, L7-Filter and 6. Utilities library, commons-lang for Java. For all subject programs, it was found that test execution classification had high precision, recall and specificity, averaging to 93%, 94% and 96%, respectively, while only training with an average 14% of the total traces. Experiments show that the proposed NN-based approach is promising in classifying test executions from different application domains. © 2021 The Authors. IET Software published by John Wiley & Sons Ltd on behalf of The Institution of Engineering and Technology.|execution trace; neural networks; software testing; test oracle|Application programs; Classification (of information); Computer operating systems; Cryptography; Deep learning; Network protocols; Neural networks; Testing; Applications domains; Embeddings; Execution trace; Method invocation; Neural-networks; Oracle problem; Program execution; Software testings; Test execution; Test oracles; Software testing|Article|Final|All Open Access; Gold Open Access; Green Open Access|Scopus|2-s2.0-85130637519
scopus|Sreedevi E.; Lakshmi D.S.; Divya A.; Gangadhar P.V.S.S.; Premalatha V.|Sreedevi, E. (49864380400); Lakshmi, D. Sree (59499324200); Divya, A. (57487291500); Gangadhar, P.V.S.S. (37046926500); Premalatha, V. (57202577864)|49864380400; 59499324200; 57487291500; 37046926500; 57202577864|PERFORMANCEOF HETEROGENEOUS ENSEMBLE APPROACH WITH TRADITIONAL METHODS BASED ON SOFTWARE DEFECT DETECTION MODEL|2022|Journal of Theoretical and Applied Information Technology|100|4||980|989|9|1||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126273818&partnerID=40&md5=5b95774ea65d4854479202fc3254c0be|Identifying defective modules from the developed software is very much indispensable for constructive management and control of software testing. Software defect detection models helps a lot in effective allocation of limited testing resources. In this context several software defect detection modelling has been proposed by using machine learning algorithm. The main intention of heterogeneous ensemble model is to regulate each of its specific model strengths and weakness undoubtedly leading to the finest passable decision being taken overall. In this paper, we proposed heterogeneous ensemble learning, a defect detection model in which different learners are combined to form heterogeneous ensemble learning. Performance of individual learning models is compared with our proposed heterogeneous ensemble models, and it shows that our model is giving a better accuracy then the models developed by individual learning models. The evaluation results show that our proposed model achieved up to 98% accuracy which is more than the evaluation accuracy achieved by individual learning models. © 2022 Little Lion Scientific. All rights reserved.|Accuracy; Defect Detection; Ensemble Learning; Feature Selection; Software Defect Detection Models||Article|Final||Scopus|2-s2.0-85126273818
scopus|Ong A.K.S.; Prasetyo Y.T.; Roque R.A.C.; Garbo J.G.I.; Robas K.P.E.; Persada S.F.; Nadlifatin R.|Ong, Ardvin Kester S. (57221675282); Prasetyo, Yogi Tri (57204827000); Roque, Ralph Andre C. (57225172592); Garbo, Jan Gabriel I. (57888745600); Robas, Kirstien Paola E. (57485151800); Persada, Satria Fadil (56286959500); Nadlifatin, Reny (56287886900)|57221675282; 57204827000; 57225172592; 57888745600; 57485151800; 56286959500; 56287886900|Determining the Factors Affecting a Career Shifter’s Use of Software Testing Tools amidst the COVID-19 Crisis in the Philippines: TTF-TAM Approach|2022|Sustainability (Switzerland)|14|17|11084||||8|10.3390/su141711084|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137915392&doi=10.3390%2fsu141711084&partnerID=40&md5=293bd70a5b81b1c5ebad83026c6385c6|The restrictions of the ongoing COVID-19 pandemic resulted in the downturn of various industries and in contrast a massive growth of the information technology industry. Consequently, more Filipinos are considering career changes to earn a living. However, more people still need to be upskilled. This study combines the extended Technology Acceptance Model and Task Technology Fit framework to determine factors affecting a career shifter’s use of software testing tools and its impact on perceived performance impact amidst the COVID-19 pandemic in the Philippines. A total of 150 software testers voluntarily participated and accomplished an online questionnaire consisting of 39 questions. The Structural Equation Modeling and Deep Learning Neural Network indicated that Task Technology Fit had a higher effect on Perceived Performance Impact. Moreover, Task Technology Fit positively influenced Perceived Usefulness. Computer Self-Efficacy was a strong predictor of Perceived Ease of Use. Perceived Ease of Use confirmed the Technology Acceptance Model framework as a strong predictor of Actual System Use. Intention to Use, Perceived Usefulness, Actual Use, and Subjective Norm were also significant factors affecting Perceived Performance Impact. This study is the first to explore the career shifter’s use of software testing tools in the Philippines. The framework would be very valuable in enhancing government policies for workforce upskilling, improving the private sector’s training and development practices, and developing a more competitive software testing tool that would hasten users’ adaptability. Lastly, the methodology, findings, and framework could be applied and extended to evaluate other technology adoption worldwide. © 2022 by the authors.|career shifter; deep neural network; software testing tools; structural equation modeling; task technology fit|Philippines; information technology|Article|Final|All Open Access; Gold Open Access|Scopus|2-s2.0-85137915392
scopus|Pham K.; Nguyen V.; Nguyen T.|Pham, Khang (59454893300); Nguyen, Vu (55893587300); Nguyen, Tien (55386311200)|59454893300; 55893587300; 55386311200|Application of Natural Language Processing Towards Autonomous Software Testing|2022|ACM International Conference Proceeding Series|||216||||1|10.1145/3551349.3563241|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146929359&doi=10.1145%2f3551349.3563241&partnerID=40&md5=fb509df27839612062ef0fc8f58e8b8e|The process of creating test cases from requirements written in natural language (NL) requires intensive human efforts and can be tedious, repetitive, and error-prone. Thus, many studies have attempted to automate that process by utilizing Natural Language Processing (NLP) approaches. Furthermore, with the advent of massive language models and transfer learning techniques, people have introduced various advancements in NLP-assisted software testing with promising results. More notably, in recent years, not only have researchers been engrossed in solving the above task, but many companies have also embedded the feature to translate from human language to test cases their products. This paper presents an overview of NLP-assisted solutions being used in both the literature and the software testing industry.  © 2022 ACM.||Application programs; Learning systems; Natural language processing systems; Autonomous software; Error prones; Language model; Language processing; Model learning; Natural languages; Processing approach; Software testings; Test case; Transfer learning; Software testing|Conference paper|Final||Scopus|2-s2.0-85146929359
scopus|Zhao W.; Patibandla M.; Ding J.|Zhao, Wenqian (55478163300); Patibandla, Meghana (58920529100); Ding, Junhua (7402608357)|55478163300; 58920529100; 7402608357|An Approach for Ensuring the Privacy in Smart Contracts|2023|Proceedings - 2023 IEEE 23rd International Conference on Software Quality, Reliability, and Security Companion, QRS-C 2023||||320|329|9|0|10.1109/QRS-C60940.2023.00046|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186745552&doi=10.1109%2fQRS-C60940.2023.00046&partnerID=40&md5=460fa4706e8e65c38f0383639decc9ab|Ensuring the privacy in smart contracts is critical to the success of the technique. Adequately testing privacy in smart contracts is a practical and effective way for ensuring the privacy. In this research, we experimented with a new approach that leverages the capacity of generative AI for automated testing privacy in blockchain based smart contracts. Generative AI tool ChatGPT was used for modeling privacy in smart contracts and producing tests according to the generated privacy model. The capacity of ChatGPT could have the potential for producing relatively comprehensive privacy requirements and adequate tests. We implemented a smart contract for managing real estate investment in Solidity based on the Ethereum blockchain platform and demonstrated the procedure and effectiveness of the proposed approach. © 2023 IEEE.|blockchain; chatGPT; data privacy; Ethereum; non-fungible token; smart contract|Artificial intelligence; Blockchain; Data privacy; Ethereum; Investments; Automated testing; Block-chain; Chatgpt; New approaches; Non-fungible token; Privacy models; Privacy requirements; Real estate investment; Smart contract|Conference paper|Final||Scopus|2-s2.0-85186745552
scopus|Zhang G.; Schmitz C.; Fimmers M.; Quix C.; Hoseini S.|Zhang, Gaoyuan (57860570000); Schmitz, Christian (55256588800); Fimmers, Matthias (57376007300); Quix, Christoph (23398177400); Hoseini, Sayed (57282601800)|57860570000; 55256588800; 57376007300; 23398177400; 57282601800|Deep learning-based automated characterization of crosscut tests for coatings via image segmentation|2022|Journal of Coatings Technology and Research|19|2||671|683|12|7|10.1007/s11998-021-00557-y|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121396892&doi=10.1007%2fs11998-021-00557-y&partnerID=40&md5=ca37f08010b73011f0107641d10ff598|A manual scratch test to measure the scratch resistance of coatings applied to a certain substrate is usually used to test the adhesion of a coating. Despite its significant amount of subjectivity, the crosscut test is widely considered to be the most practical measuring method for adhesion strength with a good reliability. Intelligent software tools help to improve and optimize systems combining chemistry, engineering based on high-throughput formulation screening (HTFS) technologies and machine learning algorithms to open up novel solutions in material sciences. Nevertheless, automated testing often misses the link to quality control by the human eye that is sensitive in spotting and evaluating defects as it is the case in the crosscut test. In this paper, we present a method for the automated and objective characterization of coatings to drive and support Chemistry 4.0 solutions via semantic image segmentation using deep convolutional networks. The algorithm evaluated the adhesion strength based on the images of the crosscuts recognizing the delaminated area and the results were compared with the traditional classification rated by the human expert. © 2021, The Author(s).|Characterization; Chemistry 4.0; Coating; Crosscut test; Deep learning; Image segmentation; Surface integrity|Adhesion; Automation; Bond strength (materials); Deep learning; Learning algorithms; Quality control; Semantic Segmentation; Semantics; Testing; Characterization; Chemistry 4.0; Crosscut test; Deep learning; Images segmentations; Intelligent software tools; Measuring method; Scratch resistance; Scratch test; Surface integrity; Coatings|Article|Final|All Open Access; Hybrid Gold Open Access|Scopus|2-s2.0-85121396892
scopus|Yahmed A.H.; Braiek H.B.; Khomh F.; Bouzidi S.; Zaatour R.|Yahmed, Ahmed Haj (57797481700); Braiek, Houssem Ben (57203412343); Khomh, Foutse (24724747600); Bouzidi, Sonia (57203592238); Zaatour, Rania (57194108078)|57797481700; 57203412343; 24724747600; 57203592238; 57194108078|DiverGet: a Search-Based Software Testing approach for Deep Neural Network Quantization assessment|2022|Empirical Software Engineering|27|7|193||||5|10.1007/s10664-022-10202-w|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139828074&doi=10.1007%2fs10664-022-10202-w&partnerID=40&md5=9482c7c9eef0478d73a0bbdc9cf06c18|Quantization is one of the most applied Deep Neural Network (DNN) compression strategies, when deploying a trained DNN model on an embedded system or a cell phone. This is owing to its simplicity and adaptability to a wide range of applications and circumstances, as opposed to specific Artificial Intelligence (AI) accelerators and compilers that are often designed only for certain specific hardware (e.g., Google Coral Edge TPU). With the growing demand for quantization, ensuring the reliability of this strategy is becoming a critical challenge. Traditional testing methods, which gather more and more genuine data for better assessment, are often not practical because of the large size of the input space and the high similarity between the original DNN and its quantized counterpart. As a result, advanced assessment strategies have become of paramount importance. In this paper, we present DiverGet, a search-based testing framework for quantization assessment. DiverGet defines a space of metamorphic relations that simulate naturally-occurring distortions on the inputs. Then, it optimally explores these relations to reveal the disagreements among DNNs of different arithmetic precision. We evaluate the performance of DiverGet on state-of-the-art DNNs applied to hyperspectral remote sensing images. We chose the remote sensing DNNs as they’re being increasingly deployed at the edge (e.g., high-lift drones) in critical domains like climate change research and astronomy. Our results show that DiverGet successfully challenges the robustness of established quantization techniques against naturally-occurring shifted data, and outperforms its most recent concurrent, DiffChaser, with a success rate that is (on average) four times higher. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.|Deep Learning; Hyperspectral images; Metamorphic Relations; Quantization assessment; Search-Based Software Testing|Climate change; Image compression; Remote sensing; Software testing; Spectroscopy; Compression strategies; Deep learning; HyperSpectral; Hyperspectral image; Metamorphic relations; Naturally occurring; Network compression; Quantisation; Quantization assessment; Search-based software testing; Deep neural networks|Article|Final|All Open Access|Scopus|2-s2.0-85139828074
scopus|Giamattei L.; Pietrantuono R.; Russo S.|Giamattei, Luca (57889347800); Pietrantuono, Roberto (23135531000); Russo, Stefano (7102994111)|57889347800; 23135531000; 7102994111|Reasoning-Based Software Testing|2023|Proceedings - International Conference on Software Engineering||||66|71|5|2|10.1109/ICSE-NIER58687.2023.00018|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172069503&doi=10.1109%2fICSE-NIER58687.2023.00018&partnerID=40&md5=f330454ba07dca289a1b1e9763511632|With software systems becoming increasingly pervasive and autonomous, our ability to test for their quality is severely challenged. Many systems are called to operate in uncertain and highly-changing environment, not rarely required to make intelligent decisions by themselves. This easily results in an intractable state space to explore at testing time. The state-of-the-art techniques try to keep the pace, e.g., by augmenting the tester’s intuition with some form of (explicit or implicit) learning from observations to search this space efficiently. For instance, they exploit historical data to drive the search (e.g., ML-driven testing) or the tests execution data itself (e.g., adaptive or search-based testing). Despite the indubitable advances, the need for smartening the search in such a huge space keeps to be pressing. We introduce Reasoning-Based Software Testing (RBST), a new way of thinking at the testing problem as a causal reasoning task. Compared to mere intuition-based or state-of-the-art learning-based strategies, we claim that causal reasoning more naturally emulates the process that a human would do to “smartly” search the space. RBST aims to mimic and amplify, with the power of computation, this ability. The conceptual leap can pave the ground to a new trend of techniques, which can be variously instantiated from the proposed framework, by exploiting the numerous tools for causal discovery and inference. Preliminary results reported in this paper are promising. © 2023 IEEE Computer Society. All rights reserved.|Causal reasoning, Software Testing|Digital storage; Causal reasoning; Causal reasoning, software testing; Changing environment; Explicit learning; Intelligent decisions; Software testings; Software-systems; State-of-the-art techniques; State-space; Testing time; Software testing|Conference paper|Final|All Open Access; Green Open Access|Scopus|2-s2.0-85172069503
scopus|Arrieta A.|Arrieta, Aitor (56514865400)|56514865400|Multi-objective metamorphic follow-up test case selection for deep learning systems|2022|GECCO 2022 - Proceedings of the 2022 Genetic and Evolutionary Computation Conference||||1327|1335|8|10|10.1145/3512290.3528697|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135239089&doi=10.1145%2f3512290.3528697&partnerID=40&md5=247627f3e4256dab8275e16bc1bbaa7b|Deep Learning (DL) components are increasing their presence in safety and mission-critical software systems. To ensure a high dependability of DL systems, robust verification methods are required, for which automation is highly beneficial (e.g., more test cases can be executed). Metamorphic Testing (MT) is a technique that has shown to alleviate the test oracle problem when testing DL systems, and therefore, increasing test automation. However, a drawback of this technique lies into the need of multiple test executions to obtain the test verdict (named as the source and the follow-up test cases), requiring additional testing cost. In this paper we propose an approach based on multi-objective search to select follow-up test cases. Our approach makes use of source test cases to measure the uncertainty provoked by such test inputs in the DL model, and based on that, select failure-revealing follow-up test cases. We integrate our approach with the NSGA-II algorithm. An empirical evaluation on three DL models tackling the image classification problem, along with five different metamorphic relations demonstrates that our approach outperformed the baseline algorithm between 17.09 to 59.20% on average when considering the revisited Hypervolume quality indicator.  © 2022 ACM.|Deep Learning Systems; Metamorphic Testing; Multi-Objective search; Test Case Selection|Deep learning; Testing; Deep learning system; Follow up; Learning models; Metamorphic testing; Mission critical softwares; Multi objective; Multi-objective search; Safety critical software; Test case; Test case selection; Learning systems|Conference paper|Final||Scopus|2-s2.0-85135239089
scopus|Li Z.; Wang C.; Liu Z.; Wang H.; Chen D.; Wang S.; Gao C.|Li, Zongjie (57221598146); Wang, Chaozheng (57219285770); Liu, Zhibo (57218364577); Wang, Haoxuan (57849500200); Chen, Dong (58046110600); Wang, Shuai (57190181124); Gao, Cuiyun (57189036288)|57221598146; 57219285770; 57218364577; 57849500200; 58046110600; 57190181124; 57189036288|CCTEST: Testing and Repairing Code Completion Systems|2023|Proceedings - International Conference on Software Engineering||||1238|1250|12|35|10.1109/ICSE48619.2023.00110|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163941249&doi=10.1109%2fICSE48619.2023.00110&partnerID=40&md5=43b7e845ba21fcdd3d967372d76f266c|Code completion, a highly valuable topic in the software development domain, has been increasingly promoted for use by recent advances in large language models (LLMs). To date, visible LLM-based code completion frameworks such as GitHub Copilot and GPT are trained using deep learning over vast quantities of unstructured text and open source code. As the paramount component and the cornerstone in daily programming tasks, code completion has largely boosted professionals' efficiency in building real-world software systems. In contrast to this flourishing market, we find that code completion systems often output suspicious results, and to date, an automated testing and enhancement framework for code completion systems is not available. This research proposes CCTEST, a framework to test and repair code completion systems in black-box settings. CCTEST features a set of novel mutation strategies, namely program structure-consistent (PSC) mutations, to generate mutated code completion inputs. Then, it detects inconsistent outputs, representing possibly erroneous cases, from all the completed code cases. Moreover, CCTEST repairs the code completion outputs by selecting the output that mostly reflects the 'average' appearance of all output cases, as the final output of the code completion systems. With around 18K test inputs, we detected 33,540 inputs that can trigger erroneous cases (with a true positive rate of 86%) from eight popular LLM-based code completion systems. With repairing, we show that the accuracy of code completion systems is notably increased by 40% and 67% with respect to BLEU score and Levenshtein edit similarity. © 2023 IEEE.||Codes (symbols); Deep learning; Open systems; Repair; Software design; Code completions; In-buildings; Language model; Model-based OPC; Open-source code; Programming tasks; Real-world; Software-systems; Text sources; Unstructured texts; Open source software|Conference paper|Final|All Open Access; Green Open Access|Scopus|2-s2.0-85163941249
scopus|Lee E.; Gong J.; Cao Q.|Lee, Eric (58630283100); Gong, Jiayu (57221535110); Cao, Qinghong (58630708100)|58630283100; 57221535110; 58630708100|Object Oriented BDD and Executable Human-Language Module Specification|2023|2023 26th ACIS International Winter Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing, SNPD-Winter 2023||||127|133|6|1|10.1109/SNPD-Winter57765.2023.10223873|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173089442&doi=10.1109%2fSNPD-Winter57765.2023.10223873&partnerID=40&md5=6138c3b0131baee40ecd525b72ec61bc|This paper presents an approach to software development which uses a generative AI Model as compiler to translate human language requirements into high-level programming language. We propose an executable human-language module specification and a tool to support it, which has been used successfully for human-language UI test automation. We anticipate further development of this approach to enable complex software to be programmed in human language, allowing for more intuitive and efficient software development. © 2023 IEEE.|BDD; Generative AI; GPT; HLP (Human Language Programming); LLM (Large Language Model); OOBDD (Object-oriented Behavior Driven Development); SDD (Specification Driven Development)|Boolean functions; High level languages; Object oriented programming; Program compilers; Software design; BDD; Generative AI; GPT; Human language; Human language programming; Language model; Large language model; Object oriented; Object-oriented behavior driven development; Specification driven development; Specifications|Conference paper|Final||Scopus|2-s2.0-85173089442
scopus|López- Francos I.G.; Mitchell S.C.; Lipkis R.; Vlastos P.G.; Mbaye S.; Infeld S.I.|López- Francos, Ignacio G. (57221317243); Mitchell, Sarah C. (59241430300); Lipkis, Rory (57208630551); Vlastos, Pavlo G. (57217305872); Mbaye, Seydou (57829348600); Infeld, Samantha I. (6507857403)|57221317243; 59241430300; 57208630551; 57217305872; 57829348600; 6507857403|A Model-Based Systems Engineering Approach for Developing an Autonomous Rover Testbed|2023|AIAA SciTech Forum and Exposition, 2023|||||||4|10.2514/6.2023-1894|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200167680&doi=10.2514%2f6.2023-1894&partnerID=40&md5=84846df8d5991495741a58dde5bf99e9|As autonomous systems become more prevalent, it is crucial to develop new methods for ensuring their safety. The National Aeronautics and Space Administration (NASA)’s Robust Software Engineering (RSE) group is addressing this need with the development of the Research for Autonomous Vehicles (R-RAV) project, an autonomous rover testbed designed for assured autonomy research. In this paper, we describe how we used a Model-Based Systems Engineering (MBSE) approach to design and build the R-RAV and implemented our first autonomy research mission. The adoption of MBSE has allowed for efficient and data-driven collaboration, and has provided a comprehensive view of the system throughout its development, reducing ambiguity while increasing traceability and productivity. The R-RAV testbed will be used to advance research in assured autonomy, including safe machine learning, automated testing, and formal verification. © 2023, American Institute of Aeronautics and Astronautics Inc, AIAA. All rights reserved.||NASA; Rovers; Automated testing; Autonomous rovers; Autonomous Vehicles; Data driven; Design and build; Machine-learning; Model-based system engineerings; National aeronautic and space administrations; Robust software; Testbeds|Conference paper|Final||Scopus|2-s2.0-85200167680
scopus|Marcolini A.; Bussola N.; Arbitrio E.; Amgad M.; Jurman G.; Furlanello C.|Marcolini, Alessia (57218103187); Bussola, Nicole (57205407123); Arbitrio, Ernesto (57962372700); Amgad, Mohamed (55037269400); Jurman, Giuseppe (6602367398); Furlanello, Cesare (6701821823)|57218103187; 57205407123; 57962372700; 55037269400; 6602367398; 6701821823|histolab: A Python library for reproducible Digital Pathology preprocessing with automated testing|2022|SoftwareX|20||101237||||22|10.1016/j.softx.2022.101237|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141781984&doi=10.1016%2fj.softx.2022.101237&partnerID=40&md5=09d5a5f60a2912d9eab325b704f61f8a|Deep Learning (DL) is rapidly permeating the field of Digital Pathology with algorithms successfully applied to ease daily clinical practice and to discover novel associations. However, most DL workflows for Digital Pathology include custom code for data preprocessing, usually tailored to data and tasks of interest, resulting in software that is error-prone and hard to understand, peer-review, and test. In this work, we introduce histolab, a Python package designed to standardize the preprocessing of Whole Slide Images in a reproducible environment, supported by automated testing. In addition, the package provides functions for building datasets of WSI tiles, including augmentation and morphological operators, a tile scoring framework, and stain normalization methods. histolab is modular, extensible, and easily integrable into DL pipelines, with support of the OpenSlide and large_image backends. To guarantee robustness, histolab embraces software engineering best practices such as multiplatform automated testing and Continuous Integration. © 2022 The Author(s)|Continuous integration; Data preprocessing; Deep Learning; Digital Pathology; Reproducibility|Automation; Deep learning; Digital libraries; E-learning; High level languages; Integration testing; Pathology; Automated testing; Clinical practices; Continuous integrations; Data preprocessing; Deep learning; Digital pathologies; Error prones; Novel associations; Reproducibilities; Work-flows; Python|Article|Final|All Open Access; Gold Open Access|Scopus|2-s2.0-85141781984
scopus|Fadhlurrohman D.H.; Sabariah M.K.; Alibasa M.J.; Husen J.H.|Fadhlurrohman, Daffa Hilmy (58636870200); Sabariah, Mira Kania (56502148700); Alibasa, Muhammad Johan (57201859953); Husen, Jati Hiliamsyah (57207911799)|58636870200; 56502148700; 57201859953; 57207911799|Naive Bayes Classification Model for Precondition-Postcondition in Software Requirements|2023|2023 International Conference on Data Science and Its Applications, ICoDSA 2023||||123|128|5|0|10.1109/ICoDSA58501.2023.10277397|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175653581&doi=10.1109%2fICoDSA58501.2023.10277397&partnerID=40&md5=23f37b1359afbe3c249609b31470f3c6|The quality of a test case primarily depends on the software requirements. However, manually identifying crucial elements like preconditions and post-conditions within software requirements can be time-consuming and labor-intensive. This challenge has prompted a research study to propose a novel approach for test case generation using text classification. The proposed approach involves categorizing software requirements into two labels: 'none' and 'both.' These labels indicate the presence or absence of preconditions and post-conditions in software requirements. To achieve this, the research employs the Naive Bayes algorithm, a widely used probabilistic classification algorithm in text classification tasks. The algorithm leverages two libraries, namely Scikit-learn and Natural Language Toolkit (NLTK). The Scikit-learn model proves quite effective through experimentation, achieving an impressive accuracy score of 0.86. This result demonstrates the feasibility of reducing the effort and time required for classifying test case components based on software requirements. By automating this process, the proposed approach offers a promising route for enhancing the efficiency and effectiveness of test case generation in software testing. By leveraging text classification and machine learning techniques, the proposed approach not only streamlines the identification of essential components in software requirements but also opens up possibilities for further automation and optimization of the testing process.  © 2023 IEEE.|natural language preprocessing; requirements; test case classification; text classification|Classification (of information); Computer software selection and evaluation; Learning systems; Machine components; Natural language processing systems; Requirements engineering; Condition; Learn+; Natural language preprocessing; Natural languages; Requirement; Software requirements; Test case; Test case classification; Test case generation; Text classification; Software testing|Conference paper|Final||Scopus|2-s2.0-85175653581
scopus|Isaku E.; Sartaj H.; Laaber C.; Yue T.; Ali S.; Schwitalla T.; Nygard J.F.|Isaku, Erblin (58666577400); Sartaj, Hassan (57208630782); Laaber, Christoph (57194171758); Yue, Tao (25651096400); Ali, Shaukat (56962801700); Schwitalla, Thomas (57193757105); Nygard, Jan F. (7003875061)|58666577400; 57208630782; 57194171758; 25651096400; 56962801700; 57193757105; 7003875061|Cost Reduction on Testing Evolving Cancer Registry System|2023|Proceedings - 2023 IEEE International Conference on Software Maintenance and Evolution, ICSME 2023||||508|518|10|3|10.1109/ICSME58846.2023.00065|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171360954&doi=10.1109%2fICSME58846.2023.00065&partnerID=40&md5=f9073ff69c0d7f3994baa4ad4d1bb29b|The Cancer Registration Support System (CaReSS), built by the Cancer Registry of Norway (CRN), is a complex real-world socio-technical software system that undergoes continuous evolution in its implementation. Consequently, continuous testing of CaReSS with automated testing tools is needed such that its dependability is always ensured. Towards automated testing of a key software subsystem of CaReSS, i.e., GURI, we present a real-world application of an extension to the open-source tool EvoMaster, which automatically generates test cases with evolutionary algorithms. We named the extension EvoClass, which enhances EvoMaster with a machine learning classifier to reduce the overall testing cost. This is imperative since testing with EvoMaster involves sending many requests to GURI deployed in different environments, including the production environment, whose performance and functionality could potentially be affected by many requests. The machine learning classifier of EvoClass can predict whether a request generated by EvoMaster will be executed successfully or not; if not, the classifier filters out such requests, consequently reducing the number of requests to be executed on GURI. We evaluated EvoClass on ten GURI versions over four years in three environments: development, testing, and production. Results showed that EvoClass can significantly reduce the testing cost of evolving GURI without reducing testing effectiveness (measured as rule coverage) across all three environments, as compared to the default EvoMaster. Overall, EvoClass achieved ≈31% of overall cost reduction. Finally, we report our experiences and lessons learned that are equally valuable for researchers and practitioners. © 2023 IEEE.|Machine Learning; Software Evolution; Testing|Application programs; Diseases; Machine learning; Open source software; Open systems; Software testing; Cancer registries; Costs reduction; Learning classifiers; Machine-learning; Real-world; Sociotechnical; Software Evolution; Software-systems; Support systems; Testing costs; Cost reduction|Conference paper|Final|All Open Access; Green Open Access|Scopus|2-s2.0-85171360954
scopus|Li S.-H.; Zhou G.; Li Z.-B.; Lu J.-C.; Huang N.-B.|Li, Shun-Hang (57556771100); Zhou, Gang (57222222786); Li, Zhi-Bo (55707022000); Lu, Ji-Cang (35731595000); Huang, Ning-Bo (57223006781)|57556771100; 57222222786; 55707022000; 35731595000; 57223006781|The Causal Reasoning Ability of Open Large Language Model: A Comprehensive and Exemplary Functional Testing|2023|IEEE International Conference on Software Quality, Reliability and Security, QRS||||240|249|9|5|10.1109/QRS60937.2023.00032|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182519704&doi=10.1109%2fQRS60937.2023.00032&partnerID=40&md5=ad865a917913aa2f9ecfcdf2ea6b69e1|As the intelligent software, the development and application of large language models are extremely hot topics recently, bringing tremendous changes to general AI and software industry. Nonetheless, large language models, especially open source ones, incontrollably suffer from some potential software quality issues such as instability, inaccuracy, and insecurity, making software testing necessary. In this paper, we propose the first solution for functional testing of open large language models to check full-scene availability and conclude empirical principles for better steering large language models, particularly considering their black box and intelligence properties. Specifically, we focus on the model's causal reasoning ability, which is the core of artificial intelligence but almost ignored by most previous work. First, for comprehensive evaluation, we deconstruct the causal reasoning capability into five dimensions and summary the forms of causal reasoning task as causality identification and causality matching. Then, rich datasets are introduced and further modified to generate test cases along with different ability dimensions and task forms to improve the testing integrity. Moreover, we explore the ability boundary of open large language models in two usage modes: prompting and lightweight fine-tuning. Our work conducts comprehensive functional testing on the causal reasoning ability of open large language models, establishes benchmarks, and derives empirical insights for practical usage. The proposed testing solution can be transferred to other similar evaluation tasks as a general framework for large language models or their derivations.  © 2023 IEEE.|black-box testing; causal reasoning; lightweight fine-tuning; open large language model; prompt design|Application programs; Computational linguistics; Computer software selection and evaluation; Open source software; Open systems; Causal reasoning; Development and applications; Fine tuning; Functional testing; Intelligent software; Language model; Lightweight fine-tuning; Open large language model; Prompt design; Reasoning ability; Black-box testing|Conference paper|Final||Scopus|2-s2.0-85182519704
scopus|Jalil S.; Rafi S.; Latoza T.D.; Moran K.; Lam W.|Jalil, Sajed (58109615000); Rafi, Suzzana (57215138802); Latoza, Thomas D. (16230457100); Moran, Kevin (57095532500); Lam, Wing (56879749600)|58109615000; 57215138802; 16230457100; 57095532500; 56879749600|ChatGPT and Software Testing Education: Promises & Perils|2023|Proceedings - 2023 IEEE 16th International Conference on Software Testing, Verification and Validation Workshops, ICSTW 2023||||430|437|7|159|10.1109/ICSTW58534.2023.00078|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163136873&doi=10.1109%2fICSTW58534.2023.00078&partnerID=40&md5=a2834eaacaaf7ddfd6590f9b3d9c759e|"Over the past decade, predictive language modeling for code has proven to be a valuable tool for enabling new forms of automation for developers. More recently, we have seen the ad-vent of general purpose ""large language models"", based on neural transformer architectures, that have been trained on massive datasets of human written text, which includes code and natural language. However, despite the demonstrated representational power of such models, interacting with them has historically been constrained to specific task settings, limiting their general applicability. Many of these limitations were recently overcome with the introduction of ChatGPT, a language model created by OpenAI and trained to operate as a conversational agent, enabling it to answer questions and respond to a wide variety of commands from end users.The introduction of models, such as ChatGPT, has already spurred fervent discussion from educators, ranging from fear that students could use these AI tools to circumvent learning, to excitement about the new types of learning opportunities that they might unlock. However, given the nascent nature of these tools, we currently lack fundamental knowledge related to how well they perform in different educational settings, and the potential promise (or danger) that they might pose to traditional forms of instruction. As such, in this paper, we examine how well ChatGPT performs when tasked with answering common questions in a popular software testing curriculum. We found that given its current capabilities, ChatGPT is able to respond to 77.5% of the questions we examined and that, of these questions, it is able to provide correct or partially correct answers in 55.6% of cases, provide correct or partially correct explanations of answers in 53.0% of cases, and that prompting the tool in a shared question context leads to a marginally higher rate of correct answers and explanations. Based on these findings, we discuss the potential promises and perils related to the use of ChatGPT by students and instructors. © 2023 IEEE."|case study; ChatGPT; education; testing|Codes (symbols); Computational linguistics; Curricula; Education computing; Large dataset; Modeling languages; Natural language processing systems; Statistical tests; Students; Well testing; Case-studies; ChatGPT; Code languages; Language model; Massive data sets; Model-based OPC; Natural languages; New forms; Software testings; Written texts; Software testing|Conference paper|Final|All Open Access; Green Open Access|Scopus|2-s2.0-85163136873
scopus||||Proceedings of the 13th International Conference on Cloud Computing, Data Science and Engineering, Confluence 2023|2023|Proceedings of the 13th International Conference on Cloud Computing, Data Science and Engineering, Confluence 2023||||||752|0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149582430&partnerID=40&md5=884f3bb987255309ad90efabb9517fa7|The proceedings contain 103 papers. The topics discussed include: COVID-19 prevention melioration: face mask and social distancing detection; software complexity reduction through the process automation in software development life cycle; a secured quantum key exchange algorithm using Fermat numbers and DNA encoding; visual malware classification using transfer learning; an authentication algorithm for mitigating dos attacks in wireless body sensor networks; animal breed classification and prediction using convolutional neural network primates as a case study; cataloguing of coronary heart malady using machine learning algorithms; security against SSDF attacks using novel attack mitigation mechanism for cognitive radio networks; design of medi-chain: a blockchain and cloud based health record system; an overview of relevant literature on different approaches to word sense disambiguation; construction of reverse logistics network of waste electrical appliances; text-based image retrieval using captioning; and test evaluation metrics and test case prioritization in the dynamics of software testing.|||Conference review|Final||Scopus|2-s2.0-85149582430
scopus|Kampel L.; Simos D.E.; Kuhn D.R.; Kacker R.N.|Kampel, Ludwig (57191694231); Simos, Dimitris E. (15835741900); Kuhn, D. Richard (55666229700); Kacker, Raghu N. (6603751138)|57191694231; 15835741900; 55666229700; 6603751138|An exploration of combinatorial testing-based approaches to fault localization for explainable AI|2022|Annals of Mathematics and Artificial Intelligence|90|7-9||951|964|13|6|10.1007/s10472-021-09772-0|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115190796&doi=10.1007%2fs10472-021-09772-0&partnerID=40&md5=5fe30bc54875835257ab3542486c2cdd|We briefly review properties of explainable AI proposed by various researchers. We take a structural approach to the problem of explainable AI, examine the feasibility of these aspects and extend them where appropriate. Afterwards, we review combinatorial methods for explainable AI which are based on combinatorial testing-based approaches to fault localization. Last, we view the combinatorial methods for explainable AI through the lens provided by the properties of explainable AI that are elaborated in this work. We pose resulting research questions that need to be answered and point towards possible solutions, which involve a hypothesis about a potential parallel between software testing, human cognition and brain capacity. © 2021, The Author(s), under exclusive licence to Springer Nature Switzerland AG.|AI; Combinatorial testing; Explainable AI; Fault localization||Article|Final||Scopus|2-s2.0-85115190796
scopus|Gerber D.; Kapasiya U.; Rosenbauer L.; Hähner J.|Gerber, Daniel (57226491682); Kapasiya, Urwashi (58701739400); Rosenbauer, Lukas (57218600362); Hähner, Jörg (20436196300)|57226491682; 58701739400; 57218600362; 20436196300|Automation of User Interface Testing by Reinforcement Learning-Based Monkey Agents|2023|Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)|13927 LNCS|||3|15|12|2|10.1007/978-3-031-44355-8_1|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177172630&doi=10.1007%2f978-3-031-44355-8_1&partnerID=40&md5=51e528329223f8b7385ec54be9c5af23|The complexity of Graphical User Interfaces (GUIs) in consumer applications such as home appliances has significantly risen in recent years. For example, the number of different views in the GUIs has increased from simple selection views to complex sub-menu structures. Alongside the development, both testing complexity and cost have risen drastically. A way of handling this increase is test automation by the use of machine learning algorithms. This work focuses on reinforcement learning-based autonomous grey-box monkey testing for consumer GUIs. As a monkey tester, a Deep Q-Network is interacting with the device under test. Experiments are performed on an oven GUI as well as on a desktop training environment. A known feature representation for monkey testing is compared to three alternative representations, as well as a random agent. A careful selection of the feature representation can improve the exploration performance. Empirical results for the autonomous exploration of GUIs show the usefulness of reinforcement learning-based monkey testing over pure random testing on consumer GUIs. This can lead to an efficiency advantage in practice, as pure random testing is often the status quo in many well-known GUI test-frameworks such as Squish. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.|Human Machine Interface; Machine Learning; Monkey Testing; Reinforcement Learning; User Interface Testing|Complex networks; Domestic appliances; Graphical user interfaces; Learning algorithms; Well testing; Consumer applications; Feature representation; Human Machine Interface; Interface testings; Machine-learning; Monkey testing; Random testing; Reinforcement learnings; Simple++; User interface testing; Reinforcement learning|Conference paper|Final||Scopus|2-s2.0-85177172630
scopus||||EASEAI 2022 - Proceedings of the 4th International Workshop on Education through Advanced Software Engineering and Artificial Intelligence, co-located with ESEC/FSE 2022|2022|EASEAI 2022 - Proceedings of the 4th International Workshop on Education through Advanced Software Engineering and Artificial Intelligence, co-located with ESEC/FSE 2022||||||46|0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142930271&partnerID=40&md5=2551cb64fce829e143c2888b0f751e2a|The proceedings contain 6 papers. The topics discussed include: student misconceptions about finite state machines: identify them in order to create a concept inventory; mining sorting concept across curriculum levels: a cyclic learning based approach; a pedagogical approach in interleaving software quality concerns at an artificial intelligence course; findings from teaching entrepreneurship to undergraduate multidisciplinary students: case study; towards automated testing for simple programming exercises; and implementing microlearning and gamification techniques in teaching software project management concepts.|||Conference review|Final||Scopus|2-s2.0-85142930271
scopus|Witte F.|Witte, Frank (58235564100)|58235564100|Strategy, planning and organization of test processes: Basis for successful project execution in software testing|2022|Strategy, Planning and Organization of Test Processes: Basis for Successful Project Execution in Software Testing||||1|256|255|1|10.1007/978-3-658-36981-1|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85157974269&doi=10.1007%2f978-3-658-36981-1&partnerID=40&md5=1ed6e4a49c9577aa2037f533668e7b39|The book provides concrete tips for the successful organization of software tests. Because: Planning and conception in advance are essential for successful test projects. Setting the right course prevents problems from the outset and highlights the need for action in software testing. In addition to theoretical basics, this work shows the implementation in practice and deals with typical problems. Frank Witte explains the decisive aspects to be considered in the test concept in order to optimally support and accompany the test process. This book is a translation of the original German 1st edition Strategie, Planung und Organisation von Testprozessen by Frank Witte, Springer Fachmedien Wiesbaden GmbH, part of Springer Nature in 2020. The translation was done with the help of artificial intelligence (machine translation by the service DeepL.com). A subsequent human revision was done primarily in terms of content, so that the book will read stylistically differently from a conventional translation. Springer Nature works continuously to further the development of tools for the production of books and on the related technologies to support the authors. © Springer Fachmedien Wiesbaden GmbH, part of Springer Nature 2022. All rights reserved.|Project Management; Software testing; Systemtest; Test concept; Test organization; Test planning; Test process; Test strategy||Book|Final||Scopus|2-s2.0-85157974269
scopus|Kaur H.; Kaur A.|Kaur, Harguneet (57188580092); Kaur, Arvinder (57548731500)|57188580092; 57548731500|Predicting Aging Related Bugs with Automated Feature Selection Techniques in Cloud Oriented Softwares|2023|Lecture Notes in Electrical Engineering|1078 LNEE|||217|231|14|0|10.1007/978-981-99-5974-7_19|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177846630&doi=10.1007%2f978-981-99-5974-7_19&partnerID=40&md5=18af127d1c66ed88df089eef56e97d63|Aging related bugs (ARBs) are accumulated errors in the long running software due to memory leakage or unreleased files and locks which result in performance degradation and depletion of re-sources. It is a challenging task to reproduce ARBs in the software during software testing. The prediction of Aging related bugs in software will greatly contribute for software quality assurance team to enhance their testing efforts. In this study, the work is presented on predicting aging related bugs in cloud oriented software with the help of source code metrics and machine learning techniques. High dimensionality and class imbalance are the two technical challenges found in prediction of aging related bugs. This study investigated the application of extracting aging related bug reports from commit content of thousands of bug reports using automated keyword abstraction and the five different feature selection techniques (Random Forest, Logistic Regression, Gradient Boosting Machine (GBM), Extra Tree Classifier, Recursive Feature elimination (RFE)) for dimensionality reduction and SMOTE to deal with the class imbalance problem in our proposed machine learning based approach. Experimental results convey that when SMOTE is applied with feature selection technique then accuracy, recall and precision are among the best performance measures to evaluate prediction. Bagging and Logistic Regression perform better than other machine learning techniques for cloud oriented software in predicting ARBs. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd 2023.|Aging related bugs; Bug prediction; Feature selection technique; Imbalance learning; Machine learning; Metrics|Computer software selection and evaluation; Feature Selection; Logistic regression; Program debugging; Quality assurance; Software testing; Aging-related bugs; Bug predictions; Bug reports; Feature selection technique; Features selection; Imbalance learning; Machine learning techniques; Machine-learning; Metric; Selection techniques; Forecasting|Conference paper|Final||Scopus|2-s2.0-85177846630
scopus|Sanchez-Garcia A.J.; Lopez-Martin C.; Abran A.|Sanchez-Garcia, Angel J. (56486564300); Lopez-Martin, Cuauhtemoc (56002702800); Abran, Alain (7004233119)|56486564300; 56002702800; 7004233119|Gradient Boosting Optimized Through Differential Evolution for Predicting the Testing Effort of Software Projects|2023|IEEE Access|11|||135235|135254|19|3|10.1109/ACCESS.2023.3337809|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179587657&doi=10.1109%2fACCESS.2023.3337809&partnerID=40&md5=f2c77311bd1d55b0620a0d3e6df07665|Software testing (ST) is one of the most important software development life cycle (SDLC) phases and ST effort is often expressed as a percentage of SDLC effort. Unfortunately, in the literature ST effort percentage ranges from 10% to 60%. In the literature most of the machine learning algorithms and metaheuristics for optimizing them have looked at predicting overall SDLC effort without focusing on any specific SDLC phase, including testing. Therefore, this study investigates the application of the Software Testing Effort Prediction (STEP) of Gradient Boosting (GB) machine learning regression algorithm optimized through Differential Evolution (DE). Its prediction accuracy is compared with those obtained when the GB is also optimized through Particle Swarm Optimization (PSO) and Genetic Algorithms (GA). The performance of GB-DE, GB-PSO, and GB-GA was also compared to that of statistical regression (SR). Seven data sets of actual projects were selected from an international public repository for software projects. The results showed that GB-DE was statistically better than SR in all seven data sets at 95% confidence, whereas GB-PSO and GB-GA were better than SR in four and three data sets, respectively. Thus, we can conclude that GB-DE can be used for STEP of either new projects or enhancement projects developed in either the third or fourth programming language generation.  © 2013 IEEE.|differential evolution; genetic algorithms; gradient boosting; ISBSG; particle swarm optimization; Testing effort prediction|Adaptive boosting; Application programs; Forecasting; Life cycle; Machine learning; Particle swarm optimization (PSO); Software design; Software testing; Differential Evolution; Effort prediction; Gradient boosting; ISBSG; Particle swarm; Particle swarm optimization; Software testings; Swarm optimization; Testing effort; Testing effort prediction; Genetic algorithms|Article|Final|All Open Access; Gold Open Access; Green Open Access|Scopus|2-s2.0-85179587657
scopus|Hossain M.; Chen H.|Hossain, Mohammad (24724333800); Chen, Hongkai (57322073300)|24724333800; 57322073300|Application of Machine Learning on Software Quality Assurance and Testing: A Chronological Survey|2022|International Journal of Computers and their Applications|29|3||150|157|7|1||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141711131&partnerID=40&md5=d526a94d14d28f947bdb220a3b3603a7|Ensuring the quality is essential for a successful Software System. Software systems need to be tested in every stage of the Software Development Life Cycle (SDLC) irrespective of the type of software being developed. If a software bug remains undetected in the early phase of the SDLC, it becomes harder to fix it at a later stage and becomes very costly. The application of machine learning in Software Quality Assurance and Testing can help testers in the testing process, including the early detection and prediction of a software bug. However, employing machine learning techniques brings new challenges to testing and quality assurance. Machine Learning (ML) uses Artificial Intelligence (AI) techniques that focus on a given dataset to find any trend present in the data. It has been observed that some software testing activities can, in fact, be represented as a learning problem. Thus, ML can be used as an efficient tool to automate software-testing activities, especially when the software system becomes very complex. This survey aims to study and summarize the application of machine learning on software quality assurance and testing in a chronological manner by selecting from articles published in the last twenty-six years or so. © ISCA.|artificial intelligence; chronological survey; machine learning; neural network; Software quality assurance and testing; support vector machine||Article|Final||Scopus|2-s2.0-85141711131
scopus|Anithakrishna G.; Mohankumar M.|Anithakrishna, G. (57562211000); Mohankumar, M. (57205467903)|57562211000; 57205467903|Analysing the Energy Value of GPU and Spoting the Energy Hungry Area in the Software Testing Scripts|2022|International Journal of Engineering Trends and Technology|7|10||277|284|7|0|10.14445/22315381/IJETT-V70I10P227|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140931783&doi=10.14445%2f22315381%2fIJETT-V70I10P227&partnerID=40&md5=32f2d38f8636a81f5bd8f9d26bd9e20d|Nowadays, the Graphic Processing Unit, GPU become a pronounced tool for individual and business computing. GPU plays a great role in a wide range of areas like parallel processing, video rendering, graphics, gaming and artificial intelligence. This work analyses the performance and energy efficiency of designing manual and automated scripts for game development and prominent video and graphics applications. These days' software games have prolonged lifetimes and have many patches and releases compared to the olden days. Nowadays green concept has a very important role in developing efficient software. Software development is cognate with different phases, which include a broad range of activities. Software metrics are some techniques that enable the analysis of code and its improvement. A powerful Graphic Processing Unit is compulsory for executing upscale games and applications that use 3D and video editing. This paper aspires to monitor GPU's performance and power concern for video rendering and game development and to spot the energy-hoggish area in the script using the thread concept. © 2022 Seventh Sense Research Group®|Energy efficiency; GPU; Green IT; Green software; Software Testing; Sustainability||Article|Final||Scopus|2-s2.0-85140931783
scopus|Durán F.; Martínez-Fernández S.; Felderer M.; Franch X.|Durán, Francisco (57815203600); Martínez-Fernández, Silverio (55363648100); Felderer, Michael (24832720900); Franch, Xavier (6603081752)|57815203600; 55363648100; 24832720900; 6603081752|Guiding the retraining of convolutional neural networks against adversarial inputs|2023|PeerJ Computer Science|9||e1454||||0|10.7717/peerj-cs.1454|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170279828&doi=10.7717%2fpeerj-cs.1454&partnerID=40&md5=d4c2a242541f2a6cf4f13513677b1922|Background: When using deep learning models, one of the most critical vulnerabilities is their exposure to adversarial inputs, which can cause wrong decisions (e.g., incorrect classification of an image) with minor perturbations. To address this vulnerability, it becomes necessary to retrain the affected model against adversarial inputs as part of the software testing process. In order to make this process energy efficient, data scientists need support on which are the best guidance metrics for reducing the adversarial inputs to create and use during testing, as well as optimal dataset configurations. Aim: We examined six guidance metrics for retraining deep learning models, specifically with convolutional neural network architecture, and three retraining configurations. Our goal is to improve the convolutional neural networks against the attack of adversarial inputs with regard to the accuracy, resource utilization and execution time from the point of view of a data scientist in the context of image classification. Method: We conducted an empirical study using five datasets for image classification. We explore: (a) the accuracy, resource utilization, and execution time of retraining convolutional neural networks with the guidance of six different guidance metrics (neuron coverage, likelihood-based surprise adequacy, distancebased surprise adequacy, DeepGini, softmax entropy and random), (b) the accuracy and resource utilization of retraining convolutional neural networks with three different configurations (one-step adversarial retraining, adversarial retraining and adversarial fine-tuning). Results: We reveal that adversarial retraining from original model weights, and by ordering with uncertainty metrics, gives the best model w.r.t. accuracy, resource utilization, and execution time. Conclusions: Although more studies are necessary, we recommend data scientists use the above configuration and metrics to deal with the vulnerability to adversarial inputs of deep learning models, as they can improve their models against adversarial inputs without using many inputs and without creating numerous adversarial inputs. We also show that dataset size has an important impact on the results. © Copyright 2023 Durán et al.|Adversarial inputs; Deep learning; Green AI; Neural networks; Software testing|Classification (of information); Convolution; Deep learning; Energy efficiency; Image classification; Image enhancement; Learning systems; Network architecture; Software testing; Statistical tests; Well testing; Adversarial input; Convolutional neural network; Deep learning; Green AI; Images classification; Learning models; Neural-networks; Resources utilizations; Software testings; Testing process; Convolutional neural networks|Article|Final|All Open Access; Gold Open Access; Green Open Access|Scopus|2-s2.0-85170279828
scopus|Abaei G.; Tah W.Z.; Toh J.Z.W.; Hor E.S.J.|Abaei, Golnoush (56040055100); Tah, Wen Zhong (57751212000); Toh, Jason Zhern Wee (57751469900); Hor, Ethan Sheng Jian (57750451300)|56040055100; 57751212000; 57751469900; 57750451300|Improving software fault prediction in imbalanced datasets using the under-sampling approach|2022|ACM International Conference Proceeding Series||||41|47|6|4|10.1145/3524304.3524310|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132311509&doi=10.1145%2f3524304.3524310&partnerID=40&md5=e96f10bab5e4a6325d8bbf722ddad963|To make most software defect-free, a considerable amount of budget needs to be allocated to the software testing phase. As each day goes by, this budget slowly rises, as most software grows in size and complexity, which causes an issue for specific companies that cannot allocate sufficient resources towards testing. To tackle this, many researchers use machine learning methods to create software fault prediction models that can help detect defect-prone modules so that resources can be allocated more efficiently during testing. Although this is a feasible plan, the effectiveness of these machine learning models also depends on a few factors, such as the issue of data imbalance. There are many known techniques in class imbalance research that can potentially improve the performance of prediction models through processing the dataset before providing it as input. However, not all methods are compatible with one another. Before building a prediction model, the dataset undergoes the preprocessing step, the under-sampling, and the feature selection process. This study uses an under-sampling process by employing the Instance Hardness Threshold (IHT), which reduces the number of data present in the majority class. The performance of the proposed approach is evaluated based on eight machine learning algorithms by applying it to eight moderate and highly imbalanced NASA datasets. The results of our proposed approach show improvement in AUC and F1-Score by 33% and 26%, respectively, compared to other research work in some datasets.  © 2022 ACM.|Imbalanced Dataset; Software Fault Prediction; Testing; Under-sampling|Budget control; Defects; Forecasting; Learning algorithms; Machine learning; NASA; Statistical tests; Defect-free; Imbalanced dataset; Machine learning methods; Performance; Prediction modelling; Software defects; Software fault prediction; Software testings; Testing phase; Under-sampling; Software testing|Conference paper|Final||Scopus|2-s2.0-85132311509
scopus|De Jesús Dominguez-García A.; Limón X.; Ocharán-Hernández J.O.; Pérez-Arriaga J.C.|De Jesús Dominguez-García, Antonio (59214119700); Limón, Xavier (56031249200); Ocharán-Hernández, Jorge Octavio (57207874836); Pérez-Arriaga, Juan Carlos (55575620500)|59214119700; 56031249200; 57207874836; 55575620500|Security Testing for Web Applications: A Systematic Literature Review|2023|Proceedings - 2023 11th International Conference in Software Engineering Research and Innovation, CONISOFT 2023||||82|91|9|0|10.1109/CONISOFT58849.2023.00020|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198229038&doi=10.1109%2fCONISOFT58849.2023.00020&partnerID=40&md5=60ab38ee381064c9955355cc70d94fe5|As the use of the Internet grows, the number and relevance of web applications have also grown, being an integral part of many sectors and businesses. However this growth has adverse effects in the form of increased security threats. Given the large number of current vulnerabilities and the wide variety of testing techniques and tools used to find vulnerabilities, it becomes complex for software developers and application testers to select the proper tools and techniques to test potential threats. This paper aims to collect and classify current security-oriented software testing tools, techniques, and security development models for web systems. According to the STRIDE threat model, our, classification considers software development activities, and associated security threats. To accomplish our goal, we conducted a systematic literature review (SLR), from 2017 to 2022. We identified 18 software testing techniques, 88 tools and four secure development processes, methodologies or models. We found a great variety of tools and techniques, from traditional penetration testing to state-of-the-art Artificial Intelligence supported tools, and we associate different threats found with their respectively testing techniques and STRIDE classification. We believe that our work serves as a foundation for software testers to select proper and modern techniques, tools, and security models, processes or methodologies related to security testing, in accordance with their threat analysis, potentially improving their security testing for web systems.  © 2023 IEEE.|Security; Software testing; Systematic literature review; Web application|Application programs; Security systems; Software design; Websites; Security; Security testing; Security threats; Software testings; Systematic literature review; Testing technique; Testing tools; Tools and techniques; WEB application; Web applications; Software testing|Conference paper|Final||Scopus|2-s2.0-85198229038
scopus|Lehman S.M.; Alrumayh A.S.; Kolhe K.; Ling H.; Tan C.C.|Lehman, Sarah M. (57195073448); Alrumayh, Abrar S. (57212228056); Kolhe, Kunal (57822003400); Ling, Haibin (57191091290); Tan, Chiu C. (18234201800)|57195073448; 57212228056; 57822003400; 57191091290; 18234201800|Hidden in Plain Sight: Exploring Privacy Risks of Mobile Augmented Reality Applications|2022|ACM Transactions on Privacy and Security|25|4|26||||16|10.1145/3524020|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135088589&doi=10.1145%2f3524020&partnerID=40&md5=f8305b019eb6d0add713bc2438e2cc62|Mobile augmented reality systems are becoming increasingly common and powerful, with applications in such domains as healthcare, manufacturing, education, and more. This rise in popularity is thanks in part to the functionalities offered by commercially available vision libraries such as ARCore, Vuforia, and Google's ML Kit; however, these libraries also give rise to the possibility of a hidden operations threat, that is, the ability of a malicious or incompetent application developer to conduct additional vision operations behind the scenes of an otherwise honest AR application without alerting the end-user. In this article, we present the privacy risks associated with the hidden operations threat and propose a framework for application development and runtime permissions targeted specifically at preventing the execution of hidden operations. We follow this with a set of experimental results, exploring the feasibility and utility of our system in differentiating between user-expectation-compliant and non-compliant AR applications during runtime testing, for which preliminary results demonstrate accuracy of up to 71%. We conclude with a discussion of open problems in the areas of software testing and privacy standards in mobile AR systems. © 2022 Association for Computing Machinery.|Augmented reality; mobile system security; user privacy|Libraries; mHealth; Software testing; AR application; Augmented reality applications; Augmented reality systems; Healthcare manufacturing; Mobile augmented reality; Mobile system security; Mobile systems; Privacy risks; System security; User privacy; Augmented reality|Article|Final||Scopus|2-s2.0-85135088589
scopus|Krishna V.V.; Gopinath G.|Krishna, V. Vamsi (57223387407); Gopinath, G. (59351227100)|57223387407; 59351227100|AGILE TEST AUTOMATION FOR WEB APPLICATION USING TESTNG FRAMEWORK WITH RANDOM INTEGRATION ALGORITHM IN MACHINE LEARNING TO PREDICT ACCURACY AND RESPONSE TIME ON AUTOMATED TEST RESULTS|2022|Journal of Theoretical and Applied Information Technology|100|16||4909|4917|8|1||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138829618&partnerID=40&md5=4d98a7c2775c5065dbb49fdb61893d5a|"""Testing"" must be a part of any software engineering approach that intends to build high-quality apps. By executing it with input values, testing seeks to find faults in the tested-object and develop confidence in its proper functioning. Web apps take first place in development and testing, according to everyday usage. By automating the entire software development testing process, testing automation saves time and money for developers and testers. Our proposed solution would use the ""TestNG framework,"" an automated testing framework, to test a public website and save the test results in the format of a "".csv"" or "".xls"" file to a given directory. The Support-Vector-Machine Algorithm (SVM), Random-Forest Algorithm & other machine-learning algorithmshave been used to analyses the output file. The outcomes of all of the different ways will be compared and displayed on a graph. By Automating The Testing Framework Manual Testing Task Will Become Easy. © 2022 Little Lion Scientific"|Random Forest Algorithm; Random Integration Algorithm; SVM; Test Automation; TestNGFramework; Web Applications||Article|Final||Scopus|2-s2.0-85138829618
scopus|Herbold S.; Haar T.|Herbold, Steffen (35226400600); Haar, Tobias (57221150560)|35226400600; 57221150560|Smoke testing for machine learning: simple tests to discover severe bugs|2022|Empirical Software Engineering|27|2|45||||10|10.1007/s10664-021-10073-7|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123572240&doi=10.1007%2fs10664-021-10073-7&partnerID=40&md5=8ef3d773a2c5c02153a1e4dc7c30e6ad|Machine learning is nowadays a standard technique for data analysis within software applications. Software engineers need quality assurance techniques that are suitable for these new kinds of systems. Within this article, we discuss the question whether standard software testing techniques that have been part of textbooks since decades are also useful for the testing of machine learning software. Concretely, we try to determine generic and simple smoke tests that can be used to assert that basic functions can be executed without crashing. We found that we can derive such tests using techniques similar to equivalence classes and boundary value analysis. Moreover, we found that these concepts can also be applied to hyperparameters, to further improve the quality of the smoke tests. Even though our approach is almost trivial, we were able to find bugs in all three machine learning libraries that we tested and severe bugs in two of the three libraries. This demonstrates that common software testing techniques are still valid in the age of machine learning and that considerations how they can be adapted to this new context can help to find and prevent severe bugs, evenin mature machine learning libraries. © 2022, The Author(s).|Boundary-value analysis; Classification; Combinatorial testing; Equivalence classes; Machine learning; Smoke testing; Software testing|Application programs; Equivalence classes; Machine learning; Program debugging; Quality assurance; Smoke; Testing; Boundary value analysis; Combinatorial testing; Machine learning software; Simple tests; Smoke test; Smoke testing; Software applications; Software testing techniques; Software testings; Standard software; Software testing|Article|Final|All Open Access; Hybrid Gold Open Access|Scopus|2-s2.0-85123572240
scopus|Noor M.N.; Khan T.A.; Haneef F.; Ramay M.I.|Noor, Muhammad Nouman (57214270409); Khan, Tamim Ahmed (35758682200); Haneef, Farah (57214269024); Ramay, Muhammad Ismail (58130981700)|57214270409; 35758682200; 57214269024; 58130981700|Machine Learning Model to Predict Automated Testing Adoption|2022|International Journal of Software Innovation|10|1|||||6|10.4018/IJSI.293268|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149468267&doi=10.4018%2fIJSI.293268&partnerID=40&md5=9f8c30ca77d52c49609ba031a5df4ffb|Software testing is an activity conducted to test the software. It has two approaches: manual testing and automation testing. Automation testing is an approach of software testing in which programming scripts are written to automate the process of testing. There are some software development projects under development phase for which automated testing is suitable to use and the other requires manual testing. It depends on factors like project requirements nature, team which is working on the project, technology on which software is developing, and intended audience, which may influence the suitability of automated testing for certain software development projects. In this paper, the authors have developed a machine learning model for prediction of automated testing adoption. They have used chi-square test for finding factors’ correlation and PART classifier for model development. The accuracy of the proposed model is 93.1624%. Copyright © 2022, IGI Global.|Automated Testing; Classifier; Machine Learning; Software Testing||Article|Final||Scopus|2-s2.0-85149468267
scopus|Chen Z.; Zhao M.; Yang L.; Xu F.; Ji H.; Wu P.; Zhang K.; Dong X.; Li X.|Chen, Zhihua (58579265500); Zhao, Ming (58139854700); Yang, Luchang (58493863000); Xu, Fan (58592868200); Ji, Hongxia (55472960700); Wu, Peiya (57222007342); Zhang, Kai (57221087428); Dong, Xiaogang (57223322912); Li, Xiaofeng (57221117207)|58579265500; 58139854700; 58493863000; 58592868200; 55472960700; 57222007342; 57221087428; 57223322912; 57221117207|Review on Applications of Knowledge Graph in Software Development|2023|2023 6th International Symposium on Autonomous Systems, ISAS 2023|||||||0|10.1109/ISAS59543.2023.10164597|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165135259&doi=10.1109%2fISAS59543.2023.10164597&partnerID=40&md5=d7ce889863beddf7aba766c23b93c95c|Knowledge graph (KG) can represent the domain knowledge in the structural entities and relations and have become a popular AI technique. Software knowledge provides a deep understanding of the software development process. In this paper, we firstly provide a brief review on the related techniques, construction methods and applications of KG in the software development process. Then, we detailedly review and discuss the specific applications of KG in the whole software development process, including the phases of software requirement analysis, software design, software testing, software vulnerability detection, software bug detection and software fault diagnosis, respectively. Moreover, this paper provides some unsolved problems about the KG's applications in the field of spacecraft control software development to facilitate future research.  © 2023 IEEE.|knowledge graph; requirement analysis; software; software bug detection; software design; software fault diagnosis; software testing; software vulnerability detection; spacecraft control|Application programs; Failure analysis; Fault detection; Knowledge graph; Requirements engineering; Software design; Bug detection; Knowledge graphs; Requirement analysis; Software; Software bug; Software bug detection; Software fault diagnosis; Software testings; Software vulnerabilities; Software vulnerability detection; Spacecraft control; Vulnerability detection; Software testing|Conference paper|Final||Scopus|2-s2.0-85165135259
scopus|Costa T.; Coelho L.; Silva M.F.|Costa, Tatiana (57470554800); Coelho, Luis (22984023900); Silva, Manuel F. (55934287000)|57470554800; 22984023900; 55934287000|Automatic Segmentation of Monofilament Testing Sites in Plantar Images for Diabetic Foot Management|2022|Bioengineering|9|3|86||||13|10.3390/bioengineering9030086|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125481350&doi=10.3390%2fbioengineering9030086&partnerID=40&md5=e712714fc86705e0cb0b4dba459daba6|Diabetic peripheral neuropathy is a major complication of diabetes mellitus, and it is the leading cause of foot ulceration and amputations. The Semmes–Weinstein monofilament examination (SWME) is a widely used, low-cost, evidence-based tool for predicting the prognosis of diabetic foot patients. The examination can be quick, but due to the high prevalence of the disease, many healthcare professionals can be assigned to this task several days per month. In an ongoing project, it is our objective to minimize the intervention of humans in the SWME by using an automated testing system relying on computer vision. In this paper we present the project’s first part, constituting a system for automatically identifying the SWME testing sites from digital images. For this, we have created a database of plantar images and developed a segmentation system, based on image processing and deep learning—both of which are novelties. From the 9 testing sites, the system was able to correctly identify most 8 in more than 80% of the images, and 3 of the testing sites were correctly identified in more than 97.8% of the images. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.|Automatic; Diabetic foot; Monofilament; Semmes–Weinstein||Article|Final|All Open Access; Gold Open Access; Green Open Access|Scopus|2-s2.0-85125481350
scopus||||35th IFIPWG 6.1 International Conference on Testing Software and Systems, ICTSS 2023|2023|Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)|14131 LNCS|||||182|0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174462244&partnerID=40&md5=68bd339f3d3d3719be5a315e0e37fa5f|The proceedings contain 20 papers. The special focus in this conference is on IFIPWG 6.1 International Conference on Testing Software and Systems. The topics include: RQCODE: Security Requirements Formalization with Testing; understanding Problem Solving in Software Testing: An Exploration of Tester Routines and Behavior; who Is Afraid of Test Smells? Assessing Technical Debt from Developer Actions; GResilience: Trading Off Between the Greenness and the Resilience of Collaborative AI Systems; a Systematic Literature Review on Prioritizing Software Test Cases Using Markov Chains; on the Evaluation of Photometric Stereo Applications Testing Using Image Modifications; Multi-device, Robust, and Integrated Android GUI Testing: A Conceptual Framework; how Do Different Types of Testing Goals Affect Test Case Design?; automated Testing of Systems of Systems; enhancing Synthetic Test Data Generation with Language Models Using a More Expressive Domain-Specific Language; Testing Quality of Training in QoE-Aware SFC Orchestration Based on DRL Approach; CATANA: Replay Testing for the Ethereum Blockchain; applying Pairwise Combinatorial Testing to Large Language Model Testing; prioritizing Test Cases with Markov Chains: A Preliminary Investigation; complete Property-Oriented Module Testing; Empirical Verification of TQED - A New Test Design Heuristic Technique; Probabilistic Approach for Minimizing Checking Sequences for Non-deterministic FSMs; compositionality in Model-Based Testing; a Rapid Review on Fuzz Security Testing for Software Protocol Implementations.|||Conference review|Final||Scopus|2-s2.0-85174462244
scopus|Bansal A.; Khanna M.; Dhawan L.; Krishnamurthy J.|Bansal, Ankita (55998430000); Khanna, Megha (55798373500); Dhawan, Laavanaya (58486302600); Krishnamurthy, Juhi (58485673100)|55998430000; 55798373500; 58486302600; 58485673100|Analysis of Search Based Algorithms for Prediction of Aging Related Bugs|2023|Lecture Notes in Networks and Systems|650 LNNS|||567|580|13|0|10.1007/978-981-99-0838-7_49|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164716388&doi=10.1007%2f978-981-99-0838-7_49&partnerID=40&md5=74cf6a27a62194ce81e1ea102e86152d|Genetic algorithms (GAs) and Search based algorithms (SBAs) are very powerful optimization methods which are inspired by the success of evolutionary processes in the natural world. These optimization methods have been used to develop effective classifiers and have been successfully applied to various domains. This paper aims to evaluate GA based methods for the task of ARB prediction and analyze their effectiveness for the same. ARBs are software defects that manifest in a software module after prolonged usage. Such bugs are extremely hard to detect through traditional software testing methods and can have a very high impact when encountered during the operation of a software. Predictive models that can analyze a software code and flag the possibility of an ARB can be useful in mitigating the impact of ARBs. In this paper, we present an empirical study, that analyses statistically, the performance of GA/SBA based classifiers for ARB prediction on five datasets. We account for the data imbalance by creating synthetic minority samples using SMOTE. Results of this study show that SBA algorithms are effective in developing predictive models for ARB detection and their performance is comparable to machine learning algorithms (ML) for the same. © 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.|Aging related bugs; Genetic algorithms; Imbalanced data; Machine learning; Search based algorithms; Software maintenance|Classification (of information); Forecasting; Genetic algorithms; Learning algorithms; Program debugging; Software testing; Aging-related bugs; Evolutionary process; Imbalanced data; Machine-learning; Natural world; Optimization method; Performance; Prediction and analysis; Predictive models; Search-based algorithms; Machine learning|Conference paper|Final||Scopus|2-s2.0-85164716388
scopus|Asik S.; Yayan U.|Asik, Sergen (58535037800); Yayan, Ugur (46061619200)|58535037800; 46061619200|Generating Python Mutants from Bug Fixes Using Neural Machine Translation|2023|IEEE Access|11|||85678|85693|15|2|10.1109/ACCESS.2023.3302695|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167824211&doi=10.1109%2fACCESS.2023.3302695&partnerID=40&md5=b8215a580e08339a5915b304e9163e85|Due to the fast-paced development of technology, the software has become a crucial aspect of modern life, facilitating the operation and management of hardware devices. Nevertheless, using substandard software can result in severe complications for users, putting human lives at risk. This underscores the significance of error-free and premium-quality software. Verification and validation are essential in ensuring high-quality software development; software testing is integral to this process. Although code coverage is a prevalent method for assessing the efficacy of test suites, it has some limitations. Therefore, mutation testing is proposed as a remedy to tackle these limitations. Furthermore, mutation testing is recognized as a method for directing test case creation and evaluating the effectiveness of test suites. Our proposed method involves autonomously learning mutations from faults in real-world software applications. Firstly, our approach involves extracting bug fixes at the method-level, classifying them according to mutation types, and performing code abstraction. Subsequently, the approach utilizes a deep learning technique based on neural machine translation to develop mutation models. Our method has been trained and assessed using approximately ∼ 588k bug fix commits extracted from GitHub. The results of our experimental assessment indicate that our models can forecast mutations resembling resolved bugs in 6% to 35% of instances. The models effectively revert fixed code to its original buggy version, reproducing the original bug and generating various other buggy codes with up to 94% accuracy. More than 96% of the generated mutants also demonstrate lexical and syntactic accuracy. © 2013 IEEE.|abstract syntax tree; bug fixes; deep learning; evaluation of generated code quality; mining software repositories; mutation testing; neural machine translation; Software quality; software testing; software verification and validation|Application programs; Codes (symbols); Computational linguistics; Computer aided language translation; Computer software selection and evaluation; Deep learning; High level languages; Machine translation; Object oriented programming; Software design; Software testing; Syntactics; Trees (mathematics); Verification; Abstract Syntax Trees; Bug fixes; Code; Code quality; Computer bugs; Deep learning; Evaluation of generated code quality; Mining software; Mining software repository; Mutation testing; Object oriented modelling; Software Measurement; Software Quality; Software repositories; Software testings; Software verification and validation; Source-coding; Python|Article|Final|All Open Access; Gold Open Access|Scopus|2-s2.0-85167824211
scopus|Olaleye T.O.; Arogundade O.T.; Misra S.; Abayomi-Alli A.; Kose U.|Olaleye, T.O. (57216846632); Arogundade, O.T. (36805695100); Misra, Sanjay (56962766700); Abayomi-Alli, A. (57218001210); Kose, Utku (36544118500)|57216846632; 36805695100; 56962766700; 57218001210; 36544118500|Predictive Analytics and Software Defect Severity: A Systematic Review and Future Directions|2023|Scientific Programming|2023||6221388||||12|10.1155/2023/6221388|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148108224&doi=10.1155%2f2023%2f6221388&partnerID=40&md5=88c2e0d44c12690f89ccf21e118dc0b8|Software testing identifies defects in software products with varying multiplying effects based on their severity levels and sequel to instant rectifications, hence the rate of a research study in the software engineering domain. In this paper, a systematic literature review (SLR) on machine learning-based software defect severity prediction was conducted in the last decade. The SLR was aimed at detecting germane areas central to efficient predictive analytics, which are seldom captured in existing software defect severity prediction reviews. The germane areas include the analysis of techniques or approaches which have a significant influence on the threats to the validity of proposed models, and the bias-variance tradeoff considerations techniques in data science-based approaches. A population, intervention, and outcome model is adopted for better search terms during the literature selection process, and subsequent quality assurance scrutiny yielded fifty-two primary studies. A subsequent thoroughbred systematic review was conducted on the final selected studies to answer eleven main research questions, which uncovers approaches that speak to the aforementioned germane areas of interest. The results indicate that while the machine learning approach is ubiquitous for predicting software defect severity, germane techniques central to better predictive analytics are infrequent in literature. This study is concluded by summarizing prominent study trends in a mind map to stimulate future research in the software engineering industry.  © 2023 T. O. Olaleye et al.||Defects; Machine learning; Quality assurance; Software testing; Germanes; Machine-learning; On-machines; Research studies; Software defects; Software engineering domain; Software products; Software testings; Systematic literature review; Systematic Review; Predictive analytics|Review|Final|All Open Access; Gold Open Access; Green Open Access|Scopus|2-s2.0-85148108224
scopus||||2023 IEEE AUTOTESTCON, AUTOTESTCON 2023 - Conference Proceedings|2023|AUTOTESTCON (Proceedings)||||||415|0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178521748&partnerID=40&md5=575a5aa11e67135e22445323f8501030|The proceedings contain 64 papers. The topics discussed include: a reconfigurable data acquisition architecture based on hybrid interleaving in electronic instrument; TPS execution in an virtual environment; standards-based digital thread as authoritative source of truth; parallel acceleration algorithm for eye diagram construction based on GPU; the power of an automated test framework; new trends in testing electronic products by simulation during design, using programmable rules, circuit analysis and ai; an effective approach to evaluating electronic warfare systems; automated testing for operational flight programs with hardware-in-the-loop; and an adoption of automation framework for model based testing to system testing for airborne safety critical systems.|||Conference review|Final||Scopus|2-s2.0-85178521748
scopus|Xiao Z.; Xiao L.|Xiao, Zhengxinchao (58000741700); Xiao, Lei (57193073480)|58000741700; 57193073480|A Systematic Literature Review on Test Case Prioritization and Regression Test Selection|2023|Proceedings - 2023 IEEE/ACIS 21st International Conference on Software Engineering Research, Management and Applications, SERA 2023||||235|242|7|2|10.1109/SERA57763.2023.10197719|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168766744&doi=10.1109%2fSERA57763.2023.10197719&partnerID=40&md5=6ab135da03f4160ca44545d46052a0a8|Regression testing is a crucial component of software testing and a crucial tool for ensuring the quality of software. An appropriate optimization method is essential for maximizing productivity and reducing expenses in regression testing. Test case prioritization (TCP) and regression test selection (RTS) are two popular methods in regression testing. This paper provides a qualitative analysis of 18 TCP and 17 RTS publications from the last five years. This paper presents four main issues. The first covers the most popular TCP techniques, the second covers the most popular RTS methods, the third covers the most popular metrics for measuring TCP and RTS, and the fourth covers data sources. Based on this study, we draw the following conclusions: (1) Defect prediction and machine learning-based TCP methods, machine learning, multi-objective, and model-based RTS methods will receive additional attention in future. (2) Defects4J is the most commonly used data set in TCP in the past five years. SIR and GitHub are the most commonly used datasets in RTS. (3) The most widely used measurement methods in TCP and RTS are APFD and cost, respectively. In future, researchers will use these two indicators to conduct a more comprehensive evaluation together with cost, fault detection capability, and test coverage.  © 2023 IEEE.|Regression testing; Systematic literature review; Test case prioritization; Test case selection|Defects; Fault detection; Machine learning; Regression analysis; Transmission control protocol; Machine-learning; Optimization method; Quality of softwares; Regression test selection; Regression testing; Selection methods; Software testings; Systematic literature review; Test case prioritization; Test case selection; Software testing|Conference paper|Final||Scopus|2-s2.0-85168766744
scopus|Lee G.; Moon S.; Choi D.; Kim G.; Jhang K.|Lee, Gwanghee (57302991400); Moon, Sangjun (58706592300); Choi, Dasom (58706592400); Kim, Gayeon (58705707200); Jhang, Kyoungson (6701605030)|57302991400; 58706592300; 58706592400; 58705707200; 6701605030|Exploration of Key Point Localization Neural Network Architectures for Y-Maze Behavior Test Automation|2023|Journal of Computing Science and Engineering|17|3||100|108|8|1|10.5626/JCSE.2023.17.3.100|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177590312&doi=10.5626%2fJCSE.2023.17.3.100&partnerID=40&md5=1918ca9a31b13918a8f56c1d9e839133|The Y-maze behavioral test is a pivotal tool for assessing the memory and exploratory tendencies of mice in novel environments. A significant aspect of this test involves the continuous tracking and pinpointing of the mouse’s location, a task that can be labor-intensive for human researchers. This study introduced an automated solution to this challenge through camera-based image processing. We argued that key point localization techniques are more effective than object detection methods, given that only a single mouse is involved in the test. Through an experimental comparison of eight distinct neural network architectures, we identified the most effective structures for localizing key points such as the mouse’s nose, body center, and tail base. Our models were designed to predict not only the mouse key points but also the reference points of the Y-maze device, aiming to streamline the analysis process and minimize human intervention. The approach involves the generation of a heatmap using a deep learning neural network structure, followed by the extraction of the key points’ central location from the heatmap using a soft argmax function. The findings of this study provide a practical guide for experimenters in the selection and application of neural network architectures for Y-maze behavioral testing. © 2023. The Korean Institute of Information Scientists and Engineers|Computer vision; Deep learning; key point detection; Y-maze behavior test|Deep learning; Mammals; Network architecture; Neural networks; Object detection; Behavioural tests; Deep learning; Heatmaps; Key point detection; Keypoints; Neural network architecture; Point detection; Point localization; Test Automation; Y-maze behavior test; Computer vision|Article|Final||Scopus|2-s2.0-85177590312
scopus|Chhabra D.; Malik M.; Sharma S.|Chhabra, Deepshikha (57202846462); Malik, Meena (55605451500); Sharma, Sachin (57461341400)|57202846462; 55605451500; 57461341400|Literature Survey on Automatic Bug Triaging Using Machine Learning Techniques|2022|AIP Conference Proceedings|2555||20017||||2|10.1063/5.0108585|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141859735&doi=10.1063%2f5.0108585&partnerID=40&md5=75b339a63f1a0d41069b3b427c6f1213|Amongst all the phases of software development life cycle software testing phase is the most crucial phase. in this phase the errors or bugs are reported by the tester. Any kind of unexpected behavior in the software is referred to bug. the same can be referred as error or flaw. As soon as the bug is reported by the software tester the next step is to fix the bug or we can say that assigning the bug to appropriate developer which is known as bug triaging. the companies spend large amount of costs in bug triaging process. The process of assigning the bug to appropriate developer is based on various factors like severity, priority and risk associated with the bug. The key idea behind the bug triaging process is to search thesuitable developer who can fix the bug short span of time. in this research paper we will address the factors which impact the performance of bug triaging process. in the later section the comparative analysis of various automatic bug triaging processes has in been done. © 2022 American Institute of Physics Inc.. All rights reserved.|Bug; Bug Assigning; Bug Life Cycle; Bug Priority; Bug Tracking; Bug Triaging||Conference paper|Final|All Open Access; Bronze Open Access|Scopus|2-s2.0-85141859735
scopus|López-Martín C.|López-Martín, Cuauhtémoc (56002702800)|56002702800|Machine learning techniques for software testing effort prediction|2022|Software Quality Journal|30|1||65|100|35|24|10.1007/s11219-020-09545-8|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101672257&doi=10.1007%2fs11219-020-09545-8&partnerID=40&md5=2a9b1d477a52036ee109efdafef06b14|Software testing (ST) has been considered as one of the most important and critical activities of the software development life cycle (SDLC) since it influences directly on quality. When a software project is planned, it is common practice to predict the corresponding ST effort (STEP) as a percentage of predicted SDLC effort. However, the effort range for ST has been reported between 10 and 60% of the predicted SDLC effort. This wide range on STEP causes uncertainty in software managers due to STEP is used for allocating resources to teams exclusively for testing activities, and for budgeting and bidding the projects. In spite of this concern, hundreds of studies have been published since 1981 about SDLC effort prediction models, and only thirty-one STEP studies published in the last two decades were identified (just two of them based their conclusions on statistical significance). The contribution of the present study is to investigate the application for STEP of five machine learning (ML) models reported as the most accurate ones when applied to SDLC effort prediction. The models were trained and tested with data sets of projects selected from an international public repository of software projects. The selection for projects was based on their data quality rating, type of development, development platform, programming language generation, sizing method, and resource level of projects. Results based on statistical significance allow suggesting the application of specific ML models to software projects by type of development, and developed on a determined platform and programming language generation. © 2021, The Author(s), under exclusive licence to Springer Science+Business Media, LLC part of Springer Nature.|ISBSG; Machine learning models; Statistical regression; Testing effort prediction|Application programs; Budget control; Computer programming languages; Forecasting; Human resource management; Life cycle; Machine learning; Predictive analytics; Software design; Critical activities; Development platform; Effort prediction model; Machine learning techniques; Public repositories; Software development life cycle; Software managers; Statistical significance; Software testing|Article|Final||Scopus|2-s2.0-85101672257
scopus|Martínez-Fernández S.; Bogner J.; Franch X.; Oriol M.; Siebert J.; Trendowicz A.; Vollmer A.M.; Wagner S.|Martínez-Fernández, Silverio (55363648100); Bogner, Justus (57189261793); Franch, Xavier (6603081752); Oriol, Marc (53880191200); Siebert, Julien (57219057225); Trendowicz, Adam (12762670400); Vollmer, Anna Maria (57197746321); Wagner, Stefan (55286051900)|55363648100; 57189261793; 6603081752; 53880191200; 57219057225; 12762670400; 57197746321; 55286051900|Software Engineering for AI-Based Systems: A Survey|2022|ACM Transactions on Software Engineering and Methodology|31|2|37e||||171|10.1145/3487043|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130727000&doi=10.1145%2f3487043&partnerID=40&md5=fbf7ac61842908f81cd945ae6a1009e4|AI-based systems are software systems with functionalities enabled by at least one AI component (e.g., for image-, speech-recognition, and autonomous driving). AI-based systems are becoming pervasive in society due to advances in AI. However, there is limited synthesized knowledge on Software Engineering (SE) approaches for building, operating, and maintaining AI-based systems. To collect and analyze state-of-the-art knowledge about SE for AI-based systems, we conducted a systematic mapping study. We considered 248 studies published between January 2010 and March 2020. SE for AI-based systems is an emerging research area, where more than 2/3 of the studies have been published since 2018. The most studied properties of AI-based systems are dependability and safety. We identified multiple SE approaches for AI-based systems, which we classified according to the SWEBOK areas. Studies related to software testing and software quality are very prevalent, while areas like software maintenance seem neglected. Data-related issues are the most recurrent challenges. Our results are valuable for: researchers, to quickly understand the state-of-the-art and learn which topics need more research; practitioners, to learn about the approaches and challenges that SE entails for AI-based systems; and, educators, to bridge the gap among SE and AI in their curricula.  © 2022 Copyright held by the owner/author(s).|AI-based systems; artificial intelligence; Software engineering; systematic mapping study|Application programs; Artificial intelligence; Computer software selection and evaluation; Curricula; Software testing; Speech recognition; AI-based system; Autonomous driving; Classifieds; Learn+; Property; Research areas; Software-systems; State of the art; Synthesised; Systematic mapping studies; Mapping|Article|Final|All Open Access; Green Open Access|Scopus|2-s2.0-85130727000
scopus|Khaliq Z.; Farooq S.U.; Khan D.A.|Khaliq, Zubair (57423387800); Farooq, Sheikh Umar (55259943800); Khan, Dawood Ashraf (35761464100)|57423387800; 55259943800; 35761464100|A deep learning-based automated framework for functional User Interface testing|2022|Information and Software Technology|150||106969||||15|10.1016/j.infsof.2022.106969|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133933090&doi=10.1016%2fj.infsof.2022.106969&partnerID=40&md5=4d5ebb5702050216d90ba1c22512170f|Context: The use of automation tools in software testing helps keep pace with the timeline of the deliverables. Over time with the inclusion of continuous integration/continuous delivery (CI/CD) pipelines, automation tools are becoming less effective. The testing community is turning to AI to help keep the pace. Objective: We study the use of transformers to automate the process of test case generation directly from the User Interface (UI) element description instead of relying on the test specification document from which test cases are extracted manually. We also demonstrate the capability of the proposed approach in repairing flaky tests. Method: We employ object detection algorithms EfficientDet and DEtectionTRansformer for detecting the elements from an application UI automatically without requiring a tester to locate complex-scripted UI elements. We also use Tesseract to automatically identify the text present on the UI elements. We transform the generated UI element description to actual test designer-written test cases using text-generation transformers like GPT-2 and T5. The generated test cases are then translated into executable test scripts using a simple parser. We carry out our cases study on 30 e-commerce applications. Results: The percentage of correct executable test cases generated by the framework employing EfficientDet is 93.82% and employing DEtectionTRansformer is 98.08%. The framework eliminates an average of 96.05% flakiness across the applications selected for the study. Conclusion: It is concluded that the proposed approach can be used with current automation tools in the industry to enhance their capability in generating test cases and repairing the flaky tests. © 2022 Elsevier B.V.|Automated testing; Deep learning; Software testing; Transformers; UI functional testing|Automation; Deep learning; Electric transformer testing; Object detection; Repair; Software testing; Automated testing; Automation tools; Deep learning; Executables; Functional testing; Interface elements; Software testings; Test case; Transformer; User interface functional testing; User interfaces|Article|Final||Scopus|2-s2.0-85133933090
scopus|Jha N.; Popli R.; Chakraborty S.; Kumar P.|Jha, Nisha (57262154100); Popli, Rashmi (55783421000); Chakraborty, Sudeshna (58280900300); Kumar, Pramod (7403960793)|57262154100; 55783421000; 58280900300; 7403960793|Software Test Automation Using Selenium and Machine Learning|2022|Lecture Notes in Networks and Systems|329|||419|429|10|2|10.1007/978-981-16-6246-1_35|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123297829&doi=10.1007%2f978-981-16-6246-1_35&partnerID=40&md5=3761bb2937361fe54c2d553c80ef8385|Software testing has always been a crucial job in accomplishing and assessing the quality standards of a software product. Software testing is done to confirm the developed software product does what it is expected to do. However, testing is expensive in terms of time, effort, and is quite complicated. Studies report that software testing alone is responsible for almost half of the total budget incurred in software development. Additionally, manual testing is more prone to bugs and creating accurate and reliable software is an open issue. Specialists and experts have been exploring more effective and successful automation techniques for testing to deal with this issue. This paper is an endeavor to review the cutting edge of how machine learning and artificial intelligence have been figured out to automate and streamline software testing processes. It also provides an insight mapping of the research into these fields. Furthermore, a practical study on testing web applications is performed using selenium. © 2022, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.|Artificial intelligence; Machine learning; Software testing; Test automation||Conference paper|Final||Scopus|2-s2.0-85123297829
scopus|Turhan F.; Çarkacioǧlu L.; TöreyIn B.U.|Turhan, Fatmanur (57226883315); Çarkacioǧlu, Levent (36696074100); TöreyIn, Behçet Uǧur (9249500700)|57226883315; 36696074100; 9249500700|Test Automation for Symbol Recognition on the Map; [Harita Üzerinde Sembol Tanima Için Test Otomasyonu]|2023|31st IEEE Conference on Signal Processing and Communications Applications, SIU 2023|||||||0|10.1109/SIU59756.2023.10223831|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173432800&doi=10.1109%2fSIU59756.2023.10223831&partnerID=40&md5=5436951d1092fd0035b34585328eafe3|In this study, various machine learning and image analysis approaches such as Template Matching, HOG, SVM, Faster RCNN and YOLO are examined and compared for the symbol recognition problem in color maps. Some difficulties were identified regarding the forms of the symbols, the complexity of the maps or the placement of the symbols on the map. Observations about the success or failure of the methods against the difficulties defined according to the experiments are presented. It has been observed that methods involving artificial neural networks are more successful when performing symbol recognition on color maps. The highest result was obtained with Faster RCNN as 91%. © 2023 IEEE.|Convolutional Neural Network; Feature Extraction; Object Detection; Software Testing; Support Vector Machines; Symbol Recognition; Template Matching|Color matching; Convolutional neural networks; Feature extraction; Object detection; Support vector machines; Template matching; Colormap; Convolutional neural network; Features extraction; Image-analysis; Machine-learning; Objects detection; Software testings; Support vectors machine; Symbol recognition; Test Automation; Software testing|Conference paper|Final||Scopus|2-s2.0-85173432800
scopus|Canaparo M.; Ronchieri E.; Bertaccini G.|Canaparo, Marco (34976326100); Ronchieri, Elisabetta (8211491800); Bertaccini, Gianluca (57927258300)|34976326100; 8211491800; 57927258300|Software defect prediction: A study on software metrics using statistical and machine learning methods|2022|Proceedings of Science|415||20||||1||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139874507&partnerID=40&md5=e3691db8ad4cdd63ad0e694d344e2044|Software defect prediction aims at identifying defect prone software modules in order to allocate optimal testing resources. The role of testing in software development life cycle is vital especially when software systems are becoming more and more complex, representing a suitable environment for defects. Several researchers have striven to develop models able to determine defective modules with the aim of reducing time and cost of software testing. Such models are typically trained on software measurements, known as software metrics, which describe the characteristics of a software project in terms of e.g., dimension and complexity. These metrics reduce the subjectivity of software quality assessment and can be relied on for decision making, e.g., to decide where to focus software tests. The aim of our work is to employ both feature selection or construction techniques and machine learning techniques to build software defect prediction models on different kinds of software dataset metrics (derived from various software projects available in the NASA and Eclipse repositories), and assess their performances by considering accuracy, precision, recall and area under the curve. We have used non parametric tests to compute the statistical significance of the obtained results. The collected metrics belong to three main categories: dimension, complexity and object orientation. The involved datasets contain class labels, i.e., information on the defectiveness of the software modules. To make our study available to research community, we have developed an open source and extensible R application that supports researchers to load the selected kinds of datasets, to filter them according to the their features and to apply machine learning techniques. © Copyright owned by the author(s) under the terms of the Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License (CC BY-NC-ND 4.0)||Computer software selection and evaluation; Decision making; Forecasting; Learning algorithms; Life cycle; Machine learning; NASA; Open source software; Software design; Software testing; Machine learning methods; Machine learning techniques; Optimal testing; Software defect prediction; Software development life-cycle; Software metrics; Software modules; Software project; Statistical learning methods; Testing resources; Defects|Conference paper|Final||Scopus|2-s2.0-85139874507
scopus|Fatch R.; Luginbühl M.; Cheng D.M.; Gaugler S.; Emenyonu N.I.; Ngabirano C.; Adong J.; Muyindike W.R.; Samet J.H.; Bryant K.; Hahn J.A.|Fatch, Robin (23396810600); Luginbühl, Marc (57196325311); Cheng, Debbie M. (7402806458); Gaugler, Stefan (57195293473); Emenyonu, Nneka I. (12796451400); Ngabirano, Christine (56996122700); Adong, Julian (57193275786); Muyindike, Winnie R. (35620921600); Samet, Jeffrey H. (7202405920); Bryant, Kendall (7005904808); Hahn, Judith A. (7202494209)|23396810600; 57196325311; 7402806458; 57195293473; 12796451400; 56996122700; 57193275786; 35620921600; 7202405920; 7005904808; 7202494209|Comparison of automated determination of phosphatidylethanol (PEth) in dried blood spots (DBS) with previous manual processing and testing|2022|Alcohol|98|||51|54|3|2|10.1016/j.alcohol.2021.11.001|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120796417&doi=10.1016%2fj.alcohol.2021.11.001&partnerID=40&md5=f5b1ffac1ab0ec9a6cfa281a40063d7e|Phosphatidylethanol (PEth) is a sensitive and specific biomarker of alcohol consumption in the prior 2–3 weeks. Standard, manual PEth testing using dried blood spots (DBS) is a multi-step time-consuming process. A novel, automated processing and testing method has been developed to decrease DBS processing and testing time. We conducted automated testing, using regioisomerically pure PEth reference material, on randomly selected DBS, which had previously been tested via manual methods and then stored for 3–6 years at −80 °C, to compare the results (PEth 16:0/18:1 homologue). We chose samples for re-testing using categories found in the literature as follows: 1) PEth <20 ng/mL; 2) PEth 20–200 ng/mL; 3) PEth >200–1000 ng/mL; 4) PEth >1000 ng/mL. We calculated agreement between the categories using the weighted kappa statistic (n = 49 DBS). We quantified agreement between continuous measures using the intraclass correlation coefficient (ICC), and further described the relationship between variables using Spearman correlation. The median PEth result was 155 ng/mL (interquartile range [IQR]: 1–1312 ng/mL) via automated methods and 98.8 ng/mL (IQR: 10.2–625.0 ng/mL) via manual methods. The weighted kappa comparing the automated to manual PEth results was 0.76 [95% Confidence Interval (CI): 0.66–0.86]. The ICC was 0.69 (95% CI: 0.54–0.79), and the Spearman correlation was 0.98 (95% CI: 0.95–0.99). While the new methods yielded somewhat higher PEth values, we found good to excellent agreement between clinically relevant PEth categories. Automated DBS processing and testing using new reference standards are promising methods for PEth testing. © 2021 Elsevier Inc.|Alcohol biomarker; Automated; Dried blood spots; LC-MS/MS; PEth; Phosphatidylethanol|Alcohol Drinking; Biomarkers; Dried Blood Spot Testing; Glycerophospholipids; alcohol; alcohol derivative; phosphatidylethanol; unclassified drug; biological marker; glycerophospholipid; phosphatidylethanol; adult; alcohol consumption; Article; automated dried blood spot testing; confidence interval; controlled study; correlation coefficient; dried blood spot testing; female; human; Human immunodeficiency virus infection; intermethod comparison; isomer; kappa statistics; limit of quantitation; major clinical study; male; quantitative analysis; sensitivity and specificity; storage temperature; time; drinking behavior; procedures|Article|Final|All Open Access; Green Open Access|Scopus|2-s2.0-85120796417
scopus|Catlett J.L.; Carr S.; Cashman M.; Smith M.D.; Walter M.; Sakkaff Z.; Kelley C.; Pierobon M.; Cohen M.B.; Buan N.R.|Catlett, Jennie L. (56364478100); Carr, Sean (57219341078); Cashman, Mikaela (57189903819); Smith, Megan D. (57215380819); Walter, Mary (57125430800); Sakkaff, Zahmeeth (37036028300); Kelley, Christine (36348758400); Pierobon, Massimiliano (15846834900); Cohen, Myra B. (8719004300); Buan, Nicole R. (6506326021)|56364478100; 57219341078; 57189903819; 57215380819; 57125430800; 37036028300; 36348758400; 15846834900; 8719004300; 6506326021|Metabolic Synergy between Human Symbionts Bacteroides and Methanobrevibacter|2022|Microbiology Spectrum|10|3|||||24|10.1128/spectrum.01067-22|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133214371&doi=10.1128%2fspectrum.01067-22&partnerID=40&md5=06a23984026b94765a11f80cf4e4f375|Trophic interactions between microbes are postulated to determine whether a host microbiome is healthy or causes predisposition to disease. Two abundant taxa, the Gram-negative heterotrophic bacterium Bacteroides thetaiotaomicron and the methanogenic archaeon Methanobrevibacter smithii, are proposed to have a synergistic metabolic relationship. Both organisms play vital roles in human gut health; B. thetaiotaomicron assists the host by fermenting dietary polysaccharides, whereas M. smithii consumes end-stage fermentation products and is hypothesized to relieve feedback inhibition of upstream microbes such as B. thetaiotaomicron. To study their metabolic interactions, we defined and optimized a coculture system and used software testing techniques to analyze growth under a range of conditions representing the nutrient environment of the host. We verify that B. thetaiotaomicron fermentation products are sufficient for M. smithii growth and that accumulation of fermentation products alters secretion of metabolites by B. thetaiotaomicron to benefit M. smithii. Studies suggest that B. thetaiotaomicron metabolic efficiency is greater in the absence of fermentation products or in the presence of M. smithii. Under certain conditions, B. thetaiotaomicron and M. smithii form interspecies granules consistent with behavior observed for syntrophic partnerships between microbes in soil or sediment enrichments and anaerobic digesters. Furthermore, when vitamin B12, hematin, and hydrogen gas are abundant, coculture growth is greater than the sum of growth observed for monocultures, suggesting that both organisms benefit from a synergistic mutual metabolic relationship. IMPORTANCE The human gut functions through a complex system of interactions between the host human tissue and the microbes which inhabit it. These diverse interactions are difficult to model or examine under controlled laboratory conditions. We studied the interactions between two dominant human gut microbes, B. thetaiotaomicron and M. smithii, using a seven-component culturing approach that allows the systematic examination of the metabolic complexity of this binary microbial system. By combining high-throughput methods with machine learning techniques, we were able to investigate the interactions between two dominant genera of the gut microbiome in a wide variety of environmental conditions. Our approach can be broadly applied to studying microbial interactions and may be extended to evaluate and curate computational metabolic models. The software tools developed for this study are available as user-friendly tutorials in the Department of Energy KBase. © 2022 American Society for Microbiology. All rights reserved.|Bacteroides; cross-feeding; metabolism; Methanobrevibacter; microbiome; synergy; syntrophy|Bacteroides; Fermentation; Gastrointestinal Microbiome; Humans; Methanobrevibacter; Microbial Interactions; hematin; polysaccharide; RNA 16S; anaerobic digestion; Article; autofluorescence; bacterial growth; bacterium culture; Bacteroides; Bacteroides thetaiotaomicron; cell growth; coculture; decision tree; epidemic doubling time; fermentation; flow cytometry; genome size; growth inhibition; human; Methanobrevibacter; Methanobrevibacter smithii; microbial community; microbial interaction; microbiome; microscopy; negative feedback; optical density; phenotype; plant growth; real time polymerase chain reaction; symbiont; synergistic effect; Bacteroides; intestine flora; metabolism; organismal interaction|Article|Final|All Open Access; Green Open Access|Scopus|2-s2.0-85133214371
scopus||||2023 International Conference on Cognitive Computing and Complex Data, ICCD 2023|2023|2023 International Conference on Cognitive Computing and Complex Data, ICCD 2023||||||350|0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188203127&partnerID=40&md5=cd5f79b8589e294515ed7fb99deee9cd|The proceedings contain 57 papers. The topics discussed include: research on traffic target recognition algorithm based on deep learning; the use of AR technology in retail promotion: an empirical study of innovative forms and customer interaction; predictive maintenance of produced water re-injection pump failure in the field of oil and gas: a review; implementing mass testing approach with computer vision techniques; enhancing the evaluation performance of convolutional neural networks-based vehicle classification systems; software testing combining the fusion of surrogate model and evolutionary algorithm; intelligent cognitive clinician; detection algorithm for safety helmet wearing of chemical plant personnel based on improved YOLOv5m; reversible multiple watermarking in medical imaging security applications; and cognitive system design for Chinese herbal medicine recognition based on DenseNet.|||Conference review|Final||Scopus|2-s2.0-85188203127
scopus|Dang X.; Gong D.; Yao X.; Tian T.; Liu H.|Dang, Xiangying (55532110400); Gong, Dunwei (7102687714); Yao, Xiangjuan (12446273900); Tian, Tian (55246152000); Liu, Huai (19640635500)|55532110400; 7102687714; 12446273900; 55246152000; 19640635500|Enhancement of Mutation Testing via Fuzzy Clustering and Multi-Population Genetic Algorithm|2022|IEEE Transactions on Software Engineering|48|6||2141|2156|15|18|10.1109/TSE.2021.3052987|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099731441&doi=10.1109%2fTSE.2021.3052987&partnerID=40&md5=c6fe96b915fded46659f1c594bfadfc3|Mutation testing, a fundamental software testing technique, which is a typical way to evaluate the adequacy of a test suite. In mutation testing, a set of mutants are generated by seeding the different classes of faults into a program under test. Test data shall be generated in the way that as many mutants can be killed as possible. Thanks to numerous tools to implement mutation testing for different languages, a huge amount of mutants are normally generated even for small-sized programs. However, a large number of mutants not only leads to a high cost of mutation testing, but also make the corresponding test data generation a non-trivial task. In this paper, we make use of intelligent technologies to improve the effectiveness and efficiency of mutation testing from two perspectives. A machine learning technique, namely fuzzy clustering, is applied to categorize mutants into different clusters. Then, a multi-population genetic algorithm via individual sharing is employed to generate test data for killing the mutants in different clusters in parallel when the problem of test data generation as an optimization one. A comprehensive framework, termed as $\mathbf {FUZGENMUT}$FUZGENMUT, is thus developed to implement the proposed techniques. The experiments based on nine programs of various sizes show that fuzzy clustering can help to reduce the cost of mutation testing effectively, and that the multi-population genetic algorithm improves the efficiency of test data generation while delivering the high mutant-killing capability. The results clearly indicate that the huge potential of using intelligent technologies to enhance the efficacy and thus the practicality of mutation testing.  © 1976-2012 IEEE.|Fuzzy clustering; Multi-population genetic algorithm (MGA); Mutation clustering; Mutation testing; Test data generation|Clustering algorithms; Efficiency; Fuzzy clustering; Genetic algorithms; Learning systems; Population statistics; Testing; Turing machines; Effectiveness and efficiencies; Intelligent technology; Machine learning techniques; Multi-population genetic algorithm; Mutation testing; Non-trivial tasks; Software testing techniques; Test data generation; Software testing|Article|Final||Scopus|2-s2.0-85099731441
scopus|Gangolli A.; Mahmoud Q.H.; Azim A.|Gangolli, Aakash (57765433400); Mahmoud, Qusay H. (6701548037); Azim, Akramul (36023296200)|57765433400; 6701548037; 36023296200|A Systematic Review of Fault Injection Attacks on IoT Systems|2022|Electronics (Switzerland)|11|13|2023||||33|10.3390/electronics11132023|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132867832&doi=10.3390%2felectronics11132023&partnerID=40&md5=a9fdad15717d01e6484333747720110d|The field of the Internet of Things (IoT) is growing at a breakneck pace and its applications are becoming increasingly sophisticated with time. Fault injection attacks on IoT systems are aimed at altering software behavior by introducing faults into the hardware devices of the system. Attackers introduce glitches into hardware components, such as the clock generator, microcontroller, and voltage source, which can affect software functioning, causing it to misbehave. The methods proposed in the literature to handle fault injection attacks on IoT systems vary from hardware-based attack detection using system-level properties to analyzing the IoT software for vulnerabilities against fault injection attacks. This paper provides a systematic review of the various techniques proposed in the literature to counter fault injection attacks at both the system level and the software level to identify their limitations and propose solutions to address them. Hybrid attack detection methods at the software level are proposed to enhance the security of IoT systems against fault injection attacks. Solutions to the identified limitations are suggested using machine learning, dynamic code instrumentation tools, hardware emulation platforms, and concepts from the software testing domain. Future research possibilities, such as the use of software fault injection tools and supervised machine learning for attack detection at the software level, are investigated. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.|attack detection; fault injection attack; machine learning; software fault injection; software testing; software vulnerability analysis||Review|Final|All Open Access; Gold Open Access|Scopus|2-s2.0-85132867832
scopus||||Proceedings - 2023 IEEE 16th International Conference on Software Testing, Verification and Validation Workshops, ICSTW 2023|2023|Proceedings - 2023 IEEE 16th International Conference on Software Testing, Verification and Validation Workshops, ICSTW 2023||||||463|0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163089743&partnerID=40&md5=6e23c7ebbf265b3700ba021904030fa3|The proceedings contain 64 papers. The topics discussed include: we tried and failed: an experience report on a collaborative workflow for GUI-based testing; model-based policy synthesis and test-case generation for autonomous systems; ADAS verification in co-simulation: towards a meta-model for defining test scenarios; improving model learning by inferring separating sequences from traces; towards explainable test case prioritization with learning-to-rank models; generating concrete test cases from vehicle data using models obtained from clustering; similarities of testing programmed and learnt software; regression test generation by usage coverage driven clustering on user traces; evaluating the effectiveness of attacks and defenses on machine learning through adversarial samples; beyond combinatorial interaction testing: on the need for transition testing in dynamically adaptive context-aware systems; and deep industry use cases on context-aware adaptive mobile systems experience testing.|||Conference review|Final||Scopus|2-s2.0-85163089743
scopus|Borah S.; Aliliele K.C.; Rakshit S.; Vajjhala N.R.|Borah, Samarjeet (26221014200); Aliliele, King Chime (57742500600); Rakshit, Sandip (57215320689); Vajjhala, Narasimha Rao (56106511000)|26221014200; 57742500600; 57215320689; 56106511000|Applications of Artificial Intelligence in Software Testing|2022|Lecture Notes in Networks and Systems|375|||727|736|9|1|10.1007/978-981-16-8763-1_60|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132048306&doi=10.1007%2f978-981-16-8763-1_60&partnerID=40&md5=74b115bd88d3222e9f605755a2a1a549|Software testing is a critical aspect of the software development process. It involves test cases or test suites to ensure the software product conforms to the user’s requirements. However, some issues currently affect the software testing process, such as human error, an unstable environment, and incorrect and incomplete requirements documentation. This paper explains how artificial intelligence (AI) concepts, including machine learning, deep learning, neural networks, and expert systems, can be applied to software testing to ease its rigorous and tedious process. This paper would also overview the different types of software testing, the advantages of using artificial intelligence pillars to software testing, and AI challenges in software testing. © 2022, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.|Artificial intelligence; Challenges; Deep learning; Machine learning; Neural networks; Software testing||Conference paper|Final||Scopus|2-s2.0-85132048306
scopus|Pandey S.; Kumar K.|Pandey, Sanchita (58279718900); Kumar, Kuldeep (57202765898)|58279718900; 57202765898|Analysis of Different Sampling Techniques for Software Fault Prediction|2023|Lecture Notes in Electrical Engineering|1049 LNEE|||59|71|12|0|10.1007/978-981-99-3569-7_5|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171984790&doi=10.1007%2f978-981-99-3569-7_5&partnerID=40&md5=dbea5162b433555a7b8775f6a4708e4d|The process of predicting whether or not a software module is faulty based on specific metrics is known as software fault prediction. Software faults predicted in prior stages help in the management of resources and time required during software testing and maintenance. Over the years, various supervised machine learning-based techniques for fault prediction have been suggested. The models are trained using a labeled dataset that consists of multiple independent variables like lines of codes, the complexity of the software, the size of the software, etc., and a dependent binary variable that is either true or false. Recent research in software fault prediction focuses on data quality. In this paper, we have mainly focused on the class imbalance problem. In imbalanced data, one of the class labels has a higher number of observations, while the other class label has a lower number of observations. Different over-sampling and under-sampling techniques are used to tackle the class imbalance problem. In this paper, random under-sampling, random over-sampling, and SMOTE are applied to six PROMISE datasets. A decision tree classifier is used to create the model. The efficiency of different sampling techniques is compared using the ROC-AUC score and F1-score. © 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.|Data imbalance; Decision tree classifier; F1-score; Random over-sampling; Random under-sampling; ROC-AUC score; SMOTE; Software fault prediction|Classification (of information); Decision trees; Forecasting; Supervised learning; Data imbalance; Decision tree classifiers; F1 scores; Over sampling; Random over-sampling; Random under samplings; ROC-AUC score; Sampling technique; SMOTE; Software fault prediction; Software testing|Conference paper|Final||Scopus|2-s2.0-85171984790
scopus|Zhu J.; Long T.; Wang W.; Memon A.|Zhu, Junjie (57271382600); Long, Teng (59627314800); Wang, Wei (57988333200); Memon, Atif (35599876500)|57271382600; 59627314800; 57988333200; 35599876500|Improving ML-based information retrieval software with user-driven functional testing and defect class analysis|2022|ESEC/FSE 2022 - Proceedings of the 30th ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering||||1291|1301|10|0|10.1145/3540250.3558941|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143078506&doi=10.1145%2f3540250.3558941&partnerID=40&md5=517c135f1da87802953ed33cf084d798|Machine Learning (ML) has become the cornerstone of information retrieval (IR) software, as it can drive better user experience by leveraging information-rich data and complex models. However, evaluating the emergent behavior of ML-based IR software can be challenging with traditional software testing approaches: when developers modify the software, they cannot often extract useful information from individual test instances; rather, they seek to holistically verify whether - and where - their modifications caused significant regressions or improvements at scale. In this paper, we introduce not only such a holistic approach to evaluate the system-level behavior of the software, but also the concept of a defect class, which represents a partition of the input space on which the ML-based software does measurably worse for an existing feature or on which the ML task is more challenging for a new feature. We leverage large volumes of functional test cases, automatically obtained, to derive these defect classes, and propose new ways to improve the IR software from an end-user's perspective. Applying our approach on a real production Search-AutoComplete system that contains a query interpretation ML component, we demonstrate that (1) our holistic metrics successfully identified two regressions and one improvement, where all 3 were independently verified with retrospective A/B experiments, (2) the automatically obtained defect classes provided actionable insights during early-stage ML development, and (3) we also detected defect classes at the finer sub-component level for which there were significant regressions, which we blocked prior to different releases.  © 2022 ACM.|AutoComplete Search; Information Retrieval System Testing; Machine Learning Testing; Query Interpretation; Relevance Search|Defects; Digital storage; Information retrieval; Regression analysis; Search engines; Software testing; Testing; Autocomplete search; Defect class; Information retrieval software; Information retrieval system testing; Information-retrieval systems; Machine learning testing; Machine-learning; Query interpretation; Relevance search; System testing; Machine learning|Conference paper|Final||Scopus|2-s2.0-85143078506
scopus|Alamleh D.|Alamleh, Dalia (57218265493)|57218265493|Utilizing AI in Test Automation to Perform Functional Testing on Web Application|2022|Lecture Notes in Networks and Systems|507 LNNS|||359|377|18|1|10.1007/978-3-031-10464-0_24|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135069199&doi=10.1007%2f978-3-031-10464-0_24&partnerID=40&md5=74f586277984af2f259c9bf2192c556b|Artificial Intelligence is the trend in software development. Unfortunately, Artificial Intelligence algorithms and technologies are still not utilized enough in software testing. Designing Test automation has become the main job for quality engineers and software testers. Mainly, Test Automation is beneficial in reducing manual testing efforts. Utilizing AI in test automation can form a huge benefit in code optimization and test oracle problem. The primary objective of the research was to approve the usability of the Fuzzy Inference System in providing a test oracle for web application functional testing. The secondary objective was to utilize Artificial Intelligence techniques like self-healing for the test Automation using web scraping. Also, to compare the web scraping approach and the Image processing approach in locating the web elements on the websites dynamically. I have addressed the problem by developing Test Automation that verifies the search functionality for a given website. The hypothesis is mainly to check if the Fuzzy Inference System can predict if the search functionality for a given website is working or not. I tested the hypothesis on ten different websites. Then, after I analysed the results, I have found that implementing the Fuzzy Inference System in test automation can form a reasonable solution for the test oracle problem. Furthermore, using the Fuzzy Inference System is as efficient as the manually prepared test oracle that covers all the possible cases for the inputs using if-else statements. Finally, I have demonstrated how web scraping can be utilized to perform self-healing for the test Automation. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.|Artificial Intelligence; Fuzzy Inference System; Test Automation; Test Oracle||Conference paper|Final||Scopus|2-s2.0-85135069199
scopus|Zeb A.; Din F.; Fayaz M.; Mehmood G.; Zamli K.Z.|Zeb, Alam (59964867700); Din, Fakhrud (56070700100); Fayaz, Muhammad (57940566800); Mehmood, Gulzar (57216561453); Zamli, Kamal Z. (8701576800)|59964867700; 56070700100; 57940566800; 57216561453; 8701576800|A Systematic Literature Review on Robust Swarm Intelligence Algorithms in Search-Based Software Engineering|2023|Complexity|2023||4577581||||13|10.1155/2023/4577581|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149384508&doi=10.1155%2f2023%2f4577581&partnerID=40&md5=8791d29b8ae10872f8913e4853448c21|Swarm intelligence algorithms are metaheuristics inspired by the collective behavior of species such as birds, fish, bees, and ants. They are used in many optimization problems due to their simplicity, flexibility, and scalability. These algorithms get the desired convergence during the search by balancing the exploration and exploitation processes. These metaheuristics have applications in various domains such as global optimization, bioinformatics, power engineering, networking, machine learning, image processing, and environmental applications. This paper presents a systematic literature review (SLR) on applications of four swarm intelligence algorithms i.e., grey wolf optimization (GWO), whale optimization algorithms (WOA), Harris hawks optimizer (HHO), and moth-flame optimizer (MFO) in the field of software engineering. It presents an in-depth study of these metaheuristics' adoption in the field of software engineering. This SLR is mainly comprised of three phases such as planning, conducting, and reporting. This study covers all related studies published from 2014 up to 2022. The study shows that applications of the selected metaheuristics have been utilized in various fields of software engineering especially software testing, software defect prediction, and software reliability. The study also points out some of the areas where applications of these swarm intelligence algorithms can be utilized. This study may act as a guideline for researchers in improving the current state-of-the-art on generally adopting these metaheuristics in software engineering.  © 2023 Alam Zeb et al.||Application programs; Balancing; Global optimization; Heuristic algorithms; Image processing; Software reliability; Swarm intelligence; Collective behaviour; Exploration and exploitation; Global optimisation; Metaheuristic; Optimization problems; Optimizers; Power engineering; Search-based; Swarm intelligence algorithms; Systematic literature review; Software testing|Review|Final|All Open Access; Gold Open Access|Scopus|2-s2.0-85149384508
scopus|Hai T.; Zhou J.; Li N.; Jain S.K.; Agrawal S.; Dhaou I.B.|Hai, Tao (36350315600); Zhou, Jincheng (57846566700); Li, Ning (57749301900); Jain, Sanjiv Kumar (57203170932); Agrawal, Shweta (57201245355); Dhaou, Imed Ben (6603398497)|36350315600; 57846566700; 57749301900; 57203170932; 57201245355; 6603398497|Cloud-based bug tracking software defects analysis using deep learning|2022|Journal of Cloud Computing|11|1|32||||22|10.1186/s13677-022-00311-8|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137319876&doi=10.1186%2fs13677-022-00311-8&partnerID=40&md5=49a66e95fadd41cf3cddce12bead1b0a|Cloud technology is not immune to bugs and issue tracking. A dedicated system is required that will extremely error prone and less cumbersome and must command a high degree of collaboration, flexibility of operations and smart decision making. One of the primary goals of software engineering is to provide high-quality software within a specified budget and period for cloud-based technology. However, defects found in Cloud-Based Bug Tracking software’s can result in quality reduction as well as delay in the delivery process. Therefore, software testing plays a vital role in ensuring the quality of software in the cloud, but software testing requires higher time and cost with the increase of complexity of user requirements. This issue is even cumbersome in the embedded software design. Early detection of defect-prone components in general and embedded software helps to recognize which components require higher attention during testing and thereby allocate the available resources effectively and efficiently. This research was motivated by the demand of minimizing the time and cost required for Cloud-Based Bug Tracking Software testing for both embedded and general-purpose software while ensuring the delivery of high-quality software products without any delays emanating from the cloud. Not withstanding that several machine learning techniques have been widely applied for building software defect prediction models in general, achieving higher prediction accuracy is still a challenging task. Thus, the primary aim of this research is to investigate how deep learning methods can be used for Cloud-Based Bug Tracking Software defect detection with a higher accuracy. The research conducted an experiment with four different configurations of Multi-Layer Perceptron neural network using five publicly available software defect datasets. Results of the experiments show that the best possible network configuration for software defect detection model using Multi-Layer Perceptron can be the prediction model with two hidden layers having 25 neurons in the first hidden layer and 5 neurons in the second hidden layer. © 2022, The Author(s).|Deep learning; Detection; Multi-layer perceptron; Prediction; Software defects|Budget control; Decision making; Deep learning; Defects; Learning systems; Multilayer neural networks; Network layers; Software design; Software testing; Bug tracking; Cloud-based; Deep learning; Defect detection; Detection; Hidden layers; High-quality software; Multilayers perceptrons; Software defects; Software testings; Forecasting|Article|Final|All Open Access; Gold Open Access|Scopus|2-s2.0-85137319876
scopus||||AISTA 2022 - Proceedings of the 2nd ACM International Workshop on AI and Software Testing/Analysis, Co-located with ISSTA 2022|2022|AISTA 2022 - Proceedings of the 2nd ACM International Workshop on AI and Software Testing/Analysis, Co-located with ISSTA 2022||||||23|0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137183870&partnerID=40&md5=582f42bb2bbe41c229c111040e584450|The proceedings contain 3 papers. The topics discussed include: TEESlice: slicing DNN models for secure and efficient deployment; test case prioritization based on neural networks classification; and Bugsby: a tool support for bug triage automation. |||Conference review|Final||Scopus|2-s2.0-85137183870
scopus|Li W.; Spatola Rossi C.; Coulon F.; Yang Z.|Li, Wenliang (57259433700); Spatola Rossi, Carla (58131211400); Coulon, Frederic (55887153000); Yang, Zhugen (57411789900)|57259433700; 58131211400; 55887153000; 57411789900|Smartphone-based sensors for water quality|2023|Comprehensive Analytical Chemistry|101|||197|221|24|1|10.1016/bs.coac.2023.02.006|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152579874&doi=10.1016%2fbs.coac.2023.02.006&partnerID=40&md5=ea1825807bb48540bdc17317dba4e79b|According to United States Geological Survey, water quality refers to suitability measurements on physical, chemical, and biological characteristics for usages. Since water is largely involved in anthropogenic activities, water quality is of grave importance. Rapid sensors are essential for providing an accurate and timely assessment of water contaminants in rural and remote areas. Current technologies are largely dependent on the laboratory infrastructure and experienced personnel, and the detection procedures and data analysis are time-consuming. The emergence of smartphone-based technology has enabled real-time and automated testing for a plethora of contaminants in water, especially in resource limited settings. Smartphone-based sensing platforms have the capability of providing multiple functions, e.g., using cameras to capture fluorescent and colorimetric images, and software applications for automated data interpretation and statistical analysis. Furthermore, smartphone-based applications, offer the possibility to share the data from one user to the next, enabling rapid communication between centralized laboratories and the onsite testing location. In this chapter, we provide a summary of novel smartphone-based sensing techniques and their application on various aspects of water analysis, including monitoring physical and chemical properties of water, as well as chemicals and biological contaminants. Smartphone-based sensing technology has shown excellent performance to conventional techniques, while considerably reducing the detection times and complexity of detection procedures. Future advances in artificial intelligence and Internet of Things have the potential to further enhance sensing platforms by reducing human intervention, increasing analytical sensitivities, and providing much needed connectivity between testing locations and laboratories worldwide. © 2023 Elsevier B.V.|Environmental monitoring; Public health; Smartphone-based sensing technology; Water analysis||Book chapter|Final||Scopus|2-s2.0-85152579874
scopus|Cvitic P.H.; Dobslaw F.; De Oliveira Neto F.G.|Cvitic, Petya Hristova (58293968400); Dobslaw, Felix (36442335300); De Oliveira Neto, Francisco Gomes (35247739300)|58293968400; 36442335300; 35247739300|Investigating Software Testing and Maintenance of Open-Source Distributed Ledger|2023|Proceedings - 2023 IEEE International Conference on Software Analysis, Evolution and Reengineering, SANER 2023||||886|896|10|1|10.1109/SANER56733.2023.00107|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160513883&doi=10.1109%2fSANER56733.2023.00107&partnerID=40&md5=9d0f6df880e60361ec6a0d344e1655ce|A distributed ledger is the backbone of all blockchain solutions. It provides a shared database spreading across a network of nodes. The number of DL solutions and their implementations has grown in recent years. Besides the architectural and performance promises of thesesolutions, organizations seekingto implement DL also need to consider the overall quality of the software available and its ecosystem. Particularly, previous research has identified the need to better understand the testing and maintenance practices behind these types of technologies. This paper investigates the testing and maintenance of 18 different open-source projects that implement distributed ledgers. We perform a manual inspection of test artefacts and mine the history of commits, issues and contributors of the chosen projects to understand the landscape of testing and maintenance in these projects. Our findings suggest that unit and integration tests are present in most projects, they do not follow a holistic system testing approach. Moreover, projects rely on a small team of core contributors (5 on average). While the projects are continuously maintained, larger changes are uncommon. Our results can be used for benchmarking and pinpointing areas of improvement for the development of distributed ledgers. © 2023 IEEE.|blockchain; distributed ledger; software maintenance; software testing|Computer software maintenance; Distributed ledger; Integration testing; Open source software; Open systems; Block-chain; Maintenance practices; Manual inspection; Open source projects; Open-source; Overall quality; Performance; Software testings; Testing and maintenance; Type of technology; Blockchain|Conference paper|Final||Scopus|2-s2.0-85160513883
scopus|Tian Z.; Chen J.; Zhu Q.; Yang J.; Zhang L.|Tian, Zhao (57214692436); Chen, Junjie (57145642900); Zhu, Qihao (59718923000); Yang, Junjie (58080825900); Zhang, Lingming (57203347002)|57214692436; 57145642900; 59718923000; 58080825900; 57203347002|Learning to Construct Better Mutation Faults|2022|ACM International Conference Proceeding Series|||64||||24|10.1145/3551349.3556949|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146951978&doi=10.1145%2f3551349.3556949&partnerID=40&md5=d39a3a915ab0b20398a08e4c2e6d6f41|Mutation faults are the core of mutation testing and have been widely used in many other software testing and debugging tasks. Hence, constructing high-quality mutation faults is critical. There are many traditional mutation techniques that construct syntactic mutation faults based on a limited set of manually-defined mutation operators. To improve them, the state-of-the-art deep-learning (DL) based technique (i.e., DeepMutation) has been proposed to construct mutation faults by learning from real faults via classic sequence-to-sequence neural machine translation (NMT). However, its performance is not satisfactory since it cannot ensure syntactic correctness of constructed mutation faults and suffers from the effectiveness issue due to the huge search space and limited features by simply treating each targeted method as a token stream. In this work, we propose a novel DL-based mutation technique (i.e., LEAM) to overcome the limitations of both traditional techniques and DeepMutation. LEAM adapts the syntax-guided encoder-decoder architecture by extending a set of grammar rules specific to our mutation task, to guarantee syntactic correctness of constructed mutation faults. Instead of predicting a sequence of tokens one by one to form a whole mutated method, it predicts the statements to be mutated under the context of the targeted method to reduce search space, and then predicts grammar rules for mutation fault construction based on both semantic and structural features in AST. We conducted an extensive study to evaluate LEAM based on the widely-used Defects4J benchmark. The results demonstrate that the mutation faults constructed by LEAM can not only better represent real faults than two state-of-the-art traditional techniques (i.e., Major and PIT) and DeepMutation, but also substantially boost two important downstream applications of mutation faults, i.e., test case prioritization and fault localization.  © 2022 ACM.|Deep Learning; Fault Injection; Mutation Testing|Deep learning; Program debugging; Semantics; Software testing; Deep learning; Fault injection; Grammar rules; High quality; Mutation testing; Search spaces; Software Testing and Debugging; State of the art; Syntactic mutation; Traditional techniques; Syntactics|Conference paper|Final||Scopus|2-s2.0-85146951978
scopus|Chatterjee A.; Ahmed B.S.; Hallin E.; Engman A.|Chatterjee, Ayan (57807545700); Ahmed, Bestoun S. (56591882100); Hallin, Erik (57847489500); Engman, Anton (57847489600)|57807545700; 56591882100; 57847489500; 57847489600|Testing of machine learning models with limited samples: an industrial vacuum pumping application|2022|ESEC/FSE 2022 - Proceedings of the 30th ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering||||1280|1290|10|2|10.1145/3540250.3558943|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143079890&doi=10.1145%2f3540250.3558943&partnerID=40&md5=b2b46a4d1460bb47e0c61cdca9a0f001|There is often a scarcity of training data for machine learning (ML) classification and regression models in industrial production, especially for time-consuming or sparsely run manufacturing processes. Traditionally, a majority of the limited ground-truth data is used for training, while a handful of samples are left for testing. In that case, the number of test samples is inadequate to properly evaluate the robustness of the ML models under test (i.e., the system under test) for classification and regression. Furthermore, the output of these ML models may be inaccurate or even fail if the input data differ from the expected. This is the case for ML models used in the Electroslag Remelting (ESR) process in the refined steel industry to predict the pressure in a vacuum chamber. A vacuum pumping event that occurs once a workday generates a few hundred samples in a year of pumping for training and testing. In the absence of adequate training and test samples, this paper first presents a method to generate a fresh set of augmented samples based on vacuum pumping principles. Based on the generated augmented samples, three test scenarios and one test oracle are presented to assess the robustness of an ML model used for production on an industrial scale. Experiments are conducted with real industrial production data obtained from Uddeholms AB steel company. The evaluations indicate that Ensemble and Neural Network are the most robust when trained on augmented data using the proposed testing strategy. The evaluation also demonstrates the proposed method's effectiveness in checking and improving ML algorithms' robustness in such situations. The work improves software testing's state-of-the-art robustness testing in similar settings. Finally, the paper presents an MLOps implementation of the proposed approach for real-time ML model prediction and action on the edge node and automated continuous delivery of ML software from the cloud.  © 2022 Owner/Author.|data augmentation; data decomposition; machine learning; mlops; software testing; vacuum pumping|Classification (of information); Learning algorithms; Machine learning; Manufacture; Regression analysis; Software testing; Steelmaking; Testing; Data augmentation; Data decomposition; Industrial production; Machine learning models; Machine-learning; Mlops; Pumping applications; Software testings; Test samples; Vacuum pumping; Application programs|Conference paper|Final|All Open Access; Bronze Open Access; Green Open Access|Scopus|2-s2.0-85143079890
scopus|Kukushkin K.; Ryabov Y.; Borovkov A.|Kukushkin, Kuzma (57208472576); Ryabov, Yury (57200114015); Borovkov, Alexey (8840090300)|57208472576; 57200114015; 8840090300|Digital Twins: A Systematic Literature Review Based on Data Analysis and Topic Modeling|2022|Data|7|12|173||||54|10.3390/data7120173|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144595103&doi=10.3390%2fdata7120173&partnerID=40&md5=8626b57e7ee02faf6715cefab4d55af8|The digital twin has recently become a popular topic in research related to manufacturing, such as Industry 4.0, the industrial internet of things, and cyber-physical systems. In addition, digital twins are the focus of several research areas: construction, urban management, digital transformation of the economy, medicine, virtual reality, software testing, and others. The concept is not yet fully defined, its scope seems unlimited, and the topic is relatively new; all this can present a barrier to research. The main goal of this paper is to develop a proper methodology for visualizing the digital-twin science landscape using modern bibliometric tools, text-mining and topic-modeling, based on machine learning models—Latent Dirichlet Allocation (LDA) and BERTopic (Bidirectional Encoder Representations from Transformers). The scope of the study includes 8693 publications on the topic selected from the Scopus database, published between January 1993 and September 2022. Keyword co-occurrence analysis and topic-modeling indicate that studies on digital twins are still in the early stage of development. At the same time, the core of the topic is growing, and some topic clusters are emerging. More than 100 topics can be identified; the most popular and fastest-growing topic is ‘digital twins of industrial robots, production lines and objects.’ Further efforts are needed to verify the proposed methodology, which can be achieved by analyzing other research fields. © 2022 by the authors.|BERTopic; bibliometrics; data analysis; digital twin; LDA model; machine learning; systematic literature review; topic-modeling|Data handling; E-learning; Embedded systems; Industrial research; Industrial robots; Information analysis; Software testing; Statistics; Virtual reality; Allocation model; Bertopic; Bibliometric; Cyber-physical systems; Data analysis models; Latent Dirichlet allocation; Latent dirichlet allocation model; Machine-learning; Systematic literature review; Topic Modeling; Machine learning|Article|Final|All Open Access; Gold Open Access|Scopus|2-s2.0-85144595103
scopus|Huang J.-T.; Zhang J.; Wang W.; He P.; Su Y.; Lyu M.R.|Huang, Jen-Tse (57606518100); Zhang, Jianping (57609185000); Wang, Wenxuan (57386731700); He, Pinjia (56241158600); Su, Yuxin (56717004400); Lyu, Michael R. (7006811415)|57606518100; 57609185000; 57386731700; 56241158600; 56717004400; 7006811415|AEON: A method for automatic evaluation of NLP test cases|2022|ISSTA 2022 - Proceedings of the 31st ACM SIGSOFT International Symposium on Software Testing and Analysis||||202|214|12|17|10.1145/3533767.3534394|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136809594&doi=10.1145%2f3533767.3534394&partnerID=40&md5=28cdf9adb24897b33c26251d9011e542|Due to the labor-intensive nature of manual test oracle construction, various automated testing techniques have been proposed to enhance the reliability of Natural Language Processing (NLP) software. In theory, these techniques mutate an existing test case (e.g., a sentence with its label) and assume the generated one preserves an equivalent or similar semantic meaning and thus, the same label. However, in practice, many of the generated test cases fail to preserve similar semantic meaning and are unnatural (e.g., grammar errors), which leads to a high false alarm rate and unnatural test cases. Our evaluation study finds that 44% of the test cases generated by the state-of-The-Art (SOTA) approaches are false alarms. These test cases require extensive manual checking effort, and instead of improving NLP software, they can even degrade NLP software when utilized in model training. To address this problem, we propose AEON for Automatic Evaluation Of NLP test cases. For each generated test case, it outputs scores based on semantic similarity and language naturalness. We employ AEON to evaluate test cases generated by four popular testing techniques on five datasets across three typical NLP tasks. The results show that AEON aligns the best with human judgment. In particular, AEON achieves the best average precision in detecting semantic inconsistent test cases, outperforming the best baseline metric by 10%. In addition, AEON also has the highest average precision of finding unnatural test cases, surpassing the baselines by more than 15%. Moreover, model training with test cases prioritized by AEON leads to models that are more accurate and robust, demonstrating AEON's potential in improving NLP software.  © 2022 ACM.|NLP software testing; test case quality|Errors; Natural language processing systems; Quality control; Software reliability; Software testing; Automatic evaluation; Language processing; Model training; Natural language processing software testing; Natural languages; Processing software; Software testings; Test case; Test case quality; Testing technique; Semantics|Conference paper|Final|All Open Access; Green Open Access|Scopus|2-s2.0-85136809594
scopus|Ma Y.; Zhao W.; Huang S.|Ma, Yongchao (58290107300); Zhao, Wei (55574200145); Huang, Songling (7405418009)|58290107300; 55574200145; 7405418009|Review on techniques for improving the reliability of smart meters; [提高智能电能表可靠性技术研究综述]|2022|Electrical Measurement and Instrumentation|59|4||1|7|6|7|10.19753/j.issn1001-1390.2020.04.001|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175968601&doi=10.19753%2fj.issn1001-1390.2020.04.001&partnerID=40&md5=f9a7d5db4b82196107c066d99778d720|The smart meter plays an increasingly important role in power grids.However, operation failures, caused by different faults during power metering, are often observed.Therefore, how to improve the reliability of smart meters becomes important and has been focused by many studies.In this paper, based on the general structure and function of a smart meter, we summarize the existing techniques for improving the reliability of smart meter from two perspectives of the inherent reliability and the use reliability respectively.The inherent reliability includes the structure design, hardware reliability analysis, key module development, software testing and so on.While the use reliability focuses on error compensation and operating status detection for smart meters.The latter category involves evaluation systems based on full life cycle theory, and the artificial intelligence technologies represented by neural networks, Bayesian algorithm, K-means algorithm, etc.Finally, future development trends towards reliability techniques of smart meter are discussed. © 2022 Harbin Jinhe Electrical Measurement & Instrumentation Magazine Publishing Co., Ltd.. All rights reserved.|artificial intelligence technology; big data; inherent reliability; smart meter; software testing; use reliability||Article|Final||Scopus|2-s2.0-85175968601
scopus|Zhou X.; Wang X.; Liu W.; Wang Z.|Zhou, Xiaofan (58001350900); Wang, Xueqi (58616162600); Liu, Wei (59890137000); Wang, Zhuozheng (24470607300)|58001350900; 58616162600; 59890137000; 24470607300|Classification Model of Depression Based on the CNN-LSTM Network|2023|Proceedings - 2023 3rd International Conference on Frontiers of Electronics, Information and Computation Technologies, ICFEICT 2023||||210|214|4|1|10.1109/ICFEICT59519.2023.00044|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172110296&doi=10.1109%2fICFEICT59519.2023.00044&partnerID=40&md5=dc5cb678a7b36aff2c516807f9030529|Depression is a common psychological disorder, which can be extremely damaging people both physically and psychologically. A rapid and accurate programme of review of depressed mood is therefore important. This project used the Depression Rest dataset for 2 classifications of depression, including none and depression. A hybrid CNN-LSTM network was used, combining the advantages of convolutional neural networks and long and short-term memory networks, which is good for processing both sequential and temporal data. After tuning and training, the test set achieved an average classification accuracy of 95.5% with excellent performance. The research significance of this project is that depression is a common psychological disorder, but it is difficult to diagnose with subjective observation. Big data analysis and machine learning techniques to accurately determine the degree of depression can provide strong support for early screening, diagnosis and treatment of depression. The study also provides a valuable reference for future automated testing of depression levels based on biomarkers.  © 2023 IEEE.|CNN-LSTM; Depression; EEG; Yule-Walker|Classification (of information); Convolutional neural networks; Long short-term memory; Classification models; CNN-LSTM; Convolutional neural network; Depression; Long and short term memory; Memory network; Psychological disorders; Sequential data; Temporal Data; Yule-walker; Learning systems|Conference paper|Final||Scopus|2-s2.0-85172110296
scopus|Seneviratne S.M.N.S.K.; Penenco V.; Kasthurirathna D.|Seneviratne, S.M.N.S.K. (58743751700); Penenco, Victoria (58743324200); Kasthurirathna, Dharshana (54420261000)|58743751700; 58743324200; 54420261000|AD-PU: A Novel Approach for Automated Identification of the Outliers in User Interface Testing (UAT)|2023|AUTOTESTCON (Proceedings)|||||||0|10.1109/AUTOTESTCON47464.2023.10296279|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178514349&doi=10.1109%2fAUTOTESTCON47464.2023.10296279&partnerID=40&md5=d981c00799981d71e47d4761afe5dc47|User acceptance testing (UAT) is the process that validates the system under test (SUT) behaves according to the business requirements. A User would use the graphical user interface to interact with the underlying code. With the improvement of various devices, end-user testing has become even more complex and time consuming. Every user has a unique interaction pattern. Due to this expected test coverage would not be met by focusing only on the functionality itself. This research is to address the issue of UAT test automation coverage and reduce defect leakage in production environments. The proposed automation solution is to identify more defects in the UAT static testing phase and make the system under test more user friendly before handing the product to the consumers. The proposed solution use Machine learning approach to identify user behaviors that does not match the proposed new functionality. The proposed AD-PU model would evaluate non-prominent user behaviours as per perceived usefulness which would effect the decision to accept the functionality as user acceptable or not.  © 2023 IEEE.|GUI; Machine learning; SUT; UAT|Acceptance tests; Automation; Behavioral research; Defects; Machine learning; Automated identification; Business requirement; End user testing; Interaction pattern; Interface testings; Machine-learning; Systems under tests; User acceptance testing; User behaviors; User interface testing; Graphical user interfaces|Conference paper|Final||Scopus|2-s2.0-85178514349
scopus|Leotta M.; Ricca F.; Stoppa S.; Marchetto A.|Leotta, Maurizio (37104276100); Ricca, Filippo (24822686600); Stoppa, Simone (57889348800); Marchetto, Alessandro (23971457800)|37104276100; 24822686600; 57889348800; 23971457800|Is NLP-based Test Automation Cheaper Than Programmable and Capture &Replay?|2022|Communications in Computer and Information Science|1621 CCIS|||77|92|15|2|10.1007/978-3-031-14179-9_6|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137976205&doi=10.1007%2f978-3-031-14179-9_6&partnerID=40&md5=77ba83ab363384f38e1e09268fdc6f97|Nowadays, there is a growing interest in the use of Natural-Language Processing (NLP) for supporting software test automation. This paper investigates the adoption of NLP in web testing. To this aim, a case study has been conducted to compare the cost of the adoption of a NLP testing approach, with respect to more consolidated approaches, i.e., programmable testing and capture and replay testing, in two testing tasks: test cases development and test case evolution/maintenance. Even if preliminary, results show that NLP testing is quite competitive with respect to the more consolidated approaches since the cumulative testing effort of a NLP testing approach, computed considering both development and evolution efforts, is almost always lower than the one of programmable testing and capture &replay testing. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.|Artificial intelligence; NLP; Test automation; Web testing|Automation; Natural language processing systems; Testing; Capture-replay; Case-studies; Development case; Language processing; Natural languages; Natural-language processing; Software test automation; Test Automation; Test case; Web testing; Software testing|Conference paper|Final||Scopus|2-s2.0-85137976205
scopus|Kokol P.|Kokol, Peter (7006196824)|7006196824|Software Quality: How Much Does It Matter?|2022|Electronics (Switzerland)|11|16|2485||||10|10.3390/electronics11162485|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137414123&doi=10.3390%2felectronics11162485&partnerID=40&md5=4d514e3ac1a30021822ef2d6f0b908b2|Interconnected computers and software systems have become an indispensable part of people’s lives in the period of digital transformation. Consequently, software quality research is becoming more and more critical. There have been multiple attempts to synthesise knowledge gained in software quality research; however, they were focused mainly on single aspects of software quality and did not structure the knowledge holistically. To fill this gap, we harvested software quality publications indexed in the Scopus bibliographic database. We analysed them using synthetic content analysis which is a triangulation of bibliometrics and content analysis. The search resulted in 15,468 publications. The performance bibliometric analysis showed that the production of research publications relating to software quality is currently following an exponential growth trend and that the software quality research community is growing. The most productive country was the United States, followed by China. The synthetic content analysis revealed that the published knowledge could be structured into six themes, the most important being the themes regarding software quality improvement by enhancing software engineering, advanced software testing and improved defect and fault prediction with machine learning and data mining. © 2022 by the author.|bibliometrics; knowledge synthesis; software engineering; software quality; synthetic knowledge synthesis||Review|Final|All Open Access; Gold Open Access|Scopus|2-s2.0-85137414123
scopus|Wibowo A.W.; Karima A.; Thohari A.N.A.; Santoso K.; Sato-Shimokawara E.|Wibowo, Angga Wahyu (58395104500); Karima, Aisyatul (58393539700); Thohari, Afandi Nur Aziz (58393539800); Santoso, Kuwat (58394326000); Sato-Shimokawara, Eri (25031564100)|58395104500; 58393539700; 58393539800; 58394326000; 25031564100|(PANDEMIC Covid-19): A Shooter Game for Education-Measuring The Impact of War Games on Virus Eradication Lessons for Students|2023|International Journal on Informatics Visualization|7|2||423|429|6|1|10.30630/joiv.7.2.1167|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163415370&doi=10.30630%2fjoiv.7.2.1167&partnerID=40&md5=7f87f69dbac9404b475b3f24d870bf54|(PANDEMIC Covid-19) is an educational shooter game inspired by the Covid-19 pandemic which occurred from the end of 2019 until early 2022. There are 2 game modes, namely Third-Person Shooter, or TPS, and First-Person Shooter, or FPS. This study was carried out to highlight the absence of a shooter genre game used in the student learning process. The research methodology in the development of this game applied the pressman method, and the stages include planning, analysis, game development and artificial intelligence, implementation, as well as evaluation. Furthermore, the testing phase used software testing techniques based on the ISO 9126 standard and involved a total of 100 participants. The age range was between 17 and 20 years, while the participants' gender percentages were 55% male and 45% female. Some of the factors tested include functionality, reliability, portability, usability, efficiency, and maintainability. There were 2 choices only in this test, i.e. agree and disagree. The functionality factor had an agreed rate of 85%; reliability 79%, portability 86%, usability 83%, efficiency 79%, and maintainability 87%. Therefore, it was concluded that this game is suitable for use in student learning in the shooter genre. Furthermore, this research was inspired because shooter games have not been developed for the student learning process. This game genre is currently used for hobbies and for profit by developers and professional players. Further research should develop game levels, enable features to play online together with other users, and should be extended to Android and IOS. © 2023, Politeknik Negeri Padang. All rights reserved.|Covid-19; game; ISO 9126; Pandemic||Article|Final|All Open Access; Gold Open Access|Scopus|2-s2.0-85163415370
scopus|Purohit S.; Singh S.; Agarwal M.; Verma N.|Purohit, Siddhi (58193161400); Singh, Simran (58193161500); Agarwal, Mansi (58194272300); Verma, Neha (58193161600)|58193161400; 58193161500; 58194272300; 58193161600|A Qualitative and Comprehensive Analysis of Software Testability Metrics and their Trends|2023|Proceedings of the 2023 2nd International Conference on Electronics and Renewable Systems, ICEARS 2023||||1545|1552|7|2|10.1109/ICEARS56392.2023.10085333|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153406700&doi=10.1109%2fICEARS56392.2023.10085333&partnerID=40&md5=7cf099264c94e20720b8f92236004377|Advancement in technology has resulted in birth of critical and complex software. These require thorough testing to ensure production of reliable and high performance software. Testing is the most expensive part of the software life cycle and an estimate of testing efforts can result in smart utilization of resources. Testability is the ease of finding faults in a software and its estimate can reduce costs and increase life of the software. However the area lacks adequate research and standardisation. Current studies majorly report on Object Oriented paradigm and code level testability. This study aims to provide a broader review on Testability metrics, models and establishing relationship between program attributes and testability. Through this survey 29 studies have been selected for analysis. Our studies conclude that testability metrics at code level and design metric corresponding to size are commonly used. Relationships amongst these metrics with their test efforts are established using various machine learning models and presents testability trends with various program attributes. This comprehensive review helps in identifying suitable metric, expected trends with various program attributes and selection of suitable models to automate processes.  © 2023 IEEE.|Controllability; Observability; Software Testability Metric; Source code metrics|Codes (symbols); Life cycle; Object oriented programming; Observability; Complex software; Comprehensive analysis; Critical software; Performance; Program attributes; Qualitative analysis; Software testability; Software testability metric; Source code metrics; Testability; Software testing|Conference paper|Final||Scopus|2-s2.0-85153406700
scopus||||Proceedings - 2023 IEEE/ACM 5th International Workshop on Software Engineering Education for the Next Generation, SEENG 2023|2023|Proceedings - 2023 IEEE/ACM 5th International Workshop on Software Engineering Education for the Next Generation, SEENG 2023||||||44|0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168699751&partnerID=40&md5=977059e2b3efeefff69c3a6ba7ece84a|The proceedings contain 8 papers. The topics discussed include: Gamify-IT - a web-based gaming platform for software engineering education; hey teachers, teach those kids some software testing; improving the quality of commit messages in students’ projects; learning to write user stories with the 4C model: context, card, conversation, and confirmation; not just a matter of style: does aesthetics have a place in software engineering curriculum?; towards a generic model for classifying software into correctness levels and its application to SQL; ‘we need to talk about ChatGPT’: the future of AI and higher education; and ‘work in the morning instead of midnight’ and other lessons learned in FinTech 512.|||Conference review|Final||Scopus|2-s2.0-85168699751
scopus|Rosenbauer L.; Pätzel D.; Stein A.; Hähner J.|Rosenbauer, Lukas (57218600362); Pätzel, David (57203392600); Stein, Anthony (56226088700); Hähner, Jörg (20436196300)|57218600362; 57203392600; 56226088700; 20436196300|A Learning Classifier System for Automated Test Case Prioritization and Selection|2022|SN Computer Science|3|5|373||||2|10.1007/s42979-022-01255-1|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134245413&doi=10.1007%2fs42979-022-01255-1&partnerID=40&md5=bf43bea2c8e898e89e5655c8af1e4bf7|For many everyday devices, each newly released model contains more functionality. This technological advance relies heavily on software solutions of increasing complexity which results in novel challenges in the domain of software testing. Most prominently, while an ever higher number of test cases is required to meet quality demands, performing a large number of test cases frequently amounts to a significant increase in development time and costs. In order to overcome this issue, agile development methods such as continuous integration usually only execute a subset of important test cases to meet both time and testing demands. One way of selecting such a subset of important test cases is to assign priorities to all the available test cases and then greedily pick the ones with the highest priority until the available time budget is spent. For this, in a previous work, we presented a new machine learning approach based on a learning classifier system (LCS). In the present article, we summarize our earlier findings (which are spread over several publications) and provide insights about the most recent adaptations we made to the method. We also provide an extended experimental analysis that outlines more in detail how it compares to a state of the art artificial neural network. It can be observed that the performance of our LCS-based approach is often much higher than the one of the network. Since our work has already been deployed by a major company, we give an overview of the resulting product as well as several of its in-production quality attributes. © 2022, The Author(s), under exclusive licence to Springer Nature Singapore Pte Ltd.|Continuous integration; Evolutionary machine learning; Software testing; XCSF classifier system||Article|Final||Scopus|2-s2.0-85134245413
scopus|Jaganeshwari K.; Djodilatchoumy S.|Jaganeshwari, K. (57224619631); Djodilatchoumy, S. (56575169900)|57224619631; 56575169900|AN AUTOMATED TESTING TOOL BASED ON GRAPHICAL USER INTERFACE WITH EXPLORATORY BEHAVIOURAL ANALYSIS|2022|Journal of Theoretical and Applied Information Technology|100|22||6657|6666|9|4||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143391238&partnerID=40&md5=c1fa71356243c99d5ffb7aeffd4898c9|Web-based applications have complex mechanisms, and it is challenging to perform any test. Computerization examination applies automation tools to decrease individual interference and repeatable assignments. In this article, we have designed and implemented an automation testing framework for web applications. The Selenium WebDriver tool was used to execute this innovative automated testing model. With this structure, testers can match the widgets with pre-trained dataset by taking screenshots of the web pages and by clicking automatically using PyAutoGUI. The screenshot property of the framework is useful to creators for evaluating their design of the web page. We introduced a novel methodology for widget detection, widget classification and testing coverage using machine learning and image processing concept. In this approach, we can give the URL as input, so, the GUI widget images can be quickly captured from the server and do not require large storage repositories to be used as training samples. Widgets of GUI images are detected from the pre-trained datasets by applying BLOB text detection. After identifying the widgets, they are classified into domain-specific categories, for example, labels, buttons, input boxes, check boxes, and links). Finally, it is evaluated to achieve a mean GUI component categorization of superior precision. Previous works have mostly used Java GUIs, Python GUIs, and Visual Basic GUIs to distinguish the types of widgets, but in our work, we observed the types of widgets using Image Processing. From this automated testing implementation on web applications, we have achieved 98.4%. of test coverage accuracy. © 2022 Little Lion Scientific.|Automated Testing; Computer Vision; DNN; GUI; Image processing||Article|Final||Scopus|2-s2.0-85143391238
scopus|Kusharki M.B.; Misra S.; Muhammad-Bello B.; Salihu I.A.; Suri B.|Kusharki, Muhammad Bello (57656078300); Misra, Sanjay (56962766700); Muhammad-Bello, Bilkisu (57192921115); Salihu, Ibrahim Anka (57077031600); Suri, Bharti (55515690800)|57656078300; 56962766700; 57192921115; 57077031600; 55515690800|Automatic Classification of Equivalent Mutants in Mutation Testing of Android Applications|2022|Symmetry|14|4|820||||9|10.3390/sym14040820|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129172137&doi=10.3390%2fsym14040820&partnerID=40&md5=e853c7d5ea41840d24392c5e3c5ff665|Software and symmetric testing methodologies are primarily used in detecting software defects, but these testing methodologies need to be optimized to mitigate the wasting of resources. As mobile applications are becoming more prevalent in recent times, the need to have mobile applications that satisfy software quality through testing cannot be overemphasized. Testing suites and software quality assurance techniques have also become prevalent, which underscores the need to evaluate the efficacy of these tools in the testing of the applications. Mutation testing is one such technique, which is the process of injecting small changes into the software under test (SUT), thereby creating mutants. These mutants are then tested using mutation testing techniques alongside the SUT to determine the effectiveness of test suites through mutation scoring. Although mutation testing is effective, the cost of implementing it, due to the problem of equivalent mutants, is very high. Many research works gave varying solutions to this problem, but none used a standardized dataset. In this research work, we employed a standard mutant dataset tool called MutantBench to generate our data. Subsequently, an Abstract Syntax Tree (AST) was used in conjunction with a tree-based convolutional neural network (TBCNN) as our deep learning model to automate the classification of the equivalent mutants to reduce the cost of mutation testing in software testing of android applications. The result shows that the proposed model produces a good accuracy rate of 94%, as well as other performance metrics such as recall (96%), precision (89%), F1-score (92%), and Matthew’s correlation coefficients (88%) with fewer False Negatives and False Positives during testing, which is significant as it implies that there is a decrease in the risk of misclassification. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.|android applications; artificial intelligence; mutation testing; software testing; tree-based convolutional neural networks||Article|Final|All Open Access; Gold Open Access; Green Open Access|Scopus|2-s2.0-85129172137
scopus|Kang D.|Kang, Dongsu (57679713900)|57679713900|Bridging Fuzz Testing and Metamorphic Testing for Classification of Machine Learning|2022|Digest of Technical Papers - IEEE International Conference on Consumer Electronics|2022-January||||||1|10.1109/ICCE53296.2022.9730476|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127035753&doi=10.1109%2fICCE53296.2022.9730476&partnerID=40&md5=88cd969f537ddc31d97f0ae008a47271|Artificial Intelligence (AI) built-in Consumer Electronics is popular, but it is hard to test and evaluate AI-based system with the existing performance metrics. Even though AI-based systems are implemented in software with flexibility, bias and non-determinism property etc., they can suffer the same defects as other software. That is why new software testing approaches are needed when testing AI-based systems. Therefore, this paper proposes a bridging approach between fuzz testing and metamorphic testing focus on the classification of machine learning. This approach can be used as a test oracle for classification of training data.  © 2022 IEEE.|classification; machine learning; metamorphic testing; test case.fuzz testing|Machine learning; Software testing; Fuzz Testing; Machine-learning; Metamorphic testing; Non Determinism; Performance metrices; Property; Software testings; Test case; Test case.; Test oracles; Classification (of information)|Conference paper|Final||Scopus|2-s2.0-85127035753
scopus|Bnouni Rhim N.; Ben Mabrouk M.|Bnouni Rhim, Nesrine (55837396400); Ben Mabrouk, Mouna (56916018100)|55837396400; 56916018100|NLP and Logic Reasoning for Fully Automating Test|2022|Lecture Notes in Networks and Systems|419 LNNS|||98|109|11|0|10.1007/978-3-030-96299-9_10|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126190417&doi=10.1007%2f978-3-030-96299-9_10&partnerID=40&md5=04eae82134d1fc5a08cb34c51d5e3544|Test automation allows automatizing some repetitive and tedious but essential tasks in a formalized testing process already in place, or to achieve additional testing that would be complicated manually. However, the automated testing software tools available today are typically used to execute a test case manually written and identified. However, it is a highly challenging task due to: (1) the large variability in structure of functional specification documents; (2) and the inter and intra observer variability across testers. In this work, we propose a novel automated test framework introducing three major contributions: (1) Modeling the interactions across all process (design, planning, and execution). Specifically, our framework permits the use of textual functional specifications to automate test projects. (2) Our framework automatizes test projects using Machine Learning (ML) and Natural Language Processing (NLP). Specifically, it automatically extracts automated test scenarios from functional specifications requirements. (3) The proposed method captures shared and complementary information between different processes. We evaluated our framework using 300 pages of project specification. We show that our framework is robust for the standardization of specification, the automatically extraction of test scenarios and the identification of automating scenarios. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.|Functional specification document; Machine Learning; Natural Language Processing; Test automation||Conference paper|Final||Scopus|2-s2.0-85126190417
scopus|Borana K.; Sharma M.; Abhyankar D.|Borana, Kamal (58304323900); Sharma, Meena (55468794600); Abhyankar, Deepak (57821507600)|58304323900; 55468794600; 57821507600|A Novel Software Quality Characteristic Recommendation Model to Handle the Dynamic Requirements of Software Projects that Improves Service Quality and Cost|2023|International Journal of Advanced Computer Science and Applications|14|7||561|569|8|0|10.14569/IJACSA.2023.0140762|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168807128&doi=10.14569%2fIJACSA.2023.0140762&partnerID=40&md5=d3032750d48e48f8240506b68ff219c9|The software is created and constructed to address particular issues in the applied field. In this context, there is a need to be aware of the crucial characteristics to assess the quality of software. But not all software requires checking all the quality-of-service parameters, resulting in effort loss and time consumption. Therefore, it is required to develop software quality characteristics recommendation model to address and resolve the issue. The proposed work involved in this paper can be subdivided into three main parts (1) a review of popular software quality models and their comparison to create a complete set of predictable, and (2) the design of an ML-based recommendation model for recommending the software quality model and software quality characteristics (3) performance analysis. The proposed recommendation system utilizes the different software quality of service attributes as well as the software attributes where these models are suitably applied to satisfy the demands. Profiling of applications and their essential requirements have been performed Based on the different quality of service parameters and the requirements of applications. These profiles are learned by machine learning algorithms for distinguishing the application-based requirement and recommending the essential attributes. The implementation of the proposed technique has been done using Python technology. The simulation aims to demonstrate how to minimize the cost of software testing and improve time and accuracy by utilizing the appropriate quality matrix. Finally, a conclusion has been drawn and the future extension of the proposed model has been reported. © 2023, Science and Information Organization. All Rights Reserved.|ML (Machine Learning); quality matrix; Recommendation system; software quality characteristics; software quality model|Computer software selection and evaluation; Learning algorithms; Machine learning; Quality of service; Software testing; Machine learning; Machine-learning; matrix; Quality matrix; Quality of Service parameters; Service costs; Service Quality; Software project; Software quality characteristics; Software quality modeling; Recommender systems|Article|Final|All Open Access; Gold Open Access|Scopus|2-s2.0-85168807128
scopus|Tweissi A.; Etaiwi W.A.; Eisawi D.A.|Tweissi, Adiy (57215002649); Etaiwi, Wael Al (26531155200); Eisawi, Dalia Al (55351167800)|57215002649; 26531155200; 55351167800|The Accuracy of AI-Based Automatic Proctoring in Online Exams|2022|Electronic Journal of e-Learning|20|4||419|435|16|14|10.34190/ejel.20.4.2600|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139937117&doi=10.34190%2fejel.20.4.2600&partnerID=40&md5=da88915ca84abecf1a0502457a077c6a|This study technically analyses one of the online exam supervision technologies, namely the Artificial Intelligence-based Auto Proctoring (AiAP). This technology has been heavily presented to the academic sectors around the globe. Proctoring technologies are developed to provide oversight and analysis of students’ behavior in online exams using AI, and sometimes with the supervision of human proctors to maintain academic integrity. Manual Testing methodology was used to do a software testing on AiAP for verification of any possible incorrect red flags or detections. The study took place in a Middle Eastern university by conducting online exams for 14 different courses, with a total of 244 students. The results were then verified by 5 human proctors in terms of monitoring measurements: screen violation, sound of speech, different faces, multiple faces, and eye movement detection. The proctoring decision was computed by averaging all monitoring measurements and then compared between the human proctors’ and the AiAP decisions, to ultimately set the AiAP against a benchmark (human proctoring) and hence to be viable for use. The decision represented the number of violations to the exam conditions, and the result showed a significant difference between Human Decision (average 25.95%) and AiAP Decision (average 35.61%), and the total number of incorrect decisions made by AiAP was 74 out of 244 exam attempts, concluding that AiAP needed some improvements and updates to meet the human level. The researchers provided some technical limitations, privacy concerns, and recommendations to carefully review before deploying and governing such proctoring technologies at institutional level. This paper contributes to the field of educational technology by providing an evidence-based accuracy test on an automatic proctoring software, and the results demand institutional provision to better establish an appropriate online exam experience for higher educational institutions. © The Authors.|academic integrity; AI-based proctoring; automatic proctoring; online exams; software accuracy||Article|Final|All Open Access; Gold Open Access|Scopus|2-s2.0-85139937117
scopus|Kalkar S.; Bose I.; Bobade S.; Anilkumar S.; Tavhare S.|Kalkar, Shreyas (57959733900); Bose, Indranil (59021445300); Bobade, Saloni (57303778100); Anilkumar, Sandhya (57958813600); Tavhare, Sarika (57425750800)|57959733900; 59021445300; 57303778100; 57958813600; 57425750800|Machine Learning Based Instrument Cluster Inspection Using Camera|2022|SAE Technical Papers|||||||0|10.4271/2022-28-0076|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141621535&doi=10.4271%2f2022-28-0076&partnerID=40&md5=eadb4a76d0fa5a3a341be45969cf91ab|In Automotive Industry, instrument clusters are used in all type of vehicles. It is an electronic instrument which displays and shows system function status, warnings, and failures/alerts. These displays and tell-tales help driver to get necessary information to drive the vehicle. Several gauges, such as speedometer, odometer, fuel-gauge etc, and other tell-tales for system failures and alerts, are included in vehicle dashboard. Instrument clusters give drivers a concentrated and easily accessible area for seeing all vital system data. The need of validation for instrument clusters become extremely important. The defects shall be caught at early stage to improve system behaviour and save product development cost. So, this is highly demanding to minimise manual testing time and effort while increasing testing accuracy to deliver defect-free product to customers. We are proposing test automation using camera to verify test results of instrument cluster using machine learning algorithm. The scope of this paper is to design a deep learning model that will be used to train, test and validate the model in HIL bench. The data base for which will be made using data scrapping from open-source images and image collected from existing IC The model will be integrated into an existing HIL bench automation setup. Using several python scripts for data collection and Yolov5 machine learning algorithm for object detection the accuracy is increased by 25% and time reduced by 24.35%.  © 2022 SAE International. All Rights Reserved.||Automobile electronic equipment; Automotive industry; Deep learning; Defects; Digital storage; Gages; Learning algorithms; Learning systems; Object detection; Systems engineering; Accessible areas; Electronic instruments; Instrument clusters; Machine learning algorithms; Machine-learning; System behaviors; System failures; System functions; Vehicle dashboards; Vital systems; Cameras|Conference paper|Final||Scopus|2-s2.0-85141621535
scopus||||Proceedings - 2023 IEEE/ACM International Conference on Software Engineering: Future of Software Engineering, ICSE-FoSE 2023|2023|Proceedings - 2023 IEEE/ACM International Conference on Software Engineering: Future of Software Engineering, ICSE-FoSE 2023||||||72|0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187702612&partnerID=40&md5=367223d61e6520b9d9d6f4c0b837c622|The proceedings contain 5 papers. The topics discussed include: software testing of generative ai systems: challenges and opportunities; future of software Engineering@ICSE 2023; large language models for software engineering: survey and open problems; software engineering for data intensive scalable computing and heterogeneous computing; and technical debt management: the road ahead for successful software delivery.|||Conference review|Final||Scopus|2-s2.0-85187702612
scopus||||16th International Conference on the Quality of Information and Communications Technology, QUATIC 2023|2023|Communications in Computer and Information Science|1871 CCIS|||||247|0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172472949&partnerID=40&md5=48404b9b8ec6ecfd4b603e55f3fc344e|The proceedings contain 17 papers. The special focus in this conference is on International Conference on the Quality of Information and Communications Technology. The topics include: Beyond Dashboards: Operationalising a Measurement Framework for Agile Teams; Exploring Data Analysis and Visualization Techniques for Project Tracking: Insights from the ITC; how a Professional Association Can Steer Digital Transformation: Case Study of the Belgian Notary Industry; DQBR25K: Data Quality Business Rules Identification Based on ISO/IEC 25012; pitching to the ‘Big Fish’: Elevating Presentation and Communication Skills in a Software Quality Course; quantum Services Generation and Deployment Process: A Quality-Oriented Approach; external Dependencies in Software Development; measuring Team Effectiveness in Scrum; quality Assurance of Digital Twins: An Experience Report in the Automotive Industry; continual Service Improvement: A Systematic Literature Review; elevating Software Quality Through Product Discovery Techniques: Key Findings from a Grey Literature Review; visual Milestone Planning in a Hybrid Development Context; quantum as a Service Architecture for Security in a Smart City; A Retrospective Analysis of Grey Literature for AI-Supported Test Automation; process Improvement Using the Scientific Method: Demonstration in Requirements Engineering.|||Conference review|Final||Scopus|2-s2.0-85172472949
scopus|Wang H.; Li J.; Zhang J.; Li W.; Li Y.; Ji X.|Wang, Huapeng (58162634700); Li, Jinsong (57671776900); Zhang, Jinhu (57212152549); Li, Wenzhuo (59891593300); Li, Yalei (57221017543); Ji, Xin (56896606900)|58162634700; 57671776900; 57212152549; 59891593300; 57221017543; 56896606900|Research on Test Technology of Smart Substation Based on Fault Simulation Injection Mode|2023|IET Conference Proceedings|2023|8||31|35|4|0|10.1049/icp.2023.1598|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174274872&doi=10.1049%2ficp.2023.1598&partnerID=40&md5=16cbf8eb89636767e10168039c81cc00|With the rapidly construction of smart grid, the degree of system and equipment interconnection is increasingly close, and a series of new technologies, such as big data, blockchain, Internet of Things, cloud computing, situation awareness, artificial intelligence, continue to promote and deepen their application in the system. Smart grid integrates a large number of new power automation systems and equipment such as new energy trading platform, smart big data platform, etc. Due to the lack of standardization of software system, frequent human-computer interaction, complex business logic and other reasons, the traditional power system software testing of the new smart grid combined with multiple systems has been unable to meet the needs of a large number of new power system products for updating, iteration and online verification. Therefore, there is an urgent need to study a new test technology to support the reliability evaluation of power systems, and provide guarantee for the safe and stable operation of the system. © The Institution of Engineering & Technology 2023.|COMMUNICATION INTERFACE; CONTROL CENTER; INFORMATION INTERACTION; SMART SUBSTATION|Automation; Big data; Computation theory; Distributed computer systems; Human computer interaction; Smart power grids; Verification; Block-chain; Communication interface; Control centre; Fault's simulations; Information interaction; Injection mode; Power; Smart grid; Smart substations; Test technology; Software testing|Conference paper|Final||Scopus|2-s2.0-85174274872
scopus|Eniser H.F.; Gros T.P.; Wüstholz V.; Hoffmann J.; Christakis M.|Eniser, Hasan Ferit (56814994200); Gros, Timo P. (57217287172); Wüstholz, Valentin (42263063400); Hoffmann, Jörg (23392307600); Christakis, Maria (35118649600)|56814994200; 57217287172; 42263063400; 23392307600; 35118649600|Metamorphic relations via relaxations: An approach to obtain oracles for action-policy testing|2022|ISSTA 2022 - Proceedings of the 31st ACM SIGSOFT International Symposium on Software Testing and Analysis||||52|63|11|11|10.1145/3533767.3534392|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132880935&doi=10.1145%2f3533767.3534392&partnerID=40&md5=114ee73c3352e26e185e1f8b37da895e|"Testing is a promising way to gain trust in a learned action policy €, in particular if πis a neural network. A ""bug""in this context constitutes undesirable or fatal policy behavior, e.g., satisfying a failure condition. But how do we distinguish whether such behavior is due to bad policy decisions, or whether it is actually unavoidable under the given circumstances? This requires knowledge about optimal solutions, which defeats the scalability of testing. Related problems occur in software testing when the correct program output is not known. Metamorphic testing addresses this issue through metamorphic relations, specifying how a given change to the input should affect the output, thus providing an oracle for the correct output. Yet, how do we obtain such metamorphic relations for action policies? Here, we show that the well explored concept of relaxations in the Artificial Intelligence community can serve this purpose. In particular, if state s′ is a relaxation of state s, i.e., s′ is easier to solve than s, and πfails on easier s′ but does not fail on harder s, then we know that πcontains a bug manifested on s′. We contribute the first exploration of this idea in the context of failure testing of neural network policies πlearned by reinforcement learning in simulated environments. We design fuzzing strategies for test-case generation as well as metamorphic oracles leveraging simple, manually designed relaxations. In experiments on three single-Agent games, our technology is able to effectively identify true bugs, i.e., avoidable failures of €, which has not been possible until now.  © 2022 Owner/Author."|action policies; fuzzing; metamorphic testing|Reinforcement learning; Action policies; Failure conditions; Fuzzing; Intelligence communities; Metamorphic relations; Metamorphic testing; Neural-networks; Optimal solutions; Policy decisions; Software testings; Software testing|Conference paper|Final|All Open Access; Bronze Open Access|Scopus|2-s2.0-85132880935
scopus|Peng X.; Ma Z.; Zhang N.; Huang Y.; Qi M.|Peng, Xiangshu (57568188700); Ma, Zhiming (57222368194); Zhang, Ning (58183669800); Huang, Yaoxian (58184373100); Qi, Menglin (57567778800)|57568188700; 57222368194; 58183669800; 58184373100; 57567778800|Lifecycle-Based Software Defect Prediction Technology|2023|Lecture Notes in Electrical Engineering|871 LNEE|||25|31|6|0|10.1007/978-981-99-1256-8_4|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152587400&doi=10.1007%2f978-981-99-1256-8_4&partnerID=40&md5=f214fe27ae32782905259232b71084aa|In order to improve the efficiency and quality of software testing, aiming at various factors affecting software reliability, how to find defective modules and optimize them in the early stage of software development has become an urgent problem to be solved, This paper introduces the software defect prediction technology based on life cycle. According to the measurement elements affecting software reliability, relevant internal indicators and design defects, find the defect module, lock it in advance, adopt machine learning technology and reasonably allocate limited resources, which is conducive to evaluate the software design scheme, optimize the design strategy, reduce design changes and improve the software operation process, It plays a role in cost evaluation, resource management, scheme determination and quality prediction in software management. It is hoped to provide some theoretical support and practical reference for the development of software defect prediction. © 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.|Introduction to the study; Software defect predict; Software lifecycle; Software metric|Defects; Engineering education; Forecasting; Life cycle; Quality control; Software design; Software testing; Introduction to the study; Prediction technologies; Quality of softwares; Software defect predict; Software defect prediction; Software defects; Software life cycles; Software metrics; Software testings; Software-Reliability; Software reliability|Conference paper|Final||Scopus|2-s2.0-85152587400
scopus|Yotov K.; Hadzhikolev E.; Hadzhikoleva S.; Cheresharov S.|Yotov, Kostadin (57216456977); Hadzhikolev, Emil (57191364629); Hadzhikoleva, Stanka (57191359477); Cheresharov, Stoyan (57195808823)|57216456977; 57191364629; 57191359477; 57195808823|Neuro-Cybernetic System for Forecasting Electricity Consumption in the Bulgarian National Power System|2022|Sustainability (Switzerland)|14|17|11074||||3|10.3390/su141711074|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137938640&doi=10.3390%2fsu141711074&partnerID=40&md5=3905f443da1eb5b4eb0cf206339cec02|Making forecasts for the development of a given process over time, which depends on many factors, is in some cases a difficult task. The choice of appropriate methods—mathematical, statistical, or artificial intelligence methods—is also not obvious, given their great variety. This paper presented a model of a forecasting system by comparing the errors in the use of time series on the one hand, and artificial neural networks on the other. The model aims at multifactor predictions based on forecast data on significant factors, which were obtained by automated testing of different methods and selection of the methods with the highest accuracy. Successful experiments were conducted to forecast energy consumption in Bulgaria, including for household consumption; industry consumption, the public sector and services; and total final energy consumption. © 2022 by the authors.|electricity consumption; forecast energy consumption; forecasting system|Bulgaria; accuracy assessment; artificial intelligence; automation; error analysis; forecasting method; fuel consumption; public sector; time series analysis|Article|Final|All Open Access; Gold Open Access|Scopus|2-s2.0-85137938640
scopus|Khaliq Z.; Farooq S.U.; Khan D.A.|Khaliq, Zubair (57423387800); Farooq, Sheikh Umar (55259943800); Khan, Dawood Ashraf (35761464100)|57423387800; 55259943800; 35761464100|Transformers for GUI Testing: A Plausible Solution to Automated Test Case Generation and Flaky Tests|2022|Computer|55|3||64|73|9|7|10.1109/MC.2021.3136791|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127564584&doi=10.1109%2fMC.2021.3136791&partnerID=40&md5=88be35096d3c1918dc0df830a8a66b2f|Artificial intelligence has made significant progress in software testing as it is being incorporated into all stages of the software test lifecycle (STLC). However, formidable challenges remain within software testing activities in the STLC. © 2022 IEEE.||Electric transformer testing; Life cycle; Automated test-case generations; GUI testing; Software testings; Software testing|Article|Final||Scopus|2-s2.0-85127564584
scopus|Pham P.; Nguyen V.; Nguyen T.|Pham, Phuoc (57222576555); Nguyen, Vu (55893587300); Nguyen, Tien (55386311200)|57222576555; 55893587300; 55386311200|A Review of AI-augmented End-to-End Test Automation Tools|2022|ACM International Conference Proceeding Series|||214||||7|10.1145/3551349.3563240|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146959478&doi=10.1145%2f3551349.3563240&partnerID=40&md5=07c776e733f1e8ce61a78844a92c3d86|Software testing is a process of evaluating and verifying whether a software product still works as expected, and it is repetitive, laborious, and time-consuming. To address this problem, automation tools have been developed to automate testing activities and enhance quality and delivery time. However, automation tools become less effective with continuous integration and continuous delivery (CI/CD) pipelines when the system under test is constantly changing. Recent advances in artificial intelligence and machine learning (AI/ML) present the potential for addressing important challenges in test automation. AI/ML can be applied to automate various testing activities such as detecting bugs and errors, maintaining existing test cases, or generating new test cases much faster than humans. In this study, we will outline testing activities where AI has significantly impacted and greatly enhanced the testing process. Based on that, we identify primary AI techniques that are used in each testing activity. Further, we conduct a comprehensive study of test automation tools to provide a clear look at the role of AI/ML technology in industrial testing tools. The results of this paper help researchers and practitioners understand the current state of AI/ML applied to software testing, which is the first important step towards achieving successful and efficient software testing.  © 2022 ACM.||Artificial intelligence; Automation; Artificial intelligence learning; Automation tools; Delivery time; End-to-end tests; Machine-learning; Quality and delivery; Software products; Software testings; Test automation tool; Test case; Software testing|Conference paper|Final||Scopus|2-s2.0-85146959478
scopus||||Proceedings of the 8th International Conference on Communication and Electronics Systems, ICCES 2023|2023|Proceedings of the 8th International Conference on Communication and Electronics Systems, ICCES 2023||||||1842|0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168110027&partnerID=40&md5=267a628e8b3105c9c0611cfd70f75893|The proceedings contain 300 papers. The topics discussed include: human posture monitoring using flex sensor; hybrid multiple cryptography for data encryption; secure color image encryption: an innovative algorithm based on 8d hyperchaotic system and DNA encoding strategies; adaptive traffic congestion control approach with emergency vehicle protocol; machine learning based cybersecurity technique for detection of upcoming cyber-attacks; link prediction in social network using gradient boosting; decentralized blockchain based online voting system with biometric authentication; intelligent system for fraud detection in online banking using improved particle swarm optimization and support vector machine; agricultural-based food visibility and traceability system using blockchain technologies; finding an optimal route path for ambulance; a novel data flow security protection algorithm for digital media in 6G environment; and software testing resource allocation algorithm based on improved evolutionary algorithm.|||Conference review|Final||Scopus|2-s2.0-85168110027
scopus||||26th International Conference on Fundamental Approaches to Software Engineering, FASE 2023, held as part of the 26th European Joint Conferences on Theory and Practice of Software, ETAPS 2023|2023|Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)|13991 LNCS|||||329|0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161399598&partnerID=40&md5=68a41ae9cc7d8ad784f132a0aca58f55|The proceedings contain 18 papers. The special focus in this conference is on Fundamental Approaches to Software Engineering. The topics include: Parallel Program Analysis via Range Splitting; runtime Enforcement Using Knowledge Bases; specification and Validation of Normative Rules for Autonomous Agents; towards Log Slicing; vamos: Middleware for Best-Effort Third-Party Monitoring; yet Another Model! A Study on Model’s Similarities for Defect and Code Smells; software Testing: 5th Comparative Evaluation: Test-Comp 2023; FuSeBMC_IA: Interval Analysis and Methods for Test Case Generation: (Competition Contribution); A Modeling Concept for Formal Verification of OS-Based Compositional Software; compositional Automata Learning of Synchronous Systems; concolic Testing of Front-end JavaScript; democratizing Quality-Based Machine Learning Development through Extended Feature Models; Efficient Bounded Exhaustive Input Generation from Program APIs; feature-Guided Analysis of Neural Networks; JavaBIP meets VerCors: Towards the Safety of Concurrent Software Systems in Java; model-based Player Experience Testing with Emotion Pattern Verification.|||Conference review|Final||Scopus|2-s2.0-85161399598
scopus|Havakeshian M.; Labiche Y.; Nejati S.; Desjardins S.; Haghighi K.|Havakeshian, Maryam (58361477700); Labiche, Yvan (6602305217); Nejati, Shiva (18038340600); Desjardins, Stephane (58364632900); Haghighi, Kourosh (58360855500)|58361477700; 6602305217; 18038340600; 58364632900; 58360855500|Test Cost Reduction for 5G and beyond using Machine Learning|2023|Proceedings - 2023 IEEE 16th International Conference on Software Testing, Verification and Validation Workshops, ICSTW 2023||||373|376|3|0|10.1109/ICSTW58534.2023.00069|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163087471&doi=10.1109%2fICSTW58534.2023.00069&partnerID=40&md5=466cd7eb1611af957f1aa6b1f2ccd45d|Software testing is essential, but expensive, especially for significant issues, feature-rich systems such as telecommunication systems evolving toward 5G and beyond. There is a need in this domain for effective testing techniques to ensure that a minimal number of test cases assess the most important combinations of system functions with respect to domain-specific criteria.Our approach aims to address this challenge by first automatically mapping existing test cases to the combinations of system capabilities they exercise and visualizing the mappings using decision tree learners. Then, the approach uses a combination of the engineers' feedback (domain-specific criteria), mapping data, and test execution logs to propose new test cases covering newly-added capabilities or better exercising/verifying existing ones while ensuring the efficacy at fault detection, code coverage, equipment cost, test execution time, redundancy avoidance, among other things. © 2023 IEEE.|5G Systems; Machine Learning; Software Testing|5G mobile communication systems; Cost reduction; Decision trees; Fault detection; Machine learning; Mapping; 5g system; Domain specific; Effective testing; Machine-learning; Software testings; System functions; Test case; Test cost reduction; Test execution; Testing technique; Software testing|Conference paper|Final||Scopus|2-s2.0-85163087471
scopus|Yuba M.; Iwasaki K.|Yuba, Mitsuru (57920376700); Iwasaki, Kiyotaka (7401978248)|57920376700; 7401978248|Systematic analysis of the test design and performance of AI/ML-based medical devices approved for triage/detection/diagnosis in the USA and Japan|2022|Scientific Reports|12|1|16874||||12|10.1038/s41598-022-21426-7|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139514048&doi=10.1038%2fs41598-022-21426-7&partnerID=40&md5=99b42b95a27afd34d3268ea222085fd6|The development of computer-aided detection (CAD) using artificial intelligence (AI) and machine learning (ML) is rapidly evolving. Submission of AI/ML-based CAD devices for regulatory approval requires information about clinical trial design and performance criteria, but the requirements vary between countries. This study compares the requirements for AI/ML-based CAD devices approved by the US Food and Drug Administration (FDA) and the Pharmaceuticals and Medical Devices Agency (PMDA) in Japan. A list of 45 FDA-approved and 12 PMDA-approved AI/ML-based CAD devices was compiled. In the USA, devices classified as computer-aided simple triage were approved based on standalone software testing, whereas devices classified as computer-aided detection/diagnosis were approved based on reader study testing. In Japan, however, there was no clear distinction between evaluation methods according to the category. In the USA, a prospective randomized controlled trial was conducted for AI/ML-based CAD devices used for the detection of colorectal polyps, whereas in Japan, such devices were approved based on standalone software testing. This study indicated that the different viewpoints of AI/ML-based CAD in the two countries influenced the selection of different evaluation methods. This study’s findings may be useful for defining a unified global development and approval standard for AI/ML-based CAD. © 2022, The Author(s).||Artificial Intelligence; Japan; Machine Learning; Pharmaceutical Preparations; Prospective Studies; Triage; drug; artificial intelligence; controlled study; emergency health service; Japan; machine learning; prospective study; randomized controlled trial|Article|Final|All Open Access; Gold Open Access; Green Open Access|Scopus|2-s2.0-85139514048
scopus|Božić J.|Božić, Josip (55872573100)|55872573100|Ontology-based metamorphic testing for chatbots|2022|Software Quality Journal|30|1||227|251|24|12|10.1007/s11219-020-09544-9|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105364543&doi=10.1007%2fs11219-020-09544-9&partnerID=40&md5=c6662ce7897f970b5e30fa47111c6627|Modern-day demands for services often require an availability on a 24/7 basis as well as online accessibility around the globe. For this sake, personalized virtual assistants, called chatbots, are implemented. Such systems offer services, goods or information in natural language. These natural language processing (NLP) programs respond to the user in real time and offer an intuitive and simple interface to interact with. Advantages like these make them increasingly popular. Therefore, ensuring correct functionality of chatbots is of increasing importance. However, since different implementations and user behaviour result in unpredictable results, the chatbot’s input and output data are difficult to predict and classify as well. Under such circumstances, test cases can be inferred from the domain of possible inputs of a system under test (SUT). Ontologies are concepts used in AI to provide formal representations of knowledge for a specific domain. Such ontological models contain structured information that is used for test generation. On the other hand, testing of chatbots represents a challenge because of the absence of a test oracle. In this paper, both challenges are addressed by conceptualizing ontologies for input generation and output processing in form of a metamorphic testing approach. In this scenario, both concepts are applied for automated testing of chatbots. The approach is demonstrated on a real system from the tourism domain, thereby discussing the obtained results. © 2021, The Author(s).|Chatbots; Functional testing; Metamorphic testing; Ontologies|Behavioral research; Natural language processing systems; Automated testing; Formal representations; Input and outputs; Metamorphic testing; NAtural language processing; Ontological models; Structured information; Virtual assistants; Ontology|Article|Final|All Open Access; Hybrid Gold Open Access|Scopus|2-s2.0-85105364543
scopus|Toda H.; Tanaka Y.; Yamade K.; Tsujimoto M.; Takada H.; Ueno M.; Tsuda Y.; Kishino Y.; Kubo S.; Kamisako T.; Yoshida K.|Toda, Hirofumi (55206333000); Tanaka, Yuji (58673671800); Yamade, Kenji (57221909338); Tsujimoto, Mayu (58103712800); Takada, Haruka (58103312200); Ueno, Minoru (58103978000); Tsuda, Yoshihiro (58103978100); Kishino, Yoshizumi (36614346000); Kubo, Shuichi (58103055000); Kamisako, Toshinori (7004226472); Yoshida, Koichiro (58341337900)|55206333000; 58673671800; 57221909338; 58103712800; 58103312200; 58103978000; 58103978100; 36614346000; 58103055000; 7004226472; 58341337900|Evaluation of the Analytical Performance of the Fully Automated Gene Analyzer µTASWako g1 for the Detection of SARS-CoV-2|2023|Clinical Laboratory|69|2||425|429|4|1|10.7754/Clin.Lab.2022.220513|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148112402&doi=10.7754%2fClin.Lab.2022.220513&partnerID=40&md5=2db344bf411224a4db691b8e1b154efa|Background: The worldwide spread of coronavirus disease 2019 (COVID-19) has led to an urgent need for nucleic acid amplification test (NAAT) for severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2). Because NAAT has many manual processes, results may vary depending on the operator. Therefore, it has been required to develop a fully automated testing device and reagent that detects genetic material from SARS-CoV-2. The µTASWako g1 system (FUJIFILM Wako Pure Chemical Corporation, Osaka, Japan), a genetic analyzer, provides results in 75 minutes by performing a fully automated PCR process. Methods: We evaluated the analytical and clinical performance of the µTASWako g1 system for the detection of SARS-CoV-2 RNA. Results: The µTASWako g1 system had the limit of detection at 2,000 copies/mL using a known concentration of RNA. In clinical samples, the µTASWako g1 system had a sensitivity of 88.0% and 100% specificity compared to conventional RT-PCR. The µTAS Wako g1 system could detect three variants of concern carrying spike mutations including N501Y, E484K, and L452R. Conclusions: As the assay on the µTASWako g1 system is highly accurate for the detection of SARS-CoV-2 regardless of the experience of operator, it can be widely applicable in clinical laboratories. © Copyright.|COVID-19; fully automated gene analyzer; nucleic acid amplification test; SARS-CoV-2; µTAS|Clinical Laboratory Techniques; COVID-19; COVID-19 Testing; Humans; RNA, Viral; SARS-CoV-2; Sensitivity and Specificity; coronavirus spike glycoprotein; virus RNA; virus RNA; analytical phase; Article; clinical evaluation; concentration (parameter); controlled study; coronavirus disease 2019; COVID-19 nucleic acid testing; diagnostic accuracy; diagnostic test accuracy study; high resolution melting analysis; intermethod comparison; laboratory automation; limit of detection; nonhuman; polymerase chain reaction; reverse transcription polymerase chain reaction; sensitivity and specificity; Severe acute respiratory syndrome coronavirus 2; variant of concern; virus detection; virus mutation; diagnosis; genetics; human; laboratory technique; procedures|Article|Final||Scopus|2-s2.0-85148112402
scopus|Alon-Barkat S.; Busuioc M.|Alon-Barkat, Saar (56922265900); Busuioc, Madalina (33567608200)|56922265900; 33567608200|Human-AI Interactions in Public Sector Decision Making: “Automation Bias” and “Selective Adherence” to Algorithmic Advice|2023|Journal of Public Administration Research and Theory|33|1||153|169|16|122|10.1093/jopart/muac007|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193223068&doi=10.1093%2fjopart%2fmuac007&partnerID=40&md5=22d8f72fd2ebd9285594db057e9bb5aa|Artificial intelligence algorithms are increasingly adopted as decisional aides by public bodies, with the promise of overcoming biases of human decision-makers. At the same time, they may introduce new biases in the human-algorithm interaction. Drawing on psychology and public administration literatures, we investigate two key biases: overreliance on algorithmic advice even in the face of “warning signals” from other sources (automation bias), and selective adoption of algorithmic advice when this corresponds to stereotypes (selective adherence). We assess these via three experimental studies conducted in the Netherlands: In study 1 (N = 605), we test automation bias by exploring participants' adherence to an algorithmic prediction compared to an equivalent human-expert prediction. We do not find evidence for automation bias. In study 2 (N = 904), we replicate these findings, and also test selective adherence. We find a stronger propensity for adherence when the advice is aligned with group stereotypes, with no significant differences between algorithmic and human-expert advice. In study 3 (N = 1,345), we replicate our design with a sample of civil servants. This study was conducted shortly after a major scandal involving public authorities' reliance on an algorithm with discriminatory outcomes (the “childcare benefits scandal”). The scandal is itself illustrative of our theory and patterns diagnosed empirically in our experiment, yet in our study 3, while supporting our prior findings as to automation bias, we do not find patterns of selective adherence. We suggest this is driven by bureaucrats' enhanced awareness of discrimination and algorithmic biases in the aftermath of the scandal. We discuss the implications of our findings for public sector decision making in the age of automation. Overall, our study speaks to potential negative effects of automation of the administrative state for already vulnerable and disadvantaged citizens. © The Author(s) 2022.|||Article|Final|All Open Access; Green Open Access; Hybrid Gold Open Access|Scopus|2-s2.0-85193223068
scopus|Senchenko A.; Patterson J.; Samuel H.; Ispir D.|Senchenko, Alexander (57549636900); Patterson, Jordan (57549637000); Samuel, Hamman (36728070200); Ispir, Dan (57551191600)|57549636900; 57549637000; 36728070200; 57551191600|SUPERNOVA: Automating Test Selection and Defect Prevention in AAA Video Games Using Risk Based Testing and Machine Learning|2022|Proceedings - 2022 IEEE 15th International Conference on Software Testing, Verification and Validation, ICST 2022||||345|354|9|6|10.1109/ICST53961.2022.00043|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133235945&doi=10.1109%2fICST53961.2022.00043&partnerID=40&md5=8b54adf7fc3374568062602840a8c7fb|Testing video games is an increasingly difficult task as traditional methods fail to scale with growing software systems. Manual testing is a very labor-intensive process, and therefore quickly becomes cost prohibitive. Using scripts for automated testing is affordable, however scripts are ineffective in non-deterministic environments, and knowing when to run each test is another problem altogether. Manual testing and writing scripts make up the current industry standard and methodology for game testing, but the writing is on the wall for this practice. The modern game's complexity, scope, and player expectations are rapidly increasing where quality control is a big portion of the production cost and delivery risk. Reducing this risk and making production happen is a big challenge for the industry currently. To keep production costs realistic up-to and after release, we are focusing on preventive quality assurance tactics alongside testing and data analysis automation. We present SUPERNOVA (Selection of tests and Universal defect Prevention in External Repositories for Novel Objective Verification of software Anomalies), a system responsible for test selection and defect prevention while also functioning as an automation hub. By integrating data analysis functionality with machine and deep learning capability, SUPERNOVA assists quality assurance testers in finding bugs and developers in reducing defects, which improves stability during the production cycle and keeps testing costs under control. The direct impact of this has been observed to be a reduction in 55% or more testing hours for an undisclosed sports game title that has shipped, which was using these test selection optimizations. Furthermore, using risk scores generated by a semi-supervised machine learning model, we are able to detect with 71% precision and 77% recall the probability of a change-list being bug inducing, and provide a detailed breakdown of this inference to developers. These efforts improve workflow and reduce testing hours required on game titles in development.  © 2022 IEEE.|auto-mated decision making; automation; defect prevention; games testing; machine learning; quality assurance; risk-based testing|Automation; Computer software selection and evaluation; Cost benefit analysis; Data handling; Deep learning; Human computer interaction; Information analysis; Learning systems; Quality assurance; Quality control; Software testing; Supervised learning; Verification; Auto-mated decision making; Decisions makings; Defect prevention; Game testing; Machine-learning; Manual testing; Production cost; Risk based testing; Test selection; Video-games; Decision making|Conference paper|Final|All Open Access; Green Open Access|Scopus|2-s2.0-85133235945
scopus|Sulaiman N.; Hasoon S.O.|Sulaiman, Nour (58109598200); Hasoon, Safwan O. (55946255800)|58109598200; 55946255800|Application of Convolution Neural Networks and Randomforest for Software Test|2022|2022 8th International Conference on Contemporary Information Technology and Mathematics, ICCITM 2022||||146|152|6|0|10.1109/ICCITM56309.2022.10031789|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148427679&doi=10.1109%2fICCITM56309.2022.10031789&partnerID=40&md5=aa02f1a6c08cd853c02ce408d0359b26|The system development life cycle includes a phase called software testing. Lots of tests are done to test the software. Here, we will focus on how to use Oracle Testing to test system output using black box testing methodology. We will test credit card software as an example, and the results will indicate whether or not a financial institution can authorize credit cards to its customers. This paper explains how to check the output of the credit card application using Convolutional Neural Networks and the Random Forest Algorithm, which will represent the Oracle test, according to the black box testing methodology, using machine learning algorithms, which can be adopted in the next versions of the credit card software to verify the validity of the results. The aim of this paper is to give results about whether a financial institution can approve credit cards for its customers. The decision to approve the card is made by the financial companies based on consideration of various reasons related to individuals which vary from creditworthiness, loans, repayment history and income criteria. © 2022 IEEE.|Artificial neural networks; Automated software testing; Black-box testing; CNN; Mutation testing; random forest; regression testing|Application programs; Black-box testing; Convolutional neural networks; Finance; Learning algorithms; Life cycle; Machine learning; Automated software testing; Convolution neural network; Credit cards; Financial institution; Mutation testing; Random forests; Regression testing; Software testings; Systems development life cycle; Testing methodology; Convolution|Conference paper|Final||Scopus|2-s2.0-85148427679
scopus|Yang W.; Hu C.; Ma S.|Yang, Wansheng (57918876600); Hu, Chi (57197746439); Ma, Siyou (57203636549)|57918876600; 57197746439; 57203636549|A Software Failure Mode Analysis Method Based on Test Knowledge Graph|2022|Proceedings - 2022 9th International Conference on Dependable Systems and Their Applications, DSA 2022||||813|819|6|0|10.1109/DSA56465.2022.00114|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141430129&doi=10.1109%2fDSA56465.2022.00114&partnerID=40&md5=cd077f132285353f4b60261db72389d4|Software failure mode analysis (SFMA) is an important process for analyzing failure propagation by identifying possible software failure points, and then summarizing software failure modes so as to improve software quality. However, the traditional SFMA is carried out mainly by software safety analysis method, which possesses heavy workload, low efficiency, and over-dependence on the experience of safety analysts. In this paper, a SFMA is proposed method based on knowledge graph. It collects the failure factors, failure mechanism and failure performance of the software under test into a fixed Resource Description Framework (RDF) triple store by establishing a knowledge graph of data assets in the software testing process. Then, the method of text clustering is applied to realize the automatic analysis of software failure mode. This method mainly covers three steps: 1) Extract failure factors - the RDF data of the descriptive text of various entity nodes related to software defect reports from the software test knowledge graph; 2) Combine the RDF triples into a normalizing text in a unified format, an easy way of further natural language processing; 3) Generate software defects with similar characteristics and similar failure behaviors into 'defect modes' or 'failure modes' by using clustering algorithms. The empirical study has proven that the SFMA proposed in this paper presents a novel, feasible solution for processing extremely large-scale data.  © 2022 IEEE.|Clustering algorithms; Failure modes; RDF triple store; SFMA; Test Knowledge Graph|Clustering algorithms; Computer software selection and evaluation; Defects; Failure (mechanical); Knowledge graph; Natural language processing systems; Quality control; Semantic Web; Software testing; Analysis method; Failure factors; Failure mode analysis; Knowledge graphs; Resource description framework triple store; Resources description frameworks; Software failure; Software failure mode analyse; Test knowledge graph; Triple store; Failure modes|Conference paper|Final||Scopus|2-s2.0-85141430129
scopus|Feng L.-C.; Wang X.-Y.; Zhang S.-Y.; Gao R.-Z.; Zhao Z.-H.|Feng, Li-Chao (57429602700); Wang, Xing-Ya (55969090300); Zhang, Shi-Yu (57429254400); Gao, Rui-Zhi (59830076100); Zhao, Zhi-Hong (55726172500)|57429602700; 55969090300; 57429254400; 59830076100; 55726172500|Mutation Operator Reduction for Cost-effective Deep Learning Software Testing via Decision Boundary Change Measurement|2022|Journal of Internet Technology|23|3||601|610|9|4|10.53106/160792642022052303018|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132004816&doi=10.53106%2f160792642022052303018&partnerID=40&md5=4e7544893f7f40d26a6e41a12600b392|Mutation testing has been deemed an effective way to ensure Deep Learning (DL) software quality. Due to the requirements of generating and executing mass mutants, mutation testing suffers low-efficiency problems. In regard to traditional software, mutation operators that are hard to cause program logic changes can be reduced. Thus, the number of the mutants, as well as their executions, can be effectively decreased. However, DL software relies on model logic to make a decision. Decision boundaries characterize its logic. In this paper, we propose a DL software mutation operator reduction technique. Specifically, for each group of DL operators, we propose and use DocEntropy to measure the model's decision boundary changes among mutants generated and the original model. Then, we select the operator group with the highest entropy value and use the involved operators for further mutation testing. An empirical study on two DL models verified that the proposed approach could lead to costeffective DL software mutation testing (i.e., 33.61% mutants and their executions decreased on average) and archive more accuracy mutation scores (i.e., 9.45% accuracy increased on average). © 2022 Taiwan Academic Network Management Committee. All rights reserved.|Decision boundary; DL software; Mutation operator reduction; Mutation testing|Computer circuits; Computer software selection and evaluation; Cost effectiveness; Deep learning; % reductions; Cost effective; Decision boundary; Deep learning software; Learning software; Mutation operator reduction; Mutation operators; Mutation testing; Program logic; Software testings; Software testing|Article|Final|All Open Access; Bronze Open Access|Scopus|2-s2.0-85132004816
scopus|Gatt C.; Bugeja M.; Micallef M.|Gatt, Cristina (57777326100); Bugeja, Mark (57203551904); Micallef, Mark (55981263700)|57777326100; 57203551904; 55981263700|Towards Domain-Specific Automated Testing via Behavioural Cloning|2022|Proceedings - 2022 IEEE 14th International Conference on Software Testing, Verification and Validation Workshops, ICSTW 2022||||146|149|3|0|10.1109/ICSTW55395.2022.00037|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133258146&doi=10.1109%2fICSTW55395.2022.00037&partnerID=40&md5=a542209175df40d65c9ffdefe9fa1a4c|When setting out a research roadmap for software testing, Bertolino [1] presented four dreams, one of which was 100% automatic testing. Fifteen years later, the dream has not been realised but the promise of artificial intelligence techniques brings us closer than ever before. In this paper, we propose that one way to achieve this goal is to leverage the commonalities that exist amongst domain-specific applications. That is to say that whilst every application within a particular domain is arguably unique, they all share a considerable overlap in terms of features.We propose an approach based on Behavioural Cloning, an AI technique whereby an agent observes traces by an expert and attempts to carry out domain-specific tasks in previously unseen contexts based on those traces. Using online stores as a case study, we discuss initial investigations into this idea, present results and identify a roadmap going forward.  © 2022 IEEE.|AI; behavioural cloning; online stores; testing|Automatic testing; Clone cells; Electronic commerce; Software testing; AI techniques; Artificial intelligence techniques; Automated testing; Behavioural cloning; Domain specific; Domain-specific application; Online store; Research roadmap; Setting outs; Software testings; Cloning|Conference paper|Final||Scopus|2-s2.0-85133258146
scopus|Geistfeld M.A.; Karner E.; Koch B.A.; Wendehorst C.|Geistfeld, Mark A. (6506743426); Karner, Ernst (57201969632); Koch, Bernhard A. (7201651106); Wendehorst, Christiane (6507588969)|6506743426; 57201969632; 7201651106; 6507588969|Civil Liability for Artificial Intelligence and Software|2022|Civil Liability for Artificial Intelligence and Software||||1|408|407|1|10.1515/9783110775402|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183237175&doi=10.1515%2f9783110775402&partnerID=40&md5=e34fe17bb87711681f41c35de488da54|Initiated by the European Commission, the first study published in this volume analyses the largely unresolved question as to how damage caused by artificial intelligence (AI) systems is allocated by the rules of tortious liability currently in force in the Member States of the European Union and in the United States, to examine whether - and if so, to what extent - national tort law regimes differ in that respect, and to identify possible gaps in the protection of injured parties. The second study offers guiding principles for safety and liability with regard to software, testing how the existing acquis needs to be adjusted in order to adequately cope with the risks posed by software and AI. The annex contains the final report of the New Technologies Formation of the Expert Group on Liability and New Technologies, assessing the extent to which existing liability schemes are adapted to the emerging market realities following the development of new digital technologies. • Analyses how damage caused by AI is allocated by the rules of tortious liability. • Offers guiding principles for safety and liability concerning software. • Assesses the extent to which liability schemes are adapted to emerging market realities. © 2023 Walter de Gruyter GmbH, Berlin/Boston.|German Civil Code; German Civil Code, other; International Law and Foreign Law; International Law, Foreign Law, Comparative Law; Law||Book|Final||Scopus|2-s2.0-85183237175
scopus|Olsthoorn M.|Olsthoorn, Mitchell (57210556113)|57210556113|More Effective Test Case Generation with Multiple Tribes of AI|2022|Proceedings - International Conference on Software Engineering||||286|290|4|5|10.1109/ICSE-Companion55297.2022.9793774|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132361993&doi=10.1109%2fICSE-Companion55297.2022.9793774&partnerID=40&md5=0d914c3468d30c20c1ca99c6b2aa3821|Software testing is a critical activity in the software development life cycle for quality assurance. Automated Test Case Generation (TCG) can assist developers by speeding up this process. It accomplishes this by evolving an initial set of randomly generated test cases over time to optimize for predefined coverage criteria. One of the key challenges for automated TCG approaches is navigating the large input space. Existing state-of-the-art TCG algorithms struggle with generating highly-structured input data and preserving patterns in test structures, among others. I hypothesize that combining multiple tribes of AI can improve the effectiveness and efficiency of automated TCG. To test this hypothesis, I propose using grammar-based fuzzing and machine learning to augment evolutionary algorithms for generating more structured input data and preserving promising patterns within test cases. Additionally, I propose to use behavioral modeling and interprocedural control dependency analysis to improve test effectiveness. Finally, I propose integrating these novel approaches into a testing framework to promote the adoption of automated TCG in industry. © 2022 IEEE.|Software and its engineering → Search-based software engineering; Software testing and debugging|Automation; Input output programs; Integration testing; Life cycle; Machine learning; Program debugging; Software design; Testing; Automated test-case generations; Critical activities; Input datas; Search-based; Software and its engineering → search-based software engineering;; Software development life-cycle; Software Testing and Debugging; Software testings; Test case; Test case generation; Quality assurance|Conference paper|Final|All Open Access; Bronze Open Access; Green Open Access|Scopus|2-s2.0-85132361993
scopus|Fu W.; Wang L.|Fu, Weiyu (57891656600); Wang, Lixia (57828762900)|57891656600; 57828762900|Software Security Testing through Coverage in Deep Neural Networks|2022|Security and Communication Networks|2022||2834982||||1|10.1155/2022/2834982|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138217455&doi=10.1155%2f2022%2f2834982&partnerID=40&md5=0b65c6e1fbe505972147fb88f17956de|With the continuous progress of society, computer technology and information technology are also experiencing rapid development. Especially in recent years, the application of computer technology has rapidly entered into people's daily life. As people's lives become richer, these applications have become particularly complex. For some large software, tens of thousands of function points or millions of lines of source code may be triggered to support it when performing related tasks. As a result, the security of such a complicated and excellent software becomes quite essential. The most effective way to ensure software security is to test the security of software products during the development process. A precise and effective security testing process is the basis for ensuring that software is tested for security. Without a detailed scientific software security testing model to guide software development for security testing, software security testing will become very difficult. This not only wastes more time and money but also does not guarantee the security of the software. A great security testing methodology should be able to find security problems that may be hidden deep within the software. In addition, a scientific process management can greatly facilitate the implementation of software security testing. As a result, it is relatively meaningful to establish a complete software security testing process model, generate excellent security test cases, and develop security process management tools for software security testing. At the same time, in recent years, deep learning has gradually entered more and more people's lives. However, the widespread application of deep learning systems can bring convenience to human life but also bring some hidden dangers. Hence, deep neural networks must be adequately tested to eliminate as many security risks as possible in some safety-critical software that involves personal and property safety. As the foundation of deep learning systems, deep neural networks should be adequately tested for security. However, deep learning systems are fundamentally different from traditional software testing, so traditional software testing techniques cannot be directly applied to deep neural network testing. In recent years, many scholars in related fields have proposed coverage guidelines based on deep learning testing, but the usefulness of these guidelines is still debatable. Based on the complexity of the large software development process and the fact that the interrelationship between nodes often constitutes a complex network of collaborative relationships, this study applies coverage-based testing in deep neural networks to test the security of software. To be specific, this research applies metrics such as peak coverage, speed to peak, and computational speed to evaluate coverage criteria and to investigate the feasibility of using coverage to guide test case selection to select solutions for security testing.  © 2022 Weiyu Fu and Lixia Wang.||Application programs; Complex networks; Learning systems; Network security; Safety engineering; Software design; Software testing; Computer technology; Daily lives; Development process; Function point; Security testing; Software products; Software security; Software security testing; Source codes; Testing process; Deep neural networks|Article|Final|All Open Access; Gold Open Access|Scopus|2-s2.0-85138217455
scopus|Tamer A.; Pester A.|Tamer, Ahmed (57802895500); Pester, Andreas (8383276100)|57802895500; 8383276100|Large Scale Covid-19 Detection with Blood Platelets Using Artificial Neural Network|2022|Lecture Notes in Networks and Systems|298|||393|399|6|3|10.1007/978-3-030-82529-4_38|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115830198&doi=10.1007%2f978-3-030-82529-4_38&partnerID=40&md5=0ecec529ceca00b1922fa36cf797cc69|Detection of COVID-19 by using patient’s blood platelets using an artificial neural network to perform large-scale automated testing. The deep learning model uses the CBC test results to detect the virus with an accuracy of 89.26%, which achieve higher accuracy than the widely used RT-PCR test. The model has achieved accuracy with only a thousand rows, which assures that the model can achieve better results with more data. The objective of the paper is to provide an automated and accurate method to detect COVID-19 using machine learning to apply it in large-scale testing, to help in containing the virus and prevent the spread of the virus. The scope of the paper is on the detection methodology using the blood platelets values extracted from the complete blood cycle (CBC) testing and discussing the future possibilities of improving the automated prevention method. The paper uses a dataset provided by Hospital Israelita Albert Einstein in Brazil, which has over 50 features of different tests as Influenza A, Influenza B, Uria, etc.…, many of these features had missing values or wasn’t relevant to the existence of the virus in the body; therefore, the feature selection led to filtering the 17 blood features. The K-Nearest Neighbour (KNN) Imputation imputed the missing values in the 17 filtered values. The analysis & visualization of the blood features concluded that the complete blood cycle test values highly correlated with each other, and there is a change occurs due to the presence of the virus is clear, especially to Eosinophils and Leukocytes, at which they represent the white blood cells forming the immune system that reacts against any virus or bacteria attracting the human body. The paper has applied five different machine learning algorithms: logistic regression, support vector machine (SVM), random forest, K neighbours and decision tree. Meanwhile, in the second approach, used an artificial neural network with intensive use of network optimization and hyperparameter tuning to achieve the highest accuracy possible. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.|Blood platelets; COVID-19; Deep learning; Deep neural network||Conference paper|Final||Scopus|2-s2.0-85115830198
scopus|Tahvili S.; Hatvani L.|Tahvili, Sahar (37093975500); Hatvani, Leo (36696277600)|37093975500; 36696277600|Artificial Intelligence Methods for Optimization of the Software Testing Process: With Practical Examples and Exercises|2022|Artificial Intelligence Methods for Optimization of the Software Testing Process: With Practical Examples and Exercises||||1|204|203|11|10.1016/C2021-0-00433-8|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143320055&doi=10.1016%2fC2021-0-00433-8&partnerID=40&md5=bd5500bb2e64af3199688af831b9a964|Artificial Intelligence Methods for Optimization of the Software Testing Process: With Practical Examples and Exercises presents different AI-based solutions for overcoming the uncertainty found in many initial testing problems. The concept of intelligent decision making is presented as a multi-criteria, multi-objective undertaking. The book provides guidelines on how to manage diverse types of uncertainty with intelligent decision-making that can help subject matter experts in many industries improve various processes in a more efficient way. As the number of required test cases for testing a product can be large (in industry more than 10,000 test cases are usually created). Executing all these test cases without any particular order can impact the results of the test execution, hence this book fills the need for a comprehensive resource on the topics on the how's, what's and whys. To learn more about Elsevier’s Series, Uncertainty, Computational Techniques and Decision Intelligence, please visit this link: https://www.elsevier.com/books-and-journals/book-series/uncertainty-computational-techniques-and-decision-intelligence  © 2022 Elsevier Inc. All rights reserved.|||Book|Final||Scopus|2-s2.0-85143320055
scopus|Zhu P.; Li Y.; Li T.; Ren H.; Sun X.|Zhu, Penghua (57218658622); Li, Ying (57362366100); Li, Tongyu (57222311750); Ren, Huimin (57701267000); Sun, Xiaolei (57221529906)|57218658622; 57362366100; 57222311750; 57701267000; 57221529906|Advanced Crowdsourced Test Report Prioritization Based on Adaptive Strategy|2022|IEEE Access|10|||53522|53532|10|6|10.1109/ACCESS.2022.3176086|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130462304&doi=10.1109%2fACCESS.2022.3176086&partnerID=40&md5=af312a2ea6f3d435084e886dd9c26ff4|Crowdsourced testing is an emerging trend in software testing, which takes advantage of the efficiency of crowdsourced and cloud platforms. Crowdsourced testing has gradually been applied in many fields. In crowdsourced software testing, after the crowdsourced workers complete the test tasks, they submit the test results in test reports. Therefore, in crowdsourced software testing, checking a large number of test reports is an arduous but unavoidable software maintenance task. Crowdsourced test reports are numerous, complex, and need to be sorted to improve inspection efficiency. There are no systematic methods for prioritizing reports in crowdsourcing test report prioritization. However, in regression testing, test case prioritization technology has matured. Therefore, we migrate the test case prioritization method to crowdsourced test report prioritization and evaluate the effectiveness of these methods. We use natural language processing technology and word segmentation to process the text in the test reports. Then we use four methods to prioritize the reports: total greedy algorithm, additional greedy algorithm, genetic algorithm, and ART. The results show that these methods all perform well in prioritizing crowdsourced test reports, with an average APFD of more than 0.8. © 2013 IEEE.|Crowdsourced software testing; test report prioritization; text classification|Classification (of information); Crowdsourcing; Efficiency; Genetic algorithms; Job analysis; Text processing; Crowdsourced software testing; Encodings; Greedy algorithms; Prioritization; Software; Software algorithms; Software testings; Task analysis; Test report prioritization; Test reports; Text classification; Software testing|Article|Final|All Open Access; Gold Open Access|Scopus|2-s2.0-85130462304
scopus|Shen Y.; Hu S.; Cai S.; Chen M.|Shen, Yingyan (57809193200); Hu, Shaojie (57808634700); Cai, Siqi (57808909000); Chen, Mincheng (57043667300)|57809193200; 57808634700; 57808909000; 57043667300|Software Defect Prediction based on Bayesian Optimization Random Forest|2022|Proceedings - 2022 9th International Conference on Dependable Systems and Their Applications, DSA 2022||||1012|1013|1|9|10.1109/DSA56465.2022.00149|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141391995&doi=10.1109%2fDSA56465.2022.00149&partnerID=40&md5=485be1f6c562f2b1d0334185354de9cd|Software defect prediction is an important way to make rational use of software testing data resources and improve software performance. However, people have used a variety of machine learning algorithms to establish defect prediction models, their parameter selection is still a problem. To solve this problem, the software defect prediction method based on Bayesian optimization random forest is proposed. This method preproccess data firstly, and then the Bayesian optimization algorithm is used to tune the hyperparameters of the random forest model. Finally the NASA MDP datasets are used for simulation verification. The experimental results show that our model has better performance for software defect prediction.  © 2022 IEEE.|Bayesian; hyperparameters; random forest; Software defect prediction|Decision trees; Defects; Forecasting; Machine learning; NASA; Random forests; Bayesian; Bayesian optimization; Data resources; Hyper-parameter; Prediction-based; Random forests; Software defect prediction; Software performance; Software testings; Testing data; Software testing|Conference paper|Final||Scopus|2-s2.0-85141391995
scopus|Xu L.; Towey D.; French A.P.; Benford S.; Zhou Z.Q.; Chen T.Y.|Xu, Liming (56611018100); Towey, Dave (8362064600); French, Andrew P. (7202095090); Benford, Steve (7006887786); Zhou, Zhi Quan (56566917900); Chen, Tsong Yueh (13104290200)|56611018100; 8362064600; 7202095090; 7006887786; 56566917900; 13104290200|Using metamorphic relations to verify and enhance Artcode classification|2021|Journal of Systems and Software|182||111060||||9|10.1016/j.jss.2021.111060|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114125392&doi=10.1016%2fj.jss.2021.111060&partnerID=40&md5=e414bb31f3d15841477fb733324687ec|Software testing is often hindered where it is impossible or impractical to determine the correctness of the behaviour or output of the software under test (SUT), a situation known as the oracle problem. An example of an area facing the oracle problem is automatic image classification, using machine learning to classify an input image as one of a set of predefined classes. An approach to software testing that alleviates the oracle problem is metamorphic testing (MT). While traditional software testing examines the correctness of individual test cases, MT instead examines the relations amongst multiple executions of test cases and their outputs. These relations are called metamorphic relations (MRs): if an MR is found to be violated, then a fault must exist in the SUT. This paper examines the problem of classifying images containing visually hidden markers called Artcodes, and applies MT to verify and enhance the trained classifiers. This paper further examines two MRs, Separation and Occlusion, and reports on their capability in verifying the image classification using one-way analysis of variance (ANOVA) in conjunction with three other statistical analysis methods: t-test (for unequal variances), Kruskal–Wallis test, and Dunnett's test. In addition to our previously-studied classifier, that used Random Forests, we introduce a new classifier that uses a support vector machine, and present its MR-augmented version. Experimental evaluations across a number of performance metrics show that the augmented classifiers can achieve better performance than non-augmented classifiers. This paper also analyses how the enhanced performance is obtained. © 2021 Elsevier Inc.|Artcode; Classification; Machine learning; Metamorphic relation; Metamorphic testing; Software verification|Analysis of variance (ANOVA); Decision trees; Image classification; Image enhancement; Support vector machines; Testing; Automatic image classification; Experimental evaluation; Metamorphic relations; Metamorphic testing; Oracle problem; Performance metrics; Pre-defined class; Statistical analysis methods; Software testing|Article|Final|All Open Access; Green Open Access|Scopus|2-s2.0-85114125392
scopus||||Proceedings - 7th International Workshop on Metamorphic Testing, MET 2022|2022|Proceedings - 7th International Workshop on Metamorphic Testing, MET 2022||||||60|0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135625148&partnerID=40&md5=76bc87d9ecb18d8e66c0a91f4d12ab7f|The proceedings contain 8 papers. The topics discussed include: in-place metamorphic testing and exploration; fairness evaluation in deepfake detection models using metamorphic testing; SR-MT: a metamorphic method to test the robustness of speech recognition software; testing ocean software with metamorphic testing; metamorphic testing in bioinformatics software: a case study on metagenomic assembly; analyzing the reliability of simulated distributed systems using metamorphic testing; on the cost-effectiveness of composite metamorphic relations for testing deep learning systems; and automated generation of metamorphic relations for query-based systems.|||Conference review|Final||Scopus|2-s2.0-85135625148
scopus|Jin D.; Wang Z.; Li M.; Zhu X.|Jin, Dongsheng (57392073700); Wang, Zhi (57192241478); Li, Mingyang (57207884211); Zhu, Xinjie (58075292100)|57392073700; 57192241478; 57207884211; 58075292100|Construction and application of knowledge graph of domestic operating system testing|2021|ACM International Conference Proceeding Series||||268|273|5|1|10.1145/3494885.3494933|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122034229&doi=10.1145%2f3494885.3494933&partnerID=40&md5=2d2b2b15a0dc114a26d54c36ffbabc8e|Aiming at the problems of poor reusability of domestic operating system test cases and insufficient sharing of test case design experience at this stage, a method for constructing knowledge graphs in the field of domestic operating system testing is proposed, and ontology construction and natural language processing technologies are applied to the field of software testing. Use the strong correlation of the knowledge graph to mine the experience knowledge in the design of historical test cases, select and reuse test cases that meet the test requirements for testers, and help them design test cases more efficiently. Through empirical research, this method gives full play to the advantages of knowledge graphs in relational network analysis and retrieval, and the coverage rate of reused test cases reaches 71%, which can greatly save test costs and improve test efficiency, and has strong engineering application value. © 2021 ACM.|Domestic operating system; Knowledge graph; Ontology construction; Reuse of test cases; Software testing|Application programs; Computer software reusability; Cost engineering; Knowledge graph; Natural language processing systems; Ontology; Reusability; Testing; Domestic operating system; Knowledge graphs; Ontology construction; Reuse; Reuse of test case; Software testings; System test; System testing; Test case; Test case designs; Software testing|Conference paper|Final||Scopus|2-s2.0-85122034229
scopus||||6th International Conference on Digital Transformation and Global Society, DTGS 2021|2022|Communications in Computer and Information Science|1503 CCIS|||||544|0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124650496&partnerID=40&md5=c536d26dd524916bd27b80d81c87b160|The proceedings contain 38 papers. The special focus in this conference is on Digital Transformation and Global Society. The topics include: Institutional Factors for Building Trust in Information Technologies: Case-Study of Saint Petersburg; main Regulatory Plans in European Union’s New Digital Regulation Package; lex Informatica: Information Technology as a Legal Tool; detection the Relevance of Urban Functions for Value-Based Smart City Management; Identifying Troubles and Expectations of the Citizens Towards Their Habitat Based on PPGIS Approach; smart Technologies and Their Role in the Modernization of Non-motorized Urban Transport in Russia; support for RoboCops: Measuring Effects of Attitudes Towards Police and Policing Technologies; learning Hard or Hardly Learning: Smartphones in the University’s Classrooms; designing Educational Trajectories for Generation Z: Identifying Cognitive Factors; a Semi-automated Pipeline for Mapping the Shifts and Continuities in Media Discourse; attitudes Towards Digital Educational Technologies, Academic Motivation and Academic Achievements Among Russian University Students; the Role of Values in Academic Cheating at University Online; designing Workflow for Improving Literature Review Process Based on Co-citation Networks; interpretable Machine Learning in Social Sciences: Use Cases and Limitations; normalization Issues in Digital Literary Studies: Spelling, Literary Themes and Biographical Description of Writers; prototyping of a Client for Board Games Automated Testing and Analysis; automated Classification of Potentially Insulting Speech Acts on Social Network Sites; following the Lead When Nothing is Certain? Exploring the Image of Russia in Kazakhstani and Ukrainian Digital News Media; participation of Transnational Migrants in the Formation of the Host Country Image Through Mass Self-communication.|||Conference review|Final||Scopus|2-s2.0-85124650496
scopus||||Proceedings - 2022 ACM/IEEE 44th International Conference on Software Engineering, ICSE 2022|2022|Proceedings - International Conference on Software Engineering|2022-May|||||2507|0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133505988&partnerID=40&md5=06d85cf5fa3363c1a8a4743cf19a2fe1|The proceedings contain 197 papers. The topics discussed include: Aper: evolution-aware runtime permission misuse detection for android apps; learning to reduce false positives in analytic bug detectors; towards a green quotient for software projects; quality-driven machine learning-based data science pipeline realization: a software engineering approach; a framework to support software developers in implementing privacy features; let’s talk open-source — an analysis of conference talks and community dynamics; program translation using model-driven engineering; software engineering for responsible ai: an empirical study and operationalized patterns; students vs. professionals: improving the learning of software testing; industry's cry for tools that support large-scale refactoring; diversity in programming education: help underrepresented groups learn programming; to disengage or not to disengage: a look at contributor disengagement in open source software; and applying reconfiguration cost and control pattern modeling to self-adaptive systems.|||Conference review|Final||Scopus|2-s2.0-85133505988
scopus|Spahiu C.S.; Stanescu L.; Marinescu R.; Brezovan M.|Spahiu, Cosmin Stoica (15926573000); Stanescu, Liana (15926500500); Marinescu, Roxana (57198089549); Brezovan, Marius (24178719300)|15926573000; 15926500500; 57198089549; 24178719300|Machine Learning System For Automated Testing|2022|2022 23rd International Carpathian Control Conference, ICCC 2022||||142|146|4|1|10.1109/ICCC54292.2022.9805972|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134167236&doi=10.1109%2fICCC54292.2022.9805972&partnerID=40&md5=bc3c5e8d301425e814d8b749b3be4f4c|The evolution of the systems' complexity grew exponentially in the last years. The security and safety topics became more important than ever in the critical systems, and currently no end-user accepts any product without clear traceability for ensuring robustness to errors and external attacks. To be able to offer this kind of products, a high amount of effort must be invested in testing topics.Even that much part of the testing can be done automatically using automated test sequences, it is critical from the timing point of view to find as many errors as possible in the first hours/days of the testing time slot.The current paper presents a solution based on machine learning which decides the order of the tests, based on learned patterns: it analyses which functionalities are more prone to errors, and it generates the test sequence which needs to be executed at each step, in a recursive manner.  © 2022 IEEE.|automated tests; machine learning|Automation; Learning systems; Machine learning; Automated test; Automated testing; Critical systems; End-users; Machine learning systems; Machine-learning; Systems complexity; Test sequence; Testing time; Timeslots; Errors|Conference paper|Final||Scopus|2-s2.0-85134167236
scopus|Sun Y.; Tan Z.; Li Z.; Long S.|Sun, Yuxia (56174859400); Tan, Ziyuan (57835675100); Li, Zhetao (35074451300); Long, Saiqin (55272375000)|56174859400; 57835675100; 35074451300; 55272375000|Predicting and Analyzing College Students' Performance Based on Multifaceted Data Using Machine Learning|2022|CTISC 2022 - 2022 4th International Conference on Advances in Computer Technology, Information Science and Communications|||||||1|10.1109/CTISC54888.2022.9849815|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136952912&doi=10.1109%2fCTISC54888.2022.9849815&partnerID=40&md5=7c291fa191e6a0b0ce0ea811868f4ad8|During the teaching process of college courses, prediction of students' final performance at early stages can help teachers intervene students and improve the teaching effects. In recent years, there have been some researches on predicting students' performance based on machine learning techniques. However, many existing works lack comprehensive and sufficient student data, and there is still room for improvement in the effectiveness of predictions. Moreover, many existing methods require obtaining student data of the whole semester, which are unavailable until the end of the semester. In order to alleviate the above problems, 576 students' data are collected during five years teaching of our Software Testing course. The multifaceted data consists of 39 attributes covering students' demographic information, theoretical learning activities, practical training activities and contest learning activities. Several prediction models are created based on logical regression, random forest, and convolutional neural network. Experimental studies show that with the student data available in the middle or second half of the semester, our models can effectively predict students' final performance. Furthermore, the student features that most affect the prediction results are analyzed in the experiments.  © 2022 IEEE.|contest; convolutional neural network; logical regression; practical training; random forest; student performance|Convolution; Convolutional neural networks; Decision trees; Forecasting; Machine learning; Random forests; Software testing; Contest; Convolutional neural network; Learning Activity; Logical regression; Performance; Performance based; Practical training; Predicting and analyzing; Random forests; Student performance; Students|Conference paper|Final||Scopus|2-s2.0-85136952912
scopus|Lu Z.|Lu, Zhiqiang (57609101800)|57609101800|An intelligent software testing method for online advertising strategy|2022|2022 IEEE International Conference on Electrical Engineering, Big Data and Algorithms, EEBDA 2022||||1103|1105|2|0|10.1109/EEBDA53927.2022.9744981|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128675418&doi=10.1109%2fEEBDA53927.2022.9744981&partnerID=40&md5=6c31568dadbf9aa2fbc3034498d7508b|In recent years, with the continuous development of Internet technology, Internet products have penetrated into People's Daily life and become an indispensable part of people's life. With the continuous development and innovation of modern artificial intelligence, big data and Internet information technology, the profit model of the Internet is also constantly updated, entering the vision of most researchers. Among them, the income brought by Internet advertising [1] is particularly prominent. So how to quickly test a kind of online advertising strategy has become the main problem facing at present. As for Internet online advertising strategies, the main research direction of major Internet companies is to design different strategies for different groups of people and businesses, and each strategy needs to go through a series of testing procedures to ensure that there will be no serious problems before a certain strategy goes online. However, Whether a real online advertising strategy can meet the established target groups and target businesses, as well as how to really bring revenue to the company can only observe the corresponding results after the online advertising strategy. © 2022 IEEE.|online advertising; process optimization; software testing; testing process|Marketing; Optimization; Testing; Advertising strategy; Continuous development; Daily lives; Intelligent software; Internet technology; Online advertizing; Process optimisation; Software testings; Testing method; Testing process; Software testing|Conference paper|Final||Scopus|2-s2.0-85128675418
scopus|Amjad H.M.W.; Rana Z.A.|Amjad, Hafiz Muhammad Waqas (59122095700); Rana, Zeeshan Ali (24438192900)|59122095700; 24438192900|Using Developer Factors and Horizontal Partitioning to Recommend Bug Severity in Open-Source Software Projects|2022|2022 17th International Conference on Emerging Technologies, ICET 2022||||130|135|5|1|10.1109/ICET56601.2022.10004678|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146842961&doi=10.1109%2fICET56601.2022.10004678&partnerID=40&md5=8053112efcc6d2e220ffbc68906dd962|Software testing is performed during engineering of software to uncover the faults hidden in software systems. This data about the faults and failures is recorded in problem report forms. In addition to recording the symptoms of the problems, the problem report forms record severity of the fault. This severity of the potential failure refers to the impact on user or business. Usually, this severity is assigned by humans responsible for testing of software. Given the fact that faults in the software are result of human errors, literature has reported the use of developers' information to predict faults in software. Using the same intuition, this paper investigates the use of developers' information (along with the static code metrics) to determine the extent of high severity faults in software. To this end, three open-source software projects are studied in this paper and the code files are identified that have a chance of high severity faults. This recommendation can help testing teams identify fault prone files and label code files with high, medium, or low chance of severe faults. Static code metrics for the three projects are collected through SonarQube and developer related factors are extracted from the GitHub through custom scripts. This data is used to develop machine learning classifiers and code files are labelled as high, medium, and low number of severe faults. In order to further study the relationship between the number of developers and the files with severe faults, association between the developer factors and the presence of high severity faults is found. Study of this association reveals that if there are more developers working on a file, the file is more probable to have critical faults.  © 2022 IEEE.|bug severity; defect severity; developer factors; developer information; OSS; static code metrics|Codes (symbols); Information use; Open source software; Open systems; Bug severity; Defect severity; Developer factor; Developer information; Open source software projects; OSS; Potential failures; Software testings; Software-systems; Static code metrics; Software testing|Conference paper|Final||Scopus|2-s2.0-85146842961
scopus|Rehman F.U.; Izurieta C.|Rehman, Faqeer Ur (57271641600); Izurieta, Clemente (16238582400)|57271641600; 16238582400|An Approach For Verifying And Validating Clustering Based Anomaly Detection Systems Using Metamorphic Testing|2022|Proceedings - 4th IEEE International Conference on Artificial Intelligence Testing, AITest 2022||||12|18|6|5|10.1109/AITest55621.2022.00011|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141093468&doi=10.1109%2fAITest55621.2022.00011&partnerID=40&md5=c08d67e62ba0d357ef1d068ab46927b3|An oracle or test oracle is a mechanism that a software tester uses to verify the program output. In software testing, the oracle problem arises when either the oracle is not available or it may be available but is so expensive that it is infeasible to apply. To help address this problem in testing machine learning-based applications, we propose an approach for testing clustering algorithms. We exemplify this in the implementation of the award-winning density-based clustering algorithm i.e., Density-based Spatial Clustering of Applications with Noise (DBSCAN). Our proposed approach is based on the 'Metamorphic Testing' technique which is considered an effective approach in alleviating the oracle problem. Our contributions in this paper include, i) proposing and showing the applicability of a broader set of 21 Metamorphic Relations (MRs), among which 8 target the verification aspect, whereas, 14 of them target the validation aspect of testing the algorithm under test, and ii) identifying and segregating the MRs (by providing a detailed analysis) to help both naive and expert users understand how the proposed MRs target both the verification and validation aspects of testing the DBSCAN algorithm. To show the effectiveness of the proposed approach, we further conduct a case study on an anomaly detection system. The results obtained show that, i) different MRs have the ability to reveal different violation rates (for the given data instances); thus, showing their effectiveness, and ii) although we have not found any implementation issues (through verification) in the algorithm under test (that further enhances our trust in the implementation), the results suggest that the DBSCAN algorithm may not be suitable for scenarios (meeting the user expectations a.k.a validation) captured by almost 79% of violated MRs; which show high susceptibility to small changes in the dataset.  © 2022 IEEE.|Anomaly Detection; Clustering; Machine Learning; Metamorphic Testing; Oracle Problem; Validation; Verification|Clustering algorithms; Learning algorithms; Machine learning; Software testing; Testing; Anomaly detection; Anomaly detection systems; Clusterings; Density-based spatial clustering of applications with noise; Machine-learning; Metamorphic relations; Metamorphic testing; Oracle problem; Test oracles; Validation; Anomaly detection|Conference paper|Final||Scopus|2-s2.0-85141093468
scopus|Borg M.|Borg, Markus (37103431600)|37103431600|Using Search-Based Software Testing to Guide the Strive for Robust Machine Learning Components: Lessons Learned Across Systems and Simulators in the Mobility Domain|2022|Proceedings - 2022 IEEE 14th International Conference on Software Testing, Verification and Validation Workshops, ICSTW 2022||||1|||0|10.1109/ICSTW55395.2022.00014|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133233077&doi=10.1109%2fICSTW55395.2022.00014&partnerID=40&md5=2ba1cca0f6bd963b004f7ef9db0530fb|This talk shares lessons learned from using search-based techniques for robustness testing in simulators.  © 2022 IEEE.||Learning systems; Machine components; Machine learning; Machine-learning; Robustness testing; Search-based; Search-based software testing; Software testing|Conference paper|Final||Scopus|2-s2.0-85133233077
scopus|Husin T.F.; Pribadi M.R.; Yohannes|Husin, Thingkilia Finnatia (57983428400); Pribadi, Muhammad Rizky (57205225991); Yohannes (59541306600)|57983428400; 57205225991; 59541306600|Implementation of LSSVM in Classification of Software Defect Prediction Data with Feature Selection|2022|International Conference on Electrical Engineering, Computer Science and Informatics (EECSI)|2022-October|||126|131|5|8|10.23919/EECSI56542.2022.9946611|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142696888&doi=10.23919%2fEECSI56542.2022.9946611&partnerID=40&md5=235fe613bd1658a605408a230e900d39|Software defect prediction enhances the quality, efficiency, and effectiveness of time and expenses for software testing by focusing on defect modules. Software defect prediction technology uses machine learning to predict defect modules, making allocating limited resources easier quickly. Software defect prediction datasets naturally have imbalanced class problems with significantly few defective modules compared to non-defective modules. In this study, software defect prediction data was classified by implementing the LSSVM algorithm with ReliefF (K=10) feature selection and applying the SMOTE method to overcome the imbalanced class problem in the dataset. The datasets used are software defect prediction datasets of the public NASA MDP Promise project, namely CM1, PC1, KC1, and KC2. Dataset divided into training and testing data using Fold Cross-Validation with ten folds. The classifier achieved the highest average accuracy on the PC1 dataset, which was 93,87%, while the highest Area Under the ROC Curve (AUC) was achieved by the classifier for the KC2 dataset, which was 78,35%. The results also indicate that AUC values for classifiers that use SMOTE always higher than non-SMOTE in each dataset  © 2022 Institute of Advanced Engineering and Science (IAES).|Classification; LSSVM; ReliefF; SMOTE; Software Defect Prediction||Conference paper|Final||Scopus|2-s2.0-85142696888
scopus|Tizpaz-Niari S.; Kumar A.; Tan G.; Trivedi A.|Tizpaz-Niari, Saeid (57193916304); Kumar, Ashish (57208058157); Tan, Gang (57192503632); Trivedi, Ashutosh (7006248965)|57193916304; 57208058157; 57192503632; 7006248965|Fairness-aware Configuration of Machine Learning Libraries|2022|Proceedings - International Conference on Software Engineering|2022-May|||909|920|11|34|10.1145/3510003.3510202|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131378824&doi=10.1145%2f3510003.3510202&partnerID=40&md5=d581225a80d3c8bd9ceeb99e8b568dbd|This paper investigates the parameter space of machine learning (ML) algorithms in aggravating or mitigating fairness bugs. Data-driven software is increasingly applied in social-critical applications where ensuring fairness is of paramount importance. The existing approaches focus on addressing fairness bugs by either modifying the input dataset or modifying the learning algorithms. On the other hand, the selection of hyperparameters, which provide finer controls of ML algorithms, may enable a less intrusive approach to influence the fairness. Can hyperparameters amplify or suppress discrimination present in the input dataset? How can we help programmers in detecting, understanding, and exploiting the role of hyperparameters to improve the fairness? We design three search-based software testing algorithms to un-cover the precision-fairness frontier of the hyperparameter space. We complement these algorithms with statistical debugging to explain the role of these parameters in improving fairness. We implement the proposed approaches in the tool Parfait-ML (PARameter FAIrness Testing for ML Libraries) and show its effectiveness and utility over five mature ML algorithms as used in six social-critical applications. In these applications, our approach successfully iden-tified hyperparameters that significantly improve (vis-a-vis the state-of-the-art techniques) the fairness without sacrificing precision. Surprisingly, for some algorithms (e.g., random forest), our approach showed that certain configuration of hyperparameters (e.g., restricting the search space of attributes) can amplify biases across applications. Upon further investigation, we found intuitive explanations of these phenomena, and the results corroborate simi-lar observations from the literature. © 2022 ACM.||Application programs; Learning algorithms; Libraries; Machine learning; Parameter estimation; Program debugging; Software testing; Critical applications; Data driven; Hyper-parameter; Hyper-parameter space; Machine learning algorithms; Machine-learning; Parameter spaces; Search-based software testing; Statistical debugging; Testing algorithm; Decision trees|Conference paper|Final|All Open Access; Green Open Access|Scopus|2-s2.0-85131378824
scopus|Serra J.; Quezada R.; Fortes S.; Tellez N.; Allaico A.; Landaverde E.; Kumar Y.; Li J.J.; Morreale P.|Serra, J. (58378911500); Quezada, R. (57989671600); Fortes, S. (57226388232); Tellez, N. (57871535800); Allaico, A. (57207737343); Landaverde, E. (57989805800); Kumar, Y. (57222584738); Li, J.J. (57196156442); Morreale, P. (6602140304)|58378911500; 57989671600; 57226388232; 57871535800; 57207737343; 57989805800; 57222584738; 57196156442; 6602140304|Validation of AI models for ITCZ Detection from Climate Data|2022|2022 5th International Conference on Data Science and Information Technology, DSIT 2022 - Proceedings|||||||3|10.1109/DSIT55514.2022.9943879|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137147218&doi=10.1109%2fDSIT55514.2022.9943879&partnerID=40&md5=be7428caa9296db4cd659f9d172fdd5b|The Climate Change topic itself and associated life adjustments became a top global problem of the XXI century. It requires immediate attention and long-term solutions. Physical tracing of weather changes, performed without Artificial Intelligence (AI), is not capable of detection in a timely manner and correctly classifying dangerous situations, which is crucial for making rapid decisions and taking immediate actions on the ground. AI and Machine Learning (ML) systems are currently dominating solutions in Computer Science research fields and the issues of their testing and validation remain a critical open problem due to their uncertain outcomes. We use test automation to validate and assure the quality of various AI systems for one kind of weather prediction. The subject of our study is Inter-Tropical Convergence Zones (ITCZs). ITCZs play an important role in the global circulation system and even small changes in their patterns can cause severe droughts or flooding as well as other disasters like hurricanes. Global warming is causing more ITCZ scenarios as shown in weather data, which makes physical detection infeasible. Our research initially discovered that ITCZ detection based on a physical model alone could misclassify some unexpected situations when the double bands occur at different places with similar intensity or at the same places with different intensities. We then designed experiments to train AI models to detect ITCZs with test automation to collect results. We further trained several AI models with focus on VGG-16, VGG-19, Xception and MobileNETV2 models, collected and compared their results through test automation. Our exhaustive trials eventually achieved a 96.8% accuracy, which might be the best AI model to detect ITCZs with test automation and without human intervention. These results show that test automation can contribute to the selection of optimum AI models.  © 2022 IEEE.|Artificial Intelligence (AI); Climate Change; Deep Learning (DL); ITCZ Detection; Test Automation; Weather Prediction|Automation; Climate models; Deep learning; Learning systems; Testing; Weather forecasting; Artificial intelligence; Climate data; Convergence zones; Deep learning; Global problems; Intelligence models; Inter-tropical convergence zone detection; Test Automation; Weather prediction; Zone detection; Global warming|Conference paper|Final||Scopus|2-s2.0-85137147218
scopus|Viggiato M.; Paas D.; Buzon C.; Bezemer C.-P.|Viggiato, Markos (57203384629); Paas, Dale (57313876500); Buzon, Chris (57313802700); Bezemer, Cor-Paul (35742992600)|57203384629; 57313876500; 57313802700; 35742992600|Using Natural Language Processing Techniques to Improve Manual Test Case Descriptions|2022|Proceedings - International Conference on Software Engineering||||311|320|9|7|10.1109/ICSE-SEIP55303.2022.9794054|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128443504&doi=10.1109%2fICSE-SEIP55303.2022.9794054&partnerID=40&md5=7e22f5e08fa935b25f9858ff15ddc837|Despite the recent advancements in test automation, testing often remains a manual, and costly, activity in many industries. Manual test cases, often described only in natural language, consist of one or more test steps, which are instructions that must be performed to achieve the testing objective. Having different employees specifying test cases might result in redundant, unclear, or incomplete test cases. Manually reviewing and validating newly-specified test cases is time-consuming and becomes impractical in a scenario with a large test suite. Therefore, in this paper, we propose an automated framework to automatically analyze test cases that are specified in natural language and provide actionable recommendations on how to improve the test cases. Our framework consists of configurable components and modules for analysis, which are capable of recommending improvements to the following: (1) the terminology of a new test case through language modeling, (2) potentially missing test steps for a new test case through frequent itemset and association rule mining, and (3) recommendation of similar test cases that already exist in the test suite through text embedding and clustering. We thoroughly evaluated the three modules on data from our industry partner. Our framework can provide actionable recommendations, which is an important challenge given the widespread occurrence of test cases that are described only in natural language in the software industry (in particular, the game industry).  © 2022 IEEE.|Association rules; Clustering; Game testing; Language modeling; Natural language processing|Association rules; Computational linguistics; Modeling languages; Natural language processing systems; Testing; Case description; Clusterings; Game testing; Language model; Language processing; Language processing techniques; Manual tests; Natural language processing; Natural languages; Test case; Software testing|Conference paper|Final||Scopus|2-s2.0-85128443504
scopus|Ali A.R.; Ur Rehman A.; Nawaz A.; Ali T.M.; Abbas M.|Ali, Amad Rizwan (58267528400); Ur Rehman, Attique (57518469400); Nawaz, Ali (57219792558); Ali, Tahir Muhammad (57204504103); Abbas, Muhammad (57649813300)|58267528400; 57518469400; 57219792558; 57204504103; 57649813300|An Ensemble Model for Software Defect Prediction|2022|2022 2nd International Conference on Digital Futures and Transformative Technologies, ICoDT2 2022|||||||5|10.1109/ICoDT255437.2022.9787439|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133191415&doi=10.1109%2fICoDT255437.2022.9787439&partnerID=40&md5=187cc9f1ca0da6ed41ae709df165bdf8|Software testing is one of the important ways to ensure the quality of software. It is found that testing cost more than 50% of overall project cost. Effective and efficient software testing utilizes the minimum resources of software. Therefore, it is important to construct the procedure which is not only able to perform the efficient testing but also minimizes the utilization of project resources. The goal of software testing is to find maximum defects in the software system. As world is continuously moving toward data driven approach for making important decision. Therefore, in this research paper we performed the machine learning analysis on the publicly available datasets and tried to achieve the maximum accuracy. The major focus of the paper is to apply different machine learning techniques on the datasets and find out which technique produce efficient result. Particularly, we proposed an ensemble learning models and perform comparative analysis among KNN, Decision tree, SVM and Naïve Bayes on different datasets and it is demonstrated that performance of Ensemble method is more than other methods in term of accuracy, precision, recall and F1-score. The classification accuracy of ensemble model trained on CM1 is 98.56%, classification accuracy of ensemble model trained on KM2 is 98.18% similarly, the classification accuracy of ensemble learning model trained on PC1 is 99.27%. This reveals that ensemble learning is more efficient method for making the defect prediction as compared other techniques.  © 2022 IEEE.|Machine learning; Software Defects; Software Quality Engineering; Software testing; Supervised learning|Computer software selection and evaluation; Decision trees; Defects; Learning systems; Support vector machines; Classification accuracy; Ensemble learning; Ensemble models; Learning models; Machine-learning; Quality of softwares; Software defect prediction; Software defects; Software quality engineering; Software testings; Software testing|Conference paper|Final||Scopus|2-s2.0-85133191415
scopus|Liu Y.; Feng L.; Wang X.; Zhang S.|Liu, Yue (57858157100); Feng, Lichao (57429602700); Wang, Xingya (55969090300); Zhang, Shiyu (57429254400)|57858157100; 57429602700; 55969090300; 57429254400|DeepBoundary: A Coverage Testing Method of Deep Learning Software based on Decision Boundary Representation|2022|Proceedings - 2022 IEEE 22nd International Conference on Software Quality, Reliability and Security Companion, QRS-C 2022||||166|172|6|2|10.1109/QRS-C57518.2022.00032|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152636615&doi=10.1109%2fQRS-C57518.2022.00032&partnerID=40&md5=898bf64b54e35aab7775280cd3214806|With the increasing application of Deep Learning (DL) Software in safety-critical fields such as autonomous driving, we need adequate testing to ensure software quality. Observing the decision-making behavior of a Deep Neural Network (DNN) is an essential step in DL software testing. Taking Guiding Deep Learning System Testing Using Surprise Adequacy (SADL) as an example, it uses the independent neuron activation values in the DNN to represent the decision-making behavior. However, the behavior of the DNN needs to be jointly determined by the continuous outputs of all neurons. As a result, the coverage value of SADL constant volatility and lack of stability. To mitigate this problem, we propose a coverage testing method based on the decision boundary representation, DeepBoundary, for the decision-making behavior of DL software. Unlike SADL, DeepBoundary generates decision boundary data to represent the decision behavior of the DNN, which makes the testing results more stable. On this basis, we calculate the kernel density between the testing data and the decision boundary data. It measures the position of the testing data in the decision space and the distance from the decision boundary. Finally, as an adequacy indicator, we calculate the decision boundary density coverage (DBC) of the entire testing set. The experiment on the dataset MNIST and two DL software shows that DeepBoundary can generate actual decision boundary data. The average confidence error in the DNNs output layer is only 4.20E-05. Compared with SADL, DeepBoundary has a stronger correlation with the defect detection ratio, which can more accurately represent testing adequacy. © 2022 IEEE.|decision boundaries; DL software; testing adequacy|Application programs; Computer software selection and evaluation; Decision making; Safety engineering; Safety testing; Software testing; Boundary data; Boundary representations; Coverage testing; Decision boundary; Decision-making behaviors; Deep learning software; Learning software; Testing adequacies; Testing data; Testing method; Deep neural networks|Conference paper|Final||Scopus|2-s2.0-85152636615
scopus||||6th International Conference on Intelligent Transportation Engineering, ICITE 2021|2022|Lecture Notes in Electrical Engineering|901 LNEE|||||1210|0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131928932&partnerID=40&md5=e4715c0bb18fda71228f2a98a0ce2744|The proceedings contain 107 papers. The special focus in this conference is on Intelligent Transportation Engineering. The topics include: Research on Optimal Distribution Route of Auto Parts Circulation System; traffic Signal Control for Urban Intersection Under Connected Vehicle Data Environment; real-Time Traffic Safety Prediction Model for the Lower Reaches of Yangtze River; exploring the Effects of Request Time, Secondary Task, and Take-Over Mode on Take-Over Performance; research on Trajectory Tracking Control of Skid Steering Vehicle Based on Model Predictive Control; fuel Efficient Predictive Cruise Control for Commercial Vehicles with Load Variation; evaluation of Dual Task Switching Behavior of Smartphone Addicted Drivers; supply Chain Financing Decision and Financing Value Under Cap-and-Trade Regulation; a Method for Daily Traffic Flow Parameter Forecasting Combining the Impact of Holidays; short-Time Prediction of Subway Inbound Passenger Flow Based on K-means Clustering Combination Model; metro Train Energy Consumption Modeling and Emulation Based on Traveling Routes; research on Management Improvement of Visual Marketing Intelligence System in Automobile 4S Shop; lane-Changing Behavior Recognition in the Connected Vehicle Environment; research on Automated Testing Scheme of Exceptional Scenarios in Unattended Train Operation of Urban Transit; research on the Coupling Relationship Between Passengers and Vehicles Based on Anylogic Simulation-Take Bus Boarding as an Example; Study on Safety Evaluation of Freeway Tunnel Operation Based on the Grey Correlation Method and IAHP; oval Shortest Path Algorithm Used for Fire Truck Dispatch; Study on High Temperature Rheological Properties of GO Modified Asphalt; Study on Design and Application of AGM Based on Artificial Intelligence.|||Conference review|Final||Scopus|2-s2.0-85131928932
scopus|Arrieta A.|Arrieta, Aitor (56514865400)|56514865400|On the Cost-Effectiveness of Composite Metamorphic Relations for Testing Deep Learning Systems|2022|Proceedings - 7th International Workshop on Metamorphic Testing, MET 2022||||42|47|5|2|10.1145/3524846.3527335|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135218555&doi=10.1145%2f3524846.3527335&partnerID=40&md5=d8c3c2505489a71f9e893e0e33a3dc14|Deep Learning (DL) components are increasing their presence in mission and safety-critical systems, such as autonomous vehicles. The verification process of such systems needs to be rigorous, for which automated solutions are paramount. To allow test automation, test oracles are necessary. In the context of DL systems, meta-morphic test oracles have found to be effective. However, such oracles require the execution of multiple tests, which makes testing more expensive. Metamorphic relation composition can reduce the cost of metamorphic testing. However, its effectiveness has found mixed answers. This paper reports the preliminary results of our study on measuring the cost-effectiveness of composite metamor-phic relations for testing DL systems. To this end, we empirically evaluate the cost-effectiveness of composite metamorphic relations within a DL model for object classification. Our results suggest that composite metamorphic relations reduce the failure revealing capability when compared to their component metamorphic relations.  © 2022 ACM.|Deep Learning Systems; Metamoprhic Testing; Metamorphic Relation Composition|Cost effectiveness; Deep learning; Safety engineering; Automated solutions; Autonomous Vehicles; Deep learning system; Metamoprhic testing; Metamorphic relation composition; Metamorphic relations; Mission critical systems; Safety critical systems; Test oracles; Verification process; Learning systems|Conference paper|Final|All Open Access; Green Open Access|Scopus|2-s2.0-85135218555
scopus|Jena S.D.; Kaur J.; Rani R.|Jena, Sushree Deepa (57550740600); Kaur, Jagdeep (10240510100); Rani, Rajneesh (36997524100)|57550740600; 10240510100; 36997524100|A Review of Prediction of Software Defect by Using Machine Learning Algorithms|2022|Lecture Notes in Electrical Engineering|832|||61|70|9|1|10.1007/978-981-16-8248-3_5|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127072118&doi=10.1007%2f978-981-16-8248-3_5&partnerID=40&md5=26e95416056548c73f9639e37ec136b9|Software testing is an important and critical phase of software development. But software testing is a time-consuming and costly process. Before testing phase if the software faults or defects are identified then the efficiency of time will increase and cost will decrease. Defect prediction is a classification problem whose goal is to classify the software modules into defect prone and non-defect prone modules. In this paper we have demonstrated a machine learning model which will classify the modules as defect prone or non-defect prone. First the defect dataset is selected from PROMISE repository. Then dataset is preprocessed in which feature selection (FS) techniques are used; then the ensemble learning is used for classification. Bagging and boosting are some type of ensemble learning which will give better accuracy than existing defect prediction models. © 2022, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.|Feature selection; Machine learning ensemble algorithm; Software defect prediction (SDP)|Classification (of information); Feature extraction; Forecasting; Learning algorithms; Machine learning; Software design; Software testing; Critical phasis; Ensemble algorithms; Ensemble learning; Features selection; Machine learning algorithms; Machine learning ensemble algorithm; Software defect prediction; Software defects; Software testings; Defects|Conference paper|Final||Scopus|2-s2.0-85127072118
scopus|Gulec U.; Yilmaz M.; Isler V.; Clarke P.M.|Gulec, Ulas (57063006200); Yilmaz, Murat (55738449500); Isler, Veysi (15127353000); Clarke, Paul M. (36536766400)|57063006200; 55738449500; 15127353000; 36536766400|Applying virtual reality to teach the software development process to novice software engineers|2021|IET Software|15|6||464|483|19|9|10.1049/sfw2.12047|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128339990&doi=10.1049%2fsfw2.12047&partnerID=40&md5=d4debd301bdc23593eaebc39e636d804|Software development is a complicated process that requires experienced human resources to produce successful software products. Although this process needs experience from the individuals, it is hard to provide this experience without encountering real incidents during the software development process. To fill this gap, this study proposes a Virtual Reality Based Software Development Framework (VR-SODEF), which provides an interactive virtual reality experience for individuals learning about the tasks of software development starting from requirement analysis through software testing. In the VR-SODEF, the participant takes on the role of a novice software developer being recruited into a virtual software development organisation who should work alongside five virtual characters, played by artificial intelligence. This exclusive viewpoint draws participants from the 2D separation of the classical experience and virtually into the world of the software development itself. Participants experience the intense dramatic elements created for simulation and confront the challenges of virtual software practitioners in a somewhat uncompromising virtual simulation environment. To examine the efficiency of the VR-SODEF, it was tested on 32 computing students, with results indicating that virtual reality can be an effective educational medium, especially for skills that might traditionally be acquired through experience rather than traditional classroom-based teaching. © 2021 The Authors. IET Software published by John Wiley & Sons Ltd on behalf of The Institution of Engineering and Technology.|interactive learning environments; software development life cycle; software development process; software engineering education; virtual reality|Computer aided instruction; E-learning; Learning systems; Life cycle; Software design; Software testing; Students; Individual learning; Interactive learning environment; Interactive virtual reality; Process needs; Software development framework; Software development life-cycle; Software development process; Software engineering education; Software products; Virtual reality experiences; Virtual reality|Article|Final|All Open Access; Gold Open Access; Green Open Access|Scopus|2-s2.0-85128339990
scopus||||CBSOFT 2021 - Brazilian Conference on Software;  Proceedings - 6th Brazilian Symposium on Systematic and Automated Software Testing, SAST 2021|2021|ACM International Conference Proceeding Series||||||72|0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118213993&partnerID=40&md5=63c076e0b13c1db928631e88c58e1017|The proceedings contain 7 papers. The topics discussed include: on using decision tree coverage criteria for testing machine learning models; an analysis of automated code inspection tools for PHP available on Github marketplace; automating transaction testing involving payment at PoS (Point of Sale) terminals: an experience report at a technology company; the impact on the test coverage caused by the introduction of adaptive behavior in a legacy web application: a case study; investigating test smells in JavaScript test code; on the use of test smells for prediction of flaky tests; and how do testers feel it? an experience report on evaluating TX in an industrial context.|||Conference review|Final||Scopus|2-s2.0-85118213993
scopus||||12th International Conference on Computer Engineering and Networks, CENet 2022|2022|Lecture Notes in Electrical Engineering|961 LNEE|||||1487|0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144502677&partnerID=40&md5=dd2537a94ad9bc060f88b9d26f2db94c|The proceedings contain 156 papers. The special focus in this conference is on Computer Engineering and Networks. The topics include: Research on a Trusted Delivery Process Model of Cloud Services; a New Tooth Semantic Segmentation Algorithm of Orthodontics; An Improved YOLOX with C_Focus Module and Spatial Attention Mechanism for Traffic Sign Detection; SCAM-YOLOv5: Improved YOLOv5 Based on Spatial and Channel Attention Module; A Leaf Recognition Algorithm Based on KNN Classifier; semantic Line Detection: A Survey; an Application of Knowledge Graph for Enterprise Risk Prediction; an Enterprise Risk Prediction Model Combined Financial Data and News Based on Memory Network; a Study on Online Reservation Behavior of Hotel Catering Industry; research on the Automated Testing Framework for Android Applications; split Learning Based on Self-supervised Learning; Design and Implementation of a Security Baseline Check System for UOS; research on High Speed Vehicle Density Prediction Based on Combined Model; a Query Intention Classification Method of e-commerce Platform Based on Support Vector Machine; case Report: Diagnostic Analysis of Meteorological Conditions Conducive to an Aircraft Icing in Chengdu, China; a Collaborative Filtering Algorithm Integrating Balance Factor and Time Weight; research on Cross Target Center Location Algorithm Based on Edge Refinement Fitting Method; self-supervised Learning in Computer Vision: A Review; deep Q Network Applied in Trading Portfolio of Virtual Currencies; College English Teaching Design Based on WE Learn Computer Platform; design of Automatic Control System for Indoor Lighting; lithium Battery Life Prediction Based on Edge Computing and Deep Learning; collaborative Optimization Study of Order, Location and Route in Warehouse System.|||Conference review|Final||Scopus|2-s2.0-85144502677
scopus|Fu W.; Wang L.|Fu, Weiyu (57891656600); Wang, Lixia (57828762900)|57891656600; 57828762900|Component-Based Software Testing Method Based on Deep Adversarial Network|2022|Security and Communication Networks|2022||4231083||||0|10.1155/2022/4231083|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141000423&doi=10.1155%2f2022%2f4231083&partnerID=40&md5=325fce89586849e70bac9d2deb18122c|With the continuous updating and application of software, the current problems in software are becoming more and more serious. Aiming at this phenomenon, the application and testing methods of componentized software based on deep adversarial networks are discussed. The experiments show that: (1) some of the software has a high fusion rate, reaching an astonishing 95% adaptability. The instability and greater potential of component-based software are solved through GAN and gray evaluation. With the evaluation system, people are dispelled. Trust degree. (2) According to the data in the graph and table, the deep learning adversarial network solves the vulnerability and closedness of the general network, and the built-in test method with experimental data reaching an average accuracy rate of 90% is the best test method for this system. With the deep learning adversarial network, the average test level of component-based software reaches level 7, which makes the new software industry of component-based software have a long way to go. © 2022 Weiyu Fu and Lixia Wang.||Deep learning; Learning systems; Network security; Software testing; Testing; Adversarial networks; Application method; Component based software; Component-based software testing; Components-based software; Continuous updating; Current problems; Grey evaluation; Test method; Testing method; Application programs|Article|Final|All Open Access; Gold Open Access|Scopus|2-s2.0-85141000423
scopus|Martins L.; Bezerra C.; Costa H.; MacHado I.|Martins, Luana (57205433655); Bezerra, Carla (56448432100); Costa, Heitor (26031311400); MacHado, Ivan (36998427800)|57205433655; 56448432100; 26031311400; 36998427800|Smart prediction for refactorings in the software test code|2021|ACM International Conference Proceeding Series||||115|120|5|5|10.1145/3474624.3477070|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117129081&doi=10.1145%2f3474624.3477070&partnerID=40&md5=a367a8bc5e7d42489a3aa390d06f2cf7|Test smells are bad practices to either design or implement a test code. Their presence may reduce the test code quality, harming the software testing activities, primarily from a maintenance perspective. Therefore, defining strategies and tools to handle test smells and improve the test code quality is necessary. State-of-the-art strategies encompass automated support mainly based on hard thresholds of rules, static and dynamic metrics to identify the test smells. Such thresholds are subjective to interpretation and may not consider the complexity of the software projects. Moreover, they are limited as they do not automate test refactoring but only count on developers' expertise and intuition. In this context, a technique that uses historical implicit or tacit data to generate knowledge could assist the identification and refactoring of test smells. This study aims to establish a novel approach based on machine learning techniques to suggest developers refactoring strategies for test smells. As an expected result, we could understand the applicability of the machine learning techniques to handle test smells and a framework proposal that helps developers in decision-making regarding the refactoring of test smells. © 2021 ACM.|Machine Learning; Software Quality; Test Smells|Codes (symbols); Computer software selection and evaluation; Decision making; Learning algorithms; Machine learning; Software testing; Testing; Bad practices; Code quality; Machine learning techniques; Machine-learning; Refactorings; Software Quality; Software testings; Strategies and tools; Test code; Test smell; Odors|Conference paper|Final||Scopus|2-s2.0-85117129081
scopus|Li X.; Tao C.; Gao J.; Guo H.|Li, Xiaomin (57788089300); Tao, Chuanqi (36086787600); Gao, Jerry (7404475003); Guo, Hongjing (57215096241)|57788089300; 36086787600; 7404475003; 57215096241|A Review of Quality Assurance Research of Dialogue Systems|2022|Proceedings - 4th IEEE International Conference on Artificial Intelligence Testing, AITest 2022||||87|94|7|6|10.1109/AITest55621.2022.00021|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141068612&doi=10.1109%2fAITest55621.2022.00021&partnerID=40&md5=96ad8fa0859996322504060bf6baa446|With the development of machine learning and big data technology, dialogue systems have been applied to many fields, including aerospace, banking and other scenarios that require high accuracy of answer. This has prompted a great deal of research on quality verification and assurance of dialogue systems. As two means to ensure the quality of software, testing and evaluation are rarely comprehensively summarized in current research work. Firstly, the dialogue systems are classified according to different classification standards. Secondly, this paper reviews the existing quality assurance work of dialogue systems from testing and dialogue evaluation, including testing methods, testing tools, evaluation metrics and dialogue quality attributes. Moreover, the issues and needs are discussed aiming at the deficiency in the current work, which can provide references for future research.  © 2022 IEEE.|dialogue evaluation; dialogue systems; quality assurance; test methods; test tools|Quality control; Software testing; Speech processing; Testing; 'current; Data technologies; Dialogue evaluation; Dialogue systems; High-accuracy; Machine-learning; Quality of softwares; Quality verification; Test method; Test tools; Quality assurance|Conference paper|Final||Scopus|2-s2.0-85141068612
scopus|Wei Z.; Wang H.; Yang Z.; Chan W.K.|Wei, Zhengyuan (57219514891); Wang, Haipeng (57217848983); Yang, Zhen (57219595980); Chan, W.K. (55471383000)|57219514891; 57217848983; 57219595980; 55471383000|SEbox4DL: A Modular Software Engineering Toolbox for Deep Learning Models|2022|Proceedings - International Conference on Software Engineering||||193|196|3|2|10.1109/ICSE-Companion55297.2022.9793795|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132418872&doi=10.1109%2fICSE-Companion55297.2022.9793795&partnerID=40&md5=7ae92766e4a83357987aaf678ada9db1|Deep learning (DL) models are widely used in software applications. Novel DL models and datasets are published from time to time. Developers may also tempt to apply new software engineering (SE) techniques on their DL models. However, no existing tool supports the applications of software testing and debugging techniques on new DL models and their datasets without modifying the code. Developers should manually write code to glue every combination of models, datasets, and SE technique and chain them together.We propose SEbox4DL, a novel and modular toolbox that automatically integrates models, datasets, and SE techniques into SE pipelines seen in developing DL models. SEbox4DL exemplifies six SE pipelines and can be extended with ease. Each user-defined task in the pipelines is to implement a SE technique within a function with a unified interface so that the whole design of SEbox4DL is generic, modular, and extensible. We have implemented several SE techniques as user-defined tasks to make SEbox4DL off-the-shelf. Our experiments demonstrate that SEbox4DL can simplify the applications of software testing and repair techniques on the latest or popular DL models and datasets. The toolbox is open-source and published at https://github.com/Wsine/SEbox4DL. A video for demonstration is available at: https://youtu.be/EYeFFi4lswc. © 2022 IEEE.|neural networks; repair; software engineering; testing; toolbox|Deep learning; HTTP; Learning systems; Open source software; Pipelines; Program debugging; Repair; Software testing; Engineering techniques; Learning dataset; Learning models; Modular softwares; Modulars; Neural-networks; Software applications; Software Testing and Debugging; Tool support; Toolbox; Application programs|Conference paper|Final||Scopus|2-s2.0-85132418872
scopus|Anand K.; Jena A.K.; Choudhary T.|Anand, Kunal (58002037700); Jena, Ajay Kumar (36620382800); Choudhary, Tanisha (58209997300)|58002037700; 36620382800; 58209997300|Performance Analysis of Feature Selection Techniques in Software Defect Prediction using Machine Learning|2022|ASSIC 2022 - Proceedings: International Conference on Advancements in Smart, Secure and Intelligent Computing|||||||6|10.1109/ASSIC55218.2022.10088364|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85154613776&doi=10.1109%2fASSIC55218.2022.10088364&partnerID=40&md5=4d6a05bc2f37c63b4d036a08534b24d4|Software Testing is an essential activity in the development process of a software product. A defect-free software is the need of the hour. Identifying the defects as early as possible is critical to avoid any disastrous consequences in the later stages of development. Software Defect Prediction (SDP) is a process of early identification of defect-prone modules. Lately, software defect prediction coupled with machine learning techniques has gained momentum as it significantly brings down maintenance costs. Feature selection (FS) plays a very significant role in a defect prediction model's efficiency; hence, choosing a suitable FS method is challenging when building a defect prediction model. This paper evaluates six filter-based FS techniques, four wrapper-based FS techniques, and two embedded FS techniques using four supervised learning classifiers over six NASA datasets from the PROMISE repository. The experimental results strengthened that FS techniques significantly improve the model's predictive performance. From our experimental data, we concluded that SVM based defect prediction model showed the best performance among all other studied models. We also observed that Fisher's score, a filter-based FS technique, outperformed all other FS techniques studied in this work.  © 2022 IEEE.|Feature Selection; High Dimensionality; Machine Learning; Software Defect Prediction; Software Testing|Classification (of information); Defects; Feature Selection; Forecasting; Learning systems; NASA; Support vector machines; Defect prediction models; Development process; Features selection; Filter-based; High dimensionality; Machine-learning; Performances analysis; Selection techniques; Software defect prediction; Software testings; Software testing|Conference paper|Final||Scopus|2-s2.0-85154613776
scopus|Loubiri O.; Maag S.|Loubiri, Oussama (58096833900); Maag, Stephane (55917333100)|58096833900; 55917333100|Automated Web Testing using Machine Learning and Containerization|2022|Proceedings - 26th International Conference on Circuits, Systems, Communications and Computers, CSCC 2022||||113|121|8|1|10.1109/CSCC55931.2022.00029|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147731882&doi=10.1109%2fCSCC55931.2022.00029&partnerID=40&md5=eb72d01fc85202c2695a83d733c3af69|Testing practices in software engineering constantly evolves due to the complexity of the systems. This has opened the space for new testing methods to try to integrate artificial intelligence with software testing tools. Automation testing refers to the use of strategies and tools which reduce the need for manual or human involvement in redundant and repetitive tasks that tend to cause human errors and then generating and executing automatically test cases. However, while a test scripts is generated, its reuse may be challenging for several reasons. In our Web systems context, a web page may be modified leading to the adaptation of the testing architecture and the eventual rewriting of the test scripts. It becomes time and effort consuming to create generic test cases that can be applied on any website. Websites keep on changing dynamically and the testers need to adapt to these changes each time and alter the test cases. These changes are often made manually or using external scripts. In this paper, we propose an approach allowing the test scripts to automatically adapt to these eventual changes of the web pages by using containers and a learning technique. We defined and implemented an algorithm on a well designed test framework and successfully evaluated our approach on thousands of websites. © 2022 IEEE.|Automation Testing; Containerization; Machine Learning; Selenium; SVM; Web Testing|Automation; Containers; Machine learning; Selenium; Software testing; Automation testing; Containerization; Machine-learning; Software testings; SVM; Test case; Test scripts; Testing method; Web testing; Web-page; Websites|Conference paper|Final||Scopus|2-s2.0-85147731882
scopus||||2022 IEEE 2nd International Conference on Computation, Communication and Engineering, ICCCE 2022|2022|2022 IEEE 2nd International Conference on Computation, Communication and Engineering, ICCCE 2022||||||129|0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148609368&partnerID=40&md5=47040c34c0e0263196888b3df0de29df|The proceedings contain 29 papers. The topics discussed include: machine learning based approach to selective measurements of hydrogen for catalytic gas sensors; adaptive grey wolf optimizer for global numerical optimization; analysis of digital pattern generation technology based on fractal graph; applying particle swarm optimization in scheduling modular software testing projects; applying system dynamics approach for optimizing software release decisions; automatic method for red spider detection in images; machine learning framework for enterprise profits forecasting; machine learning to identify bitcoin mining by web browsers; picture in picture detection for mobile captured digital video; and study of grey relational generating and development of toolbox by c language.|||Conference review|Final||Scopus|2-s2.0-85148609368
scopus|Gambi A.; Nguyen V.; Ahmed J.; Fraser G.|Gambi, Alessio (23466827200); Nguyen, Vuong (57328503500); Ahmed, Jasim (57755702500); Fraser, Gordon (9247521200)|23466827200; 57328503500; 57755702500; 9247521200|Generating Critical Driving Scenarios from Accident Sketches|2022|Proceedings - 4th IEEE International Conference on Artificial Intelligence Testing, AITest 2022||||95|102|7|22|10.1109/AITest55621.2022.00022|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141082914&doi=10.1109%2fAITest55621.2022.00022&partnerID=40&md5=7d9d671083f248b8bb146d50fe3609b7|Artificial Intelligence (AI) technologies are increasingly deployed to perform safety-critical tasks in various systems, including driverless vehicles. Therefore, ensuring the high quality of these AI-based systems is paramount to avoiding accidents and fatalities. Software testing has been proven to be a cost-effective quality assurance method for traditional software systems but requires adaptations to address the peculiarities of AI applications. For instance, thoroughly testing the software controlling autonomous vehicles requires the definition of relevant driving scenarios and their implementation in physically accurate driving simulators, which remains an open challenge. Recent work showed that simulations of critical driving scenarios such as car crashes are fundamental to generating effective test cases. However, generating such complex simulations is challenging, and state-of-the-art approaches based on natural language descriptions struggle to complete the task. Therefore, we propose CRISCE, the first approach to create accurate car crash simulations from accident sketches. Our extensive evaluation shows that CRISCE is efficient, effective, and generates accurate simulations, drastically improving state-of-art approaches based on natural language processing.  © 2022 IEEE.|critical scenarios; driving simulation; image processing; scenario synthesis; self-driving cars|Accidents; Application programs; Automobile drivers; Cost effectiveness; Image processing; Natural language processing systems; Quality assurance; Software testing; Artificial intelligence technologies; Car crashes; Critical scenario; Critical tasks; Driverless; Driving simulation; High quality; Images processing; Natural languages; Scenario synthesis; Autonomous vehicles|Conference paper|Final||Scopus|2-s2.0-85141082914
scopus|Abras J.N.; Tuckey T.; Hariharan N.|Abras, Jennifer N. (14518883700); Tuckey, Todd (36633131500); Hariharan, Nathan (7003825657)|14518883700; 36633131500; 7003825657|Progress Towards Development of a Machine Learning-Based Automated Test System|2022|AIAA Science and Technology Forum and Exposition, AIAA SciTech Forum 2022|||AIAA 2022-0311||||0|10.2514/6.2022-0311|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122931320&doi=10.2514%2f6.2022-0311&partnerID=40&md5=a6974a95bf7fe60b0d22a7e8edde45d5|The field of machine learning is broad, covering many different areas and applications. The application of machine learning to expand automated software testing is one of many possibilities . The ability to train a machine learning model to detect issues with aerodynamic simulations enables testing to be performed with more depth than current methods. The focus of the current effort is the development of a machine learning-bas ed automated test system for computati onal fluid dynamic software assessment. The underlying methodology employed is novelty detection applied through the support vector machine. Augmentation is employed to accommodate the actual data available to train the model. The machine learning-based automated test system is then demonstrated for typical external aerodynamic test cases . © 2022, American Institute of Aeronautics and Astronautics Inc, AIAA. All rights reserved.||Aerodynamics; Application programs; Automation; Aviation; Support vector machines; 'current; Aerodynamic simulations; Automated software testing; Automated test systems; Dynamic softwares; Fluid-dynamics; Machine learning models; Machine-learning; Novelty detection; Software assessment; Software testing|Conference paper|Final||Scopus|2-s2.0-85122931320
scopus|Gautam S.; Khunteta A.; Sharma P.|Gautam, Shikha (58717426500); Khunteta, Ajay (57192182612); Sharma, Pooja (40561844900)|58717426500; 57192182612; 40561844900|A Review On Software Testing Using Machine Learning Techniques|2022|ECS Transactions|107|1||3393|3406|13|1|10.1149/10701.3393ecst|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130545041&doi=10.1149%2f10701.3393ecst&partnerID=40&md5=7009358f69e7cd807a604a8cbe876fea|Software Testing is the method of executing the program with the intension of finding the errors. This process is very complex and time intensive and costly. Automation of Software testing process has turn out to be very workable solution in software engineering. For this purpose Machine learning algorithm is being used. We chose 48 primary research studies, tried to explain each Machine learning-based approach in software Testing. It gives an overview of how the input that is available data given to the model for learning and then how it is helping in giving predictions. We discovered that machine learning methods were mostly employed for test case development, refining, and evaluation. Machine Learning has also been used to evaluate the production of test oracles and predict the cost of testing procedures. © The Electrochemical Society|Machine Learning (ML); Software Testing; SUT|Learning algorithms; Machine learning; Learning-based approach; Machine learning; Machine learning algorithms; Machine learning methods; Machine learning techniques; Machine-learning; Research studies; Software testings; SUT; Testing process; Software testing|Conference paper|Final||Scopus|2-s2.0-85130545041
scopus|Pandit M.; Gupta D.; Anand D.; Goyal N.; Aljahdali H.M.; Mansilla A.O.; Kadry S.; Kumar A.|Pandit, Mahesha (57213198731); Gupta, Deepali (57208714508); Anand, Divya (57132370200); Goyal, Nitin (57197133706); Aljahdali, Hani Moaiteq (57192160630); Mansilla, Arturo Ortega (57386063400); Kadry, Seifedine (55906598300); Kumar, Arun (36968281100)|57213198731; 57208714508; 57132370200; 57197133706; 57192160630; 57386063400; 55906598300; 36968281100|Towards Design and Feasibility Analysis of DePaaS: AI Based Global Unified Software Defect Prediction Framework|2022|Applied Sciences (Switzerland)|12|1|493||||27|10.3390/app12010493|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122203632&doi=10.3390%2fapp12010493&partnerID=40&md5=aeda2739dc90e321093b9a4027e2450d|Using artificial intelligence (AI) based software defect prediction (SDP) techniques in the software development process helps isolate defective software modules, count the number of software defects, and identify risky code changes. However, software development teams are unaware of SDP and do not have easy access to relevant models and techniques. The major reason for this problem seems to be the fragmentation of SDP research and SDP practice. To unify SDP research and practice this article introduces a cloud-based, global, unified AI framework for SDP called DePaaS—Defects Prediction as a Service. The article describes the usage context, use cases and detailed architecture of DePaaS and presents the first response of the industry practitioners to DePaaS. In a first of its kind survey, the article captures practitioner’s belief into SDP and ability of DePaaS to solve some of the known challenges of the field of software defect prediction. This article also provides a novel process for SDP, detailed description of the structure and behaviour of DePaaS architecture components, six best SDP models offered by DePaaS, a description of algorithms that recommend SDP models, feature sets and tunable parameters, and a rich set of challenges to build, use and sustain DePaaS. With the contributions of this article, SDP research and practice could be unified enabling building and using more pragmatic defect prediction models leading to increase in the efficiency of software testing. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.|Cloud-based defect prediction; Cross-project defect prediction; Defect prediction as a service; DePaaS; Software defect prediction; Software defect prediction service||Article|Final|All Open Access; Gold Open Access|Scopus|2-s2.0-85122203632
scopus|Rohe M.; Stoll B.N.; Hildebrand J.; Reimann J.; Bergmann J.P.|Rohe, Maximilian (57226474612); Stoll, Benedict Niklas (57377256100); Hildebrand, Jörg (7102653643); Reimann, Jan (57205736373); Bergmann, Jean Pierre (7203025573)|57226474612; 57377256100; 7102653643; 57205736373; 7203025573|Detecting process anomalies in the gmaw process by acoustic sensing with a convolutional neural network (Cnn) for classification|2021|Journal of Manufacturing and Materials Processing|5|4|135||||30|10.3390/jmmp5040135|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121473663&doi=10.3390%2fjmmp5040135&partnerID=40&md5=ab405393f11f7caa0d322594c575f47f|Today, the quality of welded seams is often examined off-line with either destructive or non-destructive testing. These test procedures are time-consuming and therefore costly. This is especially true if the welds are not welded accurately due to process anomalies. In manual welding, experienced welders are able to detect process anomalies by listening to the sound of the welding process. In this paper, an approach to transfer the “hearing” of an experienced welder into an automated testing process is presented. An acoustic measuring device for recording audible sound is installed for this purpose on a fully automated welding fixture. The processing of the sound information by means of machine learning methods enables in-line process control. Existing research results until now show that the arc is the main sound source. However, both the outflow of the shielding gas and the wire feed emit sound information. Other investigations describe welding irregularities by evaluating and assessing existing sound recordings. Descriptive analysis was performed to find a connection between certain sound patterns and welding irregularities. Recent contributions have used machine learning to identify the degree of welding penetration. The basic assumption of the presented investigations is that process anomalies are the cause of welding irregularities. The focus was on detecting deviating shielding gas flow rates based on audio recordings, processed by a convolutional neural network (CNN). After adjusting the hyperparameters of the CNN it was capable of distinguishing between different flow rates of shielding gas. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.|Artificial intelligence; Audible sound; CNN; GMAW; Machine learning; Melband; Shielding gas||Article|Final|All Open Access; Gold Open Access; Green Open Access|Scopus|2-s2.0-85121473663
scopus||||Proceedings - 2022 IEEE 15th International Conference on Software Testing, Verification and Validation, ICST 2022|2022|Proceedings - 2022 IEEE 15th International Conference on Software Testing, Verification and Validation, ICST 2022||||||492|0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133247146&partnerID=40&md5=ceacb3f700f37a620b696425a1c12645|The proceedings contain 53 papers. The topics discussed include: machine learning based invariant generation: a framework and reproducibility study; smoke testing of cloud systems; testing software in production environments with data from the field; applying symbolic execution to test implementations of a network protocol against its specification; a survey on how test flakiness affects developers and what support they need to address it; evaluating features for machine learning detection of order- and non-order-dependent flaky tests; patterns of code-to-test co-evolution for automated test suite maintenance; an empirical study of IR-based bug localization for deep learning-based software; automated repair of responsive web page layouts; to seed or not to seed? an empirical analysis of usage of seeds for testing in machine learning projects; and learning realistic mutations: bug creation for neural bug detectors.|||Conference review|Final||Scopus|2-s2.0-85133247146
scopus|Rao N.S.V.; Al-Najjar A.; Zandi H.; Sankaran R.; Hicks S.; Roccapriori K.; Mukherjee D.|Rao, Nageswara S. V. (7401629378); Al-Najjar, Anees (57189245009); Zandi, Helia (57211788579); Sankaran, Ramanan (57190802347); Hicks, Susan (22961893400); Roccapriori, Kevin (57201673583); Mukherjee, Debangshu (56673553400)|7401629378; 57189245009; 57211788579; 57190802347; 22961893400; 57201673583; 56673553400|Virtual Infrastructure Twins: Software Testing Platforms for Computing-Instrument Ecosystems|2022|Communications in Computer and Information Science|1690 CCIS|||155|172|17|3|10.1007/978-3-031-23606-8_10|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148698546&doi=10.1007%2f978-3-031-23606-8_10&partnerID=40&md5=1806222932043d119e1f918a56e80627|Science ecosystems are being built by federating computing systems and instruments located at geographically distributed sites over wide-area networks. These computing-instrument ecosystems are expected to support complex workflows that incorporate remote, automated AI-driven science experiments. Their realization, however, requires various designs to be explored and software components to be developed, in order to support the orchestration of distributed computations and experiments. It is often too expensive, infeasible, or disruptive for the entire ecosystem to be available during the typically long software development and testing periods. We propose a Virtual Infrastructure Twin (VIT) of the ecosystem that emulates its network and computing components, and incorporates its instrument software simulators. It provides a software environment nearly identical to the ecosystem to support early development and testing, and design space exploration. We present a brief overview of previous digital infrastructure twins that culminated in the VIT concept, including (i) the virtual science network environment for developing software-defined networking solutions, and (ii) the virtual federated science instrument environment for testing the federation software stack and remote instrument control software. We briefly describe VITs for Nion microscope steering and access to GPU systems. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.||Distributed computer systems; Instrument testing; Software design; Software testing; Wide area networks; Complex workflows; Computing system; Development and testing; Distributed sites; Science experiments; Software testings; Software-component; Testing platforms; Virtual infrastructures; Wide-area networks; Ecosystems|Conference paper|Final||Scopus|2-s2.0-85148698546
scopus|Haller-Seeber S.; Gatterer T.; Hofmann P.; Kelter C.; Auer T.; Felderer M.|Haller-Seeber, Simon (56640964800); Gatterer, Thomas (57604707300); Hofmann, Patrick (57605719300); Kelter, Christopher (57604457300); Auer, Thomas (57219222257); Felderer, Michael (24832720900)|56640964800; 57604707300; 57605719300; 57604457300; 57219222257; 24832720900|Software Testing, AI and Robotics (STAIR) Learning Lab|2022|Lecture Notes in Networks and Systems|515 LNNS|||182|189|7|1|10.1007/978-3-031-12848-6_17|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135029124&doi=10.1007%2f978-3-031-12848-6_17&partnerID=40&md5=486e1ed2acefad7efc0b458fbf606835|In this paper we presented the Software Testing, AI and Robotics (STAIR) Learning Lab. STAIR is an initiative started at the University of Innsbruck to bring robotics, Artificial Intelligence (AI) and software testing into schools. In the lab physical and virtual learning units are developed in parallel and in sync with each other. Its core learning approach is based the develop of both a physical and simulated robotics environment. In both environments AI scenarios (like traffic sign recognition) are deployed and tested. We present and focus on our newly designed MiniBot that are both built on hardware which was designed for educational and research purposes as well as the simulation environment. Additionally, we describe first learning design concepts and a showcase scenario (i.e., AI-based traffic sign recognition) with different exercises which can easily be extended. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.|Artificial intelligence; Digital twin; Educational robotics; Internet of Things; Physical computing; Software testing||Conference paper|Final||Scopus|2-s2.0-85135029124
scopus|Navaei M.; Tabrizi N.|Navaei, Maryam (57948939900); Tabrizi, Nasseh (53364389900)|57948939900; 53364389900|Machine Learning in Software Development Life Cycle: A Comprehensive Review|2022|International Conference on Evaluation of Novel Approaches to Software Engineering, ENASE - Proceedings||||344|354|10|3|10.5220/0011040600003176|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140955355&doi=10.5220%2f0011040600003176&partnerID=40&md5=709a4f33e8981f7ad8c2848164dc79b4|This research concludes an overall summary of the publications so far on the applied Machine Learning (ML) techniques in different phases of Software Development Life Cycle (SDLC) that includes Requirement Analysis, Design, Implementation, Testing, and Maintenance. We have performed a systematic review of the research studies published from 2015-2021 and revealed that Software Requirements Analysis phase has the least number of papers published; in contrast, Software Testing is the phase with the greatest number of papers published. Copyright © 2022 by SCITEPRESS – Science and Technology Publications, Lda. All rights reserved.|Artificial Intelligence; Machine Learning; Machine Learning Algorithms; Software Development Life Cycle; Software Engineering|Learning algorithms; Learning systems; Life cycle; Machine learning; Requirements engineering; Analysis/design; Applied machine learning; Design implementation; Implementation testing; Machine learning algorithms; Machine learning techniques; Machine-learning; Requirement analysis; Software development life-cycle; Testing and maintenance; Software design|Conference paper|Final|All Open Access; Hybrid Gold Open Access|Scopus|2-s2.0-85140955355
scopus|La M.-V.; Koo S.H.; Jiang B.; Heng Y.X.; Tan T.Y.|La, My-Van (55694477800); Koo, Seok Hwee (57072718400); Jiang, Boran (56937537600); Heng, Ying Xuan (57374887600); Tan, Thean Yen (23475824500)|55694477800; 57072718400; 56937537600; 57374887600; 23475824500|A Study of Analytical and Clinical Sensitivity of Aptima SARS-CoV-2 Assay (Hologic) and Proposals of Complementary Tests for SARS-CoV-2 Detection in Low Viral Load Specimens|2022|Current Microbiology|79|1|29||||4|10.1007/s00284-021-02730-3|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121319470&doi=10.1007%2fs00284-021-02730-3&partnerID=40&md5=88f745c9e0836856fabf8ef96fa6b977|Early and accurate detection of SARS-CoV-2 is important for diagnosis and transmission control. The use of high-throughput and automated testing allows laboratories to better deliver diagnostic testing given manpower and resource limitations. We validated the clinical and analytical performance of the Hologic Panther Aptima SARS-CoV-2 assay with an emphasis on detection of specimens with low viral loads. The clinical performance was evaluated using 245 clinical specimens, against a comparator PCR-based laboratory developed test (LDT). The analytical performance was determined by replicate testing of contrived samples in a ten-fold dilution series (CT values 32–42, based on LDT). The Aptima assay had 96.7% overall percent agreement, 100% negative percent agreement and 88.1% positive percent agreement. It was able to consistently detect SARS-CoV-2 in contrived samples with CT = 32 by LDT (calculated 2354 copies/mL). The 95% limit of detection of the Aptima assay was estimated to be at LDT CT = 33 (equivalent to 870 copies/mL). The relative light units (RLU) × 1000 for 52 true positive clinical specimens was 962.2 ± 181.5, and that for the 186 true negative specimens was 264.6 ± 14.3. The Aptima assay was a reliable method with a high overall percent agreement against our comparator LDT. We propose that samples reported as negative by the Aptima assay with RLU > 350 be tested by a secondary method, in order to improve detection of samples with very low viral loads. © 2021, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.||COVID-19; Humans; Molecular Diagnostic Techniques; RNA, Viral; SARS-CoV-2; Sensitivity and Specificity; Viral Load; virus RNA; article; clinical evaluation; controlled study; COVID-19 testing; dilution; human; human tissue; limit of detection; polymerase chain reaction; virus load; molecular diagnosis; sensitivity and specificity; virus load|Article|Final|All Open Access; Bronze Open Access; Green Open Access|Scopus|2-s2.0-85121319470
scopus|Suhag V.; Dubey S.K.; Sharma B.K.|Suhag, Vikas (57215606447); Dubey, Sanjay Kumar (56198142400); Sharma, Bhupendra Kumar (55423723600)|57215606447; 56198142400; 55423723600|Software Defect Data Collection Framework for Github|2022|Proceedings of the Confluence 2022 - 12th International Conference on Cloud Computing, Data Science and Engineering||||82|87|5|1|10.1109/Confluence52989.2022.9734131|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127590775&doi=10.1109%2fConfluence52989.2022.9734131&partnerID=40&md5=6546f23979f6e5df004a0214c1adf718|Software has become part of every sphere of life. This increasing dependence on software has put tremendous pressure on software development teams to deliver software applications as early as possible at the cost of compromised software quality and reliability. Software quality requires extensive testing and validation of software, which is not possible with limited human resources, time and budget, so researchers moved to a new paradigm of software quality assurance i.e., Software Defect Prediction (SDP). SDP aims to build automated Machine Learning (ML) models to aid development teams in prioritizing the key aspects of software testing while maintaining the short software development life cycle. SDP requires huge amount of data to train and test ML models, traditionally PROMISE and NASA defect datasets are most prominently used by researchers, but with changes in programming languages, programming styles and limited size of datasets has made them infeasible for SDP in current scenarios. In this paper, we have developed a software defect dataset collection framework, which mines commit level defect data from GitHub. The efficiency of data mining, accuracy of data and validity of data is verified by SDP models. Results shows that proposed method is feasible as well as efficient to execute even on regular computer systems.  © 2022 IEEE.|defect dataset; defect prediction; github projects; mining software repository|Application programs; Budget control; Computer software selection and evaluation; Data mining; Life cycle; NASA; Software design; Software reliability; Software testing; Data collection; Defect dataset; Defect prediction; Github project; Machine learning models; Mining software; Mining software repository; Software defect prediction; Software defects; Software repositories; Defects|Conference paper|Final||Scopus|2-s2.0-85127590775
scopus|Kazimov T.H.; Bayramova T.A.; Malikova N.J.|Kazimov, T.H. (35275252900); Bayramova, T.A. (57188566358); Malikova, N.J. (57443197900)|35275252900; 57188566358; 57443197900|RESEARCH OF INTELLIGENT METHODS OF SOFTWARE TESTING|2021|System Research and Information Technologies|2021|4||42|52|10|3|10.20535/SRIT.2308-8893.2021.4.03|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124206542&doi=10.20535%2fSRIT.2308-8893.2021.4.03&partnerID=40&md5=16b7e9dd1262f5663d0dbdf31aed93ec|This article presents the examination of several techniques and tools used in the automated software testing process. Considering the ever-growing importance of software testing, several possible implications of implementation of artificial intelligence into this area are also discussed. The main objective of this study is to examine the field of test automation by categorising related test activities, to which artificial intelligence tools can be applied for increased efficiency, and evalu-ate the impact of the application. The main software testing methods are white-box, black-box, and grey-box methods; an effort has been made to determine a connec-tion between the given testing methods and artificial intelligence methods. A brief summary of several artificial intelligence engine tools used to automate testing was also provided. Lastly, the possible future benefits from usage of AI in software testing was investigated.. © T.H. Kazimov, T.A. Bayramova, N.J. Malikova, 2021.|Artificial intelligence; Automated testing; Software testing||Article|Final|All Open Access; Gold Open Access; Green Open Access|Scopus|2-s2.0-85124206542
scopus||||Proceedings of the 31st Conference of Open Innovations Association FRUCT, FRUCT 2022|2022|Conference of Open Innovation Association, FRUCT|2022-April|||||396|0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130405767&partnerID=40&md5=40598592595e7e6b5d8d7f14aa19d72b|The proceedings contain 48 papers. The topics discussed include: efficient grocery shopping using geolocation and data mining; smart communication system using sign language interpretation; development of a model of design thinking hybrid implementation in the post-pandemic world; methodology for in-the-wild driver monitoring dataset formation; modelling investment programs with machine learning and data mining: descriptive and predictive models of healthcare state programs in Russia; stability enhancement of single machine infinite bus system with UPFC using bat algorithm; algorithm of the hybrid transformation method for modeling dynamic systems; meta-learning, fast adaptation, and latent representation for head pose estimation; and automated testing and resilience of microservice’s network-link using Istio service mesh.|||Conference review|Final||Scopus|2-s2.0-85130405767
scopus|Walia R.|Walia, Ritu (57829371000)|57829371000|Application of Machine Learning for GUI Test Automation|2022|2022 28th International Conference on Information, Communication and Automation Technologies, ICAT 2022 - Proceedings|||||||2|10.1109/ICAT54566.2022.9811187|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135380072&doi=10.1109%2fICAT54566.2022.9811187&partnerID=40&md5=3bf9524a9b59ea8a3d932debd5faa68c|This paper examines the implementation of machine learning (ML) capabilities in a test automation suite, specifically for automation of graphical user interface (GUI) testing on an electronic design automation (EDA) tool within an integrated circuit (IC) physical design, verification, and implementation flow. We present a case study using existing tests to extract information and propose an ML implementation framework that consists of three modules, which can be adopted as a systematic pattern for test development. Our study focusses on implementation of the third module in this framework. We use the learnings from iterative testing patterns on a set of EDA tools provided by the Calibre RealTime interfaces from Siemens Digital Industries Software. The goal is to reduce human effort in selection and implementation of test cases and reallocate those resources to integral parts of the testing process like, approving and acting. We first establish metrics and variables, utilize VGG16 architecture for image classification and perform training on test data, and achieve an ML model based on accuracy and precision. Using this result, we present ML implementation as part of the script development process and analyze its impact. Based on our results, we conclude the third module of a framework for inclusion of ML in a regression testing suite for GUI test automation.  © 2022 IEEE.|convolutional neural network; GUI test automation; GUI testing; image processing; pattern recognition; quality analysis in EDA; regression testing; VGG16 algorithm|Automation; Convolutional neural networks; Electronic design automation; Graphical user interfaces; Integrated circuits; Iterative methods; Learning algorithms; Pattern recognition; Software testing; Convolutional neural network; Electronics design automation; Graphical user interface test automation; Graphical user interface testing; Graphical user interfaces test; Images processing; Interface testings; Quality analyse in electronic design automation; Regression testing; Test Automation; VGG16 algorithm; Machine learning|Conference paper|Final||Scopus|2-s2.0-85135380072
scopus||||13th International Conference on Robotics in Education, RiE 2022|2022|Lecture Notes in Networks and Systems|515 LNNS|||||196|0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135039149&partnerID=40&md5=852d715d8b9a7896964ec04a60c215ee|The proceedings contain 19 papers. The special focus in this conference is on Robotics in Education. The topics include: Teachers’ Exposure Workshop for Integrating Robotics Activities in STEM; Evaluating the Effects of Educational Robotics Activities Concerning the Interest in STEM and Collaboration Skills; Implementation of a Multi-disciplinary Robotics Curriculum for master’s Student: The Use Case of AMSCC1 International Semester; perspectives on Virtual Reality in Higher Education for Robotics and Related Engineering Disciplines; Understanding Machine Learning Through AI-powered Educational Robotics - Pilot Study with Undergraduate Students; educational Robotics: Methodological Considerations and Practice of Mechatronics; perceptual Evaluation of Educational Robots’ Consequential Sounds; towards Futures Literacy Through Computational Thinking and Storytelling Activities; taxonomy for Educational Robotics at Schools; children’s Perspectives on Robotics and the Relevance to Educational Robotics Competitions; preface; light Painting with Mobile Robots as Motivating Projects for Robotics and Control Education; educational Robots and Flow Experience; Software Testing, AI and Robotics (STAIR) Learning Lab; how Social Robots Can Facilitate Teaching Quality – Findings from an Explorative Interview Study; pupil-Robot Interaction in a Math Card Game: An Iterative Process of Studying the Use of Social Robotics in Primary School Math Education; telepresence Robots in Higher Education – The Current State of Research.|||Conference review|Final||Scopus|2-s2.0-85135039149
scopus||||15th International Conference on the Quality of Information and Communications Technology, QUATIC 2022|2022|Communications in Computer and Information Science|1621 CCIS|||||322|0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137994045&partnerID=40&md5=0861d701f6f4e4cd887d6ce55735c066|The proceedings contain 21 papers. The special focus in this conference is on Quality of Information and Communications Technology. The topics include: Improving the Quality of ICT and Forestry Service Processes with Digital Service Management Approach: A Case Study on Forestry Liquids; towards a Process Reference Model for Clinical Coding; digital Twin for IoT Environments: A Testing and Simulation Tool; simpler Is Better: On the Use of Autoencoders for Intrusion Detection; A Proposal for FPGA-Accelerated Deep Learning Ensembles in MPSoC Platforms Applied to Malware Detection; automated Threat Modeling Approaches: Comparison of Open Source Tools; understanding Black-Box Attacks Against Object Detectors from a User’s Perspective; alice in (Software Supply) Chains: Risk Identification and Evaluation; Architectural Decisions in AI-Based Systems: An Ontological View; evaluating Tangle Distributed Ledger for Access Control Policy Distribution in Multi-region Cloud Environments; toward the Adoption of Secure Cyber Digital Twins to Enhance Cyber-Physical Systems Security; an Empirical Study to Quantify the SetUp and Maintenance Benefits of Adopting WebDriverManager; assessing Black-box Test Case Generation Techniques for Microservices; reSuMo: Regression Mutation Testing for Solidity Smart Contracts; Is NLP-based Test Automation Cheaper Than Programmable and Capture &Replay?; effective Spectrum Based Fault Localization Using Contextual Based Importance Weight; comparing the Effectiveness of Assertions with Differential Testing in the Context of Web Testing; roadblocks to Attracting Students to Software Testing Careers: Comparisons of Replicated Studies; preface.|||Conference review|Final||Scopus|2-s2.0-85137994045
scopus|Cody T.; Lanus E.; Doyle D.D.; Freeman L.|Cody, Tyler (57202775438); Lanus, Erin (57194342964); Doyle, Daniel D. (57219401156); Freeman, Laura (36494460500)|57202775438; 57194342964; 57219401156; 36494460500|Systematic Training and Testing for Machine Learning Using Combinatorial Interaction Testing|2022|Proceedings - 2022 IEEE 14th International Conference on Software Testing, Verification and Validation Workshops, ICSTW 2022||||102|109|7|20|10.1109/ICSTW55395.2022.00031|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132753607&doi=10.1109%2fICSTW55395.2022.00031&partnerID=40&md5=ec649dd943226d0844b7f9d9ba930fb1|This paper demonstrates the systematic use of combinatorial coverage for selecting and characterizing test and training sets for machine learning models. The presented work adapts combinatorial interaction testing, which has been successfully leveraged in identifying faults in software testing, to characterize data used in machine learning. The MNIST hand-written digits data is used to demonstrate that combinatorial coverage can be used to select test sets that stress machine learning model performance, to select training sets that lead to robust model performance, and to select data for fine-tuning models to new domains. Thus, the results posit combinatorial coverage as a holistic approach to training and testing for machine learning. In contrast to prior work which has focused on the use of coverage in regard to the internal of neural networks, this paper considers coverage over simple features derived from inputs and outputs. Thus, this paper addresses the case where the supplier of test and training sets for machine learning models does not have intellectual property rights to the models themselves. Finally, the paper addresses prior criticism of combinatorial coverage and provides a rebuttal which advocates the use of coverage metrics in machine learning applications.  © 2022 IEEE.|black-box testing; combinatorial interaction testing; data labeling; machine learning; test set construction; training set construction|Black-box testing; Laws and legislation; Machine learning; Combinatorial interaction testing; Data labelling; Machine learning models; Machine-learning; Modeling performance; Test set construction; Test sets; Training and testing; Training set construction; Training sets; Intellectual property|Conference paper|Final|All Open Access; Green Open Access|Scopus|2-s2.0-85132753607
scopus|Ahuja M.K.; Gotlieb A.; Spieker H.|Ahuja, Mohit Kumar (57218949684); Gotlieb, Arnaud (56247674500); Spieker, Helge (57189329650)|57218949684; 56247674500; 57189329650|Testing Deep Learning Models: A First Comparative Study of Multiple Testing Techniques|2022|Proceedings - 2022 IEEE 14th International Conference on Software Testing, Verification and Validation Workshops, ICSTW 2022||||130|137|7|2|10.1109/ICSTW55395.2022.00035|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133240340&doi=10.1109%2fICSTW55395.2022.00035&partnerID=40&md5=01f6e545a8cb5bb23e9c141023fb1a91|Deep Learning (DL) has revolutionized the capabilities of vision-based systems (VBS) in critical applications such as autonomous driving, robotic surgery, critical infrastructure surveillance, air and maritime traffic control, etc. By analyzing images, voice, videos, or any type of complex signals, DL has considerably increased the situation awareness of these systems. At the same time, while relying more and more on trained DL models, the reliability and robustness of VBS have been challenged and it has become crucial to test thoroughly these models to assess their capabilities and potential errors. To discover faults in DL models, existing software testing methods have been adapted and refined accordingly. In this article, we provide an overview of these software testing methods, namely differential, metamorphic, mutation, and combinatorial testing, as well as adversarial perturbation testing and review some challenges in their deployment for boosting perception systems used in VBS. We also provide a first experimental comparative study on a classical benchmark used in VBS and discuss its results.  © 2022 IEEE.|Deep Learning; Machine Learning; Model Quality; Software Testing; Test Quality|Deep learning; Learning systems; Security systems; Well testing; Comparatives studies; Deep learning; Learning models; Machine-learning; Modeling quality; Multiple testing; Software testings; Test quality; Testing method; Vision-based system; Software testing|Conference paper|Final|All Open Access; Green Open Access|Scopus|2-s2.0-85133240340
scopus|Alzahrani M.|Alzahrani, Musaad (56609009100)|56609009100|Using Machine Learning Techniques to Predict Bugs in Classes: An Empirical Study|2022|International Journal of Advanced Computer Science and Applications|13|5||891|897|6|1|10.14569/IJACSA.2022.01305101|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131418019&doi=10.14569%2fIJACSA.2022.01305101&partnerID=40&md5=a126341d196ba49e47e5507e4dfdb0f5|Software bug prediction is an important step in the software development life cycle that aims to identify bug-prone software modules. Identification of such modules can reduce the overall cost and effort of the software testing phase. Many approaches have been introduced in the literature that have investigated the performance of machine learning techniques when used in software bug prediction activities. However, in most of these approaches, the empirical investigations were conducted using bug datasets that are small or have erroneous data leading to results with limited generality. Therefore, this study empirically investigates the performance of 8 commonly used machine learning techniques based on the Unified Bug Dataset which is a large and clean bug dataset that was published recently. A set of experiments are conducted to construct bug prediction models using the considered machine learning techniques. Each constructed model is evaluated using three performance metrics: accuracy, area under the curve, and F-measure. The results of the experiments show that logistic regression has better performance for bug prediction compared to other considered techniques. © 2022. International Journal of Advanced Computer Science and Applications. All Rights Reserved.|Bug prediction; Machine learning techniques; Software bugs; Software metrics; Unified bug dataset|Forecasting; Large dataset; Learning algorithms; Life cycle; Machine learning; Program debugging; Software design; Bug predictions; Empirical studies; Machine learning techniques; Overall costs; Performance; Software bug; Software development life-cycle; Software metrics; Software modules; Unified bug dataset; Software testing|Article|Final|All Open Access; Gold Open Access|Scopus|2-s2.0-85131418019
scopus|Chen H.; Hossain M.|Chen, Hongkai (57322073300); Hossain, Mohammad (24724333800)|57322073300; 24724333800|Application of machine learning on software quality assurance and testing: A chronological survey|2022|EPiC Series in Computing|82|||42|52|10|2||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127815180&partnerID=40&md5=d3a956c3c55eb128e324df6b07af39a6|Ensuring the quality is essential for a successful Software System. Software systems need to be tested in every stage of the Software Development Life Cycle (SDLC) irrespective of the type of software being developed. If a software bug remains undetected in the early phase of the SDLC, it becomes harder to fix it at a later stage and becomes very costly. The application of machine learning in Software Quality Assurance and Testing can help testers in the testing process, including the early detection and prediction of a software bug. However, employing machine learning techniques brings new challenges to testing and quality assurance. Machine Learning (ML) uses Artificial Intelligence (AI) techniques that focus on a given dataset to find any trend present in the data. It has been observed that some software testing activities can, in fact, be represented as a learning problem. Thus, ML can be used as an efficient tool to automate softwaretesting activities, especially when the software system becomes very complex. This survey aims to study and summarize the application of machine learning on software quality assurance and testing in a chronological manner by selecting from articles published in the last twenty-six years or so. © 2022, EasyChair. All rights  reserved.||Application programs; Computer software selection and evaluation; Life cycle; Machine learning; Quality assurance; Software design; Surveys; Artificial intelligence techniques; Late stage; Machine learning techniques; Machine-learning; Quality testing; Software bug; Software development life-cycle; Software quality assurance; Software-systems; Testing process; Software testing|Conference paper|Final||Scopus|2-s2.0-85127815180
scopus|Sangeetha M.; Malathi S.|Sangeetha, M. (56871033700); Malathi, S. (57195331995)|56871033700; 57195331995|Modeling Metaheuristic Optimization with Deep Learning Software Bug Prediction Model|2022|Intelligent Automation and Soft Computing|34|3||1587|1601|14|2|10.32604/iasc.2022.025192|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131263470&doi=10.32604%2fiasc.2022.025192&partnerID=40&md5=fff5722a315aae8d7cb9f99a66eb4aff|Software testing is an effective means of verifying software stability and trustworthiness. It is essential in the software development process and needs a huge quantity of resources such as labor, money, and time. Automated software testing can be used to save manual work, shorten testing times, and improve testing performance. Recently, Software Bug Prediction (SBP) models have been developed to improve the software quality assurance (SQA) process through the prediction of bug parts. Advanced deep learning (DL) models can be used to classify faults in software parts. Because hyperparameters have a significant impact on the performance of any DL model, a proper hyperparameter optimization approach utilizing metaheuristic methods is required. This paper provides a unique Metaheuristic Optimization with Deep Learning based SBP (MODL-SBP) methodology to ensure software dependability and trustworthiness. The suggested technique entails creating a hybrid Convolution Neural Network (CNN) bi-directional long short-term memory (BiLSTM) to forecast software pro-blems. Furthermore, the Chaotic Quantum Grasshopper Optimization Algorithm (CQGOA) is used for hyperparameter optimization of the CNN-BiLSTM models, which enhances predictive accuracy. To demonstrate the superior performance of the MODL-SBP technique, a wide range of simulations are performed on benchmark datasets, with the results highlighting the superior performance of the proposed model over other recent techniques. © 2022, Tech Science Press. All rights reserved.|deep learning; hyperparameter tuning; metaheuristics; software bug prediction; Software testing||Article|Final|All Open Access; Hybrid Gold Open Access|Scopus|2-s2.0-85131263470
scopus|De Santiago Junior V.A.|De Santiago Junior, Valdivino Alexandre (16242361900)|16242361900|A Method and Experiment to evaluate Deep Neural Networks as Test Oracles for Scientific Software|2022|Proceedings - 3rd ACM/IEEE International Conference on Automation of Software Test, AST 2022||||40|51|11|1|10.1145/3524481.3527232|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133447865&doi=10.1145%2f3524481.3527232&partnerID=40&md5=cb59cabd1023f4ced4cd6d653b0cfecb|Testing scientific software is challenging because usually such type of systems have non-deterministic behaviours and, in addition, they generate non-trivial outputs such as images. Artificial intelligence (AI) is now a reality which is also helping in the development of the software testing activity. In this article, we evaluate seven deep neural networks (DNNs), precisely deep convolutional neural networks (CNNs) with up to 161layers, playing the role of test oracle procedures for testing scientific models. Firstly, we propose a method, TOrC, which starts by generating training, validation, and test image datasets via combinatorial interaction testing applied to the original codes and second-order mutants. Within TOrC we also have classical steps such as transfer learning, a technique recommended for DNNs. Then, we verified the performance of the oracles (CNNs). The main conclusions of this research are: i) not necessarily a greater number of layers means that a CNN will present better performance; ii) transfer learning is a valuable technique but eventually we may need extended solutions to get better performances; iii) data-centric AI is an interesting path to follow; and iv) there is not a clear correlation between the software bugs, in the scientific models, and the errors (image misclassifications) presented by the CNNs. CCS CONCEPTS • Software and its engineering → Software testing and debugging;. Computing methodologies → Neural networks; Supervised learning by classification; Computer vision.  © 2022 ACM.|Data-Centric Artificial Intelligence; Deep Convolutional Neural Networks; Explainable Artificial Intelligence; Test Oracles; Transfer Learning|Convolution; Deep neural networks; Learning systems; Multilayer neural networks; Program debugging; Software testing; Testing; Transfer learning; Convolutional neural network; Data centric; Data-centric artificial intelligence; Deep convolutional neural network; Explainable artificial intelligence; Performance; Scientific modeling; Scientific softwares; Test oracles; Transfer learning; Convolutional neural networks|Conference paper|Final||Scopus|2-s2.0-85133447865
scopus|Zhang J.; Liu Y.; Gligoric M.; Legunsen O.; Shi A.|Zhang, Jiyang (57222761774); Liu, Yu (57718547700); Gligoric, Milos (26221765900); Legunsen, Owolabi (55504183900); Shi, August (56453975300)|57222761774; 57718547700; 26221765900; 55504183900; 56453975300|Comparing and Combining Analysis-Based and Learning-Based Regression Test Selection|2022|Proceedings - 3rd ACM/IEEE International Conference on Automation of Software Test, AST 2022||||17|28|11|11|10.1145/3524481.3527230|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133459174&doi=10.1145%2f3524481.3527230&partnerID=40&md5=0aa15fd0eb166780b0bc9b33afa2251f|Regression testing-rerunning tests on each code version to detect newly-broken functionality-is important and widely practiced. But, regression testing is costly due to the large number of tests and the high frequency of code changes. Regression test selection (RTS) optimizes regression testing by only rerunning a subset of tests that can be affected by changes. Researchers showed that RTS based on program analysis can save substantial testing time for (medium-sized) open-source projects. Practitioners also showed that RTS based on machine learning (ML) works well on very large code repositories, e.g., in Facebook's monorepository. We combine analysis-based RTS and ML-based RTS by using the latter to choose a subset of tests selected by the former. We first train several novel ML models to learn the impact of code changes on test outcomes using a training dataset that we obtain via mutation analysis. Then, we evaluate the benefits of combining ML models with analysis-based RTS on 10 projects, compared with using each technique alone. Combining ML-based RTS with two analysis-based RTS techniques-Ekstazi and STARTS-selects 25.34% and 21.44% fewer tests, respectively. CCS CONCEPTS • Software and its engineering $\rightarrow$Software testing and debugging.  © 2022 ACM.|machine learning; program analysis.; regression test selection; Regression testing|Open source software; Program debugging; Regression analysis; Software testing; Statistical tests; Code changes; Code versions; High frequency HF; Machine learning models; Machine-learning; Program analyse.; Program analysis; Regression test selection; Regression testing; Selection based; Machine learning|Conference paper|Final|All Open Access; Bronze Open Access|Scopus|2-s2.0-85133459174
scopus|Phung Q.-N.; Kim M.; Lee E.|Phung, Quang-Ngoc (57209208454); Kim, Misoo (57202894425); Lee, Eunseok (8979680900)|57209208454; 57202894425; 8979680900|Identifying Incorrect Patches in Program Repair Based on Meaning of Source Code|2022|IEEE Access|10|||12012|12030|18|7|10.1109/ACCESS.2022.3145983|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123718762&doi=10.1109%2fACCESS.2022.3145983&partnerID=40&md5=12f7519d605fcc4bb3aa3e1fbbd7ed6b|Automatic Program Repair (APR) techniques have shown the potential of reducing debugging costs while improving software quality by generating patches for fixing bugs automatically. However, they often generate many overfitting patches which pass only a specific test-suite but do not fix the bugs correctly. This paper proposes MIPI, a novel approach to reducing the number of overfitting patches generated in the APR. We leverage recent advances in deep learning to exploit the similarity between the patched method's name (which often encloses the developer's intention about the code) and the semantic meaning of the method's body (which represents the actual implemented behavior) for identifying and removing overfitting patches generated by APR tools. Experiments with a large dataset of patches for QuixBugs and Defects4J programs show the promise of our approach. Specifically, in a total of 1,191 patches generated by 23 existing APR tools, MIPI successfully filters out 254 (32%) of the total 797 overfitting patches with a precision of 90% while preserving 93% of the correct patches. MIPI is more precise and less damaging to the APR than existing heuristic patch assessment techniques, achieving a higher recall than automated testing-based techniques that do not have access to the test oracle. In addition, MIPI is highly complementary to existing automated patch assessment techniques. © 2013 IEEE.|APR; Automated program repair; bert; code2vec; developer intentions; patch correctness|Automation; Computer software selection and evaluation; Deep learning; Job analysis; Large dataset; Program debugging; Semantics; Software testing; Automated program repair; Automatic program repair; Automatic programs; Bert; Code; Code2vec; Computer bugs; Developer intention; Patch correctness; Software; Task analysis; Test pattern generator; Repair|Article|Final|All Open Access; Gold Open Access|Scopus|2-s2.0-85123718762
scopus|Fatima S.; Mansoor B.; Ovais L.; Sadruddin S.A.; Hashmi S.A.|Fatima, Sana (57926412700); Mansoor, Bisma (58029852900); Ovais, Laiba (58030026000); Sadruddin, Sajid Ali (58029177200); Hashmi, Syed Aun (58029513000)|57926412700; 58029852900; 58030026000; 58029177200; 58029513000|Automated Testing with Machine Learning Frameworks: A Critical Analysis †|2022|Engineering Proceedings|20|1|12||||6|10.3390/engproc2022020012|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139925334&doi=10.3390%2fengproc2022020012&partnerID=40&md5=5becd998dec7894ca8da84190f49ce2d|As software systems are becoming more and more complex and standard testing practices are exhausting, we need smart solutions to reduce the time, efforts and resources spent on software testing. The aim of this paper was to critically analyze machine learning (ML) frameworks related to software automation. We measured the performance of testing tools on the basis of the manual labor (effort) required, in addition to the test performance, accuracy or error rate, scope, time required and prerequisite knowledge requirements. These factors play a vital role to ensure ML frameworks with automation software can produce great results and hence improve software quality. © 2022 by the authors.|accuracy; automation; machine learning; manual labor; performance; prerequisite knowledge requirement; software quality; software testing; test scope; time required||Article|Final|All Open Access; Hybrid Gold Open Access|Scopus|2-s2.0-85139925334
scopus|Chung K.|Chung, Khanlian (58667571800)|58667571800|Understand and Testing AI Decisions with Explainable AI|2022|VDI Berichte|2022|2405||249|256|7|0|10.51202/9783181024058-249|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175042049&doi=10.51202%2f9783181024058-249&partnerID=40&md5=c080a1417d248e5f0cf70f0b080ed23d|Nowadays, we see more and more AI algorithms being used in vehicle software. One of themost important questions of integrating AI-based software in such security-critical environments is how to test them. The AI must perform robustly and safely. To ensure this, software that contains AI components must be tested thoroughly, which is not a trivial task: Classic software testing methods cannot be applied due to the “black-box” nature of most AI algorithms. But understanding AI decisions is key to testing and thus trusting it. One cornerstone of AI-testing could be explainable AI (xAI). It helps software developers to understand the decision-making process of AI algorithms which is fundamental for a trustworthy AI. In this talk, we present the application and benefits of xAI through two use cases. © 2022, VDI Verlag GMBH. All rights reserved.||Black-box testing; AI algorithms; Black boxes; Critical environment; Decision-making process; Security-critical; Software developer; Software testings; Testing method; Decision making|Article|Final||Scopus|2-s2.0-85175042049
scopus|Galimova E.Y.; Galimov T.A.|Galimova, E.Y. (57218644695); Galimov, T.A. (57802993100)|57218644695; 57802993100|Intellectualization of agriculture information systems and actual software testing methods|2022|IOP Conference Series: Earth and Environmental Science|1045|1|12141||||0|10.1088/1755-1315/1045/1/012141|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134193715&doi=10.1088%2f1755-1315%2f1045%2f1%2f012141&partnerID=40&md5=a27313f63fce70d50133dbbdaba1a2e4|The research is aimed at studying the process of intellectualization of information systems used in the agro-industrial complex. New opportunities created by the use of artificial intelligence in agriculture are identified. The problem of the non-universality of existing testing methods and the need to develop new methods adapted for testing artificial intelligence systems is formulated. The authors have developed a model of the resulting type of testing, which takes into account the results of expert assessments, software quality characteristics, metrics and cost indicators. The authors have developed an information system on the research topic. © Published under licence by IOP Publishing Ltd.|||Conference paper|Final|All Open Access; Gold Open Access|Scopus|2-s2.0-85134193715
scopus|Lau R.; Bagchi A.; Shen J.; Triolo T.; Sanchez K.; Yao L.; Kovarskiy J.; Castro R.|Lau, Richard (59849238100); Bagchi, Anindo (58156198200); Shen, John (58156441000); Triolo, Tony (58156437300); Sanchez, Kenneth (57200519374); Yao, Lihan (57226250999); Kovarskiy, Jacob (57193744883); Castro, Roberto (58155723200)|59849238100; 58156198200; 58156441000; 58156437300; 57200519374; 57226250999; 57193744883; 58155723200|Advanced Multi-Variate Time Series Analytic Techniques (ATTENDS)|2022|Proceedings of the International Telemetering Conference|57|||637|646|9|0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150826289&partnerID=40&md5=fbf30b2f22f10aad511384f3a3df789f|We describe an advanced architecture supporting fast decisions by using multi-variate time series analytic techniques on voluminous datasets that were previously inaccessible. The system, Advanced Multi-Variate Time Series Analytic Techniques (ATTENDS) automates data ingestion, knowledge extraction, and Artificial Intelligence/Machine Learning (AI/ML) algorithm configuration for anomaly detection, failure prediction, causal analysis, and diagnosis. To enable reusability, ATTENDS presents a set of Application Programming Interfaces (API) to support user configurability and remote invocation. The APIs implement state-of-the art AI/ML algorithms for predictive maintenance, sensor component correlation for problem diagnosis, and unsupervised learning of sensor measurement anomaly for support of automated testing and evaluation. We will present two use cases including prediction of Remaining Useful Life (RUL) of Turbofan [1] and sensor diagnosis and recommendation for maintenance actions, as well as detection and quantification of target location error in an airborne platform. © 2022 International Foundation for Telemetering. All rights reserved.||Anomaly detection; Application programming interfaces (API); Learning algorithms; Reusability; Telemetering equipment; Time series analysis; Advanced architecture; Algorithm configurations; Analytic technique; Anomaly detection; Data ingestions; Failures prediction; Fastest decisions; Knowledge extraction; Machine learning algorithms; Times series; Time series|Conference paper|Final||Scopus|2-s2.0-85150826289
scopus|Shi Y.; Gillenson M.L.; Zhang X.|Shi, Yao (57202457122); Gillenson, Mark L. (6603122706); Zhang, Xihui (57192504356)|57202457122; 6603122706; 57192504356|A Quantitative Function for Estimating the Comparative Values of Software Test Cases|2022|Journal of Database Management|33|1|||||0|10.4018/JDM.299559|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186720834&doi=10.4018%2fJDM.299559&partnerID=40&md5=99511b253fba8d6a869616d4d797e5e3|Software testing is becoming more critical to ensure that software functions properly. As the time, effort, and funds invested in software testing activities have been increased significantly, these resources still cannot meet the increasing demand of software testing. Managers must allocate testing resources to the test cases effectively in uncovering important defects. This study builds a value function that can quantify the relative value of a test case and thus play a significant role in prioritizing test cases, addressing the resource constraint issues in software testing and serving as a foundation of AI for software testing. The authors conducted a Monte Carlo simulation to exhibit application of the final value function.  © 2022, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited.|Case Study; Resource Constraint; Simulation; Software Testing|Intelligent systems; Monte Carlo methods; Case-studies; Monte Carlo's simulation; Relative value; Resource Constraint; Simulation; Software functions; Software testings; Test case; Testing resources; Value functions; Software testing|Article|Final||Scopus|2-s2.0-85186720834
scopus|Fajardo-Sondón L.R.; Sanchez-Garcia A.J.; Cortes-Verdin K.; Limón X.|Fajardo-Sondón, Luis Rodrigo (58909399400); Sanchez-Garcia, Angel J. (56486564300); Cortes-Verdin, Karen (57188875614); Limón, Xavier (56031249200)|58909399400; 56486564300; 57188875614; 56031249200|Applications of Monte-Carlo Tree Search in Software Engineering|2022|Proceedings - 2022 International Conference on Mechatronics, Electronics and Automotive Engineering, ICMEAE 2022||||145|150|5|0|10.1109/ICMEAE58636.2022.00032|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186140640&doi=10.1109%2fICMEAE58636.2022.00032&partnerID=40&md5=d7b959b9c80fbfc33216a510485c4be2|Industry 4.0 encourages the use of Artificial Intelligence in industry problems such as the development and quality of Software. Monte-Carlo Tree Search (MCTS) is a search algorithm based on a random sampling of the search space that has been used in games like Tic Tac Toe, Chess, Rubik's Cube or Sudoku. The objective of this Systematic Literature Review (SLR) is to identify opportunities to generate lines of research of this search algorithm, identifying the applications of the MCTS, as well as its advantages and disadvantages compared to other search algorithms in the Software Engineering. In the results obtained in this work, some applications of MCTS in software engineering were found, specifically in software testing and Software Product Line (SPL). It was concluded that MCTS, despite being a relatively new algorithm, can be applied to some areas of Software Engineering. As future work, it is proposed to investigate its application in other areas and compare it with the current methods of Search-Based Software Engineering.  © 2022 IEEE.|Monte-Carlo Tree Search; Search; Software Engineering; Systematic Literature Review|Application programs; Artificial intelligence; Engineering research; Learning algorithms; Monte Carlo methods; Software testing; Industry problems; Monte-carlo tree search; Quality of softwares; Random sampling; Rubik's cubes; Search; Search Algorithms; Search spaces; Systematic literature review; Tree-search; Trees (mathematics)|Conference paper|Final||Scopus|2-s2.0-85186140640
scopus||||Proceedings - 2022 IEEE 14th International Conference on Software Testing, Verification and Validation Workshops, ICSTW 2022|2022|Proceedings - 2022 IEEE 14th International Conference on Software Testing, Verification and Validation Workshops, ICSTW 2022||||||315|0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133274780&partnerID=40&md5=35d702d39a7ad25e93c205e313346d38|The proceedings contain 46 papers. The topics discussed include: using search-based software testing to guide the strive for robust machine learning components: lessons learned across systems and simulators in the mobility domain; RQCODE – towards object-oriented requirements in the software security domain; towards improving explainability, resilience and performance of cybersecurity analysis of 5G/IoT networks; prioritized variable-length test cases generation for finite state machines; falsification of multiple requirements for cyber-physical systems using online generative adversarial networks and multi-armed bandits; security testing as part of software quality assurance: principles and challenges; monitoring approaches for security and safety analysis: application to a load position system; applying combinatorial testing to high-speed railway automatic train protection system; and experience of combinatorial testing toward fault detection, isolation and recovery functionality.|||Conference review|Final||Scopus|2-s2.0-85133274780
scopus|Savic M.; Mantyla M.; Claes M.|Savic, Marko (57777327900); Mantyla, Mika (7006843663); Claes, Maelick (55949047700)|57777327900; 7006843663; 55949047700|Win GUI Crawler: A tool prototype for desktop GUI image and metadata collection|2022|Proceedings - 2022 IEEE 14th International Conference on Software Testing, Verification and Validation Workshops, ICSTW 2022||||223|228|5|0|10.1109/ICSTW55395.2022.00046|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133238728&doi=10.1109%2fICSTW55395.2022.00046&partnerID=40&md5=a51288b17baca569d19305c3d2fe1a78|Despite the widespread of test automation, automatic testing of graphical user interfaces (GUI) remains a challenge. This is partly due to the difficulty of reliably identifying GUI elements over different versions of a given software system. Machine vision techniques could be a potential way of addressing this issue by automatically identifying GUI elements with the help of machine learning. However, developing a GUI testing tool relying on automatic identification of graphical elements first requires to acquire large amount of labeled data. In this paper, we present Win GUI Crawler, a tool for automatically gathering such data from Microsoft Windows GUI applications. The tool is based on Microsoft Windows Application Driver and performs actions on the GUI using a depth-first traversal of the GUI element tree. For each action performed by the crawler, screenshots are taken and metadata is extracted for each of the different screens. Bounding boxes of GUI elements are then filtered in order to identify what GUI elements are actually visible on the screen. Win GUI Crawler is then evaluated on several popular Windows applications and the current limitations are discussed.  © 2022 IEEE.|data collection; graphical user interface; gui element identification; machine vision; test automation|Automatic testing; Computer vision; Metadata; Data collection; Gui element identification; Interface elements; Machine-learning; Machine-vision; Microsoft windows; Software-systems; Test Automation; Vision technique; Windows application; Graphical user interfaces|Conference paper|Final|All Open Access; Green Open Access|Scopus|2-s2.0-85133238728
scopus|Aho P.; Vos T.E.J.; Sybrandi O.; Patrasoiu S.; Oikarinen J.; Valdes O.R.; Hufkens L.V.|Aho, Pekka (35188652400); Vos, Tanja E. J. (8980537100); Sybrandi, Otto (57725149600); Patrasoiu, Sorin (57725053000); Oikarinen, Joona (57207846848); Valdes, Olivia Rodriguez (57210932913); Hufkens, Lianne V. (57211242126)|35188652400; 8980537100; 57725149600; 57725053000; 57207846848; 57210932913; 57211242126|IVVES (Industrial-Grade Verification and Validation of Evolving Systems)|2022|CEUR Workshop Proceedings|3144||||||0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131229051&partnerID=40&md5=ffc99a7d57bbafdd32f256a66a7049ef|An increasing number of information systems are based on machine learning (ML) or artificial intelligence (AI). In some cases, the systems are adapting their behaviour during operation based on the data being gathered. This introduces new challenges for verification, validation and software testing. The traditional way of testing the systems during the development and before the deployment does not suffice anymore. IVVES (Industrial-Grade Verification and Validation of Evolving Systems) project aims to address these challenges by researching and developing methods to test ML and AI solutions and evolving systems, and using AI and ML to improve and automate development and testing. We summarise the results of the project at a high level, and provide more details on the research and collaboration related to scriptless end-to-end testing through graphical user interface.  © 2021 The Authors.|artificial intelligence; evolving systems; machine learning; software testing|Graphical user interfaces; Industrial research; Machine learning; Verification; Development and testing; End to end; Evolving systems; Software testings; Solution system; Validation testing; Verification testing; Verification-and-validation; Software testing|Conference paper|Final||Scopus|2-s2.0-85131229051
scopus|Pandey S.; Kumar K.|Pandey, Sanchita (58279718900); Kumar, Kuldeep (57202765898)|58279718900; 57202765898|Software Fault Prediction for Imbalanced Data: A Survey on Recent Developments|2022|Procedia Computer Science|218|||1815|1824|9|23|10.1016/j.procs.2023.01.159|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159402711&doi=10.1016%2fj.procs.2023.01.159&partnerID=40&md5=94bad491199aae5bc6fc5212b1ca2644|The method of recognizing faults in a software system is acknowledged as software fault prediction. Software faults predicted in prior stages help in the management of resources and time required during software testing and maintenance. The identified software module can be fixed ahead of time, saving time and money near the end of the software development process. Over the years, various supervised machine learning-based techniques for fault prediction have been suggested. These models' accuracy is based on the training datasets. The models are created and trained using a labeled dataset consisting of multiple independent variables like lines of codes, the complexity of the software, the size of the software, etc., and a dependent binary variable, either true or false. But the fault dataset may have some concerns like a class overlapping problem, class imbalance problem, null values, etc. Recent research in software fault prediction focuses on data quality. An imbalanced dataset is one in which one of the class data is present in the majority and another class data is present in the minority. Models built using imbalanced datasets are biased which results in inaccurate predictions. Therefore, balancing the dataset is important. In this paper, the most recent software fault prediction algorithms, which focus on class imbalance issues are discussed. A comparative presentation is presented in this paper, which would benefit the scholar in selecting the best techniques of fault prediction based on different datasets and algorithms. According to the survey, SMOTE is the most commonly used data sampling technique for dealing with data quality issues. © 2023 The Authors. Published by Elsevier B.V.|Data Sampling; Imbalanced Data; Machine Learning; Software Fault Prediction|Balancing; Cloud computing; Learning systems; Software design; Software testing; Supervised learning; Data quality; Data sampling; Fault prediction; Imbalanced data; Imbalanced dataset; Machine-learning; Software fault; Software fault prediction; Software testings; Software-systems; Forecasting|Conference paper|Final|All Open Access; Gold Open Access|Scopus|2-s2.0-85159402711
scopus|Odevci B.B.; Ozdem M.; Emsen E.; Bilen T.|Odevci, Bahadir Baran (56586168400); Ozdem, Mehmet (18434504900); Emsen, Ebru (6603243804); Bilen, Tugce (57136805000)|56586168400; 18434504900; 6603243804; 57136805000|A Machine Learning Model for Predicting Performance of Gamified Software Test Specialist|2022|16th International Conference on INnovations in Intelligent SysTems and Applications, INISTA 2022|||||||0|10.1109/INISTA55318.2022.9894269|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139594104&doi=10.1109%2fINISTA55318.2022.9894269&partnerID=40&md5=9f65a4322cda231afc1063d9dcee822f|Gamification is one of the new trend in software development and it has already gained a well-deserved popularity in finance, healthcare, education and even manufacturing. Software testing is a continuous cycle layered with several stages and spanning across multiple types of testing. Teams need to design test suites and implement test execution methodologies in each stage of development. For this reason, software testing teams comprise many individuals skilled in different aspects of software testing. The inclusion of gamification in this course can lead to positive benefits based on the idea that it is used to influence behavior. This paper presents an preliminary study of Machine Learning (ML) approach for predicting performance gamification of software tester specialists under a gamified testing environment. ImonaGame is a software company that delivers gamification as a service for software testing team of 30 members with different static and dynamic data. User behavior collected in dynamic data sets was classified into categories by deconstructing complex activities into behavior chains using supervision of domain experts. The classification approach was centered on the system's testing processes' performance objectives and potential for encouragement or dissuasion. Motivators and obstacles for the target activity and its behaviors will be found when the model has been developed. After conducting preliminary research, it is possible to determine whether gameful design is an effective and efficient tactic for achieving the desired result by analyzing needs, motives, and obstacles. The source data was classified target data in four categories such as I: Static feature (personal information; 4), II: Daily feature (gamification elements; 14), III: Mission feature (points; 7 sources) and IV: Cumulative futures (Sum of daily and mission features; 13).  © 2022 IEEE.|gamification; machine learning; performance; software tester|Behavioral research; Machine learning; Software design; Classifieds; Design tests; Gamification; Health care education; Machine learning models; Machine-learning; Performance; Software tester; Software testings; Testing teams; Software testing|Conference paper|Final||Scopus|2-s2.0-85139594104
scopus|Gröpler R.; Kutty L.; Sudhi V.; Smalley D.|Gröpler, Robin (57274289800); Kutty, Libin (57226684545); Sudhi, Viju (57226695685); Smalley, Daran (57612819100)|57274289800; 57226684545; 57226695685; 57612819100|Automated Requirement Formalization Using Product Design Specifications|2022|CEUR Workshop Proceedings|3122||||||2||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128715774&partnerID=40&md5=6e87b52c6b3aaa7186831eb9b0d81717|Assuring the quality of complex and highly configurable software systems is a demanding and time-consuming process. Especially for safety-critical systems, extensive testing based on requirements is necessary. Methods for model-based test automation in agile software development offer the possibility to overcome these difficulties. However, it is still a major effort to create formal models from functional requirements in natural language on a large scale. In this paper, we present and evaluate automated support for the requirements formalization process to reduce cost and effort. We present a new approach based on Natural Language Processing (NLP) and textual similarity using requirements and product design specifications to generate human- and machine-readable models. The method is evaluated on an industrial use case from the railway domain. The recommended requirement models for the considered propulsion system show an average accuracy of more than 90% and an exact match of the entire models of about 55%. These results show that our approach can support the requirements formalization process, which can be further used for test case generation and execution, as well as for requirements and design verification. © 2022 Copyright for this paper by its authors|natural language processing; Requirements engineering; requirements modeling; textual similarity|Automation; Model checking; Modeling languages; Product design; Propulsion; Requirements engineering; Safety engineering; Safety testing; Software design; Software testing; Specifications; Design specification; Extensive testing; Model-based test; Requirement engineering; Requirements formalizations; Requirements modeling; Safety critical systems; Software-systems; Test Automation; Textual similarities; Natural language processing systems|Conference paper|Final||Scopus|2-s2.0-85128715774
scopus|Qu T.; Liu W.; Zheng W.; Tao W.|Qu, Tianrun (58010591800); Liu, Wei (57666090000); Zheng, Weining (57267400800); Tao, Wenxin (57964073400)|58010591800; 57666090000; 57267400800; 57964073400|Software Defect Detection Method Based on Graph Structure and Deep Neural Network|2022|2022 International Conference on Asian Language Processing, IALP 2022||||395|400|5|2|10.1109/IALP57159.2022.9961240|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143971238&doi=10.1109%2fIALP57159.2022.9961240&partnerID=40&md5=e3889ba4529c55067ced5d963df047ad|For software source code defect detection, in order to achieve higher generalization ability and higher detection accuracy, this paper proposes a defect detection method based on graph structure and deep neural network. Use the code representation methods of abstract syntax tree, program dependency graph and code property graph to generate the dependency relationship of code data, extract the defect candidate key nodes of source code, and slice the program. Word2vec and one hot coding methods combined with attention mechanism are used to extract the semantic feature information and sentence type information of the program statements. In the deep neural network part, the BiGRU network model with attention mechanism is selected for deep learning to extract context information, forward and backward sequence information. Compared with the existing defect detection tools by data on SARD and CVE dataset, the generalization ability and detection effect are significantly improved. When applied to software testing, this method can achieve more efficient testing capability. © 2022 IEEE.|abstract syntax tree; attention mechanism; code property graph; deep neural network; software defect detection|Defects; Graphic methods; Network coding; Semantics; Software testing; Syntactics; Trees (mathematics); Abstract Syntax Trees; Attention mechanisms; Code property graph; Defect detection; Defect detection method; Generalization ability; Graph structures; Property; Software defect detection; Software defects; Deep neural networks|Conference paper|Final||Scopus|2-s2.0-85143971238
scopus|Kirinuki H.; Matsumoto S.; Higo Y.; Kusumoto S.|Kirinuki, Hiroyuki (56875466800); Matsumoto, Shinsuke (36661111200); Higo, Yoshiki (7004831134); Kusumoto, Shinji (7102741360)|56875466800; 36661111200; 7004831134; 7102741360|Web Element Identification by Combining NLP and Heuristic Search for Web Testing|2022|Proceedings - 2022 IEEE International Conference on Software Analysis, Evolution and Reengineering, SANER 2022||||1055|1065|10|2|10.1109/SANER53432.2022.00123|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135789483&doi=10.1109%2fSANER53432.2022.00123&partnerID=40&md5=2bf33e66db0af82ec363ca12aafff971|End-to-end test automation is critical in modern web application development. However, test automation techniques used in industry face challenges in implementing and maintaining test scripts. It is difficult to determine and maintain the locators needed by test scripts to identify web elements on web pages. The reason is that locators depend on the metadata of web elements and the structure of each web page. One effective way to solve such a problem of locators is to allow test cases written in natural language to be executed without test scripts. In this study, we propose a technique to identify web elements that should be operated on a web page by interpreting natural-language-like test cases. The test cases are written in a domain-specific language that independents on the metadata of web elements and the structural information of web pages. We leverage natural language processing techniques to understand the semantics of web elements. We also create heuristic search algorithms to explore web pages and find promising test procedures. To evaluate the proposed technique, we applied it to test cases for two open-source web applications. The experimental results show that our technique was able to successfully identify about 94% of web elements to be operated in the test cases. Our approach also succeeded in identifying all the web elements that were operated in 68% of the test cases.  © 2022 IEEE.|NLP; test automation; test script; web testing|Automation; Heuristic algorithms; Metadata; Semantic Web; Semantics; Software testing; Testing; Websites; Automation techniques; End-to-end tests; Heuristic search; Natural languages; Test Automation; Test case; Test scripts; Web application development; Web testing; Web-page; Natural language processing systems|Conference paper|Final||Scopus|2-s2.0-85135789483
scopus|Taromirad M.; Runeson P.|Taromirad, Masoumeh (24328965600); Runeson, Per (57202664772)|24328965600; 57202664772|Near Failure Analysis Using Dynamic Behavioural Data|2022|Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)|13709 LNCS|||171|178|7|0|10.1007/978-3-031-21388-5_12|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142706904&doi=10.1007%2f978-3-031-21388-5_12&partnerID=40&md5=1b30e6b5f4f2b7c30775fcb6b96ddb4c|Automated testing is a safeguard against software regression and provides huge benefits. However, it is yet a challenging subject. Among others, there is a risk that the test cases are too specific, thus making them inefficient. There are many forms of undesirable behaviour that are compatible with a typical program’s specification, that however, harm users. An efficient test should provide most possible information in relation to the resources spent. This paper introduces near failure analysis which complements testing activities by analysing dynamic behavioural metrics (e.g., execution time) in addition to explicit output values. The approach employs machine learning (ML) for classifying the behaviour of a program as faulty or healthy based on dynamic data gathered throughout its executions over time. An ML-based model is designed and trained to predict whether or not an arbitrary version of a program is at risk of failure. The very preliminary evaluation demonstrates promising results for feasibility and effectiveness of near failure analysis. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.|Dynamic metrics; Failure prediction; Regression testing|Failure (mechanical); Software testing; Automated testing; Behavioral data; Dynamic data; Dynamic metrics; Failures prediction; Machine-learning; ON dynamics; Output values; Regression testing; Test case; Failure analysis|Conference paper|Final||Scopus|2-s2.0-85142706904
scopus|Wan C.; Liu S.; Xie S.; Liu Y.; Hoffmann H.; Maire M.; Lu S.|Wan, Chengcheng (57190807234); Liu, Shicheng (57271349000); Xie, Sophie (57471495500); Liu, Yifan (58610634300); Hoffmann, Henry (7401864015); Maire, Michael (7003906267); Lu, Shan (35199803400)|57190807234; 57271349000; 57471495500; 58610634300; 7401864015; 7003906267; 35199803400|Automated Testing of Software that Uses Machine Learning APIs|2022|Proceedings - International Conference on Software Engineering|2022-May|||212|224|12|18|10.1145/3510003.3510068|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133536159&doi=10.1145%2f3510003.3510068&partnerID=40&md5=6449095e204a938f9ed5d387e8fcc3a0|An increasing number of software applications incorporate machine learning (ML) solutions for cognitive tasks that statistically mimic human behaviors. To test such software, tremendous human effort is needed to design image/text/audio inputs that are relevant to the software, and to judge whether the software is processing these inputs as most human beings do. Even when misbehavior is exposed, it is often unclear whether the culprit is inside the cognitive ML API or the code using the API. This paper presents Keeper, a new testing tool for software that uses cognitive ML APIs. Keeper designs a pseudo-inverse function for each ML API that reverses the corresponding cognitive task in an empirical way (e.g., an image search engine pseudo-reverses the image-classification API), and incorporates these pseudo-inverse functions into a symbolic execution engine to automatically gener-ate relevant image/text/audio inputs and judge output correctness. Once misbehavior is exposed, Keeper attempts to change how ML APIs are used in software to alleviate the misbehavior. Our evalu-ation on a variety of open-source applications shows that Keeper greatly improves the branch coverage, while identifying many pre-viously unknown bugs. © 2022 ACM.|machine learning; machine learning API; software testing|Application programming interfaces (API); Application programs; Behavioral research; Machine learning; Open source software; Open systems; Search engines; Audio input; Cognitive machines; Cognitive task; Image texts; Machine learning API; Machine-learning; Misbehaviour; Pseudo-inverses; Software testings; Software testing|Conference paper|Final||Scopus|2-s2.0-85133536159
scopus|Reyna R.; Simske S.J.|Reyna, Ricardo (57963090700); Simske, Steven J. (7003506391)|57963090700; 7003506391|How to generate and import functional test cases into project management software systems using natural language processing|2022|Archiving 2022: Expanding Connections Across Digital Cultural Heritage - Final Program and Proceedings||||40|44|4|1|10.2352/issn.2168-3204.2022.19.1.09|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141745541&doi=10.2352%2fissn.2168-3204.2022.19.1.09&partnerID=40&md5=72da044af88b9d69ffa7419c4dae1536|The main purpose of software testing is to identify what the software does and whether it matches its functional expectations. Applying a test plan allows one to prevent problems in early stages, identifying and addressing solutions before a project goes into production. Test cases play an important role during the software testing phase. A test case is a document with comprehensive details and sequences of actions to guide the software tester through the steps that need to be taken and the outputs that are expected. The proposed system generates test cases based on scraped data that are used to interact with Natural Language Processing (NLP) approaches to generate functional test cases. A project management software (e.g., JIRA) is integrated with the JIRA python library to manage the test cases by the software tester. © 2022 Society for Imaging Science and Technology.|Automatic Testing; Functional Testing; Natural Language Processing (NLP); Software Testing; Test Case|Automatic testing; Natural language processing systems; Project management; Functional test; Functional testing; Language processing; Natural language processing; Natural languages; Project management software; Software testings; Software-systems; Test case; Test plan; Software testing|Conference paper|Final||Scopus|2-s2.0-85141745541
scopus|Mohammed M.Z.; Saleh I.A.|Mohammed, Mustafa Zaki (58178783000); Saleh, Ibrahim Ahmed (57211256902)|58178783000; 57211256902|Predicted of Software Fault Based on Random Forest and K-Nearest Neighbor|2022|ICOASE 2022 - 4th International Conference on Advanced Science and Engineering||||43|48|5|7|10.1109/ICOASE56293.2022.10075596|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152191654&doi=10.1109%2fICOASE56293.2022.10075596&partnerID=40&md5=ef9922b48e7f06f647d2c87cc62bec4a|Software systems have gotten increasingly complicated and adaptable in today's computer world. As a result, it's critical to track down and fix software design flaws on a regular basis. Software fault prediction in early phase is useful for enhancing software quality and for reducing software testing time and expense; it's a technique for predicting problems using historical data. To anticipate software flaws from historical databases, several machine learning approaches are applied. This paper focuses on creating a predictor to predict software defects, Based on previous data. For this purpose, a supervised machine learning techniques was utilized to forecast future software failures, K-Nearest Neighbor (KNN) and Random Forest (RF) applied technique applied to the defective data set belonging to the NASA's PROMISE repository. Also, a set of performance measures such as accuracy, precision, recall and f1 measure were used to evaluate the performance of the models. This paper showed a good performance of the RF model compared to the KNN model resulting in a maximum and minimum accuracy are 99%,88% on the MC1 and KC1 responsibly. In general, the study's findings suggest that software defect metrics may be used to determine the problematic module, and that the RF model can be used to anticipate software errors. © 2022 IEEE.|Defect prediction; K-Nearest Neighbor; Machine learning; Random Forest; Software engineering; Software fault|Computer software selection and evaluation; Forecasting; Learning algorithms; Learning systems; Motion compensation; NASA; Nearest neighbor search; Software design; Software testing; Supervised learning; Defect prediction; Fault-based; K-near neighbor; Machine-learning; Nearest-neighbour; Performance; Random forest modeling; Random forests; Software defects; Software fault; Defects|Conference paper|Final||Scopus|2-s2.0-85152191654
scopus|Iswafaza A.F.; Rochimah S.|Iswafaza, Aizul Faiz (57422689600); Rochimah, Siti (24476646200)|57422689600; 24476646200|Software Defect Prediction Using a Combination of Oversampling and Undersampling Methods|2022|Proceeding - 6th International Conference on Information Technology, Information Systems and Electrical Engineering: Applying Data Sciences and Artificial Intelligence Technologies for Environmental Sustainability, ICITISEE 2022||||127|132|5|2|10.1109/ICITISEE57756.2022.10057798|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150468951&doi=10.1109%2fICITISEE57756.2022.10057798&partnerID=40&md5=7b0667bde6b3d3b798a3fec58a8560fe|Software quality can be improved by doing software testing, but the more features are developed the more resources are required, therefore software defect prediction (SDP) is introduced. Various kinds of machine learning methods are used to develop SDP. However, various kinds of problems arise in SDP activities, namely data redundancy, class imbalance and feature redundancy. In this study, a combination of oversampling and under-sampling (COU) model will be proposed to solve the problem of data redundancy and class imbalance. The oversampling method used is RSMOTE and the under-sampling method used is ENN. The application of the combination model will later provide a new set of datasets that are more balanced and cleaner from ambiguous, noisy and duplication of data. From the new data generated by the model, deep learning will then be applied as a prediction model. And the evaluation will be done by applying the f-measure measurement. The results of this study indicate that the COU model used gives good results in improving the quality of SDP. When compared with the average value generated by the RSMOTE model in making predictions, the COU model provides an increase in f-measure evaluation results by 11% where the average value obtained is 0.876. So, this combination method is able to improve the performance of software defect prediction activities  © 2022 IEEE.|AEEEM; combined oversampling and under-sampling; edited nearest neighbors; RSMOTE; software defect prediction|Computer software selection and evaluation; Deep learning; Defects; Forecasting; Learning systems; Redundancy; AEEEM; Combined oversampling and under-sampling; Data-redundancy; Edited near neighbor; Nearest-neighbour; Over sampling; RSMOTE; Sampling model; Software defect prediction; Under-sampling; Software testing|Conference paper|Final||Scopus|2-s2.0-85150468951
scopus|Cai G.; Su Q.; Hu Z.|Cai, Gaocheng (57254449100); Su, Qinghua (55821331900); Hu, Zhongbo (55569632600)|57254449100; 55821331900; 55569632600|Automated test case generation for path coverage by using grey prediction evolution algorithm with improved scatter search strategy|2021|Engineering Applications of Artificial Intelligence|106||104454||||30|10.1016/j.engappai.2021.104454|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114679818&doi=10.1016%2fj.engappai.2021.104454&partnerID=40&md5=608c6dabba1b44cce7622779ceb446e7|Automated test case generation for path coverage (ATCG-PC), as an important task in software testing, aims to achieve the highest path coverage of a tested program by using as little computational overhead as possible. In ATCG-PC, “similar paths are usually executed by similar test cases” is a problem-specific knowledge which was touched by a handful of researchers but still underutilized. Inspired by the problem-specific knowledge, this paper designs a local search strategy by improving a scatter search strategy, and then proposes a grey prediction evolution algorithm with the improved scatter search strategy for ATCG-PC. Here, the improved scatter search strategy could obtain two feasible test cases by exploiting a dimension of a test case covering a certain path. The proposed algorithm is constructed by importing the improved scatter search strategy to the end of the reproduction operation of the grey prediction evolution algorithm holding strong exploration ability. Grey prediction evolution algorithm is first applied to solve ATCG-PC. The performance of the proposed algorithm is evaluated on six fog computing benchmark programs and six natural language processing benchmark programs. The experimental results demonstrate that the proposed algorithm can achieve the highest path coverage with the fewer test cases and running time than some state-of-the-art algorithms. © 2021|Automated test case generation; Grey prediction evolution algorithm; Improved scatter search strategy; Path coverage|Automation; Benchmarking; Cell proliferation; Evolutionary algorithms; Natural language processing systems; Software testing; Testing; Automated test-case generations; Benchmark programs; Gray prediction; Gray prediction evolution algorithm; Improved scatter search strategy; Path coverage; Problem-specific knowledge; Scatter search; Search strategies; Test case; Forecasting|Article|Final||Scopus|2-s2.0-85114679818
scopus|Tufano M.; Deng S.K.; Sundaresan N.; Svyatkovskiy A.|Tufano, Michele (57651427900); Deng, Shao Kun (57219765050); Sundaresan, Neel (7005588783); Svyatkovskiy, Alexey (36640625700)|57651427900; 57219765050; 7005588783; 36640625700|METHODS2TEST: A dataset of focal methods mapped to test cases|2022|Proceedings - 2022 Mining Software Repositories Conference, MSR 2022||||299|303|4|30|10.1145/3524842.3528009|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134046979&doi=10.1145%2f3524842.3528009&partnerID=40&md5=da4f4241c35ab9fd8ecea269d493bf2d|Unit testing is an essential part of the software development process, which helps to identify issues with source code in early stages of development and prevent regressions. Machine learning has emerged as viable approach to help software developers generate automated unit tests. However, generating reliable unit test cases that are semantically correct and capable of catching software bugs or unintended behavior via machine learning requires large, metadata-rich, datasets. In this paper we present Methods2Test: a large, supervised dataset of test cases mapped to corresponding methods under test (i.e., focal methods). This dataset contains 780,944 pairs of JUnit tests and focal methods, extracted from a total of 91,385 Java open source projects hosted on GitHub with licenses permitting re-distribution. The main challenge behind the creation of the Methods2Test was to establish a reliable mapping between a test case and the relevant focal method. To this aim, we designed a set of heuristics, based on developers' best practices in software testing, which identify the likely focal method for a given test case. To facilitate further analysis, we store a rich set of metadata for each method-test pair in JSON-formatted files. Additionally, we extract textual corpus from the dataset at different context levels, which we provide both in raw and tokenized forms, in order to enable researchers to train and evaluate machine learning models for Automated Test Generation. Methods2Test is publicly available at: https://github.com/microsoft/methods2test © 2022 ACM.|Datasets; software testing|Heuristic methods; Large dataset; Machine learning; Metadata; Open source software; Program debugging; Software design; Statistical tests; Automated units; Dataset; Machine-learning; Software developer; Software development process; Software testings; Source codes; Test case; Unit testing; Unit tests; Software testing|Conference paper|Final|All Open Access; Bronze Open Access; Green Open Access|Scopus|2-s2.0-85134046979
scopus|Yao T.; Zhang B.; Peng J.; Han Z.; Yang Z.; Zhang Z.; Zhang B.|Yao, Tianwen (57456837700); Zhang, Ben (57456837800); Peng, Jun (57456901600); Han, Zhiqiang (57456966300); Yang, Zhaobing (57285181200); Zhang, Zhi (57457212000); Zhang, Bo (57457212100)|57456837700; 57456837800; 57456901600; 57456966300; 57285181200; 57457212000; 57457212100|Defect Prediction Technology of Aerospace Software Based on Deep Neural Network and Process Measurement|2022|Mathematical Problems in Engineering|2022||1276830||||3|10.1155/2022/1276830|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124805497&doi=10.1155%2f2022%2f1276830&partnerID=40&md5=0613e08274d31a354f39da1feea591e0|In order to ensure high reliability, the efficiency of traditional aerospace software testing is often low. With the rapid development of machine learning, its powerful data feature extraction ability has great potential in improving the efficiency of aerospace software testing. Therefore, this paper proposed a software defect prediction method based on deep neural network and process measurement. Based on the NASA data set and combined with the software process data, the software defect measurement set is constructed. 35 measurement elements are used as the original input, and multiple single-layer automatic coding networks are superimposed to form the deep neural network model of software defect. The model is finally trained by the layer-by-layer greedy training method to realize software defect prediction. Experimental verification shows that the prediction method has a good prediction effect on aerospace software defects, and the accuracy rate reached 90%, which can greatly improve the efficiency and effect of aerospace software testing.  © 2022 Tianwen Yao et al.||Deep neural networks; Defects; Efficiency; Forecasting; NASA; Network layers; Software reliability; Verification; Aerospace software; Defect prediction; High reliability; Network measurement; Neural process; Prediction technologies; Process measurements; Software defect prediction; Software defects; Software testings; Software testing|Article|Final|All Open Access; Gold Open Access|Scopus|2-s2.0-85124805497
scopus|Chao C.; Yang Q.; Tu X.|Chao, Cong (58028267500); Yang, Qinghua (57188865188); Tu, Xiaowei (49362221800)|58028267500; 57188865188; 49362221800|Research on Test Case Generation Method of Airborne Software Based on NLP|2022|CEUR Workshop Proceedings|3304|||28|37|9|1||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144615482&partnerID=40&md5=ee069704eee9940b69c64f7ed714744d|Software testing is a key stage in the life cycle of airborne software development. At this stage, airborne software test cases are developed manually, so the preparation of test cases requires a lot of time and labor costs and is prone to human errors. To solve this problem, on the basis of Long Short-Term Memory, this paper proposes an airborne software test case automatic generation algorithm based on Bi-LSTM-CRF named entity recognition model and Part-Of-Speech tagging. First, preprocess the airborne software requirement document, replace the testable variable name and filter out the untestable requirement statements. Then, the airborne software domain corpus is trained through Bi-LSTM-CRF model to obtain named entity recognition model. Finally, the tag sequence is generated from the requirement statement through the named entity identification model, and the test case is generated through the triplet generation algorithm and the coverage criteria processing algorithm. The experiment uses the engine indicator software requirements document to verify the effect. The results show that compared with the traditional Bi-LSTM-CRF model, the training method with Part-Of-Speech tagging is more accurate, and the accuracy of the final test case generation can reach more than 80%. © 2022 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0)|Airborne Software; Bi-LSTM-CRF; Named Entity Recognition; Test Case Generation|Computational linguistics; Life cycle; Long short-term memory; Natural language processing systems; Semantics; Software design; Software testing; Speech recognition; Wages; Airborne software; Bi-LSTM-CRF; Generation algorithm; Named entity recognition; Part of speech tagging; Parts-of-speech tagging; Recognition models; Software requirement documents; Test case; Test case generation; Working fluid pressure indicators|Conference paper|Final||Scopus|2-s2.0-85144615482
scopus|Shi Y.; Huang S.; Wan J.|Shi, Yaqing (55495673300); Huang, Song (55608828500); Wan, Jinyong (57426621900)|55495673300; 55608828500; 57426621900|Reuse of Test Case based on Attributes Weight Optimization|2022|IEEE International Conference on Software Quality, Reliability and Security, QRS|2022-December|||464|472|8|1|10.1109/QRS57517.2022.00054|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151451311&doi=10.1109%2fQRS57517.2022.00054&partnerID=40&md5=c62818ce50d0d7674bdf9683afef8148|Software testing is complicated and requires a lot of manpower and material resource in the software life cycle. The design of test cases costs a lot of time. In order to improve the efficiency of software testing in the test cases design stage, this paper uses historical test assets to assist the design of test cases in new project, and proposes a test case reuse method based on attribute weight optimization. Firstly, the text vector of test data is obtained by using Natural Language Processing. The test case package is formed based on the keyword extraction and the test case clustering, and the test case vector library is constructed. Then, a test case attribute weight optimization method based on the Genetic Simulated Annealing Algorithm is proposed. Combined with the optimized attribute weights, the test case reuse is realized by using the similarity calculation of the test case data vector. Finally, the test case reuse method is experimentally verified by two projects with different types. Experimental results show that this method can effectively improve the efficiency of test cases' design. It has better understandability and maintainability, and improve the quality of test cases.  © 2022 IEEE.|attribute weight optimization; test case reuse; the Genetic Simulated Annealing Algorithm|Computer software reusability; Life cycle; Natural language processing systems; Simulated annealing; Software testing; Attribute weight; Attribute weight optimization; Reuse; Software testings; Test case; Test case designs; Test case reuse; The genetic simulated annealing algorithm; Weight optimization; Efficiency|Conference paper|Final||Scopus|2-s2.0-85151451311
scopus|Wang Q.; Chen Z.; Wang J.; Feng Y.|Wang, Qing (55698296000); Chen, Zhenyu (55579848600); Wang, Junjie (55976866600); Feng, Yang (41861285900)|55698296000; 55579848600; 55976866600; 41861285900|Intelligent Crowdsourced Testing|2022|Intelligent Crowdsourced Testing||||1|251|250|3|10.1007/978-981-16-9643-5|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167719772&doi=10.1007%2f978-981-16-9643-5&partnerID=40&md5=92901e4a1851dfbe8c0c0f04436fa306|In an article for Wired Magazine in 2006, Jeff Howe defined crowdsourcing as an idea for outsourcing a task that is traditionally performed by a single employee to a large group of people in the form of an open call. Since then, by modifying crowdsourcing into different forms, some of the most successful new companies on the market have used this idea to make people's lives easier and better. On the other hand, software testing has long been recognized as a time-consuming and expensive activity. Mobile application testing is especially difficult, largely due to compatibility issues: a mobile application must work on devices with different operating systems (e.g. iOS, Android), manufacturers (e.g. Huawei, Samsung) and keypad types (e.g. virtual keypad, hard keypad). One cannot be 100% sure that, just because a tested application works well on one device, it will run smoothly on all others. Crowdsourced testing is an emerging paradigm that can improve the cost-effectiveness of software testing and accelerate the process, especially for mobile applications. It entrusts testing tasks to online crowdworkers whose diverse testing devices/contexts, experience, and skill sets can significantly contribute to more reliable, cost-effective and efficient testing results. It has already been adopted by many software organizations, including Google, Facebook, Amazon and Microsoft. This book provides an intelligent overview of crowdsourced testing research and practice. It employs machine learning, data mining, and deep learning techniques to process the data generated during the crowdsourced testing process, to facilitate the management of crowdsourced testing, and to improve the quality of crowdsourced testing. © The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2022.|Crowdsourced testing; Crowdsourcing; Intelligent software engineering; Intelligent testing; Software testing||Book|Final||Scopus|2-s2.0-85167719772
scopus|Zheng J.; Li J.; Li C.; Li R.|Zheng, Jiahui (57221378317); Li, Junjian (57956116400); Li, Chao (57208489329); Li, Ran (57207203200)|57221378317; 57956116400; 57208489329; 57207203200|A SQL Blind Injection Method Based on Gated Recurrent Neural Network|2022|Proceedings - 2022 7th IEEE International Conference on Data Science in Cyberspace, DSC 2022||||519|525|6|0|10.1109/DSC55868.2022.00078|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141346417&doi=10.1109%2fDSC55868.2022.00078&partnerID=40&md5=81c0a4273afa25f43fc9f821bfcb65c7|Security is undoubtedly the most serious problem for Web applications, and SQL injection (SQLi) attacks are one of the most damaging. The detection of SQL blind injection vulnerability is very important, but unfortunately, it is not fast enough. This is because time-based SQL blind injection lacks web page feedback, so the delay function can only be set artificially to judge whether the injection is successful by observing the response time of the page. However, brute force cracking and binary search methods used in injection require more web requests, resulting in a long time to obtain database information in SQL blind injection. In this paper, a gated recurrent neural network-based SQL blind injection technology is proposed to generate the predictive characters in SQL blind injection. By using the neural language model based on deep learning and character sequence prediction, the method proposed in this paper can learn the regularity of common database information, so that it can predict the next possible character according to the currently obtained database information, and sort it according to probability. In this paper, the training model is evaluated, and experiments are carried out on the shooting range to compare the method used in this paper with sqlmap (the most advanced sqli test automation tool at present). The experimental results show that the method used in this paper is more effective and significant than sqlmap in time-based SQL blind injection. It can obtain the database information of the target site through fewer requests, and run faster. © 2022 IEEE.|Blind SQL injection; Gated recurrent neural network; WEB security|Database systems; Network security; Websites; Blind SQL injection; Database information; Gated recurrent neural network; Injection method; SQL injection; Time based; WEB application; Web applications; WEB security; Web-page; Recurrent neural networks|Conference paper|Final||Scopus|2-s2.0-85141346417
scopus|Woodlief T.; Elbaum S.; Sullivan K.|Woodlief, Trey (57212315457); Elbaum, Sebastian (6604075891); Sullivan, Kevin (35474257400)|57212315457; 6604075891; 35474257400|Semantic Image Fuzzing of AI Perception Systems|2022|Proceedings - International Conference on Software Engineering|2022-May|||1958|1969|11|15|10.1145/3510003.3510212|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133499277&doi=10.1145%2f3510003.3510212&partnerID=40&md5=5ace4d3250379dd31e3dc0b802b78dd9|Perception systems enable autonomous systems to interpret raw sensor readings of the physical world. Testing of perception systems aims to reveal misinterpretations that could cause system failures. Current testing methods, however, are inadequate. The cost of human interpretation and annotation of real-world input data is high, so manual test suites tend to be small. The simulation-reality gap reduces the validity of test results based on simulated worlds. And methods for synthesizing test inputs do not provide corresponding expected interpretations. To address these limitations, we developed semSensFuzz, a new approach to fuzz testing of perception systems based on semantic mutation of test cases that pair realworld sensor readings with their ground-truth interpretations. We implemented our approach to assess its feasibility and potential to improve software testing for perception systems. We used it to generate 150,000 semantically mutated image inputs for five state-of-the-art perception systems. We found that it synthesized tests with novel and subjectively realistic image inputs, and that it discovered inputs that revealed significant inconsistencies between the specified and computed interpretations. We also found that it produced such test cases at a cost that was very low compared to that of manual semantic annotation of real-world images. © 2022 ACM.|autonomous systems; perception; semantic fuzzing|Software testing; Systems engineering; Testing; Autonomous system; Image inputs; Perception systems; Physical world; Raw sensor; Real-world; Semantic fuzzing; Semantic images; Sensor readings; Test case; Semantics|Conference paper|Final|All Open Access; Bronze Open Access|Scopus|2-s2.0-85133499277
scopus|Sikic L.; Kurdija A.S.; Vladimir K.; Silic M.|Sikic, Lucija (57209640612); Kurdija, Adrian Satja (55123204200); Vladimir, Klemo (24831165400); Silic, Marin (36462812000)|57209640612; 55123204200; 24831165400; 36462812000|Graph Neural Network for Source Code Defect Prediction|2022|IEEE Access|10|||10402|10415|13|44|10.1109/ACCESS.2022.3144598|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123383541&doi=10.1109%2fACCESS.2022.3144598&partnerID=40&md5=6f026f26f6828fe3c1f1e28156cf823d|Predicting defective software modules before testing is a useful operation that ensures that the time and cost of software testing can be reduced. In recent years, several models have been proposed for this purpose, most of which are built using deep learning-based methods. However, most of these models do not take full advantage of a source code as they ignore its tree structure or they focus only on a small part of a code. To investigate whether and to what extent information from this structure can be beneficial in predicting defective source code, we developed an end-to-end model based on a convolutional graph neural network (GCNN) for defect prediction, whose architecture can be adapted to the analyzed software, so that projects of different sizes can be processed with the same level of detail. The model processes the information of the nodes and edges from the abstract syntax tree (AST) of the source code of a software module and classifies the module as defective or not defective based on this information. Experiments on open source projects written in Java have shown that the proposed model performs significantly better than traditional defect prediction models in terms of AUC and F-score. Based on the F-scores of the existing <italic>state-of-the-art</italic> models, the model has shown comparable predictive capabilities for the analyzed projects. © 2022 Institute of Electrical and Electronics Engineers Inc.. All rights reserved.|Codes; Data models; Feature extraction; Graph neural networks; Predictive models; Software; Task analysis|Codes (symbols); Deep neural networks; Defects; Forecasting; Graph neural networks; Job analysis; Network coding; Open source software; Software testing; Code; Deep learning; Features extraction; Graph neural networks; Predictive models; Software; Software defect prediction; Source codes; Task analysis; Trees (mathematics)|Article|Final|All Open Access; Gold Open Access|Scopus|2-s2.0-85123383541
scopus|Frisini D.; Stotz V.-S.; Morlacchi G.; Taumaturgo V.|Frisini, David (58168854700); Stotz, Vivien-Sophie (58169409200); Morlacchi, Giovanni (58170127000); Taumaturgo, Vincenzo (58169409300)|58168854700; 58169409200; 58170127000; 58169409300|TECHNOLOGY CONCEPT OF AN AUTOMATED SYSTEM FOR INTEGRATION TESTING|2022|48rd European Rotorcraft Forum, ERF 2022|||||||2||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151555183&partnerID=40&md5=e6cb628070654e4c99d605e6fc8e7633|Looking at the trend seen in the aerospace for Verification & Validation (V&V) process, the future of integration testing will move to a more and more automated process thanks to the use of Artificial Intelligence (AI) and robotics. For the integration testing of an avionic system many different scenarios need to be executed and validated by the user running the test. Focusing on the state of the art of the integration testing, there are some issues and inefficiencies while executing the tests. Firstly, the duration of the test sets of safety-critical systems is long and involves very repetitive tasks for the operator. During this time, the system is under test and the laboratory cannot be used for other purposes which decreases the asset's availability for other stakeholders. Moreover, with distributed offices, the on-site testing could be limitating when the execution of test procedures requires at least one person physically in the laboratory. In order to mitigate these issues ARTO (Automated Robotics for Testing Optimization) has been designed. ARTO is an automated testing system with the capability of executing functional tests that up until now are being performed by test engineers, operators or pilots. It has the objective to automate the repetitive procedures in which human interactions are required, to increase the efficiency, reduce costs and make work remotely from different locations possible. The test sequence is implemented through a dedicated HMI (human-machine interface) and executed by an automated framework, fully able to carry out the tasks needed for each sequence. The system itself consists of four main subsystems: robotics, image & audio processing, framework and user interface. ARTO is designed to be applied in the integration testing field, designed to interact, and operate with the existing testing environment of the Next-Gen Civil Tiltrotor-Technology Demonstrator. It is intended to be installed inside the Simulation and Integration Laboratory cockpit where it can operate on the displays, the keyboards, the knobs and the levers. With the video and audio feedback, it can execute the test procedures that were programmed beforehand and collect test results automatically. Copyright © 2022 by author(s).||Avionics; Integration; Laboratories; Robotics; Safety engineering; User interfaces; Automated process; Automated systems; Avionic systems; Optimisations; Safety critical systems; State of the art; Test procedures; Test sets; Validation process; Verification process; Integration testing|Conference paper|Final||Scopus|2-s2.0-85151555183
scopus|Tsydenov E.; Prokhorov A.; Wang L.|Tsydenov, Evgeny (57214826518); Prokhorov, Anton (57212545477); Wang, Li (57059516100)|57214826518; 57212545477; 57059516100|Online Estimation of Plant Participation Factors for Automatic Generation Control in Power Systems with Variable Energy Resources|2022|IEEE Transactions on Industry Applications|58|4||4401|4410|9|11|10.1109/TIA.2022.3174190|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132503694&doi=10.1109%2fTIA.2022.3174190&partnerID=40&md5=698c752f602990d8ff92f1e0bd94db5d|The article discusses the limitations of existing automatic generation control (AGC) systems that appear under the impact of variable energy resources. To overcome identified issues, the authors proposed an approach that advances the functional block responsible for computation of plant participation factors (PF). This approach connects an optimizer with a component for power flow calculations and allows online estimation of plant PFs to increase flexibility and selectivity of AGC. The corresponding optimization models were established to perform conventional and advanced control strategies. To meet performance requirements imposed by variable energy sources, the machine learning (ML) model, namely the densely connected neural network, was designed for power flow calculations. Besides, Lasso regression method was proposed to select relevant features for the considered control tasks and improve the performance of the machine learning based power flow model. Finally, the software tool was developed to implement the proposed approach and tested on a model of real 60 GW interconnection containing 464 nodes and 742 branches. The results of the software testing confirmed its feasibility and easy integration into existing AGC systems. © 1972-2012 IEEE.|Automatic generation control (AGC); Dimensionality reduction; Machine learning (ML); Neural networks; Participation factors; Power flow analysis; Renewable energy sources; Wind power|Factor analysis; Job analysis; Learning systems; Online systems; Regression analysis; Software testing; Wind power; Adaptation models; Automatic Generation; Automatic generation control; Dimensionality reduction; Generation controls; Load flow; Neural-networks; Optimisations; Participation factors; Power; Power flow analyze; Power system; Renewable energy source; Task analysis; Electric load flow|Article|Final||Scopus|2-s2.0-85132503694
scopus|Rathore S.S.; Kumar S.|Rathore, Santosh S. (55437399500); Kumar, Sandeep (57218539729)|55437399500; 57218539729|Software fault prediction based on the dynamic selection of learning technique: findings from the eclipse project study|2021|Applied Intelligence|51|12||8945|8960|15|16|10.1007/s10489-021-02346-x|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104835766&doi=10.1007%2fs10489-021-02346-x&partnerID=40&md5=70a4a82de0e2c7ed0bc9f2e51bf078d5|An effective software fault prediction (SFP) model could help developers in the quick and prompt detection of faults and thus help enhance the overall reliability and quality of the software project. Variations in the prediction performance of learning techniques for different software systems make it difficult to select a suitable learning technique for fault prediction modeling. The evaluation of previously presented SFP approaches has shown that single machine learning-based models failed to provide the best accuracy in any context, highlighting the need to use multiple techniques to build the SFP model. To solve this problem, we present and discuss a software fault prediction approach based on selecting the most appropriate learning techniques from a set of competitive and accurate learning techniques for building a fault prediction model. In work, we apply the discussed SFP approach for the five Eclipse project datasets and nine Object-oriented (OO) project datasets and report the findings of the experimental study. We have used different performance measures, i.e., AUC, accuracy, sensitivity, and specificity, to assess the discussed approach’s performance. Further, we have performed a cost-benefit analysis to evaluate the economic viability of the approach. Results showed that the presented approach predicted the software’s faults effectively for the used accuracy, AUC, sensitivity, and specificity measures with the highest achieved values of 0.816, 0.835, 0.98, and 0.903 for AUC, accuracy, sensitivity, and specificity, respectively. The cost-benefit analysis of the approach showed that it could help reduce the overall software testing cost. © 2021, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.|Cost-benefit analysis; Dynamic selection; Eclipse project; Machine learning techniques; Software fault prediction|Forecasting; Learning systems; Object oriented programming; Predictive analytics; Software reliability; Software testing; Dynamic selection; Economic viability; Fault prediction models; Learning techniques; Performance measure; Prediction performance; Software fault prediction; Software systems; Cost benefit analysis|Article|Final||Scopus|2-s2.0-85104835766
scopus|Ramchand S.; Shaikh S.; Alam I.|Ramchand, Sonam (57231403500); Shaikh, Sarang (57210376659); Alam, Irtija (57231876400)|57231403500; 57210376659; 57231876400|Role of Artificial Intelligence in Software Quality Assurance|2022|Lecture Notes in Networks and Systems|295|||125|136|11|6|10.1007/978-3-030-82196-8_10|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113518045&doi=10.1007%2f978-3-030-82196-8_10&partnerID=40&md5=5aab9d1ae9955d73af73e0df12bda103|Artificial intelligence has taken its place in almost every industry individual operate in, it has become integral part of applications and systems in our surrounding. The world quality report estimates that 64% of the companies will implement Artificial Intelligence (AI) for the Software Quality Assurance (SQA) processes. It is predicted that in the very near future, SQA engineer will not be testing manually. But they would be acquiring skills to use AI enabled tools techniques for Software Quality assurances in order to contribute to the business growth. AI proves to play a crucial role in the software testing as it makes processes leaner and yields more accurate results. This paper will discuss about how Artificial Intelligence makes impact in the software testing industry. The new era of Quality Assurance will be dominated by the power of Artificial Intelligence as it significantly reduces time and increase efficiency of the firm to develop more sophisticated software. This studies focuses on artificial intelligence applications in software testing, which of the AI algorithms are popularly adopted by the QA industry, Furthermore, this paper talks about real issues that resides in the industry for instance; why young testers are more flexible towards adopting latest technological changes. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.|Artificial intelligence; Black-box testing; Bug reporting; Regression testing; Software development life cycle; Software quality assurance; SQA; White-box testing||Conference paper|Final||Scopus|2-s2.0-85113518045
scopus|Zhang Y.; Wu L.; Shen X.; Shen Z.; Tang T.|Zhang, Yaming (57955920500); Wu, Lijin (55978341400); Shen, Xiaomei (57222117462); Shen, Zehua (57861662000); Tang, Tongli (58185428600)|57955920500; 55978341400; 57222117462; 57861662000; 58185428600|Dependability Analysis and Verification Technology of Artificial Intelligence Software|2022|Proceedings - 2022 IEEE 22nd International Conference on Software Quality, Reliability and Security Companion, QRS-C 2022||||226|232|6|1|10.1109/QRS-C57518.2022.00041|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152624700&doi=10.1109%2fQRS-C57518.2022.00041&partnerID=40&md5=4b0ee0e8c7af0778e6b5b04257068ea2|This paper focuses on the dependability analysis and verification technology of artificial intelligence software. Aiming at the dependability problems caused by the uncontrollable algorithm output of artificial intelligence software, misguided learning models and unpredictable software defects, as well as the current intelligent software testing and verification requirements, this paper analyzes the connotation and characteristics of artificial intelligence software dependability, and studies artificial intelligence software dependability mechanism and defect mode analysis method, break through artificial intelligence software dependability verification technology, innovatively build artificial intelligence software dependability index system, and finally form a comprehensive evaluation method for software dependability. © 2022 IEEE.|artificial intelligence software; coverage criteria; dependability; dependability index system|Artificial intelligence; Software testing; Verification; Well testing; Analysis and verifications; Artificial intelligence software; Coverage criteria; Dependability; Dependability analysis; Dependability index system; Indices systems; Intelligence software; Learning models; Software dependability; Defects|Conference paper|Final||Scopus|2-s2.0-85152624700
scopus|Liu W.; Li Y.; Huang B.|Liu, Wenhong (55336939600); Li, Yong (58448438600); Huang, Bo (58185430000)|55336939600; 58448438600; 58185430000|Evaluation of Intelligent Information System|2022|Proceedings - 2022 IEEE 22nd International Conference on Software Quality, Reliability and Security Companion, QRS-C 2022||||183|188|5|0|10.1109/QRS-C57518.2022.00035|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152616928&doi=10.1109%2fQRS-C57518.2022.00035&partnerID=40&md5=13c2e83809eea0c110af8e9e85df88dd|While artificial intelligence evolves rapidly, intelligent information systems are making significant progress. The core of intelligent information systems is data and models. As a result, data quality and model quality are significant for ensuring the quality of intelligent information systems. However, traditional software testing methods can not adequately evaluate the quality of data and models. In this paper, we propose the data quality evaluation method and the model evaluation method. The experiment results show the two methods are effective. © 2022 IEEE.|artificial intelligence; data quality; evaluation study; Intelligent information system; model quality|Artificial intelligence; Data reduction; Information systems; Information use; Quality control; Data quality; Evaluation study; Intelligent information systems; Model evaluation; Modeling quality; Quality evaluation method; Quality of data; Software testings; Testing method; Software testing|Conference paper|Final||Scopus|2-s2.0-85152616928
scopus|Kumar V.S.; Boulanger D.|Kumar, Vivekanandan S. (57201621048); Boulanger, David (56565054200)|57201621048; 56565054200|Automated Essay Scoring and the Deep Learning Black Box: How Are Rubric Scores Determined?|2021|International Journal of Artificial Intelligence in Education|31|3||538|584|46|54|10.1007/s40593-020-00211-5|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091086122&doi=10.1007%2fs40593-020-00211-5&partnerID=40&md5=122d97093647eeedc47e4498b1fa0229|This article investigates the feasibility of using automated scoring methods to evaluate the quality of student-written essays. In 2012, Kaggle hosted an Automated Student Assessment Prize contest to find effective solutions to automated testing and grading. This article: a) analyzes the datasets from the contest – which contained hand-graded essays – to measure their suitability for developing competent automated grading tools; b) evaluates the potential for deep learning in automated essay scoring (AES) to produce sophisticated testing and grading algorithms; c) advocates for thorough and transparent performance reports on AES research, which will facilitate fairer comparisons among various AES systems and permit study replication; d) uses both deep neural networks and state-of-the-art NLP tools to predict finer-grained rubric scores, to illustrate how rubric scores are determined from a linguistic perspective, and to uncover important features of an effective rubric scoring model. This study’s findings first highlight the level of agreement that exists between two human raters for each rubric as captured in the investigated essay dataset, that is, 0.60 on average as measured by the quadratic weighted kappa (QWK). Only one related study has been found in the literature which also performed rubric score predictions through models trained on the same dataset. At best, the predictive models had an average agreement level (QWK) of 0.53 with the human raters, below the level of agreement among human raters. In contrast, this research’s findings report an average agreement level per rubric with the two human raters’ resolved scores of 0.72 (QWK), well beyond the agreement level between the two human raters. Further, the AES system proposed in this article predicts holistic essay scores through its predicted rubric scores and produces a QWK of 0.78, a competitive performance according to recent literature where cutting-edge AES tools generate agreement levels between 0.77 and 0.81, results computed as per the same procedure as in this article. This study’s AES system goes one step further toward interpretability and the provision of high-level explanations to justify the predicted holistic and rubric scores. It contends that predicting rubric scores is essential to automated essay scoring, because it reveals the reasoning behind AIED-based AES systems. Will building AIED accountability improve the trustworthiness of the formative feedback generated by AES? Will AIED-empowered AES systems thoroughly mimic, or even outperform, a competent human rater? Will such machine-grading systems be subjected to verification by human raters, thus paving the way for a human-in-the-loop assessment mechanism? Will trust in new generations of AES systems be improved with the addition of models that explain the inner workings of a deep learning black box? This study seeks to expand these horizons of AES to make the technique practical, explainable, and trustable. © 2020, International Artificial Intelligence in Education Society.|Automated essay scoring; Deep learning; Feature importance; Natural language processing; Neural network; Rubrics|Automation; Cutting tools; Deep neural networks; Forecasting; Grading; Learning systems; Predictive analytics; Quality control; Automated essay scoring; Competitive performance; Effective solution; Formative feedbacks; Important features; Performance reports; Student assessment; Study replications; Deep learning|Article|Final||Scopus|2-s2.0-85091086122
scopus|Borg M.; Jabangwe R.; Aberg S.; Ekblom A.; Hedlund L.; Lidfeldt A.|Borg, Markus (37103431600); Jabangwe, Ronald (54418751100); Aberg, Simon (57219551403); Ekblom, Arvid (57222421219); Hedlund, Ludwig (57219555517); Lidfeldt, August (57219550135)|37103431600; 54418751100; 57219551403; 57222421219; 57219555517; 57219550135|Test automation with grad-CAM Heatmaps - A future pipe segment in MLOps for Vision AI?|2021|Proceedings - 2021 IEEE 14th International Conference on Software Testing, Verification and Validation Workshops, ICSTW 2021|||9440142|175|181|6|20|10.1109/ICSTW52544.2021.00039|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108025865&doi=10.1109%2fICSTW52544.2021.00039&partnerID=40&md5=526a985b352c898535a40c1dc973c75c|Machine Learning (ML) is a fundamental part of modern perception systems. In the last decade, the performance of computer vision using trained deep neural networks has outperformed previous approaches based on careful feature engineering. However, the opaqueness of large ML models is a substantial impediment for critical applications such as in the automotive context. As a remedy, Gradient-weighted Class Activation Mapping (Grad-CAM) has been proposed to provide visual explanations of model internals. In this paper, we demonstrate how Grad-CAM heatmaps can be used to increase the explainability of an image recognition model trained for a pedestrian underpass. We argue how the heatmaps support compliance to the EU's seven key requirements for Trustworthy AI. Finally, we propose adding automated heatmap analysis as a pipe segment in an MLOps pipeline. We believe that such a building block can be used to automatically detect if a trained ML-model is activated based on invalid pixels in test images, suggesting biased models.  © 2021 IEEE.|Grad-CAM; Image recognition; Machine learning testing; Neural networks; Test automation|Deep neural networks; Image recognition; Verification; Activation mapping; Building blockes; Critical applications; Feature engineerings; Image-recognition model; Perception systems; Pipe segments; Test Automation; Software testing|Conference paper|Final|All Open Access; Green Open Access|Scopus|2-s2.0-85108025865
scopus|Zhang C.; Shi T.; Ai J.; Tian W.|Zhang, Congran (57427257900); Shi, Tao (57215415209); Ai, Jun (57214531958); Tian, Wei (57426578000)|57427257900; 57215415209; 57214531958; 57426578000|Construction of GUI Elements Recognition Model for AI Testing based on Deep Learning|2021|Proceedings - 2021 8th International Conference on Dependable Systems and Their Applications, DSA 2021||||508|515|7|5|10.1109/DSA52907.2021.00075|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123474767&doi=10.1109%2fDSA52907.2021.00075&partnerID=40&md5=78837bfcc6e79bf9dba9d93e1c059fd9|Nowadays, GUI testing ensures the quality of GUI software. GUI automated testing by recording coordinates and handles has the disadvantages of poor reusability and low portability, which reduces the quality of GUI software testing. Therefore, GUI testing needs a more efficient testing to meet the rapid development of GUI software. AI can make testing more efficient. But the precondition of GUI software testing is to identify the GUI elements. In this context, the present paper studies the intelligent recognition of GUI elements based on deep learning, develops uniform markup rules for GUI elements and creates datasets to train the GUI element recognition model. According to the selected object detection network, the GUI element recognition model is trained, and the results are analyzed and discussed. The results of this project not only provide technical support for GUI intelligent testing, but also provide research objects and data for intelligent system reliability. © 2021 IEEE.|deep learning; GUI test; object detection; YOLOv3|Computer software portability; Deep learning; Graphical user interfaces; Intelligent systems; Object detection; Reusability; Software testing; Automated testing; Deep learning; Element-based; GUI software; GUI test; GUI testing; Intelligent recognition; Recognition models; Software testings; YOLOv3; Object recognition|Conference paper|Final||Scopus|2-s2.0-85123474767
scopus|Lafi M.; Alrawashed T.; Hammad A.M.|Lafi, Mohammed (55364801600); Alrawashed, Thamer (57209073256); Hammad, Ahmad Munir (57209274250)|55364801600; 57209073256; 57209274250|Automated Test Cases Generation from Requirements Specification|2021|2021 International Conference on Information Technology, ICIT 2021 - Proceedings|||9491761|852|857|5|9|10.1109/ICIT52682.2021.9491761|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112195196&doi=10.1109%2fICIT52682.2021.9491761&partnerID=40&md5=807d3ac8e37cccd1bde8d08849a87c83|One of the most significant phases of software development is software testing, because of its value in identifying mistakes and gaps in the early stages of program development. In the past, software testing was done manually, and this is a tiring and inaccurate process that carries with it errors and gaps and requires time, effort, and money. At present, testers tend to perform the testing process automatically, to save time, effort, and money, and to obtain accurate results. However, there are few research works on the aspect of generating test cases from requirements specification especially generate test cases from use case description. An Approach to Generate Test Cases from Use Case description is proposed in this paper that consists of several processes. The input is the use case description of the use case diagram, which is being used as a basis for the approach. In the next step, each software summary of UML use cases is utilized to extract the necessary information for the development of the control flow graph and NLP table. A control flow graph and NLP table will be generated based on a specific algorithm after that generate test paths based on a specific algorithm. Then, the test cases will be generated from the test paths and NLP table. The proposed approach will enhance the process of generation of test cases and increase the accuracy and efficiency. © 2021 IEEE.|NLP; Software Testing; Test Case Generation; Use Case Description|Data flow analysis; Flow graphs; Graph algorithms; Graphic methods; Natural language processing systems; Software design; Specifications; Testing; Automated test; Case description; Control flow graphs; Program development; Requirements specifications; Testing process; UML use case; Use case diagram; Software testing|Conference paper|Final||Scopus|2-s2.0-85112195196
scopus||||1st FICR International Conference on Rising Threats in Expert Applications and Solutions, FICR-TEAS 2020|2021|Advances in Intelligent Systems and Computing|1187|||||799|0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092648261&partnerID=40&md5=b0474843c0f12a38c993cbef7d26bdd9|The proceedings contain 95 papers. The special focus in this conference is on Rising Threats in Expert Applications and Solutions. The topics include: A Novel User Authentication Protocol Using Biometric Data for IoT Networks; comparative Study of Different Machine Learning Techniques in the Diagnosis of Dementia; automated Voter System by Using Fingerprint and Offline Data Set with Texture Image Processing; A Hybrid Cluster and PCA-Based Framework for Heart Disease Prediction Using Logistic Regression; a Deep Learning Approach of Collaborative Filtering to Recommender System with Opinion Mining; Analytical Design of the DIS Architecture: The Hybrid Model; a Model for Effective Software Testing in Cloud Environment; heuristic Expert Evaluation of e-Learning Application; image Query-Based Tablet Identification System by Examining Various Text Recognition Classifiers; assessment of Needless Code in a Program; a Survey of Load Balanced Job Scheduling Schemes in Cloud Computing; analysis of Algorithms K-Means and Apriori for Data Mining; augmenting Cloud Service Discovery Using Ontology; Performance Analysis of AES, Blowfish and Rijndael: Cryptographic Algorithms for Audio; a Secured Cloud-Based Framework for Image Processing Using Ant Colony Optimization; Chili Plant Leaf Disease Detection Using SVM and KNN Classification; a Review on Image Segmentation; ensemble Feature Extraction-Based Detection of Abnormal Mass Present in Medical Images Using Machine Learning; classification of Image Steganography in Substitution Technique; query Caching Technique Over Cloud-Based MapReduce System: A Survey; challenges and Issues in the Existing Methodology for Dynamic Data Capturing of Ontology; contextual Information Retrieval Search Engine Challenges; a Review on American Sign Language Character Recognition.|||Conference review|Final||Scopus|2-s2.0-85092648261
scopus|Faivishevsky L.; Szeskin A.; Muppalla A.K.; Shwartz-Ziv R.; Ben Ari I.; Laperdon R.; Melloul B.; Hollander T.; Hope T.; Armon A.|Faivishevsky, Lev (26326832600); Szeskin, Adi (57195523999); Muppalla, Ashwin K. (57219587080); Shwartz-Ziv, Ravid (57214867326); Ben Ari, Itamar (57219752796); Laperdon, Ronen (57259170600); Melloul, Benjamin (57259069800); Hollander, Tahi (57259458800); Hope, Tom (57191274451); Armon, Amitai (7801309400)|26326832600; 57195523999; 57219587080; 57214867326; 57219752796; 57259170600; 57259069800; 57259458800; 57191274451; 7801309400|Automated Testing of Graphics Units by Deep-Learning Detection of Visual Anomalies|2021|Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining||||2811|2821|10|0|10.1145/3447548.3467116|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114936371&doi=10.1145%2f3447548.3467116&partnerID=40&md5=0b9a178acdffa078d85ded7727ebc0f7|We present a novel system for performing real-time detection of diverse visual corruptions in videos, for validating the quality of graphics units in our company. The system is used for several types of content, including movies and 3D graphics, with strict constraints on low false alert rates and real-time processing of millions of video frames per day. These constraints required novel solutions involving both hardware and software, including new supervised and weakly-supervised methods we developed. Our deployed system has enabled a 20X reduction of human effort and discovering new corruptions missed by humans and existing approaches. © 2021 ACM.|anomaly detection; computer vision; deep learning; graphics processors validation; multiple instance learning|Data mining; Automated testing; Deployed systems; Hardware and software; Real-time detection; Realtime processing; Strict constraint; Supervised methods; Visual anomalies; Deep learning|Conference paper|Final||Scopus|2-s2.0-85114936371
scopus|Nakajima S.|Nakajima, Shin (7403109456)|7403109456|Software Testing with Statistical Partial Oracles: - Application to Neural Networks Software -|2021|Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)|12723 LNCS|||175|192|17|0|10.1007/978-3-030-77474-5_12|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111119427&doi=10.1007%2f978-3-030-77474-5_12&partnerID=40&md5=bb3a49634b90da5d426f783a89327ba8|With the advent of Bigdata analytics or machine learning software, the characteristics of test target programs become more divergent than before. It brings about two issues on the test oracle problems, uncertainties of the testing conditions and unknown correctness criteria. This paper proposes a new testing framework, which is general enough to account for the existing statistical metamorphic testing and is further amenable to adapt itself to the machine learning software testing. The proposed approach is illustrated with an experiment of testing neural network programs. © 2021, Springer Nature Switzerland AG.||Application programs; Formal languages; Machine learning; Neural networks; Object oriented programming; Correctness criterion; Machine learning software; Metamorphic testing; Test oracles; Testing conditions; Testing framework; Software testing|Conference paper|Final||Scopus|2-s2.0-85111119427
scopus|Jöckel L.; Bauer T.; Kläs M.; Hauer M.P.; Groß J.|Jöckel, Lisa (57194788762); Bauer, Thomas (57197314231); Kläs, Michael (24476497200); Hauer, Marc P. (57196391950); Groß, Janek (57223886808)|57194788762; 57197314231; 24476497200; 57196391950; 57223886808|Towards a Common Testing Terminology for Software Engineering and Data Science Experts|2021|Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)|13126 LNCS|||281|289|8|1|10.1007/978-3-030-91452-3_19|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121593422&doi=10.1007%2f978-3-030-91452-3_19&partnerID=40&md5=e23a758cb30ab23a234653b115f5b409|Analytical quality assurance, especially testing, is an integral part of software-intensive system development. With the increased usage of Artificial Intelligence (AI) and Machine Learning (ML) as part of such systems, this becomes more difficult as well-understood software testing approaches cannot be applied directly to the AI-enabled parts of the system. The required adaptation of classical testing approaches and the development of new concepts for AI would benefit from a deeper understanding and exchange between AI and software engineering experts. We see the different terminologies used in the two communities as a major obstacle on this way. As we consider a mutual understanding of the testing terminology a key, this paper contributes a mapping between the most important concepts from classical software testing and AI testing. In the mapping, we highlight differences in the relevance and naming of the mapped concepts. © 2021, Springer Nature Switzerland AG.|Analytical quality assurance; Artificial intelligence testing; Concept mapping; Data-driven model; Definitions; Machine learning evaluation; Quality characteristics; Target application scope|Application programs; Computer software selection and evaluation; Machine learning; Mapping; Software testing; Terminology; Well testing; Analytical quality assurance; Artificial intelligence testing; Concepts mappings; Data-driven model; Definition; Machine learning evaluation; Quality characteristic; Software testings; Target application; Target application scope; Quality assurance|Conference paper|Final||Scopus|2-s2.0-85121593422
scopus|Li X.; Niu W.; Zhang X.; Zhang R.; Yu Z.; Li Z.|Li, Xinqiang (57223014010); Niu, Weina (56417209400); Zhang, Xiaosong (35270951600); Zhang, Runzi (57199728307); Yu, Zhenqi (57324999000); Li, Zimu (57610015200)|57223014010; 56417209400; 35270951600; 57199728307; 57324999000; 57610015200|Improving Performance of Log Anomaly Detection with Semantic and Time Features Based on BiLSTM-Attention|2021|Proceedings - 2021 2nd International Conference on Electronics, Communications and Information Technology, CECIT 2021||||661|666|5|8|10.1109/CECIT53797.2021.00121|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128645153&doi=10.1109%2fCECIT53797.2021.00121&partnerID=40&md5=7115ba549642e41381a1cb37b5492d88|In recent years, with the increase in the scale and complexity of system software, how to effectively capture, analyze and locate the abnormal behavior generated during system operation has increasingly become a recognized problem in the software testing field. Traditional white-box-based anomaly detection methods need to provide system source code and cannot effectively detect abnormal behaviors that occur when the program is running. Black-box-based anomaly detection methods rely on test cases and have low code coverage. Anomaly detection based on the logs generated during system operation can alleviate the abovementioned problems. However, the existing system log-based abnormality detection method mainly extracts log template characteristics, and cannot effectively determine the logical and temporal abnormalities related to the log. Therefore, in order to detect anomalies in the log sequence more comprehensively, this paper proposes an anomaly detection method based on BiLSTM. This method combines the semantic and temporal characteristics of the log for modeling. In terms of semantics, the Bert natural language processing model is used to extract the contextual semantic information of the logs; in terms of time, the log time interval characteristics are extracted based on the three potential relationships of the logs. In addition, the proposed method also adds an attention mechanism to balance feature weights. Finally, we evaluate our method in experiments on two real datasets, HDFS and OpenStack. The experimental results show that our method has a great improvement in accuracy and recall.  © 2021 IEEE.|Anomaly Detection; Attention Mechanism; Bert; Deep Learning|Anomaly detection; Deep learning; Natural language processing systems; Software testing; Abnormal behavior; Anomaly detection; Anomaly detection methods; Attention mechanisms; Bert; Deep learning; Improving performance; Semantic features; Systems operation; Time features; Semantics|Conference paper|Final||Scopus|2-s2.0-85128645153
scopus|Qi Y.; Wu H.|Qi, Yongjun (57223224063); Wu, Haiyan (57220004640)|57223224063; 57220004640|Research on the Difference Between the Internet of Things and the Traditional Internet Under Artificial Intelligence|2021|2021 International Wireless Communications and Mobile Computing, IWCMC 2021||||1510|1513|3|0|10.1109/IWCMC51323.2021.9498790|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125665174&doi=10.1109%2fIWCMC51323.2021.9498790&partnerID=40&md5=35f017a86a7fb2dafb19e624ffd8de53|"The Internet of Things is the most heated topic in the current electronic information technology industry. It is generally believed that it will become a new driving force for the development of human industry, and its comprehensive application will promote the human society to step forward to the ""smart earth"". In this paper, based on artificial intelligence and Internet of Things technology, experimental design of fuzzy control and PID control algorithm anti-interference performance test simulation box. Experimental data show that due to the Internet of Things control system in the process of application, the controlled object in different degrees of non-linear, large lag, parameter time-varying and model uncertainty characteristics. It can be seen from the principle and simulation results that fuzzy control does not require the precise model of the controlled object and has strong adaptability. The experimental results show that if the pulses with a height of 0.1, a period of 10s, a width of 2S and a delay of 4s are set, interference is added to the output of a sampling time controller. Among them, T1=2, T2=1, =0.5, then the initial PID Kp0=7.6, Ki0=1.12, Kd0=4.88 in the fuzzy PID control system. The Internet of Things control system server has the advantages of comprehensive functions, good expansibility, easy operation and maintenance, etc., and the adoption of automated testing technology improves the efficiency and standardization of the server design process. © 2021 IEEE"|Artificial intelligence; Fuzzy control algorithm; Internet of things|Fuzzy control; Process control; Testing; Three term control systems; Uncertainty analysis; 'current; Controlled objects; Driving forces; Electronic information; Fuzzy control algorithms; Human society; Information technology industry; Internet of things technologies; PID control algorithm; Smart earths; Internet of things|Conference paper|Final||Scopus|2-s2.0-85125665174
scopus|Krishna V.V.; Gopinath G.|Krishna, V. Vamsi (57223387407); Gopinath, G. (59351227100)|57223387407; 59351227100|Application by Using Tanh Activated Clustering and Classification Model (TACC) in Machine Learning|2021|Webology|18|Special Issue 5||1137|1157|20|0|10.14704/WEB/V18SI05/WEB18290|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122421978&doi=10.14704%2fWEB%2fV18SI05%2fWEB18290&partnerID=40&md5=4a19b5f21dc7d3b3cc1438ff461006fb|Automatic functional tests are a long-standing issue in software development projects, and they are still carried out manually. The Selenium testing framework has gained popularity as an active community and standard environment for automated assessment of web applications. As a result, the trend setting of web services is evolving on a daily basis, and there is a need to improve automatic testing. The study involves to make the system to understand the experiences of previous test cases and apply new cases to predict the status of test case using Tanh activated Clustering and Classification model (TACC). The primary goal is to improve the model’s clustering and classification output. The outcomes show that the TACC model has increased performance and demonstrated that automated testing results can be predicted, which is cost effective and reduces manual effort to a greater extent. © 2021|Agile Methodology; Cloud Environment; Machine Learning; Software Testing; Web Application||Article|Final|All Open Access; Gold Open Access|Scopus|2-s2.0-85122421978
scopus||||"ISIT 2021 - Short Paper Proceedings of the 2nd International Conference on Intellectual Systems and Information Technologies, co-located with 1st International Forum ""Digital Reality"", DRForum 2021"|2021|CEUR Workshop Proceedings|3126|||||376|0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128875412&partnerID=40&md5=aa34314869de105cb0f43caa9c2674dc|The proceedings contain 56 papers. The topics discussed include: actual aspects of information technologies application at the problem decision of the movement organization by a convoy of vehicles; capabilities of data mining as a cognitive tool: methodological aspects; implementation of Shor’s algorithm in a digital quantum coprocessor; behavioral properties of bounded solutions for a weakly nonlinear impulse system that describe the dissemination of information on social networks; cloud technologies and artificial intelligence as the basis of digital development of the financial sector of the economy of Ukraine; intelligent monitoring of software test automation of web sites; checking the flight stability of a rotary UAV in navigation modes for different firmware; and features of the implementation of methods for a comprehensive study of properties of thermoelectric materials.|||Conference review|Final||Scopus|2-s2.0-85128875412
scopus|Zhang S.; Li Y.; Yan W.; Guo Y.; Chen X.|Zhang, Shaokun (59448276600); Li, Yuanchun (57125143000); Yan, Weixiang (58653421200); Guo, Yao (55548454000); Chen, Xiangqun (8382494100)|59448276600; 57125143000; 58653421200; 55548454000; 8382494100|Dependency-aware Form Understanding|2021|Proceedings - International Symposium on Software Reliability Engineering, ISSRE|2021-October|||139|149|10|4|10.1109/ISSRE52982.2021.00026|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126392109&doi=10.1109%2fISSRE52982.2021.00026&partnerID=40&md5=4b0f5842ab44baaa7ff768f6705154b8|Form understanding is an important task in many fields such as software testing, AI assistants, and improving accessibility. One key goal of understanding a complex set of forms is to identify the dependencies between form elements. However, it remains a challenge to capture the dependencies accurately due to the diversity of UI design patterns and the variety in development experiences. In this paper, we propose a deep-learning-based approach called DependEX, which integrates convolutional neural networks (CNNs) and transformers to help understand dependencies within forms. DependEX extracts semantic features from UI images using CNN-based models, captures contextual patterns using a multilayer transformer encoder module, and models dependencies between form elements using two embedding layers. We evaluate DependEX with a large-scale dataset from mobile Web applications. Experimental results show that our proposed model achieves over 92% accuracy in identifying dependencies between UI elements, which significantly outperforms other competitive methods, especially for heuristic-based methods. We also conduct case studies on automatic form filling and test case generation from natural language (NL) instructions, which demonstrates the applicability of our approach.  © 2021 IEEE.|Automatic form filling; CNN; Deep learning; Dependencies; Form understanding|Convolutional neural networks; Deep learning; Heuristic methods; Large dataset; Semantics; Automatic form filling; Convolutional neural network; Deep learning; Dependency; Design Patterns; Development experiences; Form filling; Form understanding; Software testings; UI designs; Software testing|Conference paper|Final||Scopus|2-s2.0-85126392109
scopus||||Proceedings - 2021 21st International Conference on Software Quality, Reliability and Security Companion, QRS-C 2021|2021|Proceedings - 2021 21st International Conference on Software Quality, Reliability and Security Companion, QRS-C 2021||||||1205|0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140918228&partnerID=40&md5=16f36d5dc05fbaa30f1ff6ec97ef3a7f|The proceedings contain 171 papers. The topics discussed include: ADVRET: an adversarial robustness evaluating and testing platform for deep learning models; application-oriented serial interface communication protocols formal modeling method; automated functional testing of search engines using metamorphic testing; metamorphic testing for autonomous driving systems in fog based on quantitative measurement; metamorphic testing for traffic light recognition in autonomous driving systems; reports aggregation of crowdsourcing test based on feature fusion; semantic-based false alarm detection approach via machine learning; test case reuse based on software testing knowledge graph and collaborative filtering recommendation algorithm; the effect of combinatorial coverage for neurons on fault detection in deep neural networks; an ontology-based approach for automatic specification, verification, and validation of software security requirements: preliminary results; and quality assurance of micro-services - when to trust your micro-service test results?.|||Conference review|Final||Scopus|2-s2.0-85140918228
scopus|Shirzadehhajimahmood S.; Prasetya I.S.W.B.; Dignum F.; Dastani M.; Keller G.|Shirzadehhajimahmood, Samira (57220114778); Prasetya, I.S.W.B. (8980537400); Dignum, Frank (7003423512); Dastani, Mehdi (6603932250); Keller, Gabriele (7201829632)|57220114778; 8980537400; 7003423512; 6603932250; 7201829632|Using an agent-based approach for robust automated testing of computer games|2021|A-TEST 2021 - Proceedings of the 12th International Workshop on Automating TEST Case Design, Selection, and Evaluation, co-located with ESEC/FSE 2021||||1|8|7|11|10.1145/3472672.3473952|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113871036&doi=10.1145%2f3472672.3473952&partnerID=40&md5=c37f829a7b48d1f13d87ea43c98be3b5|Modern computer games typically have a huge interaction spaces and non-deterministic environments. Automation in testing can provide a vital boost in development and it further improves the overall software's reliability and efficiency. Moreover, layout and game logic may regularly change during development or consecutive releases which makes it difficult to test because the usage of the system continuously changes. To deal with the latter, tests also need to be robust. Unfortunately, existing game testing approaches are not capable of maintaining test robustness. To address these challenges, this paper presents an agent-based approach for robust automated testing based on the reasoning type of AI.  © 2021 ACM.|agent-based automated testing; automated testing of computer games; Robust automated testing|Automation; Computer games; Computer testing; Software reliability; Agent-based approach; Automated testing; Game testing; Software testing|Conference paper|Final|All Open Access; Green Open Access|Scopus|2-s2.0-85113871036
scopus|Cinquini M.; Giannotti F.; Guidotti R.|Cinquini, Martina (57640963300); Giannotti, Fosca (7004495132); Guidotti, Riccardo (56506805200)|57640963300; 7004495132; 56506805200|Boosting Synthetic Data Generation with Effective Nonlinear Causal Discovery|2021|Proceedings - 2021 IEEE 3rd International Conference on Cognitive Machine Intelligence, CogMI 2021||||54|63|9|8|10.1109/CogMI52975.2021.00016|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128804338&doi=10.1109%2fCogMI52975.2021.00016&partnerID=40&md5=19e35d59179dc479866bc755f4e8c6a2|Synthetic data generation has been widely adopted in software testing, data privacy, imbalanced learning, artificial intelligence explanation, etc. In all such contexts, it is important to generate plausible data samples. A common assumption of approaches widely used for data generation is the independence of the features. However, typically, the variables of a dataset de-pend on one another, and these dependencies are not considered in data generation leading to the creation of implausible records. The main problem is that dependencies among variables are typically unknown. In this paper, we design a synthetic dataset generator for tabular data that is able to discover nonlinear causalities among the variables and use them at generation time. State-of-the-art methods for nonlinear causal discovery are typically inefficient. We boost them by restricting the causal discovery among the features appearing in the frequent patterns efficiently retrieved by a pattern mining algorithm. To validate our proposal, we design a framework for generating synthetic datasets with known causalities. Wide experimentation on many synthetic datasets and real datasets with known causalities shows the effectiveness of the proposed method.  © 2021 IEEE.|Causal Discovery; Data Generation; Explainability; Pattern Mining; Synthetic Datasets|Data mining; Data privacy; Causal discovery; Data generation; Data sample; Explainability; Imbalanced Learning; Pattern mining; Software testings; Synthetic data generations; Synthetic datasets; Testing data; Software testing|Conference paper|Final|All Open Access; Green Open Access|Scopus|2-s2.0-85128804338
scopus|Broer Bahaweres R.; Oktaviani E.; Kesuma Wardhani L.; Hermadi I.; Suroso A.; Permana Solihin I.; Arkeman Y.|Broer Bahaweres, Rizal (55625202600); Oktaviani, Elda (57222290490); Kesuma Wardhani, Luh (56495533000); Hermadi, Irman (23967933100); Suroso, ArifImam (53864020700); Permana Solihin, Indra (57222292051); Arkeman, Yandra (55946558300)|55625202600; 57222290490; 56495533000; 23967933100; 53864020700; 57222292051; 55946558300|Behavior-driven development (BDD) Cucumber Katalon for Automation GUI testing case CURA and Swag Labs|2020|Proceedings - 2nd International Conference on Informatics, Multimedia, Cyber, and Information System, ICIMCIS 2020|||9354325|87|92|5|8|10.1109/ICIMCIS51567.2020.9354325|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102188415&doi=10.1109%2fICIMCIS51567.2020.9354325&partnerID=40&md5=fe3dd3a90be4b43b4bf0ace3d5ca6939|Graphical user interface (GUI) is widely used in software applications. About 50% of the application code is for GUI implementation. Because labor costs are high and demands for high-quality software are increasing, automation GUI testing will be a good investment for any software company. We will apply the Behavior-driven development (BDD) method for automation GUI testing with the Cucumber framework on the CURA and Swag Labs web applications. The BDD methodology used is based on the NLP (natural language program) concept. Where the information of semi-Automatically produce a step definition and code framework. The scenarios are given on the natural language and then applied to Software Testing. Class diagrams and sequence diagrams are also applied to each represent a code framework automatically. The author uses Katalon Studio software. It was found that the results of the test case automation GUI testing on the CURA website with 210 steps passed, 3 step warnings with average responses times in the test case were 1.92 minutes. The results of the test case automation GUI testing on the Swag Labs web with 87 where 36 steps failed, 4 step warning and 44 step passed with an average responses times in the test case are 2,122 minutes. © 2020 IEEE.|Behavior-driven Development; Cucumber; Empirical Software Engineering; GUI Testing; Software Testing Automation|Application programs; Automation; Boolean functions; Graphical user interfaces; Information systems; Information use; Wages; Application codes; Code frameworks; Graphical user interfaces (GUI); High-quality software; Natural languages; Sequence diagrams; Software applications; Software company; Software testing|Conference paper|Final||Scopus|2-s2.0-85102188415
scopus|Biringa C.; Kul G.|Biringa, Chidera (57223897472); Kul, Gokhan (56344509500)|57223897472; 56344509500|Automated User Experience Testing through Multi-Dimensional Performance Impact Analysis|2021|Proceedings - 2021 IEEE/ACM International Conference on Automation of Software Test, AST 2021|||9462978|125|128|3|3|10.1109/AST52587.2021.00024|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113740365&doi=10.1109%2fAST52587.2021.00024&partnerID=40&md5=e3b63cd9a9a50a31bccc0e6c6c8e24f7|Although there are many automated software testing suites, they usually focus on unit, system, and interface testing. However, especially software updates such as new security features have the potential to diminish user experience. In this paper, we propose a novel automated user experience testing methodology that learns how code changes impact the time unit and system tests take, and extrapolate user experience changes based on this information. Such a tool can be integrated into existing continuous integration pipelines, and it provides software teams immediate user experience feedback. We construct a feature set from lexical, layout, and syntactic characteristics of the code, and using Abstract Syntax Tree-Based Embeddings, we can calculate the approximate semantic distance to feed into a machine learning algorithm. In our experiments, we use several regression methods to estimate the time impact of software updates. Our open-source tool achieved a 3.7% mean absolute error rate with a random forest regressor. © 2021 IEEE.|continuous integration; security updates; software development; software testing; user experience|Automation; Decision trees; Learning algorithms; Machine learning; Open source software; Regression analysis; Semantics; Software testing; Syntactics; Turing machines; Abstract Syntax Trees; Automated software testing; Continuous integrations; Experience feedback; Interface testings; Mean absolute error; Performance impact; Testing methodology; User experience|Conference paper|Final|All Open Access; Green Open Access|Scopus|2-s2.0-85113740365
scopus||||AISTA 2021 - Proceedings of the 1st ACM International Workshop on AI and Software Testing/Analysis, co-located with ECOOP/ISSTA 2021|2021|AISTA 2021 - Proceedings of the 1st ACM International Workshop on AI and Software Testing/Analysis, co-located with ECOOP/ISSTA 2021||||||23|0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111760888&partnerID=40&md5=acc207f2081fad5039e87169dba40642|The proceedings contain 4 papers. The topics discussed include: on the use of evolutionary algorithms for test case prioritization in regression testing considering requirements dependencies; impact of programming languages on machine learning bugs; NerdBug: automated bug detection in neural networks; and automated cell header generator for Jupyter notebooks.|||Conference review|Final||Scopus|2-s2.0-85111760888
scopus|Kumar L.; Tummalapalli S.; Murthy L.B.|Kumar, Lov (56120791500); Tummalapalli, Sahithi (57190253628); Murthy, Lalita Bhanu (57192228561)|56120791500; 57190253628; 57192228561|An Empirical Framework to Investigate the Impact of Bug Fixing on Internal Quality Attributes|2021|Arabian Journal for Science and Engineering|46|4||3189|3211|22|5|10.1007/s13369-020-05095-0|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096440461&doi=10.1007%2fs13369-020-05095-0&partnerID=40&md5=96669714f410d82a03770af72bb10603|Software testing is the process of fixing bugs by changing the design of the software or simple logic of the software. Researchers have proposed many tools and methods using machine learning techniques to assist practitioners in decision making and automating software engineering tasks. These tools help to find the faulty classes at the starting phase of the software development life cycle. After finding faulty classes using these tools, testers used different techniques to find and fix these faults. The early identification of the faults or bugs fixing process helps to improves the quality of software and reduces the cost required to fix these faults or bugs. The primary objective of this work is to understand whether faults present in code elements are indicators of problems in the design of the software or not. This work investigates the impact of bug fixing operation on four popular internal quality attributes such as complexity, cohesion, inheritance, and coupling. The above investigation has been validated using thirteen different projects. Furthermore, we have also investigated the possibility of prediction models for predicting changes in internal quality attributes. These prediction models are trained using five different classifiers on balance data as well as original data and validated using fivefold cross-validation. The experimental results show that the predictive power of models using LSSVM with the polynomial kernel is better as compared to other techniques. The experimental results also show that the bugs are present in the class having at least one critical attribute in more than 80% of cases. Furthermore, the consistent value of AUC reveals that the prediction of changes in the internal quality attribute is possible using source code metrics. © 2020, King Fahd University of Petroleum & Minerals.|Classification techniques; Data sampling; Fault; Quality attribute; Source code metrics||Article|Final||Scopus|2-s2.0-85096440461
scopus|Zhao J.|Zhao, Jianjun (35786932000)|35786932000|Towards testing of deep learning systems|2021|CEUR Workshop Proceedings|2809|||33|||0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101205436&partnerID=40&md5=4f55a228a9c8b17110b5dcfe0bab4526|Deep learning has achieved great success in many application domains such as image processing, speech recognition, and autonomous vehicles. However, how to ensure the reliability of deep learning systems remains an open problem. In this keynote, I introduce several automated testing techniques to ensure the reliability of deep learning systems. Copyright © 2019 for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).|Deep learning; Software testing; System reliability|Engineering education; Image processing; Learning systems; Privacy by design; Software engineering; Speech recognition; Systems engineering; Testing; Automated testing; Deep learning|Conference paper|Final||Scopus|2-s2.0-85101205436
scopus|Gao K.; Wang J.; Wang B.; Wang R.; Jia J.|Gao, Kunyu (57426763500); Wang, Jinbo (37036653200); Wang, Bin (57215283138); Wang, Ruixue (57193127092); Jia, Jiao (57191433541)|57426763500; 37036653200; 57215283138; 57193127092; 57191433541|UAV Test Data Generation Method based on CycleGAN|2021|Proceedings - 2021 8th International Conference on Dependable Systems and Their Applications, DSA 2021||||338|343|5|2|10.1109/DSA52907.2021.00052|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123491155&doi=10.1109%2fDSA52907.2021.00052&partnerID=40&md5=1d768bcd168078bf3e0417dd18afe06c|Unmanned aerial vehicles (UAV) have developed rapidly in recent years. With the popularity of artificial intelligence, UAV has been closely related to the military, economic and life fields. However, there are still security concerns with intelligent software. If these hidden dangers appear in reality, they will cause economic losses and even endanger people's lives. Thus, intelligent software must be tested and verified before they can be put into service. To ensure the effectiveness of testing, we need to generate high-quality, large-scale and low-cost datasets. However, due to weather, technical conditions and other factors, the existing datasets are difficult to meet the demand. Accordingly, we propose a novel method to generate dataset for UAV software testing based on Cycle-Consistent Adversarial Networks (CycleGAN) in this paper. In addition, We conduct experiments and verification on the real dataset of Google Maps. The results show that even if the dataset is disturbed, the images we generate are still of high quality. © 2021 IEEE.|CycleGAN; Test data generation; UAV|Antennas; Large dataset; Losses; Software testing; Statistical tests; Cyclegan; Economic loss; Generation method; High quality; Intelligent software; Large-scales; Low-costs; Technical conditions; Test data generation; Vehicle tests; Unmanned aerial vehicles (UAV)|Conference paper|Final||Scopus|2-s2.0-85123491155
scopus|Singhal P.; Kundu S.; Gupta H.; Jain H.|Singhal, Priyank (36601564000); Kundu, Shakti (54420380700); Gupta, Harshita (57544334700); Jain, Harsh (58253992900)|36601564000; 54420380700; 57544334700; 58253992900|Application of Artificial Intelligence in Software Testing|2021|Proceedings of the 2021 10th International Conference on System Modeling and Advancement in Research Trends, SMART 2021||||489|492|3|2|10.1109/SMART52563.2021.9676244|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125176150&doi=10.1109%2fSMART52563.2021.9676244&partnerID=40&md5=d81e896e71a0d3f9c8f7eb9f16c7b70a|Many of the applications and services that we use daily are powered by Artificial Intelligence. The Artificial Intelligence plays important role in our lives now-a-days. With the passing of every minute huge amount of digital data is produced from different sources. This data must be carefully monitored and also requires to be manipulated along with the results and actions that are generated. The release of such products depends on the time parameter which becomes crucial due to more complex software programmes being developed. The product released must be carefully examined to serve all business requirements. Artificial Intelligence becomes important in software testing because one can get more accurate results in less time. The following paper will throw light on the important pillars of Artificial Intelligence with reference to its applications in Software Testing. The software testing results are much better produced by applications of Artificial Intelligence, as per the findings. Further testing driven by Artificial Intelligence will create better quality assurance in times to come. There will be reduction in time by using Artificial Intelligence based software testing thereby increasing efficiency of the organization to develop much more sophisticated software for the market. The approach of applying Artificial Intelligence in software testing will help to create smarter automated testing for complex software applications. © 2021 IEEE.|Artificial Intelligence; Natural Language Processing (NLP); Software Testing; Test Automation|Application programs; Artificial intelligence; Natural language processing systems; Quality assurance; % reductions; Business requirement; Complex software; Digital datas; ITS applications; Natural language processing; Software project; Software testings; Test Automation; Time parameter; Software testing|Conference paper|Final||Scopus|2-s2.0-85125176150
scopus|Ebadi H.; Moghadam M.H.; Borg M.; Gay G.; Fontes A.; Socha K.|Ebadi, Hamid (57274525600); Moghadam, Mahshid Helali (38561807800); Borg, Markus (37103431600); Gay, Gregory (25723089800); Fontes, Afonso (57220959909); Socha, Kasper (57275262800)|57274525600; 38561807800; 37103431600; 25723089800; 57220959909; 57275262800|Efficient and Effective Generation of Test Cases for Pedestrian Detection-Search-based Software Testing of Baidu Apollo in SVL|2021|Proceedings - 3rd IEEE International Conference on Artificial Intelligence Testing, AITest 2021||||103|110|7|25|10.1109/AITEST52744.2021.00030|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118804446&doi=10.1109%2fAITEST52744.2021.00030&partnerID=40&md5=5f94af29d0c96b99a57164c0907b95e2|With the growing capabilities of autonomous vehicles, there is a higher demand for sophisticated and pragmatic quality assurance approaches for machine learning-enabled systems in the automotive AI context. The use of simulation-based prototyping platforms provides the possibility for early-stage testing, enabling inexpensive testing and the ability to capture critical corner-case test scenarios. Simulation-based testing properly complements conventional on-road testing. However, due to the large space of test input parameters in these systems, the efficient generation of effective test scenarios leading to the unveiling of failures is a challenge. This paper presents a study on testing pedestrian detection and emergency braking system of the Baidu Apollo autonomous driving platform within the SVL simulator. We propose an evolutionary automated test generation technique that generates failure-revealing scenarios for Apollo in the SVL environment. Our approach models the input space using a generic and flexible data structure and benefits a multi-criteria safety-based heuristic for the objective function targeted for optimization. This paper presents the results of our proposed test generation technique in the 2021 IEEE Autonomous Driving AI Test Challenge. In order to demonstrate the efficiency and effectiveness of our approach, we also report the results from a baseline random generation technique. Our evaluation shows that the proposed evolutionary test case generator is more effective at generating failure-revealing test cases and provides higher diversity between the generated failures than the random baseline.  © 2021 IEEE.|Advanced Driver Assistance Systems; Automotive Simulators; Evolutionary Algorithm; Pedestrian Detection; Search-Based Test Generation|Ability testing; Advanced driver assistance systems; Automobile drivers; Pedestrian safety; Quality assurance; Simulation platform; Automotive simulator; Automotives; Autonomous driving; Generation techniques; Pedestrian detection; Search-based; Search-based test generation; Test case; Test generations; Test scenario; Autonomous vehicles|Conference paper|Final|All Open Access; Green Open Access|Scopus|2-s2.0-85118804446
scopus|Saeed S.; Abubakar M.M.; Karabatak M.|Saeed, Sabeer (57254371500); Abubakar, Mohammed Mansur (57254135600); Karabatak, Murat (16230752700)|57254371500; 57254135600; 16230752700|Software Engineering for Data Mining (ML-Enabled) Software Applications|2021|9th International Symposium on Digital Forensics and Security, ISDFS 2021|||||||1|10.1109/ISDFS52919.2021.9486319|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114672578&doi=10.1109%2fISDFS52919.2021.9486319&partnerID=40&md5=17d245ae957d6c196882134b13db750a|As the data increase keeps on getting more extensive due to technology evolvement from the rational database, online transaction, cloud computing, data warehouse to big data analytics. This changes influences organizations to advance from data mining support to machine learning-enabled software platform. Seemingly, the study summarised secondary data from non-grey and grey academic literature as the research field recently started getting attention. Consequently, the work identifies, analyzes, and synthesizes the challenges of ML-enabled software development, which differs from traditional software development. But, with the adoption of the SE technique to engineer ML-enabled software development, the study was able to identify advancement for ML-enabled software likes automation of mismatch detection, which occurs due to the nature of different perspectives of stakeholders involved. Another one is integrating ML and SE data end-to-end pipeline to allow Systematic test mechanism and test automation where necessary when ML is complex in format to enable standard SE test logs. Then, education, training, and cooperation between the stakeholders, especially SE and ML, to gain more experience, knowledge, put rifts aside to join hands, and work together to ascertain user requirements. Finally, the work reframed the traditional SE development process to engineer the ML software development process. Therefore, the study can benefit stakeholders in the ML and SE communities in handling ML development challenges and may benefits academicians in conduction future research on software engineering for artificial intelligence. © 2021 IEEE.|Artificial Intelligence (AI); Data Mining (DM); Deep Learning (DL); Machine Learning (ML); Software Engineering (SE)|Advanced Analytics; Application programs; Data Analytics; Data warehouses; Digital forensics; Electronic crime countermeasures; Machine learning; Software design; Academic literature; Development process; Online transaction; Research fields; Software applications; Software development process; Software platforms; User requirements; Data mining|Conference paper|Final||Scopus|2-s2.0-85114672578
scopus|Tsimpourlas F.; Rajan A.; Allamanis M.|Tsimpourlas, Foivos (57203224939); Rajan, Ajitha (16239550300); Allamanis, Miltiadis (39361040300)|57203224939; 16239550300; 39361040300|Supervised learning over test executions as a test oracle|2021|Proceedings of the ACM Symposium on Applied Computing||||1521|1531|10|8|10.1145/3412841.3442027|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104951112&doi=10.1145%2f3412841.3442027&partnerID=40&md5=3cc96b9a3312760d939595c741e94ea1|The challenge of automatically determining the correctness of test executions is referred to as the test oracle problem and is a key remaining issue for automated testing. The paper aims at solving the test oracle problem in a scalable and accurate way. To achieve this, we use supervised learning over test execution traces. We label a small fraction of the execution traces with their verdict of pass or fail. We use the labelled traces to train a neural network (NN) model to learn to distinguish runtime patterns for passing versus failing executions for a given program. We evaluate our approach using case studies from different application domains - 1. Module from Ethereum Blockchain, 2. Module from PyTorch deep learning framework, 3. Microsoft SEAL encryption library components and 4. Sed stream editor. We found the classification models for all subject programs resulted in high precision, recall and specificity, averaging to 89%, 88% and 92% respectively, while only training with an average 15% of the total traces. Our experiments show that the proposed NN model is promising as a test oracle and is able to learn runtime patterns to distinguish test executions for systems and tests from different application domains. © 2021 ACM.|execution trace; neural networks; software testing; test oracle|Cryptography; Deep learning; Supervised learning; Automated testing; Classification models; Execution trace; High-precision; Learning frameworks; Library components; Neural network model; Test execution; Testing|Conference paper|Final||Scopus|2-s2.0-85104951112
scopus||||EASEAI 2021 - Proceedings of the 3rd International Workshop on Education through Advanced Software Engineering and Artificial Intelligence, co-located with ESEC/FSE 2021|2021|EASEAI 2021 - Proceedings of the 3rd International Workshop on Education through Advanced Software Engineering and Artificial Intelligence, co-located with ESEC/FSE 2021||||||64|0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116188520&partnerID=40&md5=778fcbdd5dd7da13bc4456a8c98be03f|The proceedings contain 10 papers. The topics discussed include: the good, the bad, and the ugly: mining for patterns in student source code; experience report on soft and project skills building through repetition; experience report on teaching testing through gamification; a tool for evaluating computer programs from students; seeding digital competencies from early childhood: a competence based approach; agile principles applied in learning contexts; students perception on the impact of their involvement in the learning process: an empirical study; practice makes better: quiz retake software to increase student learning; towards authentic undergraduate research experiences in software engineering and machine learning; and analysis of the transition to a virtual learning semester in a college software testing course.|||Conference review|Final||Scopus|2-s2.0-85116188520
scopus|Gao J.; Patil P.H.; Lu S.; Cao D.; Tao C.|Gao, Jerry (7404475003); Patil, Pankaj Hanmant (57315241700); Lu, Shengqiang (57149174600); Cao, Dongyu (57246808200); Tao, Chuanai (36086787600)|7404475003; 57315241700; 57149174600; 57246808200; 36086787600|Model-Based Test Modeling and Automation Tool for Intelligent Mobile Apps|2021|Proceedings - 15th IEEE International Conference on Service-Oriented System Engineering, SOSE 2021||||1|10|9|3|10.1109/SOSE52839.2021.00028|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118097976&doi=10.1109%2fSOSE52839.2021.00028&partnerID=40&md5=0c01fc6b4af82cce72bdaf60b958b849|Functionalities of AI-powered mobile Apps or systems heavily depend on the given training dataset. The challenge in this case is that a learning system will change its behavior due to a slight change of dataset. While current alternative approaches for evaluating these apps either focus on individual performance measurement such as accuracy etc. Inspired by principles of the decision tree test method in software engineering, we introduce a 3D decision tree testing model for AI testing, a combined AI feature input tree, context tree, and output tree methodology for testing AI-powered applications. We report a newly developed AI test automation tool (known as AITest), which is built and implemented based on an innovative 3D AI Test model for AI-powered functions in intelligent mobile apps to support model-based AI function testing, test data generation, and auto test scripting and execution, and adequate test coverage analysis. Furthermore, the tool infrastructure, components, sample applications, and case study results are presented.  © 2021 IEEE.|AI test automation; AI testing; AI testing and analysis; intelligent system testing|Application programs; Automation; Decision trees; Intelligent systems; Learning systems; Model checking; Software testing; Three dimensional computer graphics; AI test automation; AI testing; AI testing and analyse; Intelligent system testing; Mobile app; Model-based test; Modelling tools; System testing; Test Automation; Test models; Testing|Conference paper|Final||Scopus|2-s2.0-85118097976
scopus|Yadav V.; Botchway R.K.; Senkerik R.; Kominkova Z.O.|Yadav, Vinod (57303202200); Botchway, Raphael Kwaku (57213065239); Senkerik, Roman (23975048900); Kominkova, Zuzana Oplatkova (57550806800)|57303202200; 57213065239; 23975048900; 57550806800|Robot Testing from a machine learning perspective|2021|International Conference on Electrical, Computer, and Energy Technologies, ICECET 2021|||||||2|10.1109/ICECET52533.2021.9698727|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127759498&doi=10.1109%2fICECET52533.2021.9698727&partnerID=40&md5=9ee626c2d2d0e7ba467a4e10525dcd3d|The need to scale software test automation while managing the test automation process within a reasonable time frame remains a crucial challenge for software development teams (DevOps). Unlike hardware, the software cannot wear out but can fail to satisfy the functional requirements it is supposed to meet due to the defects observed during system operation. In this era of big data, DevOps teams can deliver better and efficient code by utilizing machine learning (ML) to scan their new codes and identify test coverage gaps. This study introduces robot testing and machine learning to manage the test automation process to guarantee software reliability and quality within a reasonable timeframe. © 2021 IEEE.|automation; big data; machine learning; robotic testing; test automation|Automation; Machine learning; Software design; Software reliability; Software testing; Automation process; Data development; Development teams; Functional requirement; Robotic testing; Software development teams; Software test automation; Systems operation; Test Automation; Time frame; Big data|Conference paper|Final||Scopus|2-s2.0-85127759498
scopus||||3rd EAI International Conference on Multimedia Technology and Enhanced Learning, ICMTEL 2021|2021|Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering, LNICST|387|||||1084|0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113393374&partnerID=40&md5=4ae1f5df75f52f96227ea21ea55a6f35|The proceedings contain 97 papers. The special focus in this conference is on Multimedia Technology and Enhanced Learning. The topics include: Research on the Method of Eliminating Duplicated Encrypted Data in Cloud Storage Based on Generated Countermeasure Network; design of Distributed Hybrid Pipeline Multimedia Aided Scheduling System; intelligent Scheduling of Distributed Displacement Pipeline Based on Hybrid Discrete Drosophila Optimization Algorithm; research on Grid Planning Method of Distribution Network Based on Artificial Intelligence Technology; intelligent Monitoring Method for Backstage Data Security of Tourism Information Promotion Platform Based on Cloud Computing; preface; research on Multithreaded Data Scheduling Control Method for Power Communication Based on Wireless Sensor; research on Industrial Product Modeling Design Method Based on Deep Learning; a Frequency Conversion Circuit for Piezoelectric Vibrating Energy Harvesting; an Adaptive Optimization Strict Reverse Navigation Algorithm for Ship Fine Alignment Process; research on Load Feature Extraction Method of Typical Users Based on Deep Learning; enterprise Financial Risk Early Warning System Based on Catastrophe Progression Method; research on Transportation Route Planning Method of Regional Logistics Network Based on Transfer Learning; simultaneous Localization of Multiple Defects in Software Testing Based on Reinforcement Learning; Design of Embedded Network Human Machine Interface Based on VR Technology; Design of Information Security System Based on JSP Technology and Reinforcement Model; sliding Mode Adaptive Control for Sensorless Permanent Magnet Synchronous Motor; recognition Method of Metal Material Pitting Defect Based on Visual Signal Processing; an Improved Detection Method of Safety Helmet Wearing Based on CenterNet; influence Maximization Based on True Threshold in Social Networks; arabic Question-Answering System Using Search Engine Techniques.|||Conference review|Final||Scopus|2-s2.0-85113393374
scopus|Liu E.; Huang S.; Zong C.; Zheng C.; Yao Y.; Zhu J.; Tang S.; Wang Y.|Liu, Erhu (57203356186); Huang, Song (55608828500); Zong, Cheng (57212610408); Zheng, Changyou (36652245300); Yao, Yongming (57197745146); Zhu, Jing (57226007986); Tang, Shiqi (57190581798); Wang, Yanqiu (57224015149)|57203356186; 55608828500; 57212610408; 36652245300; 57197745146; 57226007986; 57190581798; 57224015149|MTGAN: Extending test case set for deep learning image classifier|2021|IEICE Transactions on Information and Systems|E104.D|5||709|722|13|1|10.1587/transinf.2020EDP7162|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106689171&doi=10.1587%2ftransinf.2020EDP7162&partnerID=40&md5=34c245f0bf4afcc8281bfc22847f1580|SUMMARY During the recent several years, deep learning has achieved excellent results in image recognition, voice processing, and other research areas, which has set off a new upsurge of research and application. Internal defects and external malicious attacks may threaten the safe and reliable operation of a deep learning system and even cause unbearable consequences. The technology of testing deep learning systems is still in its infancy. Traditional software testing technology is not applicable to test deep learning systems. In addition, the characteristics of deep learning such as complex application scenarios, the high dimensionality of input data, and poor interpretability of operation logic bring new challenges to the testing work. This paper focuses on the problem of test case generation and points out that adversarial examples can be used as test cases. Then the paper proposes MTGAN which is a framework to generate test cases for deep learning image classifiers based on Generative Adversarial Network. Finally, this paper evaluates the effectiveness of MTGAN. Copyright © 2021 The Institute of Electronics, Information and Communication Engineers|Adversarial example; Deep learning; GAN; Test case|Image classification; Image recognition; Learning systems; Software testing; Testing; Adversarial networks; Complex applications; High dimensionality; Image Classifiers; Reliable operation; Research and application; Test case generation; Testing technology; Deep learning|Article|Final|All Open Access; Gold Open Access|Scopus|2-s2.0-85106689171
scopus|Jha N.; Popli R.|Jha, Nisha (57262154100); Popli, Rashmi (55783421000)|57262154100; 55783421000|Artificial intelligence for software testing-perspectives and practices|2021|Proceedings - 2021 4th International Conference on Computational Intelligence and Communication Technologies, CCICT 2021||||377|382|5|6|10.1109/CCICT53244.2021.00075|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115070018&doi=10.1109%2fCCICT53244.2021.00075&partnerID=40&md5=8d6e8ebacc316dcb42817f27f96fefae|Artificial Intelligence (AI) has emerged as a buzzword for current software applications. The modern advancements in the Information Technology sector have invigorated the need to incorporate AI competencies into software services. This objective has constrained the organizations to revisit their software development processes. Software testing plays a vital role in validating the software quality. Both the AI and software testing researchers and Practitioners must lead the innovations to address their integrating challenges. AI and Machine Learning (ML) have the potential to advance the capabilities to test the software intensely. The objective of the paper is to review the state-of-the-art of applying AI in software testing briefly. It also discusses the software testing activities mapped to AI and the related challenges.  © 2021 IEEE.|Artificial Intelligence; Machine Learning; Software Testing; Test Automation|Application programs; Computer software selection and evaluation; Integration testing; Intelligent computing; Service industry; Software quality; Information technology sector; Modern advancement; Software applications; Software development process; Software services; State of the art; Software design|Conference paper|Final||Scopus|2-s2.0-85115070018
scopus|Phuong Tran C.T.; Valmiki M.G.; Xu G.; Gao J.Z.|Phuong Tran, Chi Thi (57222573405); Valmiki, Mohana Gudur (57222578838); Xu, Guoyan (56298472500); Gao, Jerry Zeyu (7404475003)|57222573405; 57222578838; 56298472500; 7404475003|An intelligent mobile application testing experience report|2021|Journal of Physics: Conference Series|1828|1|12080||||0|10.1088/1742-6596/1828/1/012080|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103274768&doi=10.1088%2f1742-6596%2f1828%2f1%2f012080&partnerID=40&md5=5602b124805a9b31458f1a4b89a83133|Artificial intelligence applications provide tremendous opportunities to improve human life and drive innovation. AI systems/applications which operate in a real-world environment have to encounter an infinite set of feasible scenarios. Conventional testing approach to test the AI application allows only limited testing and does not allow taking the different contexts into consideration and may lead to insufficient validation and characterization. Therefore, to ensure robustness, certainty and reliability of AI applications, the authors applied classification-based AI software testing framework and 3D decision tables to generate test cases. Moreover, the authors compared the quality assurance metrics (accuracy, correctness, reliability and consistency) of AI and non-AI functions in the AI mobile application scenario. Our results indicate and confirm that complete AI function validation is not possible with conventional testing methods, but AI software testing strategy proposed based on classification framework and 3D decision tables has a good effect. © 2021 Institute of Physics Publishing. All rights reserved.||Application programs; Decision tables; Mobile computing; Software reliability; Software testing; Testing; Classification framework; Conventional testing; Experience report; Mobile application testing; Mobile applications; Real world environments; Software testing strategies; Testing framework; Artificial intelligence|Conference paper|Final|All Open Access; Gold Open Access|Scopus|2-s2.0-85103274768
scopus|Xu J.; Wang F.; Ai J.|Xu, Jiaxi (57216952150); Wang, Fei (58599100300); Ai, Jun (57214531958)|57216952150; 58599100300; 57214531958|Defect Prediction with Semantics and Context Features of Codes Based on Graph Representation Learning|2021|IEEE Transactions on Reliability|70|2|9290043|613|625|12|69|10.1109/TR.2020.3040191|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097938676&doi=10.1109%2fTR.2020.3040191&partnerID=40&md5=b22c0b47a913ba7342b5bd46c1e6261a|To optimize the process of software testing and to improve software quality and reliability, many attempts have been made to develop more effective methods for predicting software defects. Previous work on defect prediction has used machine learning and artificial software metrics. Unfortunately, artificial metrics are unable to represent the features of syntactic, semantic, and context information of defective modules. In this article, therefore, we propose a practical approach for identifying software defect patterns via the combination of semantics and context information using abstract syntax tree representation learning. Graph neural networks are also leveraged to capture the latent defect information of defective subtrees, which are pruned based on a fix-inducing change. To validate the proposed approach for predicting defects, we define mining rules based on the GitHub workflow and collect 6052 defects from 307 projects. The experiments indicate that the proposed approach performs better than the state-of-the-art approach and five traditional machine learning baselines. An ablation study shows that the information about code concepts leads to a significant increase in accuracy.  © 1963-2012 IEEE.|Deep learning; defect prediction; graph representation learning; software defect dataset; software engineering|Computer software selection and evaluation; Forecasting; Graph structures; Machine learning; Semantics; Software quality; Software reliability; Software testing; Syntactics; Trees (mathematics); Abstract Syntax Trees; Context features; Context information; Defect prediction; Graph neural networks; Graph representation; Software metrics; State-of-the-art approach; Defects|Article|Final|All Open Access; Bronze Open Access|Scopus|2-s2.0-85097938676
scopus|Khatibsyarbini M.; Isa M.A.; Jawawi D.N.A.; Shafie M.L.M.; Wan-Kadir W.M.N.; Hamed H.N.A.; Suffian M.D.M.|Khatibsyarbini, Muhammad (57105628900); Isa, Mohd Adham (43061242400); Jawawi, Dayang N. A. (15058008600); Shafie, Muhammad Luqman Mohd (57203284112); Wan-Kadir, Wan Mohd Nasir (57402894000); Hamed, Haza Nuzly Abdull (24724160300); Suffian, Muhammad Dhiauddin Mohamed (59337923500)|57105628900; 43061242400; 15058008600; 57203284112; 57402894000; 24724160300; 59337923500|Trend Application of Machine Learning in Test Case Prioritization: A Review on Techniques|2021|IEEE Access|9|||166262|166282|20|13|10.1109/ACCESS.2021.3135508|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121830569&doi=10.1109%2fACCESS.2021.3135508&partnerID=40&md5=60835d1547bb0261a6d092b1e35c36c4|Software quality can be assured by passing the process of software testing. However, software testing process involve many phases which lead to more resources and time consumption. To reduce these downsides, one of the approaches is to adopt test case prioritization (TCP) where numerous works has indicated that TCP do improve the overall software testing performance. TCP does have several kinds of techniques which have their own strengths and weaknesses. As for this review paper, the main objective of this paper is to examine deeper on machine learning (ML) techniques based on research questions created. The research method for this paper was designed in parallel with the research questions. Consequently, 110 primary studies were selected where, 58 were journal articles, 50 were conference papers and 2 considered as others articles. For overall result, it can be said that ML techniques in TCP has trending in recent years yet some improvements are certainly welcomed. There are multiple ML techniques available, in which each technique has specified potential values, advantages, and limitation. It is notable that ML techniques has been considerably discussed in TCP approach for software testing.  © 2013 IEEE.|Machine learning; Software engineering; Software testing; Systematic literature review; Test case prioritization|Application programs; Artificial intelligence; Computer software selection and evaluation; Learning systems; Market Research; Transmission control protocol; License; Machine learning techniques; Machine-learning; Market researches; Software; Software testings; Systematic; Systematic literature review; Test case prioritization; Software testing|Article|Final|All Open Access; Gold Open Access|Scopus|2-s2.0-85121830569
scopus|Gupta A.; Mahapatra R.P.|Gupta, Atulya (57223033274); Mahapatra, Rajendra Prasad (36710370600)|57223033274; 36710370600|A Circumstantial Methodological Analysis of Recent Studies on NLP-driven Test Automation Approaches|2021|Lecture Notes in Networks and Systems|185 LNNS|||155|167|12|3|10.1007/978-981-33-6081-5_14|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105916002&doi=10.1007%2f978-981-33-6081-5_14&partnerID=40&md5=155a12343a31bf966641a225719a20f9|From manual testing to test automation, test generation is advancing. With the emergence of new challenges—and legacy challenges already persisting—there is a great need of turning test creation activity into a way that is more responsive and effortless. Natural language processing, with its applicability in different domains, is swiftly adopted by researchers in software testing discipline to perform automation of such activities. Attempts like this will bring in prominent paradigm shifts in the conventional and mundane non-automated frameworks of test cases creation (software development activity) from requirement specifications. To explore, as how natural language processing could be employed to assist software testing, this paper presents a detailed article with methodological investigation of some recent research studies. The detailed knowledge will help the practitioners to get insights of how natural language processing (NLP) is being carried out in testing domain and what specific role does each term associated with it will play. © 2021, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.|Natural language processing; NLP; Test automation; Test case generation; Test cases||Conference paper|Final||Scopus|2-s2.0-85105916002
scopus|Talakh M.; Holub S.; Lazarenko Y.|Talakh, Maria (57211567133); Holub, Serhii (57216031565); Lazarenko, Yurii (57644204100)|57211567133; 57216031565; 57644204100|Intelligent Monitoring of Software Test Automation of Web Sites|2021|CEUR Workshop Proceedings|3126|||40|45|5|0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128918926&partnerID=40&md5=f988a141dc48043908b79d2baa2b2c46|The active use of test automation approaches in software development causes further automation of this process, in particular, in the field of results analysis. This paper presents the results of applying the methodology for creating information technologies of multi-level intelligent monitoring to provide data for decision-making processes by a testing engineer. Methods of text mining and machine learning are combined to build a methodology for creating intelligent multi-level monitoring systems. On the example of a set of reports, which were divided by an expert into 4 classes, the processes of coordination of interactions of different types of methods for forming an array of informative features, typical aggregates for the synthesis of classifier models at each stage of monitoring were investigated. The task of classifying the results of text research was solved to obtain the reason for the failure of the tests. A set of n-grams for each class of tests formed an array of input data for the synthesizer of models of the monitoring information system. The classification of these data was provided using an ensemble of models, where the resulting value was obtained combining predictions by meta-learning using stacking. The effectiveness of the described methodology has been experimentally proven. © 2021 Copyright for this paper by its authors|ensemble training; Intellectual monitoring; test automation|Automation; Coordination reactions; Decision making; Learning systems; Personnel training; Software design; Software testing; Websites; Decision-making process; Ensemble training; Intellectual monitoring; Intelligent monitoring; Multilevels; Result analysis; Software test automation; Test Automation; Testing engineers; Web-sites; Monitoring|Conference paper|Final||Scopus|2-s2.0-85128918926
scopus|Nasrabadi M.Z.; Parsa S.|Nasrabadi, Morteza Zakeri (57219747851); Parsa, Saeed (8407441400)|57219747851; 8407441400|Learning to Predict Software Testability|2021|26th International Computer Conference, Computer Society of Iran, CSICC 2021|||9420548||||8|10.1109/CSICC52343.2021.9420548|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106182864&doi=10.1109%2fCSICC52343.2021.9420548&partnerID=40&md5=883c9b45ada5bc7430faa784b9feeaff|Software testability is the propensity of code to reveal its existing faults, particularly during automated testing. Testing success depends on the testability of the program under test. On the other hand, testing success relies on the coverage of the test data provided by a given test data generation algorithm. However, little empirical evidence has been shown to clarify whether and how software testability affects test coverage. In this article, we propose a method to shed light on this subject. Our proposed framework uses the coverage of Software Under Test (SUT), provided by different automatically generated test suites, to build machine learning models, determining the testability of programs based on many source code metrics. The resultant models can predict the code coverage provided by a given test data generation algorithm before running the algorithm, reducing the cost of additional testing. The predicted coverage is used as a concrete proxy to quantify source code testability. Experiments show an acceptable accuracy of 81.94% in measuring and predicting software testability.  © 2021 IEEE.|machine learning; software analytics; software metrics; software testability; Software testing|Automatic test pattern generation; Forecasting; Automated testing; Automatically generated; Code coverage; Machine learning models; Software testability; Source code metrics; Test coverage; Test data generation; Software testing|Conference paper|Final||Scopus|2-s2.0-85106182864
scopus|Atkinson T.; Silaghi M.C.|Atkinson, Timothy (57219495806); Silaghi, Marius C. (6602908095)|57219495806; 6602908095|Bayesian Networks for software testing|2021|Proceedings of the International Florida Artificial Intelligence Research Society Conference, FLAIRS|34||||||0|10.32473/flairs.v34i1.128513|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131124252&doi=10.32473%2fflairs.v34i1.128513&partnerID=40&md5=45e4e9378fd38f146b40e536ea1ad2f0|A software design methodology is proposed that involves development of approximate models based on Bayesian Networks capturing probabilistic representations of expected behavior, which are further used in developing and running tests that can dynamically diagnose bugs and attacks during production. While automation of Software design is still a very remote goal, it can already benefit from AI tools and ideas. One of the main challenges with automating software design methods, for any product with modest complexity, is the mere intractability of enumerating all scenarios of the product usage when also taking into account user intentions. This leads to an intractability of generating exact specifications and exhaustive tests. We show how approximate models of the design can exploit AI techniques to represent the system and to derive meaningful tests, warning when the environment is not behaving as designed, detecting bugs and attacks. The representation can use Bayesian Networks that are rather simple, enabling usage by novice practitioners. We validate the methodologies with on two different applications: a device driver for Wi-Fi Direct, and a website, MindBlog.com. In the Wi-Fi Direct use case, we successfully built a test ensuring the connection is fair and contrasted it experimentally to earlier work where we created a robust Bayes network based on expert knowledge. In the MindBlog.com use case, we show that the procedure is flexible and can detect when the developers found a bug and were attempting to debug their application yielding anomalous behavior. © 2021, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.||Artificial intelligence; Product design; Program debugging; Software design; Software testing; Statistical tests; Wi-Fi; Wireless local area networks (WLAN); Approximate modeling; Bayesia n networks; Design method; Model-based OPC; Network capturing; Probabilistic representation; Running tests; Software design methodologies; Software testings; User's intentions; Bayesian networks|Conference paper|Final|All Open Access; Gold Open Access|Scopus|2-s2.0-85131124252
scopus|Akinpelu D.; Schoegl I.|Akinpelu, David (57229920300); Schoegl, Ingmar (21234430500)|57229920300; 21234430500|Towards a high-pressure microchannel reactor for fuel characterization|2021|American Society of Mechanical Engineers, Power Division (Publication) POWER|2021-July||||||1|10.1115/POWER2021-64910|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113367530&doi=10.1115%2fPOWER2021-64910&partnerID=40&md5=61c28c3b1c4b7076d945c610068db24f|Within the area of combustion, externally heated microtubes have been introduced to study the combustion characteristics of fuels and fuel blends. Microreactors have advantages over other conventional fuel testing methods because of their potential to test small volumes (20 ml) at high throughput. In this work, a high-pressure microreactor is designed and implemented to test fuels up to a pressure of 20 bar where automated testing reduces test time substantially. The novelty of this device is its capability to operate at pressure exceeding the current state of the art of 12 bar. The combustion behavior of fuels is tested in an externally heated quartz tube, with a diameter less than the conventional quenching diameter of the fuel. The ultimate objective of the experiment is to investigate the impact of fuel on flame characteristics. The ability to reach engine relevant pressure conditions and its inherent small volume requirements make this device a potential candidate for measurements of laboratory transportation fuels and fuel blends. For initial validation, tests from an earlier intermediate pressure experiment with ethane/air and nitrogen mixtures are repeated. Chemiluminescence images are taken to evaluate the combustion characteristics in terms of the three classical flame regimes: weak flames, Flames with Repetitive Extinction, and Ignition (FREI) and normal flames. Previous results at intermediate pressure showed that as the pressure increases, the weak flame and FREI regimes shift towards lower velocities. Also, as dilution level increase (i.e. reducing oxygen concentration), the transition from the weak flame to FREI becomes less abrupt and is completely lost for marginal oxygen concentration. The objective of this study is to document flame dynamics at higher pressures. © 2021 American Society of Mechanical Engineers (ASME). All rights reserved.||Chemical reactors; Chemiluminescence; Ignition; Oxygen; Testing; Combustion characteristics; Conventional quenching; Flame characteristics; Fuel characterization; Intermediate pressures; Micro channel reactors; Oxygen concentrations; Transportation fuels; Fuels|Conference paper|Final||Scopus|2-s2.0-85113367530
scopus||||47th International Conference on Current Trends in Theory and Practice of Computer Science, SOFSEM 2021|2021|Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)|12607 LNCS|||||622|0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101560255&partnerID=40&md5=7d5234f4d6f1482e228335adb7dcc514|The proceedings contain 44 papers. The special focus in this conference is on Current Trends in Theory and Practice of Computer Science. The topics include: Concatenation Operations and Restricted Variants of Two-Dimensional Automata; distance Hedonic Games; distributed Independent Sets in Interval and Segment Intersection Graphs; hierarchical b-Matching; improved Algorithms for Online Load Balancing; iterated Uniform Finite-State Transducers on Unary Languages; new Bounds on the Half-Duplex Communication Complexity; novel Results on the Number of Runs of the Burrows-Wheeler-Transform; on the Redundancy of D-Ary Fano Codes; towards Knowledge Exchange: State-of-the-Art and Open Problems; on the Terminal Connection Problem; parameterized Complexity of d-Hitting Set with Quotas; parameterizing Role Coloring on Forests; the Balanced Satisfactory Partition Problem; the Multiple Traveling Salesman Problem on Spiders; tightness of Sensitivity and Proximity Bounds for Integer Linear Programs; using the Metro-Map Metaphor for Drawing Hypergraphs; weighted Microscopic Image Reconstruction; A Normal Sequence Compressed by PPM ∗ But Not by Lempel-Ziv 78; clusters of Repetition Roots: Single Chains; invited Talk: Resilient Distributed Algorithms; drawing Two Posets; fair Division Is Hard Even for Amicable Agents; the Complexity of Flow Expansion and Electrical Flow Expansion; an Infrastructure for Platform-Independent Experimentation of Software Changes; using Process Models to Understand Security Standards; web Test Automation: Insights from the Grey Literature; a Pipeline for Measuring Brand Loyalty Through Social Media Mining; predicting Tennis Match Outcomes with Network Analysis and Machine Learning; role-Based Access Control on Graph Databases; Semi-automatic Column Type Inference for CSV Table Understanding; towards Minimally Conscious Cyber-Physical Systems: A Manifesto.|||Conference review|Final||Scopus|2-s2.0-85101560255
scopus||||5th International Conference on Software Testing, Machine Learning and Complex Process Analysis, TMPA 2019|2021|Communications in Computer and Information Science|1288 CCIS|||||208|0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104702213&partnerID=40&md5=e592ab64a0f6da9c31231f0031ee4598|The proceedings contain 17 papers. The special focus in this conference is on Software Testing, Machine Learning and Complex Process Analysis. The topics include: The Influence of Self-organizing Teams on the Structure of the Social Graph; making Bounded Model Checking Interprocedural in (Static Analysis) Style; static Taint Analysis for JavaScript Programs; generation of Testing Metrics by Using Cluster Analysis of Bug Reports; building an Adaptive Logs Classification System: Industrial Report; Development of the Test Suite with Formally Verified FSM Coverage: A Case Study; generation of Test-Based Traces for Automated Partial Software Specifications Extraction; chaotic Time Series Prediction: Run for the Horizon; machine Learning and Value Generation in Software Development: A Survey; the Conception of Strings Similarity in Software Engineering; Multi-perspective Process Mining with Embedding Configurations into DB-Based Event Logs; On DB-Nets and Their Applications; pre-processing Network Messages of Trading Systems into Event Logs for Process Mining; time Series Classification Based on Visualization of Recurrence Plots; relation Between Test Coverage and Timed Automata Model Structure.|||Conference review|Final||Scopus|2-s2.0-85104702213
scopus|Mazhari A.A.; Ticknor R.; Swei S.; Krzesniak S.; Teodorescu M.|Mazhari, Arash Alex (57194243496); Ticknor, Randall (57218836332); Swei, Sean (55900680300); Krzesniak, Stanley (57226536229); Teodorescu, Mircea (8972556100)|57194243496; 57218836332; 55900680300; 57226536229; 8972556100|Automated Testing and Characterization of Additive Manufacturing (ATCAM)|2021|Journal of Materials Engineering and Performance|30|9||6862|6873|11|3|10.1007/s11665-021-06042-2|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111871683&doi=10.1007%2fs11665-021-06042-2&partnerID=40&md5=95e259b23b7391a3c9ad05ea40e7ebd1|The sensitivity of additive manufacturing (AM) to the variability of feedstock quality, machine calibration, and accuracy drives the need for frequent characterization of fabricated objects for a robust material process. The constant testing is fiscally and logistically intensive, often requiring coupons that are manufactured and tested in independent facilities. As a step toward integrating testing and characterization into the AM process while reducing cost, we propose the automated testing and characterization of AM (ATCAM). ATCAM is configured for fused deposition modeling (FDM) and introduces the concept of dynamic coupons to generate large quantities of basic AM samples. An in situ actuator is printed on the build surface to deploy coupons through impact, which is sensed by a load cell system utilizing machine learning (ML) to correlate AM data. We test ATCAM’s ability to distinguish the quality of three PLA feedstock at differing price points by generating and comparing 3000 dynamic coupons in 10 repetitions of 100 coupon cycles per material. ATCAM correlated the quality of each feedstock and visualized fatigue of in situ actuators over each testing cycle. Three ML algorithms were then compared, with Gradient Boost regression demonstrating a 71% correlation of dynamic coupons to their parent feedstock and provided confidence for the quality of AM data ATCAM generates. © 2021, This is a U.S. government work and not under copyright protection in the U.S.; foreign copyright protection may apply.|additive manufacturing; advanced characterization; automated testing; computational materials design; fused deposition modeling; machine learning|Actuators; Additives; Digital storage; Feedstocks; Fused Deposition Modeling; Automated testing; Fused deposition modeling (FDM); Load cells; Ml algorithms; Reducing costs; Robust materials; Testing cycles; Integration testing|Article|Final|All Open Access; Hybrid Gold Open Access|Scopus|2-s2.0-85111871683
scopus|Mehta S.; Patnaik K.S.|Mehta, Sweta (57222256908); Patnaik, K. Sridhar (24438167800)|57222256908; 24438167800|Improved prediction of software defects using ensemble machine learning techniques|2021|Neural Computing and Applications|33|16||10551|10562|11|64|10.1007/s00521-021-05811-3|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102026578&doi=10.1007%2fs00521-021-05811-3&partnerID=40&md5=b3a60d250a98b993fd618e9e0ee5b521|Software testing process is a crucial part in software development. Generally the errors made by developers get fixed at a later stage of the software development process. This increases the impact of the defect. To prevent this, defects need to be predicted during the initial days of the software development, which in turn helps in efficient utilization of the testing resources. Defect prediction process involves classification of software modules into defect prone and non-defect prone. This paper aims to reduce the impact of two major issues faced during defect prediction, i.e., data imbalance and high dimensionality of the defect datasets. In this research work, various software metrics are evaluated using feature selection techniques such as Recursive Feature Elimination (RFE), Correlation-based feature selection, Lasso, Ridge, ElasticNet and Boruta. Logistic Regression, Decision Trees, K-nearest neighbor, Support Vector Machines and Ensemble Learning are some of the algorithms in machine learning that have been used in combination with the feature extraction and feature selection techniques for classifying the modules in software as defect prone and non-defect prone. The proposed model uses combination of Partial Least Square (PLS) Regression and RFE for dimension reduction which is further combined with Synthetic Minority Oversampling Technique due to the imbalanced nature of the used datasets. It has been observed that XGBoost and Stacking Ensemble technique gave best results for all the datasets with defect prediction accuracy more than 0.9 as compared to algorithms used in the research work. © 2021, The Author(s), under exclusive licence to Springer-Verlag London Ltd. part of Springer Nature.|Data imbalance; Defect prediction; Dimension reduction; Machine learning algorithms; Stacking ensemble classifier; XGBoost|Decision trees; Defects; Feature extraction; Forecasting; Learning systems; Logistic regression; Nearest neighbor search; Predictive analytics; Software testing; Support vector machines; Support vector regression; Ensemble techniques; K-nearest neighbors; Machine learning techniques; Partial least-square regression; Recursive feature elimination; Selection techniques; Software development process; Synthetic minority over-sampling techniques; Software design|Article|Final||Scopus|2-s2.0-85102026578
scopus|Ricca F.; Marchetto A.; Stocco A.|Ricca, Filippo (24822686600); Marchetto, Alessandro (23971457800); Stocco, Andrea (36882807000)|24822686600; 23971457800; 36882807000|AI-based test automation: A grey literature analysis|2021|Proceedings - 2021 IEEE 14th International Conference on Software Testing, Verification and Validation Workshops, ICSTW 2021|||9440153|263|270|7|26|10.1109/ICSTW52544.2021.00051|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108030680&doi=10.1109%2fICSTW52544.2021.00051&partnerID=40&md5=5f38c7d53a902dbe8d3fb08be180b535|This paper provides the results of a survey of the grey literature concerning the use of artificial intelligence to improve test automation practices. We surveyed more than 1, 200 sources of grey literature (e.g., blogs, white-papers, user manuals, StackOverflow posts) looking for highlights by professionals on how AI is adopted to aid the development and evolution of test code. Ultimately, we filtered 136 relevant documents from which we extracted a taxonomy of problems that AI aims to tackle, along with a taxonomy of AI-enabled solutions to such problems. Manual code development and automated test generation are the most cited problem and solution, respectively. The paper concludes by distilling the six most prevalent tools on the market, along with think-aloud reflections about the current and future status of artificial intelligence for test automation.  © 2021 IEEE.|Artificial intelligence; Grey literature; Test automation|Automation; Software testing; Surveys; Taxonomies; Testing; Verification; Automated test generations; Grey literature; Manual codes; Relevant documents; Test Automation; Think aloud; User manual; White papers; Artificial intelligence|Conference paper|Final||Scopus|2-s2.0-85108030680
scopus|Swathi B.; Tiwari H.|Swathi, Baswaraju (57655874800); Tiwari, Harshvardhan (36667697200)|57655874800; 36667697200|Test automation framework using soft computing techniques|2021|Proceedings of the 2021 1st International Conference on Advances in Electrical, Computing, Communications and Sustainable Technologies, ICAECT 2021|||9392602||||9|10.1109/ICAECT49130.2021.9392602|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109211957&doi=10.1109%2fICAECT49130.2021.9392602&partnerID=40&md5=0abd5fab1d5c455f762d548ffbd894ee|Soft-computing helps in modeling and providing solution for real-world problems using various techniques like genetic algorithm, machine learning and artificial neural networks. This paper proposes the model to design test automation framework extending the traditional strategies like keyword-driven and page-object models. Test case generation and optimization problem is addressed. Representation of test cases is considered to be a challenge in various encoding schemes with respect to test case representation in soft computing techniques. An insight into test case representation and suitable soft computing algorithms applicable to test case generation is covered. © 2021 IEEE|Genetic algorithm; Keyword driven; Page object model; Soft computing; Test cases|Genetic algorithms; Machine learning; Neural networks; Soft computing; Design tests; Encoding schemes; Keyword driven; Optimization problems; Real-world problem; Softcomputing techniques; Test automation frameworks; Test case generation; Testing|Conference paper|Final||Scopus|2-s2.0-85109211957
scopus|Krishnamurthy K.; Sriganeshan V.; Medina A.M.|Krishnamurthy, Kritika (56915411600); Sriganeshan, Vathany (12798714800); Medina, Ana Maria (8613788100)|56915411600; 12798714800; 8613788100|An unusual case of lymphoplasmacytic lymphoma/Waldenström macroglobulinemia presenting with intractable seizures and interference with automated testing|2021|Journal of Hematopathology|14|1||69|73|4|0|10.1007/s12308-020-00432-6|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099062279&doi=10.1007%2fs12308-020-00432-6&partnerID=40&md5=743eacdfe29a46c8d3cb0eddf5135731|Lymphoplasmacytic lymphoma (LPL) is a B cell neoplasm composed of small lymphocytes, plasmacytoid lymphocytes, and plasma cells, which typically involves the bone marrow. Most cases of LPL present with Waldenstrom macroglobulinemia (WM) defined as the presence of monoclonal immunoglobulins of IgM type and LPL in the bone marrow. Herein, we present a case of LPL/WM presenting with intractable refractory seizures. A 71-year-old man with a 5-month history of seizures was brought to the emergency room after being found unresponsive. Automated hematology analysis revealed imprecise counts, wide variation, and multiple error flags. Peripheral smear review showed extracellular pale blue clumps of amorphous material. A marked cryoprecipitate of 7% was detected on a cryoglobulin screen. Serum protein electrophoresis (SPEP) detected a M-protein (1.58 g/dL) in the gamma region. Serum immunofixation revealed an IgM lambda monoclonal protein. A bone marrow biopsy showed hypercellularity with increased lymphocytes forming interstitial aggregates, admixed with plasmacytoid lymphocytes and plasma cells. Immunohistochemically, the lymphoma cells were positive for CD20 and negative for CD3, CD5, CD10, CD23, Cyclin D1 (Bcl-1), and Bcl-6. CD138 highlighted increased plasma cells. Flow cytometric analysis revealed 2.7% B cells with a predominance of lambda light chains, suggestive of a monoclonal B cell population. MYD88 mutational analysis revealed c.794T>C(p.L265P) mutation. A diagnosis of lymphoplasmacytic lymphoma/Waldenstrom macroglobulinemia was established. The patient underwent plasmapheresis leading to significant improvement in his symptoms. This case highlights a rare, unusual presentation of LPL/WM where the interference in automated testing led to identification of cryoglobulinemia and subsequent diagnosis of LPL/WM. © 2021, The Author(s), under exclusive licence to Springer-Verlag GmbH, DE part of Springer Nature.|Automated lab testing; CNS presentations of LPL/WM; Cryoglobulinemia; Lymphoplasmacytic lymphoma/Waldenstrom macroglobulinemia; MYD88L265P|albumin; antihypertensive agent; bendamustine; CD20 antibody; CD23 antigen; CD3 antigen; CD5 antigen; common acute lymphoblastic leukemia antigen; cryoglobulin; cyclin D1; globulin; immunoglobulin M; levetiracetam; M protein; myeloid differentiation factor 88; oxcarbazepine; phenytoin; protein bcl 6; syndecan 1; acute respiratory failure; aged; Article; bone marrow biopsy; case report; clinical article; computer assisted tomography; confusion; cryoglobulinemia; cryoprecipitate; disorientation; Doppler flowmetry; drug substitution; drug withdrawal; echocardiography; electrocardiography; electroencephalography; erythrocyte count; faintness; flow cytometry; gene mutation; hemoglobin blood level; human; hypertension; hypotension; immunohistochemistry; intensive care unit; intractable epilepsy; leukocyte differential count; low drug dose; male; neutrophilia; plasmapheresis; platelet count; protein electrophoresis; reticulocyte count; Sanger sequencing; seizure; tonic clonic seizure; Waldenstroem macroglobulinemia|Article|Final|All Open Access; Bronze Open Access|Scopus|2-s2.0-85099062279
scopus|Esfandyari S.; Rafe V.|Esfandyari, Sajad (57196436041); Rafe, Vahid (14054926800)|57196436041; 14054926800|Correction to: GALP: a hybrid artificial intelligence algorithm for generating covering array (Soft Computing, (2021), 25, 11, (7673-7689), 10.1007/s00500-021-05788-0)|2021|Soft Computing|25|11||7691|||0|10.1007/s00500-021-05848-5|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105433322&doi=10.1007%2fs00500-021-05848-5&partnerID=40&md5=d0a56a823e02aaf1077a6890586779e1|While typesetting the article the below references are published without surname. The correct references are copied below. 1. Ahmed BS, Zamli KZ, Lim CP (2012) Application of particle swarm optimization to uniform and variable strength covering array construction. Appl Soft Comput 12(4):1330–1347. 2. Ahmed BS, Abdulsamad TS, Potrus MY (2015) Achievement of minimized combinatorial test suite for configuration-aware software functional testing using the Cuckoo Search algorithm. Inf Softw Technol 66:13–29. 3. Calvagna A, Gargantini A (2009) IPO-s: incremental generation of combinatorial interaction test data based on symmetries of covering arrays. In: International conference on software testing, verification, and validation workshops, Denver, CO, USA. 4. Hartman A (2005) Software and hardware testing using combinatorial covering suites, vol 34. Springer, Berlin. 5. Hartman A (2019) IBM intelligent test case handler. IBM alphaworks. http://www.alphaworks.ibm.com/tech/ whitch 6. Jenkins B (2019) Jenny download web page. Bob Jenkins’ Website. http://burtleburtle.net/bob/math/jenny. html 7. Kuhn DR (2019) ACTS page download. http://csrc. nist.gov/groups/SNS/acts/download_tools.html 8. Zamli KZ, Din F, Kendall G, Ahmed BS (2017a) An experimental study of hyper-heuristic selection and acceptance mechanism for combinatorial t-way test suite generation. Inf Sci 399:121–153. The original article has been updated. © 2021, Springer-Verlag GmbH Germany, part of Springer Nature.|||Erratum|Final|All Open Access; Bronze Open Access|Scopus|2-s2.0-85105433322
scopus|Kirinuki H.; Matsumoto S.; Higo Y.; Kusumoto S.|Kirinuki, Hiroyuki (56875466800); Matsumoto, Shinsuke (36661111200); Higo, Yoshiki (7004831134); Kusumoto, Shinji (7102741360)|56875466800; 36661111200; 7004831134; 7102741360|NLP-assisted Web Element Identification Toward Script-free Testing|2021|Proceedings - 2021 IEEE International Conference on Software Maintenance and Evolution, ICSME 2021||||639|643|4|7|10.1109/ICSME52107.2021.00072|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123357888&doi=10.1109%2fICSME52107.2021.00072&partnerID=40&md5=0cf273ce399bd1c8aabdbf783c76bc0c|End-to-end test automation is important in modern web application development. However, existing test automation techniques have challenges in implementing and maintaining test scripts. It is difficult to keep correct locators, which test scripts require to identify web elements on web pages. The reason is that locators depend on the metadata in web elements or the structure of each web page. One efficient way to solve the problem of locators is to make test cases written in natural language executable without test scripts. As the first step of script-free testing, we propose a technique to identify web elements to be operated and to determine test procedures by interpreting test cases. The test cases are written in a domain-specific language without relying on the metadata of web elements or the structural information of web pages. We leverage natural language processing techniques to understand the semantics of web elements. We also create heuristic search algorithms to find promising test procedures. To evaluate our proposed technique, we applied it to two open-source web applications. The experimental results show that our technique successfully identified 94% of web elements to be operated in the test cases.  © 2021 IEEE.|Locator; Script-free Testing; Web Testing|Heuristic algorithms; Metadata; Natural language processing systems; Problem oriented languages; Semantics; Software testing; Testing; End-to-end tests; Locator; Script-free testing; Test Automation; Test case; Test procedures; Test scripts; Web application development; Web testing; Web-page; Websites|Conference paper|Final||Scopus|2-s2.0-85123357888
scopus||||ISSTA 2021 - Proceedings of the 30th ACM SIGSOFT International Symposium on Software Testing and Analysis|2021|ISSTA 2021 - Proceedings of the 30th ACM SIGSOFT International Symposium on Software Testing and Analysis||||||649|0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111433796&partnerID=40&md5=fba3464cdf3c8a478acf2e72caf0cdfd|The proceedings contain 58 papers. The topics discussed include: identifying privacy weaknesses from multi-party trigger-action integration platforms; WebEvo: taming web application evolution via detecting semantic structure changes; modular call graph construction for security scanning of Node.js applications; attack as defense: characterizing adversarial examples using robustness; exposing previously undetectable faults in deep neural networks; DeepCrime: mutation testing of deep learning systems based on real faults; DeepHyperion: exploring the feature space of deep learning-based systems through illumination search; automatic test suite generation for key-points detection DNNs using many-objective search; efficient white-box fairness testing through gradient search; and an infrastructure approach to improving effectiveness of android UI testing tools.|||Conference review|Final||Scopus|2-s2.0-85111433796
scopus||||Proceedings - 2021 IEEE/ACIS 21st International Fall Conference on Computer and Information Science, ICIS 2021-Fall|2021|Proceedings - 2021 IEEE/ACIS 21st International Fall Conference on Computer and Information Science, ICIS 2021-Fall||||||328|0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123636586&partnerID=40&md5=de7166a1e838d95ce3dfd2f4ce3247f3|The proceedings contain 57 papers. The topics discussed include: enhancing cyber-physical systems with machine learning - drilling holes into the walls between disciplines; multi-level modeling and cooperation mechanisms of tasks for swarm intelligent systems; research on complex system intelligent maintenance decision method; an improved similarity-based prognostics method for remaining useful life estimation of aero-engine; analysis and research on altmetrics index of domestic scholars in the field of international library and information science; research on international standardization of software quality and software testing; and an approach to critical success factors in designing cloud-based application solutions.|||Conference review|Final||Scopus|2-s2.0-85123636586
scopus|Feng Y.; Xia Z.; Guo A.; Chen Z.|Feng, Yang (41861285900); Xia, Zhilong (57221802413); Guo, An (57221804932); Chen, Zhenyu (55579848600)|41861285900; 57221802413; 57221804932; 55579848600|Survey of testing techniques of autonomous driving software; [自动驾驶软件测试技术研究综述]|2021|Journal of Image and Graphics|26|1||13|27|14|9|10.11834/jig.200493|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100248268&doi=10.11834%2fjig.200493&partnerID=40&md5=1516fa91d3a7097fcba0a600feb00187|An autonomous driving system(ADS) is a cyber-physical system that integrates a number of complicated software modules, such as high-precision sensors, artificial intelligence, and navigation systems. The autonomous driving software in this system performs sensing, positioning, forecasting, planning, and controlling tasks. With the development of artificial intelligence technologies and the continuous upgrading of onboard hardware devices, advanced autonomous driving software has been applied in a variety of safety-critical scenarios. Thus, the testing technology that assures its stability and reliability has naturally become the focus of academia and industry. To summarize the advance of the testing technology of autonomous driving software, this paper first characterizes the architecture and design of autonomous driving software. It presents the reference architecture of autonomous driving software and details the primary functionality of each component. It also introduces the interaction between these components and summarizes the features and challenges of autonomous driving software testing. Then, this paper extensively reviews the literature, providing a comprehensive discussion on the testing technology of autonomous driving software, which includes three related topics: simulation-based testing, real-scenario testing, and component-oriented testing. Simulation testing provides a method to examine the behaviors of real vehicle software in virtual environments. It constructs the internal and external factors and conditions that influence the software system to simulate various situations faced by autonomous vehicles with different degrees. This paper examines two critical components of simulation testing: the simulation methods and simulation targets. With regard to the simulation methods, software simulation, semi-physical simulation, and X-in-the-loop simulation are investigated. Currently, all these simulation methods are widely employed in autonomous driving software testing. They are capable of reflecting the behaviors of autonomous driving software under various virtual environments and thus enable engineers to test autonomous driving software at a much lower cost. For the simulation targets, this paper details the simulation of static environments, dynamic scenarios, sensors, and vehicle dynamics. Various simulation techniques are designed for these targets and are further employed to test different functionalities of autonomous driving software. For each simulation target, this paper discusses its usage and state-of-the-art simulation techniques. However, because simulation testing can reflect the behavior of autonomous driving software only in a virtual environment, it cannot completely represent the testing results under real scenarios. Compared with simulation testing, the cost of real scenario testing is relatively high, and the testing scale is often small. Thus, it cannot cover the input field and operating environment completely. However, real scenario testing is critical in quality assurance because it is the only way to identify the performance of autonomous driving software under real physical settings. This paper introduces the real-scenario testing cases conducted by the manufacturers of autonomous driving cars, which provide solid data that reflect the real road traffic scenario for the simulation testing of autonomous driving software. Component-oriented testing focuses on assuring the quality of individual components of autonomous driving software. In modern autonomous driving software, deep neural networks (DNNs) play a critical role. They are employed to assist in various driving tasks, such as perception, decision, and planning. However, testing the DNN-embedded software component is significantly different from conventional software components because their business logic is learned from massive data but is not defined with interpretable rules. To ensure the quality of these components, software engineers often adopt data-driven testing techniques. This paper introduces data-driven testing techniques for three primary components, i.e., perception, decision and planning, and controlling. For the perception component, the primary challenge is to generate test data to input into various sensors, such as LiDAR, radar, and camera. The existing solutions are often built based on a mutation algorithm to augment the seed dataset, with the goal of increasing neuron coverages. For the decision and planning component, some researchers leverage reinforcement learning algorithms to combine traditional path planning algorithms, expert systems, and machine learning techniques to enhance the testing engines. For the controlling component, the testing often involves the hardware, including speed controller, steering controller, braking controller, and stability controller. Researchers have evaluated the performance and reliability of controller-oriented algorithms and explored automated test generation methods. Finally, this paper summarizes and analyzes the current challenges of automatic driving software testing and prospects for the future research direction and emphasis of automatic driving software testing technology. © 2021, Editorial and Publishing Board of Journal of Image and Graphics. All right reserved.|Autonomous driving software; Data-driven testing; Simulation testing; Software testing; Survey||Review|Final||Scopus|2-s2.0-85100248268
scopus|Vedpal; Chauhan N.|Vedpal (55584312500); Chauhan, Naresh (24469783600)|55584312500; 24469783600|Role of Machine Learning in Software Testing|2021|2021 5th International Conference on Information Systems and Computer Networks, ISCON 2021|||||||3|10.1109/ISCON52037.2021.9702427|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126457544&doi=10.1109%2fISCON52037.2021.9702427&partnerID=40&md5=285eaa112918353695460249cb8e978c|Software reliability and robustness is the main objective to perform testing of the software. Now the machine learning approaches are used to develop applications in almost every area like health care, business prediction, etc. The testing of such type of software by using the conventional testing techniques does not give promising results. The testing techniques based on machine learning helps to produce reliable and robust software within time and allocated budget. In this paper the role of the machine learning algorithms in the design of testing approaches for testing the software has been presented. The machine learning-based testing techniques are used in the generation and execution order of the test cases. The outcomes of the machine learning based techniques showing the efficacy as compared to the other techniques.  © 2021 IEEE.|Machine learning; Machine learning based testing; MLTCP; software testing|Application programs; Budget control; Learning algorithms; Machine learning; Software reliability; Testing; Conventional testing; Machine learning approaches; Machine learning based testing; Machine-learning; MLTCP; Reliability and robustness; Software robustness; Software testings; Software-Reliability; Testing technique; Software testing|Conference paper|Final||Scopus|2-s2.0-85126457544
scopus|Niu Y.; Wu Z.; Liang F.|Niu, Yingbei (57219438015); Wu, Zhenyu (57223680853); Liang, Feng (57223685181)|57219438015; 57223680853; 57223685181|Analysis of Intelligent application software testing and evaluation technology|2021|ACM International Conference Proceeding Series|PartF168982||3450906||||0|10.1145/3448734.3450906|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106064567&doi=10.1145%2f3448734.3450906&partnerID=40&md5=ea384bdb93fd4844037cc53b816e3cd8|Aiming at the problem of intelligent application software evaluation, this paper analyzes several common defect location technologies: defect location technology based on coverage, defect location technology based on program slice, defect location technology based on model and algorithm evaluation method. Aiming at the deep learning algorithm model based on convolutional neural network commonly used in intelligent application software, the corresponding test method is proposed. This paper compares the advantages of intelligent application software testing with traditional software testing, and discusses the challenges and development direction of intelligent application software testing in the future. © 2021 ACM.|defect location; intelligent application software; Software testing|Computer software selection and evaluation; Convolutional neural networks; Data Science; Deep learning; Defects; Learning algorithms; Location; Software testing; Testing; Defect location; Development directions; Intelligent applications; Model and algorithms; Program slice; Software evaluation; Test method; Application programs|Conference paper|Final||Scopus|2-s2.0-85106064567
scopus|Zhuo Z.; Cai T.; Zhang X.; Lv F.|Zhuo, Z. (57393589900); Cai, T. (57392986500); Zhang, X. (57393441100); Lv, F. (56257929400)|57393589900; 57392986500; 57393441100; 56257929400|Long short-term memory on abstract syntax tree for SQL injection detection|2021|IET Software|15|2||188|197|9|31|10.1049/sfw2.12018|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122099584&doi=10.1049%2fsfw2.12018&partnerID=40&md5=fc5995899afadde830c9948078f512ab|SQL injection attack (SQLIA) is a code injection technique, used to attack data-driven applications by executing malicious SQL statements. Techniques like pattern matching, software testing and grammar analysis etc. are frequently used to prevent such attack. However, major bottlenecks still remain in detecting SQLIA with bypassing techniques, getting access to source code and requiring an additional manual operation to extract features. The authors propose a novel detection approach based on long short-term memory and abstract syntax tree, which could detect SQLIAs from the raw query strings and work under SQL detection bypassing scenario. Our deep learning technique explicitly uses both context and syntax information that previous methods failed to fully grasp. Experimental results clearly illustrate the superior performance of our method compared to other existing works when detecting with complete SQL raw queries. © 2021 The Authors. IET Software published by John Wiley & Sons Ltd on behalf of The Institution of Engineering and Technology.||Brain; Long short-term memory; Software testing; Syntactics; Trees (mathematics); Abstract Syntax Trees; Code injection; Data-driven applications; Injection techniques; Manual operations; Pattern-matching; Software testings; Source codes; SQL injection; SQL statements; Pattern matching|Article|Final||Scopus|2-s2.0-85122099584
scopus|Alharbi B.; Aljojo N.; Alshutayri A.; Banjar A.; Zainol A.; Alharbi A.; Alghanmi S.; Mansour S.; Alshehri M.|Alharbi, Basma (56313712100); Aljojo, Nahla (56150970100); Alshutayri, Areej (54419468800); Banjar, Ameen (57209376523); Zainol, Azida (26322222600); Alharbi, Asmaa (59925301600); Alghanmi, Sanaa (59925418600); Mansour, Shaza (59924814300); Alshehri, Mram (59925055600)|56313712100; 56150970100; 54419468800; 57209376523; 26322222600; 59925301600; 59925418600; 59924814300; 59925055600|The design and implementation of an interactive mobile Augmented Reality application for an improved furniture shopping experience|2021|Revista Romana de Informatica si Automatica|31|3||69|80|11|5|10.33436/v31i3y202106|https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007063458&doi=10.33436%2fv31i3y202106&partnerID=40&md5=cbacab33932208ac41d88e401981e903|Furniture shopping, when done in the traditional way, is a time-consuming task. A lot of time and effort is put to check different furniture items from different stores, and to make sure that these items match together. We propose an Augmented Reality based mobile application for furniture shopping. The main objective of the proposed application is to enhance users experience while shopping for furniture. We incorporate state-of-the-art technologies that enable interaction with the physical and virtual environment simultaneously. The proposed application allows users to view items from different stores, as well as ’try’ them before buying using AR. Thus, users can choose the right color, shape and size while they are sitting at home. In this work, we followed the waterfall software engineering model and described each main component. Specifically, details of requirement gathering, software design and implementation, and software testing are presented here. The proposed application was implemented using Vuforia. The software testing verified and validated the developed application, and the results were compared in light of related work. For future work, we aim to further improve the users experience in furniture shopping by incorporating more state-of-the-art techniques, such as an AI-based shopping assistant or an ML-based recommender system. © 2021, National Institute for R and D in Informatics. All rights reserved.|Android; Augmented Reality; Furniture Shopping Application; Mobile Application||Article|Final|All Open Access; Gold Open Access|Scopus|2-s2.0-105007063458
scopus||||C and ESAR 2021 - Proceedings of the 28th Computer and Electronics Security Application Rendezvous - Automation in Cybersecurity, co-located with the 6th European Cyber Week, ECW 2021|2021|CEUR Workshop Proceedings|3056|||||227|0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122848806&partnerID=40&md5=b1077266bbb0ab1a7aedab133454101f|The proceedings contain 15 papers. The topics discussed include: PROSECCO: formally-proven secure compiled code; from source code to crash test-cases through software testing automation; automation of binary analysis: from open source collection to threat intelligence; automated risk analysis of a vulnerability disclosure using active learning; attack forecast and prediction; network automation and security; integrating security into software development lifecycle : an experience return; cyber range automation, a bedrock for AI applications; and cheat detection in cyber security capture the flag games - an automated cyber threat hunting approach.|||Conference review|Final||Scopus|2-s2.0-85122848806
scopus|Lal A.; Kumar G.|Lal, Anushka (57220899681); Kumar, Girish (58829706500)|57220899681; 58829706500|Intelligent Testing in Software Industry|2021|2021 12th International Conference on Computing Communication and Networking Technologies, ICCCNT 2021|||||||3|10.1109/ICCCNT51525.2021.9580012|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126211800&doi=10.1109%2fICCCNT51525.2021.9580012&partnerID=40&md5=c14fe3249a41d5742cd332e509a36954|As the world is progressing towards digitization, software has become a critical component that is affecting the world's prosperity and economic competitiveness. This dependence on software and its corresponding impact in various sectors make it imperative for the need to accept and maintain the high quality of software. Testability is one of those software quality factors that has to be plugged in from the early stage of software development to upgrade the quality of software. Therefore, this study aims to investigate the approach of intelligent testing for improving software testability. Through an extensive literature review, numerous factors are identified that affect testability. Controllability and observability are two important factors. However, software complexity and understandability also play a significant role in this regard. Identifying the impact of testability on deliverability, an emphasis is given to the use of Artificial Intelligence (AI) based automated testing to greatly improve the effectiveness, coverage, and execution time of any software. The role of AI lies in its ability to proactively predict and solve any issues even before they have occurred. An illustration is provided on utilization of some openly available website testing AI tools to test the distinctive features of a university website. These tools have successfully assisted in testing and optimizing the sensitive areas of the website in least time possible. This study can be used by researchers to further explore the scope of intelligent testing and work towards the development of more robust AI testing tools to enhance software testability. © 2021 IEEE.|Artificial Intelligence; Nibbler; Pingdom; Selenium IDE; Software testing; Testim; Wave Accessibility tool; website testing|Artificial intelligence; Computer software selection and evaluation; Selenium; Software design; Websites; Intelligent testing; Nibble; Pingdom; Quality of softwares; Selenia IDE; Software testings; Testability; Testim; Wave accessibility tool; Website testing; Software testing|Conference paper|Final||Scopus|2-s2.0-85126211800
scopus|Gomes J.C.M.; Souza L.C.; Oliveira L.C.|Gomes, Julio Cartier M. (57195419636); Souza, Leandro Carlos (59157975200); Oliveira, Leiva Casemiro (55320111500)|57195419636; 59157975200; 55320111500|SmartSPR sensor: Machine learning approaches to create intelligent surface plasmon based sensors|2021|Biosensors and Bioelectronics|172||112760||||32|10.1016/j.bios.2020.112760|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095916400&doi=10.1016%2fj.bios.2020.112760&partnerID=40&md5=7963c8a7db28a6ef45d33299398cf1c0|Surface plasmon resonance (SPR) based sensors allow the evaluation of aqueous and gaseous solutions from real-time measurements of molecular interactions. The reliability of the response generated by a SPR sensor must be guaranteed, especially in substance detection, diagnoses, and other routine applications since poorly handled samples, instrumentation noise features, or even molecular tampering manipulations can lead to wrong interpretations. This work investigates the use of different machine learning (ML) techniques to deal with these issues, and aim to improve and attest to the quality of the real-time SPR responses so-called sensorgrams. A new strategy to describe a SPR-sensorgram is shown. The results of the proposed ML-approach allow the creation of intelligent SPR sensors to give a safe, reliable, and auditable analysis of sensorgram responses. Our arrangement can be embedded in an Intelligence Module that can classify sensorgrams and identify the substances presents in it. Also made it possible to order and analyze interest areas of sensorgrams, standardizing data, and supporting eventual audit procedures. With those intelligence features, the new generation of SPR-intelligent biosensors is qualifying to perform automated testing. A properly protocol for Leishmaniasis diagnosis with SPR was used to verify this new feature. © 2020 Elsevier B.V.|Automated diagnosis testing; Machine learning; Optical sensor; Smart biosensor; SPR intelligent sensor; Surface plasmon resonance|Biosensing Techniques; Intelligence; Machine Learning; Reproducibility of Results; Surface Plasmon Resonance; Chemical detection; Machine learning; Plasmons; Automated testing; Machine learning approaches; Noise features; Real time; Real time measurements; Sensorgram; SPR sensors; Article; automation; classification; clinical audit; controlled study; human; leishmaniasis; machine learning; proof of concept; standardization; surface plasmon resonance; genetic procedures; intelligence; machine learning; reproducibility; surface plasmon resonance; Surface plasmon resonance|Article|Final||Scopus|2-s2.0-85095916400
scopus|Strandberg P.E.; Frasheri M.; Enoiu E.P.|Strandberg, Per Erik (57193354005); Frasheri, Mirgita (55979636800); Enoiu, Eduard Paul (36462407100)|57193354005; 55979636800; 36462407100|Ethical AI-Powered Regression Test Selection|2021|Proceedings - 3rd IEEE International Conference on Artificial Intelligence Testing, AITest 2021||||83|84|1|6|10.1109/AITEST52744.2021.00025|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118765881&doi=10.1109%2fAITEST52744.2021.00025&partnerID=40&md5=6def368603386b7c1afe4c5bc3e3a6e4|Test automation is common in software development; often one tests repeatedly to identify regressions. If the amount of test cases is large, one may select a subset and only use the most important test cases. The regression test selection (RTS) could be automated and enhanced with Artificial Intelligence (AI-RTS). This however could introduce ethical challenges. While such challenges in AI are in general well studied, there is a gap with respect to ethical AI-RTS. By exploring the literature and learning from our experiences of developing an industry AI-RTS tool, we contribute to the literature by identifying three challenges (assigning responsibility, bias in decision-making and lack of participation) and three approaches (explicability, supervision and diversity). Additionally, we provide a checklist for ethical AI-RTS to help guide the decision-making of the stakeholders involved in the process.  © 2021 IEEE.|artificial intelligence; computer ethics; regression test selection; test automation|Artificial intelligence; Automation; Decision making; Regression analysis; Software design; Software testing; Computer ethics; Decisions makings; Regression test selection; Test Automation; Test case; Philosophical aspects|Conference paper|Final|All Open Access; Green Open Access|Scopus|2-s2.0-85118765881
scopus|Chetouane N.; Wotawa F.|Chetouane, Nour (57209344360); Wotawa, Franz (6603677377)|57209344360; 6603677377|On the Application of Machine Learning in Software Testing|2021|Artificial Intelligence: Methods for Software Engineering||||243|268|25|0|10.1142/97898112399220009|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136348274&doi=10.1142%2f97898112399220009&partnerID=40&md5=03d56ce89985b9bfd08da4c7dc76d661|[No abstract available]|||Book chapter|Final||Scopus|2-s2.0-85136348274
scopus|Zhao K.; Cao Y.; Yin J.; Zhong L.|Zhao, Kun (58970121600); Cao, Yang (58970432400); Yin, Jie (58971059200); Zhong, Lin (58970432500)|58970121600; 58970432400; 58971059200; 58970432500|Optimization of Determination Conditions of Sulfur Dioxide Residue in Chilli Products by Automatic Potentiometric Titration; [自动电位滴定法测定辣椒制品中二氧化硫残留量检测条件优化]|2021|Science and Technology of Food Industry|42|2||237|240and249|240012|0|10.13386/j.issn1002-0306.2020030266|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189459314&doi=10.13386%2fj.issn1002-0306.2020030266&partnerID=40&md5=cbba4ca414a75159b8326960949458d5|A method using automatic distillation apparatus coupled with automatic potentiometric titration was established to determine SO2 residue in chili products.The optimal conditions were determined by orthogonal test L16 (45), and the results were as follows;The distillation time 5 min, the volume of distilled water 200 mL, the volume of received solution 40 mL, the stirring speed 8 r/min, the potential change rate 50 mV/min.On this condition, the relative standard deviations were between 0.69%~0.95%, the standard addition recoveries were between 98.3%-99.6%.This method is simple, rapid and accurate.It5 s suitable for the automated testing of large quantities of sample.The results can provide reference for study SO2 residue in chili products and other food. © 2021 Editorial Department of Science and Technology of Food Science. All rights reserved.|automatic potentiometric titration; chilli products; optimization; orthogonal test; sulfur dioxide||Article|Final||Scopus|2-s2.0-85189459314
scopus|Rhmann W.; Ansari G.A.|Rhmann, Wasiur (57207355961); Ansari, Gufran Ahmad (57188651550)|57207355961; 57188651550|Ensemble Techniques-Based Software Fault Prediction in an Open-Source Project|2021|Research Anthology on Usage and Development of Open Source Software|1|||693|709|16|4|10.4018/978-1-7998-9158-1.ch036|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116539316&doi=10.4018%2f978-1-7998-9158-1.ch036&partnerID=40&md5=a189f213cf2a50b7d0fee8e913ce9005|Software engineering repositories have been attracted by researchers to mine useful information about the different quality attributes of the software. These repositories have been helpful to software professionals to efficiently allocate various resources in the life cycle of software development. Software fault prediction is a quality assurance activity. In fault prediction, software faults are predicted before actual software testing. As exhaustive software testing is impossible, the use of software fault prediction models can help the proper allocation of testing resources. Various machine learning techniques have been applied to create software fault prediction models. In this study, ensemble models are used for software fault prediction. Change metrics-based data are collected for an open-source android project from GIT repository and code-based metrics data are obtained from PROMISE data repository and datasets kc1, kc2, cm1, and pc1 are used for experimental purpose. Results showed that ensemble models performed better compared to machine learning and hybrid search-based algorithms. Bagging ensemble was found to be more effective in the prediction of faults in comparison to soft and hard voting. © 2021 by IGI Global. All rights reserved.|||Book chapter|Final||Scopus|2-s2.0-85116539316
scopus|Hnatkowska B.; Huzar Z.; Tuzinkiewicz L.|Hnatkowska, Bogumila (22135070400); Huzar, Zbigniew (6508241488); Tuzinkiewicz, Lech (13607912400)|22135070400; 6508241488; 13607912400|Consistency Assessment of Datasets in the Context of a Problem Domain|2021|Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)|12799 LNAI|||112|125|13|1|10.1007/978-3-030-79463-7_10|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112697995&doi=10.1007%2f978-3-030-79463-7_10&partnerID=40&md5=10b6f0e3c824d7f23528e91c6c7e3d9f|Datasets have many applications, e.g., are used for software testing or serve as training data in artificial intelligence. In any case, they must be of good quality, i.e., be consistent with the domain represented by the dataset. The work aims to propose an approach to checking the consistency between a dataset and its domain. It is assumed that the collected data has a form of uninterpretable records, except for the knowledge of the attributes’ names. The domain is represented by an ontology in the form of a UML class diagram. The proposed method consists of two stages: first, a UML class diagram is generated from a dataset, and then it is compared with the diagram representing the domain ontology with the use of defined measures. A case study illustrates the proposed approach. It has been shown that the proposed measures help to find inconsistencies and improve data quality. The proposed method enables the quality assessment of a data sample. © 2021, Springer Nature Switzerland AG.|Dataset; Domain ontology; UML class diagrams|Intelligent systems; Ontology; Software testing; Data quality; Data sample; Domain ontologies; Problem domain; Quality assessment; Training data; UML class diagrams; Application programs|Conference paper|Final||Scopus|2-s2.0-85112697995
scopus|Siddiqui A.; Zia M.Y.I.; Otero P.|Siddiqui, Atif (8506628000); Zia, Muhammad Yousuf Irfan (57192103831); Otero, Pablo (6601947277)|8506628000; 57192103831; 6601947277|A universal machine-learning-based automated testing system for consumer electronic products|2021|Electronics (Switzerland)|10|2|136|1|26|25|8|10.3390/electronics10020136|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099421832&doi=10.3390%2felectronics10020136&partnerID=40&md5=9b7ea1ec21b039fd73896cf03558a872|Consumer electronic manufacturing (CEM) companies face a constant challenge to main-tain quality standards during frequent product launches. A manufacturing test verifies product functionality and identifies manufacturing defects. Failure to complete testing can even result in product recalls. In this research, a universal automated testing system has been proposed for CEM companies to streamline their test process in reduced test cost and time. A universal hardware interface is designed for connecting commercial off-the-shelf (COTS) test equipment and unit under test (UUT). A software application, based on machine learning, is developed in LabVIEW. The test site data for around 100 test sites have been collected. The application automatically selects COTS test equipment drivers and interfaces on UUT and test measurements for test sites through a universal hardware interface. Further, it collects real-time test measurement data, performs analysis, generates reports and key performance indicators (KPIs), and provides recommendations using machine learning. It also maintains a database for historical data to improve manufacturing processes. The proposed system can be deployed standalone as well as a replacement for the test department module of enterprise resource planning (ERP) systems providing direct access to test site hardware. Finally, the system is validated through an experimental setup in a CEM company. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.|Commercial off-the-shelf (COTS) test equipment; Consumer electronic manufacturing (CEM) industry; Enterprise resource planning (ERP); Hardware interfacing; Industrial automation; LabVIEW; Machine learning||Article|Final|All Open Access; Gold Open Access|Scopus|2-s2.0-85099421832
scopus|Perez Morales D.; Kitamura T.; Takada S.|Perez Morales, Daniel (57226406688); Kitamura, Takashi (55436053600); Takada, Shingo (7202611302)|57226406688; 55436053600; 7202611302|Coverage-Guided Fairness Testing|2021|Studies in Computational Intelligence|985|||183|199|16|12|10.1007/978-3-030-79474-3_13|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111426693&doi=10.1007%2f978-3-030-79474-3_13&partnerID=40&md5=4153df7ebc42bd89fd57195000fc7e99|Software testing is a crucial task. Unlike conventional software, AI software that uses decision-making algorithms or classifiers needs to be tested for discrimination or bias. Such bias can cause discrimination towards certain individuals based on their protected attributes, such as race, gender or nationality. It is a major concern to have discrimination as an unintended behavior. Previous work tested for discrimination randomly, which has resulted in variations in the results for each test execution. These varying results indicate that, for each test execution, there is discrimination that is not found. Even though it is nearly impossible to find all discrimination unless we check all possible combinations in the system, it is important to detect as much discrimination as possible. We thus propose Coverage-Guided Fairness Testing (CGFT). CGFT leverages combinatorial testing to generate an evenly-distributed test suite. We evaluated CGFT with two different datasets, creating three models with each. The results show an improvement in the number of unfairness found using CGFT compared to previous work. © 2021, The Author(s), under exclusive license to Springer Nature Switzerland AG.|Combinatorial testing; Fairness; Machine learning; Testing||Book chapter|Final||Scopus|2-s2.0-85111426693
scopus|Yi J.; Tao H.; Cheng W.Y.|Yi, Ji (57223910803); Tao, He (57215896401); Cheng, Wu Yong (57223914658)|57223910803; 57215896401; 57223914658|Research on the application of deep learning in computer interlocking system simulation test platform|2020|Proceedings - 2020 International Conference on Intelligent Computing and Human-Computer Interaction, ICHCI 2020|||9424852|290|293|3|1|10.1109/ICHCI51889.2020.00069|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106398897&doi=10.1109%2fICHCI51889.2020.00069&partnerID=40&md5=6a548cda4b9089a9a33a1fac08803300|Computer interlocking system is a safety-critical system. Aiming at the problems of insufficient testing, low efficiency, strong subjectivity, and poor comprehensibility in the current functional testing of computer interlocking systems using manual testing and automatic testing. A design scheme of a simulation test platform based on deep learning for automated testing of interlocking system functions is proposed. By analyzing the system structure of the interlock system and the process of manual and automatic testing, the design idea and implementation method of the simulation test platform are determined, and the automatic testing target of the interlock function is finally realized, thus achieving the goal of complete and efficient safety testing. © 2020 IEEE.|Automatic testing; Computer interlock system; The simulation test|Automatic testing; Computer testing; Deep learning; Human computer interaction; Intelligent computing; Learning systems; Safety devices; Safety engineering; Simulation platform; Automated testing; Computer interlocking; Current functional testing; Interlock systems; Interlocking systems; Safety critical systems; Simulation test platforms; System structures; Safety testing|Conference paper|Final||Scopus|2-s2.0-85106398897
scopus|Ricca F.; Mascardi V.; Verri A.|Ricca, Filippo (24822686600); Mascardi, Viviana (6506722954); Verri, Alessandro (57193129975)|24822686600; 6506722954; 57193129975|Test'n'Mo: A Collaborative Platform for Human Testers and Intelligent Monitoring Agents|2021|VORTEX 2021 - Proceedings of the 5th ACM International Workshop on Verification and mOnitoring at Runtime EXecution, co-located with ECOOP/ISSTA 2021|||3468446|17|21|4|1|10.1145/3464974.3468446|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111418159&doi=10.1145%2f3464974.3468446&partnerID=40&md5=99a9ba3bebf34299fee1d3058d3878f4|Many software bugs have disruptive consequences, both in financial terms and in loss of life. Software Testing is one widely used approach to detect software bugs and ensure software quality but the testing activity, conducted either manually or using testing frameworks, is repetitive and expensive. Runtime Monitoring, differently from Software Testing, does not require test cases to be designed and executed and - once the property to be monitored has been specified - it does not rely on human beings performing any further actions, unless a violation is detected. However the property to be monitored, that must feed the monitor along with the trace or stream of observed events, may be very hard to identify and specify. In this extended abstract we present the Test'n'Mo vision which goes in the direction of exploiting Artificial intelligence and Machine Learning as enabling techniques for a hybrid platform for Software Testing and Runtime Monitoring. In Test'n'Mo, human testers and software agents of different kinds - 'Learning Agents' and 'Runtime Monitoring and Testing Agents' - collaborate to achieve their common testing goal. Although Test'n'Mo is meant to address User Interface testing of web/mobile apps, the Test'n'Mo approach may be adapted to other software testing activities. © 2021 ACM.|collaborative human-agent testing platform; runtime monitoring agents; test agents|Artificial intelligence; Computer software selection and evaluation; Intelligent agents; Monitoring; Program debugging; Software quality; Testing; User interfaces; Vortex flow; Collaborative platform; Enabling techniques; Extended abstracts; Intelligent monitoring; Interface testings; Learning agents; Runtime Monitoring; Testing framework; Software testing|Conference paper|Final||Scopus|2-s2.0-85111418159
scopus|Nagulapalli L.R.; Umar S.; Yadesa T.B.; Deressa T.D.; Jimalo K.M.|Nagulapalli, Linga Reddy (57223597448); Umar, Syed (56104639100); Yadesa, Tariku Birhanu (57223632187); Deressa, Tadele Debisa (57223594482); Jimalo, Kamal Mohammed (57223637380)|57223597448; 56104639100; 57223632187; 57223594482; 57223637380|Reproducible Analysis and Intelligent Scientific Criteria in Engineering Papers Classification Using Data Science|2021|Lecture Notes in Networks and Systems|177 LNNS|||677|683|6|0|10.1007/978-981-33-4501-0_63|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105919646&doi=10.1007%2f978-981-33-4501-0_63&partnerID=40&md5=764fbe54ad06559dc63ca7bbd601f5c7|In this paper, we discuss, any work must be reproducible in order to influence research and contribute to our profession's knowledge. Nevertheless, studies show that 70% of university laboratory work cannot reproduce. Reproducible work with not always available data sets or procedures not clearly specified is uncommon in software engineering and complex specifications engineering. The lack of reproducible research prevents development, which means that researchers must replicate a scratch study. The RE researcher will read conference papers, find empirical articles and then review data that can (if available) be replicated in the empirical report. This paper deals with two aspects of the problem and discusses in RE articles, RE documents and theoretical documents. In learning and development of an automatic classification in RE and empirical document identification, recent conference papers and RE documents have been utilized. They use the ERRC approach for performing supervised lecture classifications using natural language therapy and machine learning. Our software is equated with a fundamental keyword approach. We study the paper collections from the engineering conference sponsored by IEEE on Requirements and the International Software Testing and Evaluation Symposium sponsored by IEEE in order to test our process. In all but a few cases, we examine that the procedure of ERRC worked superior than the reference procedure. © 2021, Springer Nature Singapore Pte Ltd.|Empirical research; Information retrieval; Machine learning; Reproducible research; Requirements engineering; Statistical analysis; Supervised classification learning text classification||Conference paper|Final||Scopus|2-s2.0-85105919646
scopus||||Proceedings - 5th Jornadas Costarricenses de Investigacion en Computacion e Informatica, JoCICI 2021|2021|Proceedings - 5th Jornadas Costarricenses de Investigacion en Computacion e Informatica, JoCICI 2021||||||82|0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133429893&partnerID=40&md5=d6870ee82bf521988337f130e2d4d15a|The proceedings contain 13 papers. The topics discussed include: estimation for a student collaboration hours management system at the University of Costa Rica: a case study; technical debt measurement during software development using Sonarqube: literature review and a case study; detection of solid waste deposits in urban areas using artificial intelligence and image processing: a literature review; virtual machine rotation for mitigation of a Slowloris attack; agent-based tool for model-based test case generation and execution; predicting the incidence of dengue in Costa Rica using a decision tree model based on climatic and socioeconomic variables; improving performance of error-tolerant applications: a case study of approximations on an off-the-shelf neural accelerator; application of process metrics for software testing: a case study; sampling methods with least information loss in transit videos for the reduction of manual work and computational processing; and asynchronous detection of Slowloris attacks via random forests.|||Conference review|Final||Scopus|2-s2.0-85133429893
scopus|Lethbridge T.C.|Lethbridge, Timothy C. (59101581700)|59101581700|Low-Code Is Often High-Code, So We Must Design Low-Code Platforms to Enable Proper Software Engineering|2021|Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)|13036 LNCS|||202|212|10|33|10.1007/978-3-030-89159-6_14|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118138977&doi=10.1007%2f978-3-030-89159-6_14&partnerID=40&md5=564c440be8ea02debed5b2c9b84ff657|The concept of low-code (and no-code) platforms has been around for decades, even before the term was used. The idea is that applications on these platforms can be built by people with less technical expertise than a professional programmer, yet can leverage powerful technology such as, for example, for databases, financial analysis, web development and machine learning. However, in practice, software written on such platforms often accumulates large volumes of complex code, which can be worse to maintain than in traditional languages because the low-code platforms tend not to properly support good engineering practices such as version control, separation of concerns, automated testing and literate programming. In this paper we discuss experiences with several low-code platforms and provide suggestions for directions forward towards an era where the benefits of low-code can be obtained without accumulation of technical debt. Our recommendations focus on ensuring low-code platforms enable scaling, understandability, documentability, testability, vendor-independence, and the overall user experience for developers those end-users who do some development. © 2021, Springer Nature Switzerland AG.|End-user programming; Low-code platforms; Modeling; Spreadsheets; Technical debt; Umple|Codes (symbols); Information management; Software testing; Complex codes; Financial analysis; Large volumes; Low-code platform; Modeling; Professional programmers; Technical debts; Technical expertise; Umple; Web development; Computer programming|Conference paper|Final||Scopus|2-s2.0-85118138977
scopus|Jiang B.; Wei W.; Yi L.; Chan W.K.|Jiang, Bo (56727207300); Wei, Wenlin (58062885600); Yi, Li (58062875400); Chan, W.K. (55471383000)|56727207300; 58062885600; 58062875400; 55471383000|DroidGamer: Android Game Testing with Operable Widget Recognition by Deep Learning∗|2021|IEEE International Conference on Software Quality, Reliability and Security, QRS|2021-December|||197|206|9|2|10.1109/QRS54544.2021.00031|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146198170&doi=10.1109%2fQRS54544.2021.00031&partnerID=40&md5=bd10b21495c442d647e155e999b0909a|Android game applications are an important type of application widely used by end users. Bugs in such applications can significantly affect user experience. Due to the use of rendered Graphical User Interface (GUI) widgets, automated testing of Android game application becomes challenging because such GUI widgets cannot be queried with Android system APIs, making existing GUI-based testing techniques blind to the locations of widgets. In this work, we propose DroidGamer, a novel GUI traversal-based Android game testing technique, which relies on deep learning models to recognize operable GUI widgets. DroidGamer adopts a novel GUI model traversal algorithm and a new GUI state equivalence criterion over the widget recognition results of the deep learning models. Our experiment on 10 open-source Android games shows that DroidGamer is significantly more effective than existing techniques including Monkey, Stoat, and PUMA for testing Android games in terms of both code coverage and fault detection ability. © 2021 IEEE.|Android game testing; deep learning; test case generation; widget recognition|Ability testing; Android (operating system); Application programming interfaces (API); Deep learning; Fault detection; Learning systems; Program debugging; Android game testing; Android games; Deep learning; End-users; Game testing; Learning models; Test case generation; Testing technique; Users' experiences; Widget recognition; Graphical user interfaces|Conference paper|Final||Scopus|2-s2.0-85146198170
scopus|Prasetya I.S.W.B.; Shirzadehhajimahmood S.; Ansari S.G.; Fernandes P.; Prada R.|Prasetya, I.S.W.B. (8980537400); Shirzadehhajimahmood, Samira (57220114778); Ansari, Saba Gholizadeh (57219185008); Fernandes, Pedro (57215870539); Prada, Rui (6603926477)|8980537400; 57220114778; 57219185008; 57215870539; 6603926477|An agent-based architecture for AI-enhanced automated testing for XR systems, a short paper|2021|Proceedings - 2021 IEEE 14th International Conference on Software Testing, Verification and Validation Workshops, ICSTW 2021|||9440175|213|217|4|3|10.1109/ICSTW52544.2021.00044|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108026898&doi=10.1109%2fICSTW52544.2021.00044&partnerID=40&md5=8a66e9778d66cdab9ff89988659e6315|This short paper presents an architectural overview of an agent-based framework called iv4XR for automated testing that is currently under development by an H2020 project with the same name. The framework's intended main use case of is testing the family of Extended Reality (XR) based systems (e.g. 3D games, VR sytems, AR systems), though the approach can indeed be adapted to target other types of interactive systems. The framework is unique in that it is an agent-based system. Agents are inherently reactive, and therefore are arguably a natural match to deal with interactive systems. Moreover, it is also a natural vessel for mounting and combining different AI capabilities, e.g. reasoning, navigation, and learning.  © 2021 IEEE.|Agent based testing, AI for testing games; AI for automated testing, automated testing XR systems|Verification; 3D games; Agent based architectures; Agent-based framework; Agent-based systems; AR system; Automated testing; Interactive system; Software testing|Conference paper|Final|All Open Access; Green Open Access|Scopus|2-s2.0-85108026898
scopus|Huang S.; Chen H.; Hui Z.; Liu Y.|Huang, Song (55608828500); Chen, Hao (57221501982); Hui, Zhanwei (36499601600); Liu, Yuchan (57221502711)|55608828500; 57221501982; 36499601600; 57221502711|A Survey of the Use of Test Report in Crowdsourced Testing|2020|Proceedings - 2020 IEEE 20th International Conference on Software Quality, Reliability, and Security, QRS 2020|||9282788|430|441|11|5|10.1109/QRS51102.2020.00062|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099306584&doi=10.1109%2fQRS51102.2020.00062&partnerID=40&md5=40c68f3da7b09650e3559479a558b7d1|With the rise of crowdsourced software testing in recent years, the issuers of crowd test tasks can usually collect a large number of test reports after the end of the task. These reports have insufficient validity and completeness, and manual review often takes a lot of time and effort. The crowdsourced test task publisher hopes that after the crowdsourced platform collects the test report, it can analyze the validity and completeness of the report to determine the severity of the report and improve the efficiency of crowdsourced software testing. In the past ten years, researchers have used various technologies (such as natural language processing, information retrieval, machine learning, deep learning) to assist in analyzing reports to improve the efficiency of report review. We have summarized the relevant literature of report analysis in the past ten years, and then classified from report classification, duplicate report detection, report prioritization, report refactoring, and summarized the most important research work in each area. Finally, we propose research trends in these areas and analyze the challenges and opportunities facing crowdsourced test report analysis. © 2020 IEEE.|crowdsourced testing; duplicate report; report classification; report prioritization; report refactoring; Survey|Computer software selection and evaluation; Crowdsourcing; Deep learning; Efficiency; Natural language processing systems; Software reliability; Testing; NAtural language processing; Prioritization; Refactorings; Research trends; Test reports; Test tasks; Various technologies; Software testing|Conference paper|Final||Scopus|2-s2.0-85099306584
scopus|Masuda S.; Matsuodani T.; Tsuda K.|Masuda, Satoshi (36803608600); Matsuodani, Tohru (6507446701); Tsuda, Kazuhiko (7202766371)|36803608600; 6507446701; 7202766371|Syntax-tree similarity for test-case derivability in software requirements|2021|Proceedings - 2021 IEEE 14th International Conference on Software Testing, Verification and Validation Workshops, ICSTW 2021|||9440190|162|172|10|2|10.1109/ICSTW52544.2021.00037|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108030234&doi=10.1109%2fICSTW52544.2021.00037&partnerID=40&md5=575536be81064cda736de9c7fe3d2886|Software testing has been important for software engineering to contribute to developing high-quality software. Decision table testing is a general technique to derive test cases with information on conditions and actions from software requirements. Deriving conditions and actions from requirements is key for efficient decision table testing. This paper proposes and evaluates a syntax-tree similarity method for test-case derivability in software requirements. We define the syntax-tree similarity technique used in our method as selecting test-case-derivable sentences from requirements at pre-processing. The syntax tree is defined as divided into sub-trees that consist of a root to each leaf. The syntax-tree similarity technique calculates the similarity between each sentence in the requirements and test-case-derivable sentence. The method involves natural language processing to select test-case-derivable sentences from the requirements on the basis of syntax-tree similarity then determines conditions and actions through dependency and case analyses. After selecting requirements by syntax-tree similarity, our method derives conditions and actions from the requirements by the deriving rules we define. Experiments revealed that the F-measure of the accuracy of the derived conditions and actions increased 16% from that reported in prior work. The results from case studies further indicate the effectiveness of our method.  © 2021 IEEE.|Derive test cases; Software requirements; Syntax-tree similarity|Decision tables; Natural language processing systems; Requirements engineering; Syntactics; Testing; Trees (mathematics); Verification; Case analysis; Case-studies; F measure; High-quality software; NAtural language processing; Pre-processing; Software requirements; Syntax tree; Software testing|Conference paper|Final||Scopus|2-s2.0-85108030234
scopus|Jaganeshwari K.; Djodilatchoumy S.|Jaganeshwari, K. (57224619631); Djodilatchoumy, S. (56575169900)|57224619631; 56575169900|A Novel approach of GUI Mapping with image based widget detection and classification|2021|Proceedings of 2021 2nd International Conference on Intelligent Engineering and Management, ICIEM 2021|||9445281|342|346|4|6|10.1109/ICIEM51511.2021.9445281|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108028550&doi=10.1109%2fICIEM51511.2021.9445281&partnerID=40&md5=6f1a9a9beacc95ad04e49aa1c58da78b|Software testing is vital for the intellectual benefits of software reliability and quality. At present, Graphical user interfaces are the most common and widely used interfaces in the software industry. Furthermore, GUI Testing is an important approach to ensure the quality of software. Automated software testing is a GUI front end applications similar to APP, and WEB, etc and is a vastly time and resource-consuming task. Therefore, this will become even more complex in rapidly updated GUI applications such as Ex: Patches/Version updates of a mobile App, or the product and offer updates in marketing websites like Flipkart, Amazon, etc., in which the GUI components are continuously updated infinitely. Developing a test case scenario whenever a new GUI component is updated will affect the productivity of the application. In our experiment, we found a better way of improving GUI testing by consequently detecting and classifying GUI widgets using machine learning techniques. Additionally, we also found that detecting and classifying GUI objects in screenshots and reports with a position of the widgets (x, y coordinates) and type of the widgets, matches with trained samples, URL links, and screen links. Hence, we in this paper will analyze and devise an efficient automated testing strategy for Web Applications. This is a unique way of web Graphical user interface testing with a computer vision. This paper will also present the parameters used for object detection, classification, and evaluation with image processing using machine learning algorithms with better accuracy. © 2021 IEEE.|Automated Testing; GUI Testing; Image processing; Object classification; Object Detection; Real Time Test environment|Application programs; E-learning; Image classification; Learning algorithms; Machine learning; Object detection; Software quality; Software reliability; Software testing; Automated software testing; Automated testing; GUI applications; Machine learning techniques; Quality of softwares; Software industry; Trained samples; WEB application; Graphical user interfaces|Conference paper|Final||Scopus|2-s2.0-85108028550
scopus|Yadav V.; Botchway R.K.; Senkerik R.; Oplatkova Z.K.|Yadav, Vinod (57303202200); Botchway, Raphael Kwaku (57213065239); Senkerik, Roman (23975048900); Oplatkova, Zuzana Kominkova (15043128400)|57303202200; 57213065239; 23975048900; 15043128400|Robotic Automation of Software Testing From a Machine Learning Viewpoint|2021|Mendel|27|2||68|73|5|4|10.13164/mendel.2021.2.068|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123604331&doi=10.13164%2fmendel.2021.2.068&partnerID=40&md5=9ee97e2f74bbba12735424d95fa83620|The need to scale software test automation while managing the test automation process within a reasonable time frame remains a crucial challenge for software development teams (DevOps). Unlike hardware, the software cannot wear out but can fail to satisfy the functional requirements it is supposed to meet due to the defects observed during system operation. In this era of big data, DevOps teams can deliver better and efficient code by utilizing machine learning (ML) to scan their new codes and identify test coverage gaps. While still in its infancy, the inclusion of ML in software testing is a reality and requirement for coming industry demands. This study introduces the prospects of robot testing and machine learning to manage the test automation process to guarantee software reliability and quality within a reasonable timeframe. Although this paper does not provide any particular demonstration of ML-based technique and numerical results from MLbased algorithms, it describes the motivation, possibilities, tools, components, and examples required for understanding and implementing the robot test automation process approach. © 2021, Brno University of Technology. All rights reserved.|Automation; Big data; Machine learning; Robotic software testing; Software reliability; Test automation|Big data; Machine learning; Robotics; Software design; Software reliability; Automation process; Machine-learning; Robotic automation; Robotic software testing; Robotic softwares; Software test automation; Software testings; Software-Reliability; Test Automation; Time frame; Software testing|Article|Final|All Open Access; Gold Open Access; Green Open Access|Scopus|2-s2.0-85123604331
scopus|Spieker H.; Gotlieb A.|Spieker, Helge (57189329650); Gotlieb, Arnaud (56247674500)|57189329650; 56247674500|Summary of: Adaptive Metamorphic Testing with Contextual Bandits|2021|Proceedings - 2021 IEEE 14th International Conference on Software Testing, Verification and Validation, ICST 2021|||9438595|275|277|2|0|10.1109/ICST49551.2021.00037|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107977413&doi=10.1109%2fICST49551.2021.00037&partnerID=40&md5=40710dc9ce57ab8d6c69cdb1e9e769f1|Metamorphic Testing (MT) is a software testing paradigm that aims at using user-specified properties of a program under test to either check its expected outputs or to generate new test cases [1] , [2]. More precisely, MT tackles the so-called oracle problem which occurs whenever predicting the expected outputs of a system is just too difficult or even impossible. A typical example where MT has been successfully deployed is for testing machine learning models. For instance, in supervised machine learning, we train models for classification problems, but testing these models is hard as only stochastic behaviors of these models can be specified [3]. Indeed, we initially train these models with existing labelled datasets and then we exploit them to classify new data samples. Testing these models means only to reserve some portion of the labelled datasets to control that the correct classification is given for these reserved datasets. However, nothing is really available to test these models on unlabelled data samples. © 2021 IEEE.||Classification (of information); Learning systems; Stochastic models; Stochastic systems; Supervised learning; Testing; Verification; Contextual bandits; Data sample; Metamorphic testing; Oracle problem; Stochastic behavior; Supervised machine learning; Testing machine; Train model; Software testing|Conference paper|Final||Scopus|2-s2.0-85107977413
scopus|Paduraru C.; Paduraru M.; Stefanescu A.|Paduraru, Ciprian (55637207200); Paduraru, Miruna (57210841881); Stefanescu, Alin (57188811190)|55637207200; 57210841881; 57188811190|RiverFuzzRL - An open-source tool to experiment with reinforcement learning for fuzzing|2021|Proceedings - 2021 IEEE 14th International Conference on Software Testing, Verification and Validation, ICST 2021|||9438567|430|435|5|7|10.1109/ICST49551.2021.00055|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107918441&doi=10.1109%2fICST49551.2021.00055&partnerID=40&md5=9f99d05a66b7393caae98aa3ea6a0bd7|Combining fuzzing techniques and reinforcement learning could be an important direction in software testing. However, there is a gap in support for experimentation in this field, as there are no open-source tools to let academia and industry to perform experiments easily. The purpose of this paper is to fill this gap by introducing a new framework, named RiverFuzzRL, on top of our already mature frame-work for AI-guided fuzzing, River. We provide out-of-the-box implementations for users to choose from or customize for their test target. The work presented here is performed on testing binaries and does not require access to the source code, but it can be easily adapted to other types of software testing as well. We also discuss the challenges faced, opportunities, and factors that are important for performance, as seen in the evaluation. © 2021 IEEE.|binary analysis; fuzzing; open-source tool; reinforcement learning; symbolic execution|Open source software; Reinforcement learning; Verification; Well testing; Frame-work; Open source tools; Source codes; Software testing|Conference paper|Final||Scopus|2-s2.0-85107918441
scopus|Job M.A.|Job, Minimol Anil (57207911210)|57207911210|Automating and Optimizing Software Testing using Artificial Intelligence Techniques|2021|International Journal of Advanced Computer Science and Applications|12|5||594|602|8|14|10.14569/IJACSA.2021.0120571|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107536835&doi=10.14569%2fIJACSA.2021.0120571&partnerID=40&md5=480c4348e6115756c2bbbec33d7c5f47|The final product of software development process is a software system and testing is one of the important stages in this process. The success of this process can be determined by how well it accomplishes its goal. Due to the advancement of technology, various software testing tools have been introduced in the software engineering discipline. The use of software is increasing day-by-day and complexity of software functions are challenging and there is need to release the software within the short quality evaluation period, there is a high demand in adopting automation in software testing. Emergence of automatic software testing tools and techniques helps in quality enhancement and reducing time and cost in the software development activity. Artificial Intelligence (AI) techniques are widely applied in different areas of Software engineering (SE). Application of AI techniques can help in achieving good performance in software Testing and increase the productivity of the software development firms. This paper briefly presents the state of the art in the field of software testing by applying AI techniques in software testing. © 2021. All Rights Reserved.|artificial intelligence; software engineering; software quality; Software testing; testing automation|Application programs; Artificial intelligence; Computer software selection and evaluation; Software design; Artificial intelligence techniques; Engineering disciplines; High demand; Quality evaluation; Software development process; Software functions; Software testings; Software-systems; Testing automation; Testing tools; Software testing|Article|Final|All Open Access; Gold Open Access|Scopus|2-s2.0-85107536835
scopus|Rahman T.; Nwokeji J.; Matovu R.; Frezza S.; Sugnanam H.; Pisolkar A.|Rahman, Tajmilur (58714678500); Nwokeji, Joshua (55827999400); Matovu, Richard (57193153070); Frezza, Stephen (6701460244); Sugnanam, Harika (57434759300); Pisolkar, Aparna (57435310500)|58714678500; 55827999400; 57193153070; 6701460244; 57434759300; 57435310500|Analyzing Competences in Software Testing: Combining Thematic Analysis with Natural Language Processing (NLP)|2021|Proceedings - Frontiers in Education Conference, FIE|2021-October||||||7|10.1109/FIE49875.2021.9637220|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123872223&doi=10.1109%2fFIE49875.2021.9637220&partnerID=40&md5=ddeb815b91923c0beb1da2652425ab32|This Full Paper (Research) presents an analysis on the competences in software testing for the fresh graduates in computer science. Software Testing education (ST) is receiving increasing attention in literature, recent studies have evaluated instructional methods used in ST education. However, analysis of competences (skills, knowledge, and ability) required in ST education are lacking in literature. Competences play critical roles in curriculum development e.g., they inform the design of student learning outcomes, learning objectives and program outcomes. This full paper in the research category aims to analyze competences in ST education and then examine the gap between these competences and the current ST curriculum. Using natural language processing (NLP) techniques, we collect 2033 job descriptions from three popular job portals (indeed, monster, and career builder) in the USA and Canada. Also, we collected course syllabi from 20 universities offering ST courses and use these to assess the current curriculum in ST. We analyzed the data using thematic analysis and found that the current software testing curricula do not always teach or equip students with some of the soft skills they require to be successful in software testing career. For instance, our result shows that soft skills such as teamwork, communication, leadership, which are often required by software testing employers are not always taught in ST courses.  © 2021 IEEE.|Competency; Curriculum Development; Software Testing; Testing Skills|Curricula; Employment; Natural language processing systems; Students; 'current; Competency; Curriculum development; Education course; Instructional methods; Paper research; Soft skills; Software testings; Testing skill; Thematic analysis; Software testing|Conference paper|Final||Scopus|2-s2.0-85123872223
scopus|Li S.; Tsai C.-C.; Soenen E.; Lee F.J.C.; Hsieh C.-H.|Li, Shenggao (56098189700); Tsai, Chien-Chun (7404968480); Soenen, Eric (6602466203); Lee, Frank J C (55575070000); Hsieh, Cheng-Hsiang (57141458900)|56098189700; 7404968480; 6602466203; 55575070000; 57141458900|Energy Efficient Design Through Design and Technology Co-Optimization Near the Finish Line of CMOS Scaling|2021|Proceedings - A-SSCC 2021: IEEE Asian Solid-State Circuits Conference|||||||0|10.1109/A-SSCC53895.2021.9634774|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123990907&doi=10.1109%2fA-SSCC53895.2021.9634774&partnerID=40&md5=067bb6f23c6e6c5a803edb7932ab4fb7|Moore's Law (Fig.1) has worked like a self-fulfilled prophecy for over 50 years since Gordon Moore's 1965 prediction of integrated circuits. It sets the pace of the semiconductor industry, including lithography tools, device and material technologies, simulation software, testing equipment, and etc., along an exponential growth line, i.e., transistor density to double every \sim 18 months. The world has seen a transformational change, as exemplified by massive computing and communication capability in data centers, wired/wireless networks, smartphones, wearables, and IoTs, and continued growth in AI, robotics, unmanned vehicles, VR, and many more. Fig.2 is the performance trend of supercomputers, a precursor of future computers, now near the exaFlops line. The most powerful machine has an energy efficiency of 68pJ/Flop. How much can be squeezed?  © 2021 IEEE.||CMOS integrated circuits; Energy efficiency; Integrated circuit design; Semiconductor device manufacture; Supercomputers; Vehicle to vehicle communications; CMOS scaling; Co-optimization; Design and technology; Energy-efficient design; Lithography tools; Moore Law; Semiconductor industry; Tool device; Tool materials; Tool technology; Software testing|Conference paper|Final||Scopus|2-s2.0-85123990907
scopus|Tejo Vinay M.; Lukeshnadh M.; Keerthi Samhitha B.; Mana S.C.; Jose J.|Tejo Vinay, M. (57222082452); Lukeshnadh, M. (57222092520); Keerthi Samhitha, B. (58196961700); Mana, Suja Cherukullapurath (40762048700); Jose, Jithina (57210733868)|57222082452; 57222092520; 58196961700; 40762048700; 57210733868|A Robust and Intelligent Machine Learning Algorithm for Software Testing|2021|Lecture Notes in Electrical Engineering|709|||455|462|7|0|10.1007/978-981-15-8752-8_46|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101373695&doi=10.1007%2f978-981-15-8752-8_46&partnerID=40&md5=f2c95a54602a4c732810a6dc3c02b3c5|In software engineering, the single point is to deliver top notch yield while enhancing the expense and the time expected to finish the application development. To accomplish this objective, software groups will play out the test on their application before live creation. For test automation documentation assumes a critical job. This paper center around mechanize experiment age dependent on accessible test assets, challenges which could be conveyed by methods for orderly practice improvement and characterizing test system for any software application. One noteworthy motivation is to ensure perceptibility among necessities and system experiments. Along these lines, the significance of experiments is dull and testing, especially under time objectives and when there are progressive changes to necessities. Right now, customized test age diminishes the cost of testing just as guarantees that experiments properly spread all necessities, a huge objective in prosperity essential systems and for the measures they need to come. This proposed application guarantees proficient test inclusion of software surrenders, where key usefulness won't be missed in the automatic test absconds expectation. Right now, experiments can be produced after application development completes a component or a lot of highlights. © 2021, Springer Nature Singapore Pte Ltd.|Automation; Component; Deployment; Machine learning; Testing|Application programs; Learning algorithms; Machine learning; Application development; Intelligent machine; Single point; Software applications; Test Automation; Test systems; Software testing|Conference paper|Final||Scopus|2-s2.0-85101373695
scopus|Bai Y.; Xue Z.; Zhang Y.; Wang M.; Ren Y.; Tan J.|Bai, Yang (57217304957); Xue, ZhuXin (57193749685); Zhang, YiYi (57543388300); Wang, MingYu (57544107200); Ren, Yingchao (59273999800); Tan, Jian (57422783600)|57217304957; 57193749685; 57543388300; 57544107200; 59273999800; 57422783600|A method for testing the feasibility of 3D map design based on multi-agent AI-driven|2021|Proceedings - 2021 2nd International Conference on Big Data Economy and Information Management, BDEIM 2021||||429|433|4|1|10.1109/BDEIM55082.2021.00094|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126862453&doi=10.1109%2fBDEIM55082.2021.00094&partnerID=40&md5=3837f542289d2b816fae1c04d613a41a|As one of the most cutting-edge technologies of graphics and multimedia, the core of the three-dimensional map is the spatial layout design of the virtual world. The three-dimensional digital map has significant spatial design significance. It uses a method consistent with geographic theory to integrate the real and the fiction and attach it to various applications such as factory layout, workshop layout, production line planning, and so on. Therefore, the three-dimensional digital map as the spatial background of production and operation to carry various resources is an important part of digital design. Among them, ensuring that the virtual avatar representing a real person can move in an open and feasible space and reach the expected endpoint is an important content of three-dimensional map path planning. To solve the problem of 3D map design level testing, this paper proposes an automated testing method driven by ai multi-agents, which simulates three typical human behaviors and conducts automatic, fast, and comprehensive testing of 3D maps to evaluate the level of 3D map design.  © 2021 IEEE.|component; map design; Multi-agent; test|Behavioral research; Maps; Motion planning; Three dimensional computer graphics; Virtual reality; 3D maps; Component; Cutting edge technology; Digital map; Graphics and multimedias; Map design; Multi agent; Spatial layout; Test; Three-dimensional maps; Multi agent systems|Conference paper|Final||Scopus|2-s2.0-85126862453
scopus||||Proceedings - 2021 IEEE 14th International Conference on Software Testing, Verification and Validation Workshops, ICSTW 2021|2021|Proceedings - 2021 IEEE 14th International Conference on Software Testing, Verification and Validation Workshops, ICSTW 2021||||||300|0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108107294&partnerID=40&md5=e71cb34cad3a6ee67d4db885bae40c31|The proceedings contain 41 papers. The topics discussed include: flaky mutants; another concern for mutation testing; test automation with Grad-CAM heatmaps – a future pipe segment in MLOps for vision AI?; agents for automated user experience testing; prioritized test generation guided by software fault prediction; automatic equivalent mutants classification using abstract syntax tree neural network; an environment for benchmarking combinatorial test suite generators; supervised learning for test suit selection in continuous integration; and an empirical study of parallelizing test execution using CUDA unified memory and OpenMP GPU offloading.|||Conference review|Final||Scopus|2-s2.0-85108107294
scopus|Rosenbauer L.; Pätzel D.; Stein A.; Hähner J.|Rosenbauer, Lukas (57218600362); Pätzel, David (57203392600); Stein, Anthony (56226088700); Hähner, Jörg (20436196300)|57218600362; 57203392600; 56226088700; 20436196300|An Organic Computing System for Automated Testing|2021|Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)|12800 LNCS|||135|149|14|1|10.1007/978-3-030-81682-7_9|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112721892&doi=10.1007%2f978-3-030-81682-7_9&partnerID=40&md5=5e7a3dc6d0cdb201a4fef3ddc7cfd3d3|Testing is a vital part of the development of a new software product. With the rise of test automation, companies more and more rely on large sets of test cases. This leads to situations in which it is unfeasible to run all tests due to a limited time budget which eventually results in the need for selecting an optimal subset of tests to execute. Recently, this test selection problem has been approached using machine learning methods. In this work, we design an Organic Computing (OC) system which makes use of these methods. While OC design techniques have originally been targeted at creating embedded systems, we show that these methodologies can be employed to software verification as well. We are able to demonstrate that the implemented system is a robust and highly autonomous solution which fits modern development practices such as continuous integration well. © 2021, Springer Nature Switzerland AG.|Continuous integration; Organic computing; System architecture; Testing|Budget control; Embedded systems; Software testing; Testing; Verification; Automated testing; Continuous integrations; Design technique; Machine learning methods; Modern development; Organic computing; Software products; Software verification; Learning systems|Conference paper|Final||Scopus|2-s2.0-85112721892
scopus|Htay K.M.; Othman R.R.; Amir A.|Htay, Khin Maung (57209021998); Othman, Rozmie Razif (36873148100); Amir, Amiza (36170326400)|57209021998; 36873148100; 36170326400|Utilization of Gravitational Search Algorithm for Combinatorial T-Way Testing|2021|Journal of Physics: Conference Series|1755|1|12007||||1|10.1088/1742-6596/1755/1/012007|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102413606&doi=10.1088%2f1742-6596%2f1755%2f1%2f012007&partnerID=40&md5=9e5b06ef929158de1a3675db28222f96|Different techniques of software testing are adopted to deal with bugs found in the highly complicated multifunctional software. However, those techniques have difficulty detecting bugs effectively because most of the bugs are triggered by interaction failures between the input parameters and values in the system. Thus, combinatorial t-way testing strategies have come into existence to produce quality minimized test cases, as well as those test cases can cover all the necessary interactions of parameters once at the least. Besides, as t-way testing is considered as an NP-hard problem, new strategies are always welcomed in this research area in pursuit of the optimum test suite. The main point of this paper is to propose the concept of a type of artificial intelligence (AI) algorithm called gravitational search algorithm (GSA) for t-way interaction testing. GSA is a stochastic optimization algorithm inspired by Newton's law of gravity and motion and has been widely applied to figure out optimal solutions to real-world issues. © 2021 Published under licence by IOP Publishing Ltd.||Artificial intelligence; Learning algorithms; NP-hard; Optimization; Program debugging; Well testing; Detecting bugs; Gravitational search algorithm (GSA); Gravitational search algorithms; Input parameter; Interaction testing; Optimal solutions; Stochastic optimization algorithm; T-way testing; Software testing|Conference paper|Final|All Open Access; Gold Open Access|Scopus|2-s2.0-85102413606
scopus|Wehner N.; Seufert M.; Schuler J.; Casas P.; Hossfeld T.|Wehner, Nikolas (57191331741); Seufert, Michael (54930475400); Schuler, Joshua (57221266753); Casas, Pedro (24767317000); Hossfeld, Tobias (57218403122)|57191331741; 54930475400; 57221266753; 24767317000; 57218403122|How are your Apps Doing? QoE Inference and Analysis in Mobile Devices|2021|Proceedings of the 2021 17th International Conference on Network and Service Management: Smart Management for Future Networks and Services, CNSM 2021||||49|55|6|3|10.23919/CNSM52442.2021.9615549|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123415025&doi=10.23919%2fCNSM52442.2021.9615549&partnerID=40&md5=23585a0378876ad96ae8268f77785a54|Web browsing has become the most important application of the Internet for the end user. When it comes to mobile devices, web services are mainly accessed through apps. This paper tackles the problem of Web Quality of Experience (QoE) in mobile devices, with a specific focus on apps QoE monitoring and analysis, using in-network (encrypted) traffic measurements. Measuring apps QoE is complex, not only from an instrumentation point of view, but also from the heterogeneity of user interactions which might realize substantially different user experience. To this end, we conduct a feasibility study on four specific and popular Android apps and their corresponding web services. Our test automation framework emulates and measures different user interactions commonly executed during an app session, including the app startup, clicking, scrolling, and searching. The resulting traffic is characterized on different dimensions, and machine learning models are trained to identify web services, apps, and user interactions, and to infer their QoE. The proposed models can correctly identify the specific web service and app in 86% of the cases and accurately estimate the associated QoE with small errors. Our preliminary study represents a first step towards an in-network, web QoE monitoring solution for mobile-device apps.  © 2021 IFIP.|Apps; Encryption; Machine Learning; QoE|Cryptography; E-learning; Machine learning; Quality control; Web services; Websites; Encrypted traffic; End-users; Feasibility studies; In networks; Machine-learning; Monitoring and analysis; Traffic measurements; User interaction; Users' experiences; Web quality; Quality of service|Conference paper|Final|All Open Access; Green Open Access|Scopus|2-s2.0-85123415025
scopus||||3rd EAI International Conference on Multimedia Technology and Enhanced Learning, ICMTEL 2021|2021|Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering, LNICST|388|||||1084|0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115852257&partnerID=40&md5=6ba6a766927f685aa49824b08892ba72|The proceedings contain 97 papers. The special focus in this conference is on Multimedia Technology and Enhanced Learning. The topics include: Research on the Method of Eliminating Duplicated Encrypted Data in Cloud Storage Based on Generated Countermeasure Network; design of Distributed Hybrid Pipeline Multimedia Aided Scheduling System; intelligent Scheduling of Distributed Displacement Pipeline Based on Hybrid Discrete Drosophila Optimization Algorithm; research on Grid Planning Method of Distribution Network Based on Artificial Intelligence Technology; intelligent Monitoring Method for Backstage Data Security of Tourism Information Promotion Platform Based on Cloud Computing; preface; research on Multithreaded Data Scheduling Control Method for Power Communication Based on Wireless Sensor; research on Industrial Product Modeling Design Method Based on Deep Learning; a Frequency Conversion Circuit for Piezoelectric Vibrating Energy Harvesting; an Adaptive Optimization Strict Reverse Navigation Algorithm for Ship Fine Alignment Process; research on Load Feature Extraction Method of Typical Users Based on Deep Learning; enterprise Financial Risk Early Warning System Based on Catastrophe Progression Method; research on Transportation Route Planning Method of Regional Logistics Network Based on Transfer Learning; simultaneous Localization of Multiple Defects in Software Testing Based on Reinforcement Learning; Design of Embedded Network Human Machine Interface Based on VR Technology; Design of Information Security System Based on JSP Technology and Reinforcement Model; sliding Mode Adaptive Control for Sensorless Permanent Magnet Synchronous Motor; recognition Method of Metal Material Pitting Defect Based on Visual Signal Processing; an Improved Detection Method of Safety Helmet Wearing Based on CenterNet; influence Maximization Based on True Threshold in Social Networks; arabic Question-Answering System Using Search Engine Techniques.|||Conference review|Final||Scopus|2-s2.0-85115852257
scopus||||4th International Conference on Applied Informatics, ICAI 2021|2021|Communications in Computer and Information Science|1455 CCIS|||||512|0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119007654&partnerID=40&md5=6a77520cbda122ce25e4f8220b158074|The proceedings contain 35 papers. The special focus in this conference is on Applied Informatics. The topics include: A Supervised Approach to Credit Card Fraud Detection Using an Artificial Neural Network; comparison of Heart Rate Variability Analysis with Empirical Mode Decomposition and Fourier Transform; evalu@ + Sports. Creatine Phosphokinase and Urea in High-Performance Athletes During Competition. a Framework for Predicting Injuries Caused by Fatigue; heart Rate Variability: Validity of Autonomic Balance Indicators in Ultra-Short Recordings; An Improved Machine Learnings Diagnosis Technique for COVID-19 Pandemic Using Chest X-ray Images; evaluation of Local Thresholding Algorithms for Segmentation of White Matter Hyperintensities in Magnetic Resonance Images of the Brain; super-Resolution Algorithm Applied in the Zoning of Aerial Images; an Enhanced Lightweight Speck System for Cloud-Based Smart Healthcare; hybrid Algorithm for Symmetric Based Fully Homomorphic Encryption; Information Encryption and Decryption Analysis, Vulnerabilities and Reliability Implementing the RSA Algorithm in Python; Optimization of Multi-level HEED Protocol in Wireless Sensor Networks; machine Learning Classification Based Techniques for Fraud Discovery in Credit Card Datasets; LiDAR and Camera Data for Smart Urban Traffic Monitoring: Challenges of Automated Data Capturing and Synchronization; mobility in Smart Cities: Spatiality of the Travel Time Indicator According to Uses and Modes of Transportation; preliminary Studies of the Security of the Cyber-Physical Smart Grids; enterprise Modeling: A Multi-perspective Tool-Supported Approach; architectural Approach for Google Services Integration; proposal to Improve Software Testing in Small and Medium Enterprises; object Detection Based Software System for Automatic Evaluation of Cursogramas Images; solar Radiation Prediction Using Machine Learning Techniques.|||Conference review|Final||Scopus|2-s2.0-85119007654
scopus|Jin C.|Jin, Cong (8704560000)|8704560000|Cross-project software defect prediction based on domain adaptation learning and optimization|2021|Expert Systems with Applications|171||114637||||62|10.1016/j.eswa.2021.114637|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100588747&doi=10.1016%2fj.eswa.2021.114637&partnerID=40&md5=68d1f964aa6187d44c3844792ae7a45e|Software defect prediction (SDP) is very helpful for optimizing the resource allocation of software testing and improving the quality of software products. The cross-project defect prediction (CPDP) model based on machine learning is first learned through the existing training data with sufficient number and defect labels on one project, and then used to predict the defect labels of another new project with insufficient number and fewer labeled data. However, its prediction performance has a large gap compared with the within-project defect prediction (WPDP) model. The main reason is that there are usually differences between the distributions of training data in different software projects, and it has a greater impact on the prediction performance of the CPDP model. To solve this problem, the kernel twin support vector machines (KTSVMs) is used to implement domain adaptation (DA) to match the distributions of training data for different projects. Moreover, KTSVMs with DA function (called DA-KTSVM) is further used as the CPDP model in this paper. Since the parameters of DA-KTSVM have an impact on its predictive performance, these parameters are optimized by an improved quantum particle swarm optimization algorithm (IQPSO), and the optimized DA-KTSVM is called as DA-KTSVMO. In order to confirm the effectiveness of DA-KTSVMO, some experiments are implemented on 17 open source software projects. Experimental results and analysis show that DA-KTSVMO can not only achieve better prediction performance than other CPDP models compared, but also achieve almost the same or better compared performance than WPDP models when the training sample data is sufficient. In addition, DA-KTSVMO can make better use of existing sufficient data knowledge and realize the reuse of defective data to improve the prediction performance of DA-KTSVMO. © 2021 Elsevier Ltd|Cross-project defect prediction; Domain adaptation; Improved quantum particle swarm optimization; Optimization; Software defect prediction|Defects; Forecasting; Open systems; Particle swarm optimization (PSO); Software quality; Software testing; Support vector machines; Domain adaptation learning; Open source software projects; Prediction performance; Predictive performance; Quality of softwares; Quantum particle swarm optimization algorithm; Software defect prediction; Twin support vector machines; Open source software|Article|Final||Scopus|2-s2.0-85100588747
scopus|Chen H.; Huang S.; Liu Y.; Luo R.; Xie Y.|Chen, Hao (57221501982); Huang, Song (55608828500); Liu, Yuchan (57221502711); Luo, Run (57222903121); Xie, Yifei (58062856700)|57221501982; 55608828500; 57221502711; 57222903121; 58062856700|An Effective Crowdsourced Test Report Clustering Model Based on Sentence Embedding|2021|IEEE International Conference on Software Quality, Reliability and Security, QRS|2021-December|||888|899|11|6|10.1109/QRS54544.2021.00098|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146197401&doi=10.1109%2fQRS54544.2021.00098&partnerID=40&md5=de8b584f72d7a73a41b53026379d965e|In the crowdsourced testing industry, efficient and automated classification of true bugs from test reports can greatly reduce the cost of software testing. Most of the existing methods are based on TF-IDF or machine learning methods to vectorize the test report and then construct a classifier. However, the document vector constructed by keywords more or less ignores the description information in the document, which affects the performance of classification and detection of real defects. In order to use the description information to construct an effective report clustering model, we propose a model called RCSE to encode test report description information at the sentence level, calculate the similarity between the test reports from the feature similarity of the description sentence, then cluster the test report. We evaluated the model on 3,442 reports. The experimental results show that the clustering model based on sentence embedding has an average purity of 12.3 % and an ARI of 22.0% higher than the keyword-based model on three report datasets. © 2021 IEEE.|clustering; crowdsourced testing; deep learning; sentence embedding|Classification (of information); Cluster analysis; Crowdsourcing; Deep learning; Embeddings; Information retrieval systems; Program debugging; Software testing; Clustering model; Clusterings; Crowdsourced testing; Deep learning; Description information; Embeddings; Industry classification; Model-based OPC; Sentence embedding; Test reports; Testing|Conference paper|Final||Scopus|2-s2.0-85146197401
scopus|Singh M.; Chhabra J.K.|Singh, Manpreet (59586998100); Chhabra, Jitender Kumar (6701779304)|59586998100; 6701779304|Software Fault Prediction Using Machine Learning Models and Comparative Analysis|2021|Communications in Computer and Information Science|1395 CCIS|||30|45|15|0|10.1007/978-981-16-1480-4_3|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107389489&doi=10.1007%2f978-981-16-1480-4_3&partnerID=40&md5=1803d610f2a6dc0b9b98680633d0b878|Software Testing is an important phase of Software Development Life cycle. Effective software testing helps in identifying faulty modules, but this process becomes very time consuming, especially for large /complex software. Moreover early identification of error prone modules can be useful in producing better quality software. Hence software fault prediction has gained significant attention of the researchers in the recent years. Mainly two types of techniques are being used for it: statistical methods and Machine learning models, out of which recent trend is more inclined towards machine Learning based techniques. Identification of faulty modules is a binary classification problem and machine learning models such as Decision Tree and its variants, Random Forest and Support Vector Machine, are best suited for the fault prediction. This paper attempts to predict software faults using four different classification models. Further, the performance evaluation of these models is also carried out in this paper using accuracy, Precision, Recall, F1-Score and execution time of over 12 datasets, extracted from one of the most commonly used PROMISE repository. Based on these performance metrics comparison of applied four models is done and our comparative analysis indicates that in most of the cases Support Vector Machine model is able to predict software faults more efficiently than the rest in terms of accuracy as well as execution time © 2021, Springer Nature Singapore Pte Ltd.||Binary trees; Decision trees; Forecasting; Life cycle; Predictive analytics; Software design; Software quality; Software testing; Support vector machines; Binary classification problems; Classification models; Comparative analysis; Machine learning models; Performance metrics; Software development life cycle; Software fault prediction; Support vector machine models; Learning systems|Conference paper|Final||Scopus|2-s2.0-85107389489
scopus|Zhang W.; Jiao C.; Zhou Q.; Liu Y.; Xu T.|Zhang, Wenning (37011746800); Jiao, Chongyang (57224473210); Zhou, Qinglei (24451497400); Liu, Yang (57361315700); Xu, Ting (57224466586)|37011746800; 57224473210; 24451497400; 57361315700; 57224466586|Gender-Based Deep Learning Firefly Optimization Method for Test Data Generation|2021|Computational Intelligence and Neuroscience|2021||8056225||||5|10.1155/2021/8056225|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107642234&doi=10.1155%2f2021%2f8056225&partnerID=40&md5=5d22d119401e17636cc6810d65ee5671|Software testing is a widespread validation means of software quality assurance in industry. Intelligent optimization algorithms have been proved to be an effective way of automatic test data generation. Firefly algorithm has received extensive attention and been widely used to solve optimization problems because of less parameters and simple implement. To overcome slow convergence rate and low accuracy of the firefly algorithm, a novel firefly algorithm with deep learning is proposed to generate structural test data. Initially, the population is divided into male subgroup and female subgroup. Following the randomly attracted model, each male firefly will be attracted by another randomly selected female firefly to focus on global search in whole space. Each female firefly implements local search under the leadership of the general center firefly, constructed based on historical experience with deep learning. At the final period of searching, chaos search is conducted near the best firefly to improve search accuracy. Simulation results show that the proposed algorithm can achieve better performance in terms of success coverage rate, coverage time, and diversity of solutions.  © 2021 Wenning Zhang et al.||Algorithms; Computer Simulation; Deep Learning; Female; Humans; Male; Software; Bioluminescence; Computer software selection and evaluation; Optimization; Quality assurance; Software quality; Software testing; Test facilities; Automatic test data generation; Diversity of solutions; Firefly algorithms; Historical experience; Intelligent optimization algorithm; Optimization method; Optimization problems; Test data generation; algorithm; computer simulation; female; human; male; software; Deep learning|Article|Final|All Open Access; Gold Open Access; Green Open Access|Scopus|2-s2.0-85107642234
scopus|Patrício C.; Pinto R.; Marques G.|Patrício, Cristiano (57211345557); Pinto, Rui (57217738073); Marques, Gonçalo (57571376300)|57211345557; 57217738073; 57571376300|A Study on Software Testing Standard Using ISO/IEC/IEEE 29119-2: 2013|2021|Studies in Systems, Decision and Control|295|||43|62|19|2|10.1007/978-3-030-47411-9_3|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087572220&doi=10.1007%2f978-3-030-47411-9_3&partnerID=40&md5=83f1e680c169c395dc8e36389d17cd7b|ISO/IEC/IEEE 29119 is an internationally agreed set of standards for software testing that must be adopted during all software development processes and incorporated by every software company when conducting every software testing development. This article presents a study on ISO/IEC/IEEE 29119 standard, focusing on the description of a three-layer process model that covers: (1) organizational test specifications; (2) test management and (3) dynamic testing. Therefore, a comprehensive survey has been done to summarise and analyse the intended purpose of the implementation and adoption of this software testing standard. Furthermore, this paper also states the added value related to the implementation of this standard for any organisation in terms of software quality assurance. The adoption of software testing processes is an essential part of the software development that must be included in every development project, in particular, considering the artificial intelligence software development. The costs associated are relatively high. However, the cost associated with the treatment of bugs and software problems is even higher. © 2021, Springer Nature Switzerland AG.|ISO standard; ISO/IEC/IEEE 29119-2; Software testing||Book chapter|Final||Scopus|2-s2.0-85087572220
scopus||||Proceedings - 2021 21st International Conference on Software Quality, Reliability and Security, QRS 2021|2021|IEEE International Conference on Software Quality, Reliability and Security, QRS|2021-December|||||1136|0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146198210&partnerID=40&md5=bad3e3d86ab74f02f3d3b4808dec1051|The proceedings contain 108 papers. The topics discussed include: analyzing structural security posture to evaluate system design decisions; CTSCOPY: hunting cyber threats within enterprise via provenance graph-based analysis; dynamic interval-based watermarking for tracking down network attacks; explainable apt attribution for malware using NLP techniques; impact of datasets on machine learning based methods in android malware detection: an empirical study; strategies for reducing traffic volume and security on smart grid; a framework for progressive regression testing PLC programs; a tool to support vibration testing method for automatic test case generation and test result analysis; an empirical study on test case prioritization metrics for deep neural networks; analysis of road representations in search-based testing of autonomous driving systems; application of combinatorial testing to quantum programs; automated testing of android applications integrating residual network and deep reinforcement learning; and evaluating and improving static analysis tools via differential mutation analysis.|||Conference review|Final||Scopus|2-s2.0-85146198210
scopus|Sunil S.; Sonu P.; Sarath S.; Rahul Nath R.; Viswan V.|Sunil, Sharath (57337168600); Sonu, P. (57336747000); Sarath, S. (57396852800); Rahul Nath, R. (57336475300); Viswan, Vivek (57336333700)|57337168600; 57336747000; 57396852800; 57336475300; 57336333700|An Effective Approach for Classifying Acute Lymphoblastic Leukemia Using Hybrid Hierarchical Classifiers|2021|Communications in Computer and Information Science|1440 CCIS|||151|161|10|3|10.1007/978-3-030-81462-5_14|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118983275&doi=10.1007%2f978-3-030-81462-5_14&partnerID=40&md5=7d56001ac640357ff0c9c45652106410|Acute Lymphoblastic Leukemia is an anomaly that affects White Blood Cells. This type of cancer occurs when there is an error in blood cell DNA. Children are prone to this type of cancer. After the initial stages, it spreads to other organs like the liver and spleen. The problem with this type of cancer is that, unlike other forms of cancer, it doesn’t cause any tumors hence it is very hard to detect. Manual testing methods were used before the automation, but it was time-consuming and very much prone to errors. To solve that problem, automated testing methods were introduced. Different systems [1, 3, 4] were introduced in the past, but most of them have variable accuracies. These Automated Systems [1, 3, 4] used image processing and unsupervised machine learning techniques to classify the images into cancerous and healthy. The proposed system uses Hybrid Hierarchical Classifiers to classify the cancer cells, which will be an improvement over the previous systems and solves the problem of variable accuracies. © 2021, Springer Nature Switzerland AG.|Acute lymphoblastic leukemia; Hybrid hierarchical classifiers; Image processing; Machine learning; Medical image analysis|Automation; Blood; Cells; Hierarchical systems; Image classification; Machine learning; Medical imaging; Testing; Acute lymphoblastic leukaemias; Blood cells; Effective approaches; Hierarchical classifiers; Hybrid hierarchical classifier; Images processing; Manual testing; Medical image analysis; Testing method; White blood cells; Diseases|Conference paper|Final||Scopus|2-s2.0-85118983275
scopus|Bahaweres R.B.; Imam Suroso A.; Wahyu Hutomo A.; Permana Solihin I.; Hermadi I.; Arkeman Y.|Bahaweres, Rizal Broer (55625202600); Imam Suroso, Arif (53864020700); Wahyu Hutomo, Alam (57222290681); Permana Solihin, Indra (57222292051); Hermadi, Irman (23967933100); Arkeman, Yandra (55946558300)|55625202600; 53864020700; 57222290681; 57222292051; 23967933100; 55946558300|Tackling Feature Selection Problems with Genetic Algorithms in Software Defect Prediction for Optimization|2020|Proceedings - 2nd International Conference on Informatics, Multimedia, Cyber, and Information System, ICIMCIS 2020|||9354282|64|69|5|15|10.1109/ICIMCIS51567.2020.9354282|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102188506&doi=10.1109%2fICIMCIS51567.2020.9354282&partnerID=40&md5=6d755fddf91b9ca9b0c7ac306db36f91|Software defect prediction is a way to improve quality by finding and tracking defective modules in the software which helps reduce costs during the software testing process. The use of machine learning methods for predicting software defects can be applied to predict defects in each software module. However, basically the software defect prediction dataset has two problems, namely class imbalance with very few defective modules compared to non-defective modules and contains noisy attributes due to irrelevant features. With these two problems, it will result in overfitting and lead to biased classification results so that it will have an impact on significantly reducing the performance of the machine learning model. In this study, we propose the implementation of bagging techniques and genetic algorithms to improve the classification performance of machine learning models in predicting software defects based Logistic Regression, Naive Bayes, SVM, KNN, Decision Tree. Bagging techniques and Genetic algorithms are approaches that can handle two main problems in software defects prediction, each of which can handle the class imbalance and feature selection problem. We used 6 NASA Promise datasets to evaluate the classification performance results based on AUC and G-Means values. The results using 10 cross-validations show that the proposed method can improve classification performance when compared to the original algorithm. The Decision Tree shows the highest performance of the 3 datasets tested, with the highest value of 94.61 % on the KC4 dataset. We also compare GA performance with another natural algorithm, Particle Swarm Optimization (PSO). The results show that the performance of all machine learning models with GA can outperform the algorithms with PSO. © 2020 IEEE.|Bagging; Class Imbalance; Feature Selection; Genetic Algorithm; Particle Swarm Optimization; Software Defect Prediction|Classification (of information); Decision trees; Defects; Feature extraction; Forecasting; Information systems; Information use; Learning algorithms; Learning systems; Logistic regression; NASA; Particle swarm optimization (PSO); Software testing; Support vector machines; Classification performance; Classification results; Feature selection problem; Machine learning methods; Machine learning models; Original algorithms; Software defect prediction; Software modules; Genetic algorithms|Conference paper|Final||Scopus|2-s2.0-85102188506
scopus|Kesri V.; Nayak A.; Ponnalagu K.|Kesri, Vaibhav (57214223297); Nayak, Anmol (57190669389); Ponnalagu, Karthikeyan (56724735600)|57214223297; 57190669389; 56724735600|AutoKG - An automotive domain knowledge graph for software testing: A position paper|2021|Proceedings - 2021 IEEE 14th International Conference on Software Testing, Verification and Validation Workshops, ICSTW 2021|||9440180|234|238|4|10|10.1109/ICSTW52544.2021.00047|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108021658&doi=10.1109%2fICSTW52544.2021.00047&partnerID=40&md5=1ca3f1540a1e7c0912803defe84e593d|Industries have a significant amount of data in semi-structured and unstructured formats which are typically captured in text documents, spreadsheets, images, etc. This is especially the case with the software description documents used by domain experts in the automotive domain to perform tasks at various phases of the Software Development Life Cycle (SDLC). In this paper, we propose an end-to-end pipeline to extract an Automotive Knowledge Graph (AutoKG) from textual data using Natural Language Processing (NLP) techniques with the application of automatic test case generation. The proposed pipeline primarily consists of the following components: 1) AutoOntology, an ontology that has been derived by analyzing several industry scale automotive domain software systems, 2) AutoRE, a Relation Extraction (RE) model to extract triplets from various sentence types typically found in the automotive domain, and 3) AutoVec, a neural embedding based algorithm for triplet matching and context-based search. We demonstrate the pipeline with an application of automatic test case generation from requirements using AutoKG.  © 2021 IEEE.|Automotive Domain Knowledge Graph; Natural Language Processing; Software Testing|Knowledge representation; Life cycle; Natural language processing systems; Pipelines; Software design; Verification; Automatic test-case generations; Automotive domains; Context-based search; Knowledge graphs; NAtural language processing; Relation extraction; Software description; Software development life cycle; Software testing|Conference paper|Final||Scopus|2-s2.0-85108021658
scopus||||1st International Conference on Machine Learning, Internet of Things and Big Data, ICMIB 2020|2021|Lecture Notes in Networks and Systems|185 LNNS|||||572|0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105910291&partnerID=40&md5=29a5b1c1d11b1f08a6bf056cae07526e|The proceedings contain 49 papers. The special focus in this conference is on Machine Learning, Internet of Things and Big Data. The topics include: Multi-agent System of Autonomous Underwater Vehicles in Octagon Formation; fuzzy Q-Reinforcement Learning-Based Energy Optimization in IoT Network; A Circumstantial Methodological Analysis of Recent Studies on NLP-driven Test Automation Approaches; plant Disease Recognition from Leaf Images Using Convolutional Neural Network; Optimum Design of Profile Modified Spur Gear Using PSO; benchmark of Unsupervised Machine Learning Algorithms for Condition Monitoring; Investigation of the Efficiency for Fuzzy Logic-Based MPPT Algorithm Dedicated for Standalone Low-Cost PV Systems; distributed Channel Assignment in Cognitive-Radio Enabled Internet of Vehicles; Low-Cost Smart Solar DC Nano-Grid for Isolated Rural Electrification: Cyber-Physical System Design and Implementation; load Reduction Using Temporal Modeling and Prediction in Periodic Sensor Networks; Direct Torque Control of Mathematically Modeled Induction Motor Drive Using PI-Type-I Fuzzy Logic Controller and Sliding Mode Controller; measuring the Performance of a Model Semantic Knowledge-Base for Automation of Commonsense Reasoning; COVID-19 Detection and Prediction Using Chest X-Ray Images; automated Precision Irrigation System Using Machine Learning and IoT; UHWSF: Univariate Holt Winter’s Based Store Sales Forecasting; a Nature-Inspired-Based Multi-objective Service Placement in Fog Computing Environment; advanced Binary Matrix-Based Frequent Pattern Mining Algorithm; sentiment Analysis Using Semi Supervised Machine Learning Technique; unconstrained Optimization Technique in Wireless Sensor Network for Energy Efficient Clustering; Global Path Optimization of Humanoid NAO in Static Environment Using Prim’s Algorithm; a Smartphone App Based Model for Classification of Users and Reviews (A Case Study for Tourism Application).|||Conference review|Final||Scopus|2-s2.0-85105910291
scopus|Spieker H.; Gotlieb A.|Spieker, Helge (57189329650); Gotlieb, Arnaud (56247674500)|57189329650; 56247674500|Adaptive metamorphic testing with contextual bandits|2020|Journal of Systems and Software|165||110574||||27|10.1016/j.jss.2020.110574|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082018209&doi=10.1016%2fj.jss.2020.110574&partnerID=40&md5=1bba19d8ad9ed4a856cca7eb1be80621|Metamorphic Testing is a software testing paradigm which aims at using necessary properties of a system under test, called metamorphic relations, to either check its expected outputs, or to generate new test cases. Metamorphic Testing has been successful to test programs for which a full oracle is not available or to test programs for which there are uncertainties on expected outputs such as learning systems. In this article, we propose Adaptive Metamorphic Testing as a generalization of a simple yet powerful reinforcement learning technique, namely contextual bandits, to select one of the multiple metamorphic relations available for a program. By using contextual bandits, Adaptive Metamorphic Testing learns which metamorphic relations are likely to transform a source test case, such that it has higher chance to discover faults. We present experimental results over two major case studies in machine learning, namely image classification and object detection, and identify weaknesses and robustness boundaries. Adaptive Metamorphic Testing efficiently identifies weaknesses of the tested systems in context of the source test case. © 2020 Elsevier Inc.|Contextual bandits; Machine learning; Metamorphic testing; Software testing|Learning systems; Object detection; Reinforcement learning; Testing; Case-studies; Contextual bandits; In contexts; Metamorphic relations; Metamorphic testing; Reinforcement learning techniques; System under test; Test program; Software testing|Article|Final|All Open Access; Green Open Access|Scopus|2-s2.0-85082018209
scopus|Zhang X.; Xie X.; Ma L.; Du X.; Hu Q.; Liu Y.; Zhao J.; Sun M.|Zhang, Xiyue (57194007361); Xie, Xiaofei (55268560900); Ma, Lei (55479591700); Du, Xiaoning (57207130233); Hu, Qiang (57216121087); Liu, Yang (56911879800); Zhao, Jianjun (35786932000); Sun, Meng (53983437100)|57194007361; 55268560900; 55479591700; 57207130233; 57216121087; 56911879800; 35786932000; 53983437100|Towards characterizing adversarial defects of deep learning software from the lens of uncertainty|2020|Proceedings - International Conference on Software Engineering|||3380368|739|751|12|57|10.1145/3377811.3380368|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091918936&doi=10.1145%2f3377811.3380368&partnerID=40&md5=53b0054266a1e0b5957b3ef89234c823|Over the past decade, deep learning (DL) has been successfully applied to many industrial domain-specific tasks. However, the current state-of-the-art DL software still suffers from quality issues, which raises great concern especially in the context of safety- and security-critical scenarios. Adversarial examples (AEs) represent a typical and important type of defects needed to be urgently addressed, on which a DL software makes incorrect decisions. Such defects occur through either intentional attack or physical-world noise perceived by input sensors, potentially hindering further industry deployment. The intrinsic uncertainty nature of deep learning decisions can be a fundamental reason for its incorrect behavior. Although some testing, adversarial attack and defense techniques have been recently proposed, it still lacks a systematic study to uncover the relationship between AEs and DL uncertainty. In this paper, we conduct a large-scale study towards bridging this gap. We first investigate the capability of multiple uncertainty metrics in differentiating benign examples (BEs) and AEs, which enables to characterize the uncertainty patterns of input data. Then, we identify and categorize the uncertainty patterns of BEs and AEs, and find that while BEs and AEs generated by existing methods do follow common uncertainty patterns, some other uncertainty patterns are largely missed. Based on this, we propose an automated testing technique to generate multiple types of uncommon AEs and BEs that are largely missed by existing techniques. Our further evaluation reveals that the uncommon data generated by our method is hard to be defended by the existing defense techniques with the average defense success rate reduced by 35%. Our results call for attention and necessity to generate more diverse data for evaluating quality assurance solutions of DL software.  © 2020 Association for Computing Machinery.|Adversarial attack; Deep learning; Software testing; Uncertainty|Defects; Network security; Quality assurance; Software quality; Testing; Automated testing; Defense techniques; Intentional Attacks; Large-scale studies; Learning software; Safety and securities; State of the art; Systematic study; Deep learning|Conference paper|Final|All Open Access; Green Open Access|Scopus|2-s2.0-85091918936
scopus|Wang Z.; Yan M.; Liu S.; Chen J.-J.; Zhang D.-D.; Wu Z.; Chen X.|Wang, Zan (35216436800); Yan, Ming (56307496100); Liu, Shuang (57221491904); Chen, Jun-Jie (57145642900); Zhang, Dong-Di (57204638958); Wu, Zhuo (57217176709); Chen, Xiang (57189091783)|35216436800; 56307496100; 57221491904; 57145642900; 57204638958; 57217176709; 57189091783|Survey on Testing of Deep Neural Networks; [深度神经网络测试研究综述]|2020|Ruan Jian Xue Bao/Journal of Software|31|5||1255|1275|20|31|10.13328/j.cnki.jos.005951|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086626717&doi=10.13328%2fj.cnki.jos.005951&partnerID=40&md5=6b1989213f450a9cb3d65354f99dd5aa|With the rapid development of deep neural networks, the emerging of big data as well as the advancement of computational power, Deep Neural Network (DNN) has been widely applied in various safety-critical domains such as autonomous driving, automatic face recognition, and aircraft collision avoidance systems. Traditional software systems are implemented by developers with carefully designed programming logics and tested with test cases which are designed based on specific coverage criteria. Unlike traditional software development, DNN defines a data-driven programming paradigm, i.e., developers only design the structure of networks and the inner logic is reflected by weights which are learned during training. Traditional software testing methods cannot be applied to DNN directly. Driven by the emerging demand, more and more research works have focused on testing of DNN, including proposing new testing evaluation criteria, generation of test cases, etc. This study provides a thorough survey on testing DNN, which summarizes 92 works from related fields. These works are systematically reviewed from three perspectives, i.e., DNN testing metrics, test input generation, and test oracle. Existing achievements are introduced in terms of image processing, speech processing, and natural language processing. The datasets and tools used in DNN testing are surveyed and finally the thoughts on potential future research directions are summarized on DNN testing, which, hopefully, will provide references for researchers interested in the related directions. © Copyright 2020, Institute of Software, the Chinese Academy of Sciences. All rights reserved.|Deep neural network; Test case generation; Test coverage|Aircraft accidents; Computation theory; Face recognition; Natural language processing systems; Software design; Software testing; Speech processing; Surveys; Testing; Training aircraft; Aircraft collision avoidance systems; Automatic face recognition; Computational power; Future research directions; NAtural language processing; Programming paradigms; Safety-critical domain; Testing evaluation; Deep neural networks|Review|Final||Scopus|2-s2.0-85086626717
scopus|Xinxin H.; Kerong B.; Xian Z.|Xinxin, Han (57208319282); Kerong, Ben (26423587800); Xian, Zhang (58923739300)|57208319282; 26423587800; 58923739300|Research on Named Entity Recognition Technology in Military Software Testing; [军用软件测试领域的命名实体识别技术研究]|2020|Journal of Frontiers of Computer Science and Technology|14|5||740|748|8|7|10.3778/j.issn.1673-9418.1906031|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105739486&doi=10.3778%2fj.issn.1673-9418.1906031&partnerID=40&md5=72814c9d214e5c49e4e748c8a1fa4be7|Named entity recognition is an important stage in the construction of knowledge graph. Based on the national military standard and software testing documents, the entity type classification and the data set construction and labeling are completed. In the field of software testing, aiming at the problem that the character and word joint entity recognition method has low recognition precision, the character level feature extraction method is improved, and the CWA- BiLSTM- CRF (character and word attention- bi- directional long short term memory- conditional random field) recognition framework is proposed. The framework consists of two parts: the first part constructs a pre- trained word fusion dictionary, inputs the words and characters together to the bi- directional long short term memory network for training, and adds attention mechanism to measure the semantic contribution of each character in the word to extract the character-level features; the second part, the character-level features and word vectors are spliced, input to the bi- directional long short term memory network for training, and then through the conditional random field to solve the problem of unreasonable sequence of label results, the entities in the text are identified. The experimental results are compared with 3 commonly used deep learning character- level feature extraction methods. Both accuracy and recall rates are improved, and the optimal F1 value is 88.93%. Experiments show that the improved method is suitable for the named entity recognition task in the military software testing field, which lays the foundation for the next construction of the knowledge graph. © 2020 Journal of Computer Engineering and Applications Beijing Co., Ltd.; Science Press. All rights reserved.|bi-directional long short term memory (BiLSTM); conditional random field (CRF); knowledge graph; named entity recognition; software testing||Article|Final||Scopus|2-s2.0-85105739486
scopus|Ahmad J.; Baharom S.; Ghani A.A.A.; Zulzalil H.; Din J.|Ahmad, Johanna (57193720009); Baharom, Salmi (25645797800); Ghani, Abdul Azim Abd (55441496400); Zulzalil, Hazura (25825821100); Din, Jamilah (39861316500)|57193720009; 25645797800; 55441496400; 25825821100; 39861316500|Towards prioritize event sequence test cases using machine learning approach|2020|Journal of Advanced Research in Dynamical and Control Systems|12|7 Special Issue||1642|1647|5|0|10.5373/JARDCS/V12SP7/20202269|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088803798&doi=10.5373%2fJARDCS%2fV12SP7%2f20202269&partnerID=40&md5=8d3e1d37ff126d7133b1016701ddbf50|Testing is one of the crucial phases in software development cycle. Without a proper plan, failure to deliver the product to the customer on time might happen. Furthermore, increasing cost, resources and time to test might also increase due to failure to plan the testing phase. Due to that reason, number of techniques has been proposed to increase the effectiveness of testing, and test case prioritization is one of it. In previous research, the researchers combined 6 factors to prioritize event sequence test cases. Realizing machine learning is one of the new approaches in software testing, the researchers apply naïve bayes approach into the pairwise events. The naïve bayes will calculate the probability for each of test case. The details of how the prioritization process after the implementation of naïve bayes will be explain in future research since this is ongoing research since 2015. © 2020, Institute of Advanced Scientific Research, Inc. All rights reserved.|Event Sequence; Machine Learning; Prioritize; Software Testing||Article|Final||Scopus|2-s2.0-85088803798
scopus|Garousi V.; Bauer S.; Felderer M.|Garousi, Vahid (13408954200); Bauer, Sara (57216844923); Felderer, Michael (24832720900)|13408954200; 57216844923; 24832720900|NLP-assisted software testing: A systematic mapping of the literature|2020|Information and Software Technology|126||106321||||58|10.1016/j.infsof.2020.106321|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084949953&doi=10.1016%2fj.infsof.2020.106321&partnerID=40&md5=0ff581bcf04c671a8156eb239a1d8a58|Context: To reduce manual effort of extracting test cases from natural-language requirements, many approaches based on Natural Language Processing (NLP) have been proposed in the literature. Given the large amount of approaches in this area, and since many practitioners are eager to utilize such techniques, it is important to synthesize and provide an overview of the state-of-the-art in this area. Objective: Our objective is to summarize the state-of-the-art in NLP-assisted software testing which could benefit practitioners to potentially utilize those NLP-based techniques. Moreover, this can benefit researchers in providing an overview of the research landscape. Method: To address the above need, we conducted a survey in the form of a systematic literature mapping (classification). After compiling an initial pool of 95 papers, we conducted a systematic voting, and our final pool included 67 technical papers. Results: This review paper provides an overview of the contribution types presented in the papers, types of NLP approaches used to assist software testing, types of required input requirements, and a review of tool support in this area. Some key results we have detected are: (1) only four of the 38 tools (11%) presented in the papers are available for download; (2) a larger ratio of the papers (30 of 67) provided a shallow exposure to the NLP aspects (almost no details). Conclusion: This paper would benefit both practitioners and researchers by serving as an “index” to the body of knowledge in this area. The results could help practitioners utilizing the existing NLP-based techniques; this in turn reduces the cost of test-case design and decreases the amount of human resources spent on test activities. After sharing this review with some of our industrial collaborators, initial insights show that this review can indeed be useful and beneficial to practitioners. © 2020 Elsevier B.V.|Natural Language Processing (NLP); Software testing; Systematic literature mapping; Systematic literature review|Mapping; Natural language processing systems; Body of knowledge; Industrial collaborators; Large amounts; NAtural language processing; Natural language requirements; Review papers; State of the art; Systematic mapping; Software testing|Review|Final|All Open Access; Green Open Access|Scopus|2-s2.0-85084949953
scopus|Olszewska J.I.|Olszewska, J.I. (55623356800)|55623356800|Ai-t: Software testing ontology for ai-based systems|2020|IC3K 2020 - Proceedings of the 12th International Joint Conference on Knowledge Discovery, Knowledge Engineering and Knowledge Management|2|||291|298|7|4|10.5220/0010147902910298|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107269009&doi=10.5220%2f0010147902910298&partnerID=40&md5=2db576c82a1fc8762d3799321bb2ee17|Software testing is an expanding area which presents an increasing complexity. Indeed, on one hand, there is the development of technologies such as Software Testing as a Service (TaaS), and on the other hand, there is a growing number of Artificial Intelligence (AI)-based softwares. Hence, this work is about the development of an ontological framework for AI-softwares' Testing (AI-T), which domain covers both software testing and explainable artificial intelligence; the goal being to produce an ontology which guides the testing of AI softwares, in an effective and interoperable way. For this purpose, AI-T ontology includes temporal interval logic modelling of the software testing process as well as ethical principle formalization and has been built using the Enterprise Ontology (EO) methodology. Our resulting AI-T ontology proposes both conceptual and implementation models and contains 708 terms and 706 axioms. Copyright © 2020 by SCITEPRESS - Science and Technology Publications, Lda. All rights reserved.|Accountability; Decision support systems; Explainable artificial intelligence (xai); Intelligent systems; Interoperability; Knowledge engineering; Knowledge representation; Ontological domain analysis and modeling; Software engineering ontology; Software testing; Transparency; Unbiased machine learning|Decision support systems; Intelligent systems; Knowledge representation; Ontology; Software testing; Well testing; Accountability; Analysis and models; Domain analysis; Domain model; Explainable artificial intelligence (xai); Knowledge-representation; Machine-learning; Ontological domain analyse and modeling; Software Engineering Ontology; Software testings; Unbiased machine learning; Interoperability|Conference paper|Final|All Open Access; Green Open Access; Hybrid Gold Open Access|Scopus|2-s2.0-85107269009
scopus|Yan M.; Wang L.; Fei A.|Yan, Min (57213355498); Wang, Li (57188963875); Fei, Aiguo (57198318716)|57213355498; 57188963875; 57198318716|ARTDL: Adaptive Random Testing for Deep Learning Systems|2020|IEEE Access|8||8944083|3055|3064|9|12|10.1109/ACCESS.2019.2962695|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078325948&doi=10.1109%2fACCESS.2019.2962695&partnerID=40&md5=d7ac309f6d48668e677a4260a17b2a7a|With recent breakthroughs in Deep Learning (DL), DL systems are increasingly deployed in safety-critical fields. Hence, some software testing methods are required to ensure the reliability and safety of DL systems. Since the rules of DL systems are inferred from training data, it is difficult to know the implementation rules about each behavior of DL systems. At the same time, Random Testing (RT) is a popular testing method and the knowledge about software implementation is not needed when we use RT. Therefore, RT is very suitable for the testing of DL systems. And the existing mechanisms for testing DL systems also depend heavily on RT by the labeled test data. In order to increase the effectiveness of RT for DL systems, we design, implement and evaluate the Adaptive Random Testing for DL systems (ARTDL), which is the first Adaptive Random Testing (ART) method to improve the effectiveness of RT for DL systems. ARTDL refers to the idea of ART. That is, fewer test cases are needed to detect failures by selecting the test case with the furthest distance from non-failure-causing test cases. Firstly, we propose the Feature-based Euclidean Distance (FED) as the distance metric that can be used to measure the difference between failure-causing inputs and non-failure-causing inputs. Secondly, we verify the availability of FED by presenting the failure pattern of DL models. Finally, we design ARTDL algorithm to generate the test cases that are more likely to cause failures based on the FED. We implement ARTDL to test top performing DL models in the field of image classification and automatic driving. The results show that, on average, the number of test cases used to find the first bug is reduced by 62.74% through ARTDL, compared with RT. © 2019 IEEE.|adaptive random testing; Deep learning testing; distance metric; metamorphic testing|Automobile drivers; Safety engineering; Safety testing; Software reliability; Software testing; Adaptive random testing; Automatic driving; Distance metrics; Euclidean distance; Failure-causing inputs; Metamorphic testing; Reliability and safeties; Software implementation; Deep learning|Article|Final|All Open Access; Gold Open Access|Scopus|2-s2.0-85078325948
scopus||||Proceedings - 2020 IEEE 13th International Conference on Software Testing, Verification and Validation, ICST 2020|2020|Proceedings - 2020 IEEE 13th International Conference on Software Testing, Verification and Validation, ICST 2020||||||494|0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091594264&partnerID=40&md5=da1138b177f0a6c8680aea3287711380|The proceedings contain 54 papers. The topics discussed include: toward automated assessment of user experience in extended reality; smart, and also reliable and gas-efficient, contracts; one-click formal methods; MiMIs: simple, efficient, and fast bounded-exhaustive test case generators; Callisto: entropy-based test generation and data quality assessment for machine learning systems; a family of experiments to assess the impact of page object pattern in web test suite development; substate profiling for enhanced fault detection and localization: an empirical study; determining method-call sequences for object creation in C++; SPECMATE: automated creation of test cases from acceptance criteria; and optimizing mutation testing by discovering dynamic mutant subsumption relations.|||Conference review|Final||Scopus|2-s2.0-85091594264
scopus|Du X.; Zhou Z.; Yin B.; Xiao G.|Du, Xiaoting (57200272616); Zhou, Zenghui (57211412346); Yin, Beibei (16242881200); Xiao, Guanping (57188680910)|57200272616; 57211412346; 16242881200; 57188680910|Cross-project bug type prediction based on transfer learning|2020|Software Quality Journal|28|1||39|57|18|17|10.1007/s11219-019-09467-0|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073827187&doi=10.1007%2fs11219-019-09467-0&partnerID=40&md5=badb04ec205641f3feb7aded53daf2c4|The prediction of bug types provides useful insights into the software maintenance process. It can improve the efficiency of software testing and help developers adopt corresponding strategies to fix bugs before releasing software projects. Typically, the prediction tasks are performed through machine learning classifiers, which rely heavily on labeled data. However, for a software project that has insufficient labeled data, it is difficult to train the classification model for predicting bug types. Although labeled data of other projects can be used as training data, the results of the cross-project prediction are often poor. To solve this problem, this paper proposes a cross-project bug type prediction framework based on transfer learning. Transfer learning breaks the assumption of traditional machine learning methods that the training set and the test set should follow the same distribution. Our experiments show that the results of cross-project bug type prediction have significant improvement by adopting transfer learning. In addition, we have studied the factors that influence the prediction results, including different pairs of source and target projects, and the number of bug reports in the source project. © 2019, Springer Science+Business Media, LLC, part of Springer Nature.|Bug prediction; Bug report; Cross-project; Transfer learning|Machine learning; Program debugging; Software testing; Bug predictions; Bug reports; Classification models; Cross-project; Machine learning methods; Software maintenance process; Software project; Transfer learning; Forecasting|Article|Final||Scopus|2-s2.0-85073827187
scopus|Behera A.K.; Panda M.|Behera, Ajit Kumar (55567336500); Panda, Mrutyunjaya (24829805900)|55567336500; 24829805900|Software Reliability Prediction with Ensemble Method and Virtual Data Point Incorporation|2020|Learning and Analytics in Intelligent Systems|10|||69|77|8|3|10.1007/978-3-030-39033-4_7|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179861829&doi=10.1007%2f978-3-030-39033-4_7&partnerID=40&md5=98a7b498334e57b55da4e238c3122153|Software reliability is one of the key aspects of software quality estimation and prediction during software testing period. Hence, accurate prediction of software reliability is an important but critical job. Machine Learning (ML) techniques have been proven victorious in providing superior results than traditional techniques for software reliability prediction. Generally, ML models entail sufficient data for training to achieve improved generalization. Inadequate training data may lead to land at suboptimal solution. This article suggests a method of enriching training dataset through exploration and incorporation of virtual data from existing data. For boost up the overall accuracy and reducing the risk of model selection an ensemble framework of five ML methods is suggested. The extended software reliability dataset is then exposed to the constituent models as well as the ensemble approach separately to estimate the future data. Extensive simulation results on a couple of software reliability datasets reveal that our proposed model significantly improves the prediction accuracy. © 2020, Springer Nature Switzerland AG.|Artificial neural network; Ensemble framework; Interpolation; Machine learning; NRMSE; Software reliability; Virtual data|Computer software selection and evaluation; E-learning; Forecasting; Interpolation; Neural networks; Software reliability; Software testing; Datapoints; Ensemble framework; Ensemble methods; Machine-learning; NRMSE; Reliability prediction; Software quality estimation; Software quality prediction; Software-Reliability; Virtual data; Machine learning|Conference paper|Final||Scopus|2-s2.0-85179861829
scopus|Aiken B.; Wait K.W.|Aiken, Bradford (57219667591); Wait, Keith W. (16176834600)|57219667591; 16176834600|Improving fidelity of energy management software testing through hierarchical clustering of train consist data|2020|2020 Joint Rail Conference, JRC 2020|||||||0|10.1115/JRC2020-8113|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094639097&doi=10.1115%2fJRC2020-8113&partnerID=40&md5=ce7a2f98d4cefc76bf5fc3814eb3b3a9|Energy management systems, such as New York Air Brake's LEADER [1], are real-time control technologies that optimize train performance as Level 2 Autonomy systems under the SAE's “Levels of Driving Automation” classification system [2], and are now commonly used by many railroads. Such systems require extensive testing due to varying requirements of speed and fuel efficiency, compatibility with the wide variation in consists actually marshalled in the field, as well as the potential for the systems to cause break-in-twos or other undesirable situations. Devising accurate test cases that translate well to real-world usage is a common obstacle in the software development process. Using empirical data gathered from sampling field observations and an unsupervised machine learning model, we have created a simple but effective software system capable of performing automated statistical analysis on train consists and recommending a small number of consists which best capture the variation observed on-track. The data produced by such a system is demonstrably useful in developing truly representative test cases for train control systems/energy management software. In this investigation, we first applied such an algorithm to a population of train consists from some arbitrary segment of North American track to identify the most representative sample. We then evaluated the performance of the LEADER driving strategy for the sample set of consists with one of two consists that had previously been used for ad-hoc development testing of the software. Our findings from these simulations indicate that the consists identified by the clustering algorithm display greater variation in LEADER-controlled performance across several features than the ad-hoc testing consists do. Such metrics are transit time, fuel consumption, speed limit adherence, and air brake usage. Application of the algorithm is therefore beneficial in that it allows for more efficient and more thorough testing and characterization of energy management software. © 2020 ASME|Consist; Hierarchical clustering; Machine learning; Railroad; Unsupervised learning|Air brakes; Application programs; Computer control systems; Energy efficiency; Energy management; Energy management systems; Hierarchical clustering; Information management; Railroad transportation; Real time control; Sampling; Software design; Software testing; Well testing; Classification system; Development testing; Energy management softwares; Management software; Representative sample; Software development process; Train control systems; Unsupervised machine learning; Clustering algorithms|Conference paper|Final||Scopus|2-s2.0-85094639097
scopus|Kaur A.|Kaur, Amandeep (58378940700)|58378940700|An approach to extract optimal test cases using AI|2020|Proceedings of the Confluence 2020 - 10th International Conference on Cloud Computing, Data Science and Engineering|||9058244|649|654|5|3|10.1109/Confluence47617.2020.9058244|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083971396&doi=10.1109%2fConfluence47617.2020.9058244&partnerID=40&md5=48694f8072a5a454cb3c491064309a3b|Regression testing is the backbone of the functional Software Testing. Unlike any other testing; regression validation evolves the whole suite of code which incorporates the existing code as well as new code or the change request. Validating all the possible scenarios is not effective as it increases the expenditure. This gains the outlook for the researchers to analyze a more efficient way for regression testing by electing a subset from the test suite to spot the defects. Ample research has crop up for this NP-Hard problem and folks are implementing the metaheuristic techniques and dominantly the nature-inspired ones. In this paper, to extract the optimal test cases we have utilized Harris Hawks Optimization (HHO) which is a nature-inspired technique and portrays chasing drive away style of Harris' hawks termed as Surprise Pounce. In this tactic, assorted hawks combine together to pounce a prey through the offbeat directions to surprise the prey. This paper focuses on the Harris Hawks Optimization algorithm and its applications in the domain of software testing. © 2020 IEEE.|Harris Hawks Optimization; Optimization; Regression testing; Software testing; Test case selection|Application programs; Biomimetics; Cloud computing; Codes (symbols); Digital storage; NP-hard; Optimization; Regression analysis; Well testing; ITS applications; Meta-heuristic techniques; Optimization algorithms; Regression testing; Test case; Software testing|Conference paper|Final||Scopus|2-s2.0-85083971396
scopus|Byun T.; Rayadurgam S.|Byun, Taejoon (57195399464); Rayadurgam, Sanjai (6602312334)|57195399464; 6602312334|Manifold for Machine Learning Assurance|2020|Proceedings - 2020 ACM/IEEE 42nd International Conference on Software Engineering: New Ideas and Emerging Results, ICSE-NIER 2020|||9397537|97|100|3|13|10.1145/3377816.3381734|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104680473&doi=10.1145%2f3377816.3381734&partnerID=40&md5=3c02c94d1235b00e1506089694626fc7|The increasing use of machine-learning (ML) enabled systems in critical tasks fuels the quest for novel verification and validation techniques yet grounded in accepted system assurance principles. In traditional system development, model-based techniques have been widely adopted, where the central premise is that abstract models of the required system provide a sound basis for judging its implementation. We posit an analogous approach for ML systems using an ML technique that extracts from the high-dimensional training data implicitly describing the required system, a low-dimensional underlying structure-A manifold. It is then harnessed for a range of quality assurance tasks such as test adequacy measurement, test input generation, and runtime monitoring of the target ML system. The approach is built on variational autoencoder, an unsupervised method for learning a pair of mutually near-inverse functions between a given high-dimensional dataset and a low-dimensional representation. Preliminary experiments establish that the proposed manifold-based approach, for test adequacy drives diversity in test data, for test generation yields fault-revealing yet realistic test cases, and for run-Time monitoring provides an independent means to assess trustability of the target system's output. Ccs Concepts • Software and its engineering ? Software testing and debugging; • Computing methodologies ? Machine learning.  © 2020 ACM.|machine learning testing; neural networks; variational autoencoder|Digital storage; Inverse problems; Machine learning; Printing machinery; Quality assurance; Software testing; Testing; Computing methodologies; High-dimensional dataset; Low-dimensional representation; Model based techniques; Software Testing and Debugging; Traditional systems; Unsupervised method; Verification-and-validation; Program debugging|Conference paper|Final|All Open Access; Bronze Open Access; Green Open Access|Scopus|2-s2.0-85104680473
scopus|Perera A.|Perera, Anjana (57221479309)|57221479309|Using Defect Prediction to Improve the Bug Detection Capability of Search-Based Software Testing|2020|Proceedings - 2020 35th IEEE/ACM International Conference on Automated Software Engineering, ASE 2020|||9286062|1170|1174|4|3|10.1145/3324884.3415286|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099233260&doi=10.1145%2f3324884.3415286&partnerID=40&md5=9bc62d7f7e2e8db25ffa4af463725d47|Automated test generators, such as search based software testing (SBST) techniques, replace the tedious and expensive task of manually writing test cases. SBST techniques are effective at generating tests with high code coverage. However, is high code coverage sufficient to maximise the number of bugs found? We argue that SBST needs to be focused to search for test cases in defective areas rather in non-defective areas of the code in order to maximise the likelihood of discovering the bugs. Defect prediction algorithms give useful information about the bug-prone areas in software. Therefore, we formulate the objective of this thesis: Improve the bug detection capability of SBST by incorporating defect prediction information. To achieve this, we devise two research objectives, i.e., 1) Develop a novel approach (SBST CL) that allocates time budget to classes based on the likelihood of classes being defective, and 2) Develop a novel strategy (SBST ML) to guide the underlying search algorithm (i.e., genetic algorithm) towards the defective areas in a class. Through empirical evaluation on 434 real reported bugs in the Defects4J dataset, we demonstrate that our novel approach, SBST CL, is significantly more efficient than the state of the art SBST when they are given a tight time budget in a resource constrained environment. © 2020 ACM.|Automated Test Generation; Defect Prediction; Search-Based Software Engineering; Search-Based Software Testing|Automation; Budget control; Defects; Forecasting; Genetic algorithms; Automated test; Defect prediction; Empirical evaluations; Novel strategies; Research objectives; Search Algorithms; Search-based software testing; State of the art; Software testing|Conference paper|Final|All Open Access; Green Open Access|Scopus|2-s2.0-85099233260
scopus|Singh S.K.; Chakrabarti S.K.; Jayagopi D.B.|Singh, Shivam Kumar (59049427700); Chakrabarti, Sujit Kumar (23484425600); Jayagopi, Dinesh Babu (59157709800)|59049427700; 23484425600; 59157709800|Automated Testing of Refreshable Braille Display|2020|IFIP Advances in Information and Communication Technology|590|||181|192|11|2|10.1007/978-3-030-62803-1_15|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097376176&doi=10.1007%2f978-3-030-62803-1_15&partnerID=40&md5=0b69865d39011478b23bedfcdc6b5cf9|A majority of visually impaired population of India and other developing economies live in poverty. Accessibility without affordability has little meaning to this population. Assistive technology has great potential to make education accessible to this population, e.g. through refreshable Braille display devices. However, most existing solutions in this space remain out of reach for these users due to high cost. Innovation in data science and software engineering can play an important role in making assistive technological solutions affordable and accessible. In this paper, we present a machine-learning based automated testing approach that has played an important role in enabling us to design one of the most affordable refreshable Braille display devices of the world. The key component of our approach is a visual inspection module (VIM) created using Convolutional Neural Networks (CNNs). In our experiment, our model was able to detect malfunction of a Refreshable Braille display with 97.3% accuracy. Our model is small enough to be run on a battery-powered computer in real- time. Such accurate automatic testing methods have the potential to significantly reduce the cost of RBDs. © 2020, IFIP International Federation for Information Processing.|Automated testing; CNN; DCT; KNN; OpenCv; ORB; RBD; VIM|Automatic testing; Convolutional neural networks; Data Science; Engineering education; Software engineering; Turing machines; Assistive technology; Automated testing; Battery powered; Developing economies; Refreshable braille display; Technological solution; Visual inspection; Visually impaired; Display devices|Conference paper|Final||Scopus|2-s2.0-85097376176
scopus|Thota M.K.; Shajin F.H.; Rajesh P.|Thota, Mahesh Kumar (57219612355); Shajin, Francis H (57218325222); Rajesh, P. (58954359700)|57219612355; 57218325222; 58954359700|Survey on software defect prediction techniques|2020|International Journal of Applied Science and Engineering|17|4||331|344|13|286|10.6703/IJASE.202012_17(4).331|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100834217&doi=10.6703%2fIJASE.202012_17%284%29.331&partnerID=40&md5=2a49e223432655d9aebd846927bfab0e|Recent advancements in technology have emerged the requirements of hardware and software applications. Along with this technical growth, software industries also have faced drastic growth in the demand of software for several applications. For any software industry, developing good quality software and maintaining its eminence for user end is considered as most important task for software industrial growth. In order to achieve this, software engineering plays an important role for software industries. Software applications are developed with the help of computer programming where codes are written for desired task. Generally, these codes contain some faulty instances which may lead to the buggy software development cause due to software defects. In the field of software engineering, software defect prediction is considered as most important task which can be used for maintaining the quality of software. Defect prediction results provide the list of defect-prone source code artefacts so that quality assurance team scan effectively allocate limited resources for validating software products by putting more effort on the defect-prone source code. As the size of software projects becomes larger, defect prediction techniques will play an important role to support developers as well as to speed up time to market with more reliable software products. One of the most exhaustive and pricey part of embedded software development is consider as the process of finding and fixing the defects. Due to complex infrastructure, magnitude, cost and time limitations, monitoring and fulfilling the quality is a big challenge, especially in automotive embedded systems. However, meeting the superior product quality and reliability is mandatory. Hence, higher importance is given to V&V (Verification & Validation). Software testing is an integral part of software V&V, which is focused on promising accurate functionality and long-term reliability of software systems. Simultaneously, software testing requires much effort, cost, infrastructure and expertise as the development. The costs and efforts elevate in safety critical software systems. Therefore, it is essential to have a good testing strategy for any industry with high software development costs. In this work, we are planning to develop an efficient approach for software defect prediction by using soft computing based machine learning techniques which helps to predict optimize the features and efficiently learn the features. © The Author(s). This is an open access article distributed under the terms of the Creative Commons Attribution License (CC BY 4.0), which permits unrestricted distribution provided the original author and source are cited.|Defect prediction; Soft computing; Validation; Verification||Article|Final||Scopus|2-s2.0-85100834217
scopus|Rhmann W.; Ansari G.A.|Rhmann, Wasiur (57207355961); Ansari, Gufran Ahmad (57188651550)|57207355961; 57188651550|Ensemble techniques-based software fault prediction in an open-source project|2020|International Journal of Open Source Software and Processes|11|2||33|48|15|5|10.4018/IJOSSP.2020040103|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093877092&doi=10.4018%2fIJOSSP.2020040103&partnerID=40&md5=f0e73c9a10a2eb17b94c2b0ed2161cc3|Software engineering repositories have been attracted by researchers to mine useful information about the different quality attributes of the software. These repositories have been helpful to software professionals to efficiently allocate various resources in the life cycle of software development. Software fault prediction is a quality assurance activity. In fault prediction, software faults are predicted before actual software testing. As exhaustive software testing is impossible, the use of software fault prediction models can help the proper allocation of testing resources. Various machine learning techniques have been applied to create software fault prediction models. In this study, ensemble models are used for software fault prediction. Change metrics-based data are collected for an open-source android project from GIT repository and code-based metrics data are obtained from PROMISE data repository and datasets kc1, kc2, cm1, and pc1 are used for experimental purpose. Results showed that ensemble models performed better compared to machine learning and hybrid search-based algorithms. Bagging ensemble was found to be more effective in the prediction of faults in comparison to soft and hard voting. © 2020, IGI Global.|Change Metrics; GIT Repository; Hybrid Search-Based Algorithms; Machine Learning; Quality; Software Metrics; Static Code Metrics; Testing||Article|Final||Scopus|2-s2.0-85093877092
scopus|Mahapatra S.; Mishra S.|Mahapatra, Sumit (58766025800); Mishra, Subhankar (56289643200)|58766025800; 56289643200|Usage of Machine Learning in Software Testing|2020|Learning and Analytics in Intelligent Systems|8|||39|54|15|5|10.1007/978-3-030-38006-9_3|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112172836&doi=10.1007%2f978-3-030-38006-9_3&partnerID=40&md5=c99d628abf8023a3a09b43d289c9f754|Finding, pinpointing and correcting bugs in the software takes a lot of effort for software developers. Traditional testing requires humans to search and analyze data. Humans being prone to poor assumptions and hence skewed results leads to overlooked bugs. Machine learning helps systems to learn and apply the learned knowledge in the future which helps software testers with more accurate knowledge. Capability of several advanced machine learning techniques such as deep learning in a number of software engineering tasks such as code completion, defect prediction, bug localization, clone detection, code search and learning API sequences. A lot of approaches have been proposed by the researchers over the years at modifying programs automatically. Repairing programs by generate-and-validate techniques gain a lot by producing acceptable patches to the programmers and not overfitting through learning from past history and generating patches from correct code via probabilistic model. These approaches given the right environments play significant role in reducing the effort and time consumption as well as cost of the bug fixing for the software developers. In this chapter, various machine learning algorithms and their impact in software testing and bug fixing are explored. The last chapter concludes with the future of machine learning and predictive analysis and how they might be used for addressing the challenge of reacting faster to dynamic expectations of customers and their needs. © 2020, Springer Nature Switzerland AG.|Automated software testing; Defect prediction; Machine learning; Software testing; Vulnerability analysis|Deep learning; Defects; Learning algorithms; Learning systems; Program debugging; Automated software testing; Bug-fixing; Defect prediction; Help systems; Human being; Learn+; Machine-learning; Software developer; Software testings; Vulnerability analysis; Software testing|Book chapter|Final||Scopus|2-s2.0-85112172836
scopus|Niculescu B.; Faur C.I.; Tataru T.; Diaconu B.M.; Cruceru M.|Niculescu, Bogdan (57700730400); Faur, Cosmin Ioan (54973768600); Tataru, Tiberiu (57193140630); Diaconu, Bogdan Marian (56764097200); Cruceru, Mihai (6506243815)|57700730400; 54973768600; 57193140630; 56764097200; 6506243815|Investigation of biomechanical characteristics of orthopedic implants for tibial plateau fractures by means of deep learning and support vector machine classification|2020|Applied Sciences (Switzerland)|10|14|4697||||7|10.3390/app10144697|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088587366&doi=10.3390%2fapp10144697&partnerID=40&md5=99941d034423368394f6bd0f6333ac45|An experimental comparative study of the biomechanical behavior of commonly used orthopedic implants for tibial plateau fractures was carried out. An artificial bone model Synbone1110 was used and a Schatzker V type tibial plateau fracture was created in vitro, then stabilized with three different implant types, classic L plate, Locking Plate System (PLS), and Hybrid External Fixator (HEF). The stiffness of the bone-implant assembly was assessed by means of mechanical testing using an automated testing machine. It was found that the classic L plate type internal implant has a significantly higher value of deformation then the other two implant types. In case of the other implant types, PLS had a better performance than HEF at low and medium values of the applied force. At high values of the applied forces, the difference between deformation values of the two types became gradually smaller. An Artificial Neural Network model was developed to predict the implant deformation as a function of the applied force and implant device type. To establish if a clear-cut distinction exists between mechanical performance of PLS and HEF, a Support Vector Machine classifier was employed. At high values of the applied force, the Support Vector Machine (SVM) classifier predicts that no statistically significant difference exists between the performance of PLS and HEF. © 2020 by the authors.|Biomechanical characteristics; Deep learning; Orthopedic implants; Support vector machine; Tibial plateau fractures||Article|Final|All Open Access; Gold Open Access|Scopus|2-s2.0-85088587366
scopus|Gudaparthi H.; Johnson R.; Challa H.; Niu N.|Gudaparthi, Hemanth (57219439856); Johnson, Reese (36863894500); Challa, Harshitha (57219432900); Niu, Nan (36856329200)|57219439856; 36863894500; 57219432900; 36856329200|Deep Learning for Smart Sewer Systems: Assessing Nonfunctional Requirements|2020|Proceedings - 2020 ACM/IEEE 42nd International Conference on Software Engineering: Software Engineering in Society, ICSE-SEIS 2020|||9276508|35|38|3|6||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099117170&partnerID=40&md5=d9b56d8a964844d32050e5e3e2b1c6f1|Combined sewer overflows represent significant risks to human health as untreated water is discharged to the environment. Municipalities recently began collecting large amounts of water-related data and considering the adoption of deep learning solutions like recurrent neural network (RNN) for overflow prediction. In this paper, we contribute a novel metamorphic relation to characterize RNN robustness in the presence of missing data. We show how this relation drives automated testing of three implementation variants: LSTM, GRU, and IndRNN thereby uncovering deficiencies and suggesting more robust solutions for overflow prediction.  © 2020 ACM.|• Computing methodologies → Machine learning; • Social and professional topics → Economic impact|Digital storage; Health risks; Long short-term memory; Sewers; Software engineering; Automated testing; Combined sewer overflows; Large amounts; Metamorphic relations; Missing data; Non-functional requirements; Recurrent neural network (RNN); Robust solutions; Deep learning|Conference paper|Final||Scopus|2-s2.0-85099117170
scopus|Santos De Campos D.; James Ferreira D.|Santos De Campos, Dirson (8281623200); James Ferreira, Deller (56084650500)|8281623200; 56084650500|Plagiarism detection based on blinded logical test automation results and detection of textual similarity between source codes|2020|Proceedings - Frontiers in Education Conference, FIE|2020-October||9274098||||5|10.1109/FIE44824.2020.9274098|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098560644&doi=10.1109%2fFIE44824.2020.9274098&partnerID=40&md5=95fd8737182c941f3173f1fbaf5e5a68|This Research to Practice Full Paper presents in this paper. Finding logical errors is the most difficult skill for students from all sorts of disciplines that involve computer programming. Unfortunately, because of this difficulty, some students resort to plagiarism. Plagiarism corrupts the evaluation process. Several tools are used in different researches for this purpose. Recent research has defined a taxonomy of the most relevant types of plagiarism that can be found in source codes. The Hybrid Framework was made to map the student plagiarisms using NLP tecnhics and software test automation techniques for automatic exercise correction with tools available for this purpose. This framework has been tested in the laboratory with promising results. © 2020 IEEE.|Automatic Exercise Correction; Code similarity; Natural Language Processing; Plagiarism; Tools to Assess Learning; TPACK|Computer programming; Intellectual property; Software testing; Hybrid framework; Logical errors; Logical tests; Plagiarism detection; Recent researches; Software test automation; Source codes; Textual similarities; Students|Conference paper|Final||Scopus|2-s2.0-85098560644
scopus||||Proceedings - 2020 IEEE 13th International Conference on Software Testing, Verification and Validation Workshops, ICSTW 2020|2020|Proceedings - 2020 IEEE 13th International Conference on Software Testing, Verification and Validation Workshops, ICSTW 2020||||||511|0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091752448&partnerID=40&md5=ae0d7d51b5d39cc52e78908d9f93a27c|The proceedings contain 69 papers. The topics discussed include: optimizing decision making in concolic execution using reinforcement learning; a case-based approach for introducing testing tools and principles; incorporating testing topics in an object-oriented programming course; how can software testing be improved by analytics to deliver better apps?; selective regression testing based on big data: comparing feature extraction techniques; prioritization of test cases with varying test costs and fault severities for certification testing; on using k-means clustering for test suite reduction; session-based recommender systems for action selection in GUI test generation; towards a deep learning model for vulnerability detection on web application variants; and conformance testing in UPPAAL: a diabolic approach.|||Conference review|Final||Scopus|2-s2.0-85091752448
scopus|Arokiam J.; Bradbury J.S.|Arokiam, Jude (57219535923); Bradbury, Jeremy S. (7201391157)|57219535923; 7201391157|Automatically Predicting Bug Severity Early in the Development Process|2020|Proceedings - 2020 ACM/IEEE 42nd International Conference on Software Engineering: New Ideas and Emerging Results, ICSE-NIER 2020|||9397519|17|20|3|9|10.1145/3377816.3381738|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104613561&doi=10.1145%2f3377816.3381738&partnerID=40&md5=09552a99dc7284f8f64759be798a40a0|Bug severity is an important factor in prioritizing which bugs to fix first. The process of triaging bug reports and assigning a severity requires developer expertise and knowledge of the underlying software. Methods to automate the assignment of bug severity have been developed to reduce the developer cost, however, many of these methods require 70-90% of the project's bug reports as training data and delay their use until later in the development process. Not being able to automatically predict a bug report's severity early in a project can greatly reduce the benefits of automation. We have developed a new bug report severity prediction method that leverages how bug reports are written rather than what the bug reports contain. Our method allows for the prediction of bug severity at the beginning of the project by using an organization's historical data, in the form of bug reports from past projects, to train the prediction classier. In validating our approach, we conducted over 1000 experiments on a dataset of five NASA robotic mission software projects. Our results demonstrate that our method was not only able to predict the severity of bugs earlier in development, but it was also able to outperform an existing keyword-based classifier for a majority of the NASA projects.Ccs Concepts• Software and its engineering ? Software maintenance tools; Maintaining software; Software testing and debugging; • Computing methodologies ? Machine learning.  © 2020 ACM.|bug severity; machine learning; natural language processing|Forecasting; NASA; Software testing; Computing methodologies; Development process; Historical data; Keyword-based; Prediction methods; Robotic missions; Software maintenance tools; Software Testing and Debugging; Program debugging|Conference paper|Final||Scopus|2-s2.0-85104613561
scopus|Lin L.; Wang L.; Li H.|Lin, Lin (57214729301); Wang, Libo (57214722485); Li, Hui (57214727578)|57214729301; 57214722485; 57214727578|Design of Quality Management and Inspection Platform for Industrial Control Integration Based on AI|2020|Journal of Physics: Conference Series|1437|1|12097||||0|10.1088/1742-6596/1437/1/012097|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079006778&doi=10.1088%2f1742-6596%2f1437%2f1%2f012097&partnerID=40&md5=d78bf59320a5fd456b01df3526d71f69|With the application and development of industrial internet, the third-party software testing is facing new problems. In order to solve the problem of multi-region, distributed, multi-role and dynamic testing in third-party testing and realize the functions of centralized control, distributed management, traceability, resource sharing, paperless and networked office, this paper designs an integrated quality management testing platform based on AI for industrial control. The establishment of this platform will fill the gaps in the technology of integrated testing platform for third-party software testing and evaluation of China's industrial Internet, and further promote the construction of testing capability and quality management level of China's industrial Internet enterprises. © Published under licence by IOP Publishing Ltd.||Application programs; Big data; Dynamic analysis; Industrial management; Quality management; Software testing; Centralized control; Distributed management; Industrial controls; Inspection platform; Integrated quality; Testing and evaluation; Testing platforms; Third party software; Quality control|Conference paper|Final|All Open Access; Gold Open Access|Scopus|2-s2.0-85079006778
scopus|Saranti A.; Taraghi B.; Ebner M.; Holzinger A.|Saranti, Anna (36761552200); Taraghi, Behnam (42862622600); Ebner, Martin (9638772000); Holzinger, Andreas (23396282000)|36761552200; 42862622600; 9638772000; 23396282000|Property-Based Testing for Parameter Learning of Probabilistic Graphical Models|2020|Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)|12279 LNCS|||499|515|16|5|10.1007/978-3-030-57321-8_28|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090175338&doi=10.1007%2f978-3-030-57321-8_28&partnerID=40&md5=edaca321f6af97291078bc782e3f0bc5|Code quality is a requirement for successful and sustainable software development. The emergence of Artificial Intelligence and data driven Machine Learning in current applications makes customized solutions for both data as well as code quality a requirement. The diversity and the stochastic nature of Machine Learning algorithms require different test methods, each of which is suitable for a particular method. Conventional unit tests in test-automation environments provide the common, well-studied approach to tackle code quality issues, but Machine Learning applications pose new challenges and have different requirements, mostly as far the numerical computations are concerned. In this research work, a concrete use of property-based testing for quality assurance in the parameter learning algorithm of a probabilistic graphical model is described. The necessity and effectiveness of this method in comparison to unit tests is analyzed with concrete code examples for enhanced retraceability and interpretability, thus highly relevant for what is called explainable AI. © 2020, IFIP International Federation for Information Processing.|Machine learning; Probabilistic graphical models; Property-based testing|Codes (symbols); Concrete testing; Data mining; Extraction; Graphic methods; Machine learning; Quality assurance; Software design; Stochastic systems; Customized solutions; Machine learning applications; Numerical computations; Parameter learning; Probabilistic graphical models; Property based testing; Stochastic nature; Sustainable softwares; Learning algorithms|Conference paper|Final||Scopus|2-s2.0-85090175338
scopus|Wu D.; Zhu J.; Tang S.|Wu, Donglai (57219335844); Zhu, Jia (57219343811); Tang, Shilei (57685524400)|57219335844; 57219343811; 57685524400|Application in Computer Software Testing Based on Artificial Intelligence Technology|2020|ACM International Conference Proceeding Series||||177|181|4|1|10.1145/3419635.3419683|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092293997&doi=10.1145%2f3419635.3419683&partnerID=40&md5=0aa4e0a9cfd11b334b29336e195f0d76|Software testing is an important part of the software development life cycle, and it is also the guarantee of software quality and reliability for a long time now and in the future. The main method of sex. In recent years, people have begun to try to apply artificial intelligence technology to the problem of test case generation, resulting in an evolutionary test method. The article introduces the current research status of the automatic generation method of test cases based on structured, focusing on the evolutionary test, and compares and summarizes its application based on genetic algorithm. The application results show that the evolutionary testing method is currently the most efficient method of automatically generating software test cases. Finally, some opinions on the further research direction of evolutionary testing are put forward.  © 2020 ACM.|artificial intelligence technology; evolution testing; genetic algorithm; Software testing|Application programs; Artificial intelligence; Automatic test pattern generation; Computer software selection and evaluation; Computer testing; Genetic algorithms; Life cycle; Software design; Software quality; Software reliability; Artificial intelligence technologies; Automatic Generation; Current research status; Evolutionary testing; ITS applications; Software development life cycle; Test case generation; Test method; Software testing|Conference paper|Final||Scopus|2-s2.0-85092293997
scopus||||2020 10th International Conference on Advanced Computer Information Technologies, ACIT 2020 - Proceedings|2020|Proceedings - International Conference on Advanced Computer Information Technologies, ACIT||||||931|0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183490987&partnerID=40&md5=5940aca350b88a8e386302bcba77bf1c|The proceedings contain 192 papers. The topics discussed include: advisory framework to interconnect distributed water bodies targeting agriculture farms; method of robotic process automation in software testing using artificial intelligence; investigation of information sharing behavior in work teams; deformation methods of functionally defined objects using perturbation functions; sequent calculus for a program-oriented predicate logic over complex-named data; don’t forget the user: from user preferences to personal privacy policies; analysis of the development of socio-cultural potential of Ukraine with the application of the apparatus of fuzzy logic; construction of economic models of ensuring Ukraine's energy resources economy; and modeling of biological wastewater treatment process taking into account reverse effect of concentration on diffusion coefficient.||Agriculture; Artificial intelligence; Behavioral research; Decision making; Diffusion; Economics; Energy resources; Fuzzy logic; Mathematical operators; Software testing; Wastewater treatment; Computer information technology; Distributed water; Information sharing; Perturbation functions; Process automation; Sequent calculus; Software testings; Ukraine; Waterbodies; Work team; Application programs|Conference review|Final||Scopus|2-s2.0-85183490987
scopus|Zhu H.; Bayley I.; Liu D.; Zheng X.|Zhu, Hong (55569786200); Bayley, Ian (35306468500); Liu, Dongmei (57015746400); Zheng, Xiaoyu (57219336534)|55569786200; 35306468500; 57015746400; 57219336534|Automation of Datamorphic Testing|2020|Proceedings - 2020 IEEE International Conference on Artificial Intelligence Testing, AITest 2020|||9176826|64|72|8|8|10.1109/AITEST49225.2020.00017|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092309202&doi=10.1109%2fAITEST49225.2020.00017&partnerID=40&md5=fce100f06c5f8f25c1d1bae8812eced0|This paper presents an automated tool called Morphy for datamorphic testing. It classifies software test artefacts into test entities and test morphisms, which are mappings on testing entities. In addition to datamorphisms, metamorphisms and seed test case makers, Morphy also employs a set of other test morphisms including test case metrics and filters, test set metrics and filters, test result analysers and test executers to realise test automation. In particular, basic testing activities can be automated by invoking test morphisms. Test strategies can be realised as complex combinations of test morphisms. Test processes can be automated by recording, editing and playing test scripts that invoke test morphisms and strategies. This paper proposes a set of test strategies that combine datamorphisms to generate test sets that adequately cover various types of mutant test cases. These strategies are formally defined. Their implementation algorithms are provided. The correctness of the algorithms are proved. The paper also illustrates their uses for testing both traditional software and AI applications with three case studies. © 2020 IEEE.|Artificial Intelligence; Datamorphic test; Software test; Test automation; Test tools|Application programs; Artificial intelligence; Automation; Testing; AI applications; Automated tools; Case-studies; Implementation algorithms; Test Automation; Test process; Test scripts; Test strategies; Software testing|Conference paper|Final|All Open Access; Green Open Access|Scopus|2-s2.0-85092309202
scopus||||Proceedings of 2020 IEEE International Conference on Power, Intelligent Computing and Systems, ICPICS 2020|2020|Proceedings of 2020 IEEE International Conference on Power, Intelligent Computing and Systems, ICPICS 2020||||||1075|0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092717750&partnerID=40&md5=7d695c377a04517a5d5b5321c9826691|The proceedings contain 236 papers. The topics discussed include: research on motion trajectory tracking control method based on mobile robot servo system; script converter for automated testing of laptops; research on integration and sharing system of network movie and TV data resources under new media environment; research on the intelligent identification method of personnel violation in substations based on deep learning; UAV security situation awareness method based on semantic analysis; a control strategy of microgrid-connected system based on VSG; detection of the rail profile wear based on image processing; MVDR algorithm for broadband coherent source signals based on data reconstruction; and algorithm of maintenance time and maintenance amount based on maintenance degree.|||Conference review|Final||Scopus|2-s2.0-85092717750
scopus|Gudaparthi H.; Johnson R.; Challa H.; Niu N.|Gudaparthi, Hemanth (57219439856); Johnson, Reese (36863894500); Challa, Harshitha (57219432900); Niu, Nan (36856329200)|57219439856; 36863894500; 57219432900; 36856329200|Deep learning for smart sewer systems: assessing nonfunctional requirements|2020|Proceedings - International Conference on Software Engineering||||35|38|3|11|10.1145/3377815.3381379|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092170245&doi=10.1145%2f3377815.3381379&partnerID=40&md5=98fa2c02e18fae751582a7a8918fc4d2|Combined sewer overflows represent significant risks to human health as untreated water is discharged to the environment. Municipalities recently began collecting large amounts of water-related data and considering the adoption of deep learning solutions like recurrent neural network (RNN) for overflow prediction. In this paper, we contribute a novel metamorphic relation to characterize RNN robustness in the presence of missing data. We show how this relation drives automated testing of three implementation variants: LSTM, GRU, and IndRNN thereby uncovering deficiencies and suggesting more robust solutions for overflow prediction. © 2020 Association for Computing Machinery.|Metamorphic testing; Nonfunctional requirements; Recurrent neural network; Robustness; Smart sewer systems; Water management|Digital storage; Engineering education; Health risks; Long short-term memory; Sewers; Software engineering; Automated testing; Combined sewer overflows; Large amounts; Metamorphic relations; Missing data; Non-functional requirements; Recurrent neural network (RNN); Robust solutions; Deep learning|Conference paper|Final||Scopus|2-s2.0-85092170245
scopus|Paces P.|Paces, Pavel (21935098900)|21935098900|Avionics testing with artificial intelligence support|2020|AIAA/IEEE Digital Avionics Systems Conference - Proceedings|2020-October||9256563||||1|10.1109/DASC50938.2020.9256563|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097997717&doi=10.1109%2fDASC50938.2020.9256563&partnerID=40&md5=9a0f4faa7300282425fd51f08671ff3d|This paper describes a concept allowing for automated testing of avionics installed on a test bench where concepts of Artificial Intelligence are used. This test bench technology provides means for fast discovery of changes in behavior of new releases of avionics software where feature corrections can lead to modified behavior of other functions. The tested avionics is installed in a simulator test bench allowing to simulate behavior and systems of the respective airplane type. The test bench allows the pilot himself to test the functionality which can be repeated by the automation system itself. The technology behind the simulator collects all the data from the test bench internal buses under different conditions to be used as a reference to identity deviations from expected behavior of the avionic systems. The Artificial Intelligence methods used in our approach include state space search algorithms for determination of required control routines and data learning related to identification of deviations in behavior. © 2020 IEEE.|Artificial intelligence; Avionics; Search; Software; State space; Testing|Automation; Digital avionics; Software testing; Testing; Artificial intelligence methods; Automated testing; Automation systems; Avionic systems; Avionics testing; Simulator test; State space search algorithm; Test benches; Artificial intelligence|Conference paper|Final||Scopus|2-s2.0-85097997717
scopus|Del Carpio A.F.; Angarita L.B.|Del Carpio, Alvaro Fernandez (55695575700); Angarita, Leonardo Bermon (56728592300)|55695575700; 56728592300|Trends in Software Engineering Processes using Deep Learning: A Systematic Literature Review|2020|Proceedings - 46th Euromicro Conference on Software Engineering and Advanced Applications, SEAA 2020|||9226311|445|454|9|17|10.1109/SEAA51224.2020.00077|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096529855&doi=10.1109%2fSEAA51224.2020.00077&partnerID=40&md5=39cc684f0a1dc66ae9cee42092386347|In recent years, several researchers have applied machine learning techniques to several knowledge areas achieving acceptable results. Thus, a considerable number of deep learning models are focused on a wide range of software processes. This systematic review investigates the software processes supported by deep learning models, determining relevant results for the software community. This research identified that the most extensively investigated sub-processes are software testing and maintenance. In such sub-processes, deep learning models such as CNN, RNN, and LSTM are widely used to process bug reports, malware classification, libraries and commits recommendations generation. Some solutions are oriented to effort estimation, classify software requirements, identify GUI visual elements, identification of code authors, the similarity of source codes, predict and classify defects, and analyze bug reports in testing and maintenance processes.  © 2020 IEEE.|Deep Learning; Machine Learning; Software Processes; Systematic Review|Application programs; Computer software maintenance; Learning systems; Long short-term memory; Object oriented programming; Software testing; Applied machine learning; Malware classifications; Software community; Software engineering process; Software requirements; Systematic literature review; Systematic Review; Testing and maintenance; Deep learning|Conference paper|Final||Scopus|2-s2.0-85096529855
scopus|Tanwar N.; Singh A.; Singh R.|Tanwar, Neha (59104822600); Singh, Ajmer (57192272026); Singh, Rajvir (57215037820)|59104822600; 57192272026; 57215037820|A Support Vector Machine Based Approach for Effective Fault Localization|2020|Advances in Intelligent Systems and Computing|1053|||825|835|10|1|10.1007/978-981-15-0751-9_75|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081370147&doi=10.1007%2f978-981-15-0751-9_75&partnerID=40&md5=5d5cd4acfe9f821f53665593124f19bf|Software maintenance is one of the most costly activities in software life cycle. It costs almost 70% of the total cost of the software. Testing aims to reveal the faults from the software under test (SUT). The fault localization is tiresome, dull, costly but crucial for program debugging. As size and complexity of software increase, manual locating faults becomes very tedious and hence necessitates automatic fault localization. If the fault proneness of the software components can be predicted, then such components may be given more focus. Such approach would not only save time but also enhance the quality of the software. Support vector machine (SVM) is a prominent machine learning algorithm. Regularization of parameters, convex optimization and kernel tricks are the prevailing features of SVM. This work reports a SVM-based framework for fault localization on the basis of code smells. Paper presents a performance analysis against four popular algorithms, namely ZeroR, OneR, Naive Bayes and Decision Stump. The proposed model is empirically evaluated in the reference of Json project. The results of the experimentation show that the proposed model can effectively classify the instances in the classes of their respective categories of code smells. Also, the kernel used in the proposed model gives better performance than counterpart kernels and the proposed model itself performs better than the other compared algorithms in terms of accuracy, precision, recall and F-measure. © 2020, Springer Nature Singapore Pte Ltd.|Fault localization; Software; Support vector machine|Computer software; Convex optimization; Learning algorithms; Learning systems; Life cycle; Odors; Soft computing; Software quality; Software testing; Support vector machines; Automatic fault localizations; Decision stumps; Fault localization; Fault proneness; Kernel trick; Performance analysis; Software component; Software life cycles; Program debugging|Conference paper|Final||Scopus|2-s2.0-85081370147
scopus|Braiek H.B.; Khomh F.|Braiek, Houssem Ben (57203412343); Khomh, Foutse (24724747600)|57203412343; 24724747600|On testing machine learning programs|2020|Journal of Systems and Software|164||110542||||134|10.1016/j.jss.2020.110542|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081030171&doi=10.1016%2fj.jss.2020.110542&partnerID=40&md5=0019441a753439c6d2a0513d3a102029|Nowadays, we are witnessing a wide adoption of Machine learning (ML) models in many software systems. They are even being tested in safety-critical systems, thanks to recent breakthroughs in deep learning and reinforcement learning. Many people are now interacting with systems based on ML every day, e.g., voice recognition systems used by virtual personal assistants like Amazon Alexa or Google Home. As the field of ML continues to grow, we are likely to witness transformative advances in a wide range of areas, from finance, energy, to health and transportation. Given this growing importance of ML-based systems in our daily life, it is becoming utterly important to ensure their reliability. Recently, software researchers have started adapting concepts from the software testing domain (e.g., code coverage, mutation testing, or property-based testing) to help ML engineers detect and correct faults in ML programs. This paper reviews current existing testing practices for ML programs. First, we identify and explain challenges that should be addressed when testing ML programs. Next, we report existing solutions found in the literature for testing ML programs. Finally, we identify gaps in the literature related to the testing of ML programs and make recommendations of future research directions for the scientific community. We hope that this comprehensive review of software testing practices will help ML engineers identify the right approach to improve the reliability of their ML-based systems. We also hope that the research community will act on our proposed research directions to advance the state of the art of testing for ML programs. © 2020|Data cleaning; Feature engineering testing; Implementation testing; Machine learning; Model testing|Deep learning; Learning systems; Reinforcement learning; Safety engineering; Software reliability; Data cleaning; Feature engineerings; Future research directions; Implementation testing; Model testing; Property based testing; Safety critical systems; Voice-recognition systems; Software testing|Article|Final|All Open Access; Green Open Access|Scopus|2-s2.0-85081030171
scopus|Ma P.; Wang S.; Liu J.|Ma, Pingchuan (57212850218); Wang, Shuai (57190181124); Liu, Jin (57220547853)|57212850218; 57190181124; 57220547853|Metamorphic testing and certified mitigation of fairness violations in NLP models|2020|IJCAI International Joint Conference on Artificial Intelligence|2021-January|||458|465|7|63||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097348746&partnerID=40&md5=ee3e7faf4a1835bf4cfb4a92edf22c6c|Natural language processing (NLP) models have been increasingly used in sensitive application domains including credit scoring, insurance, and loan assessment. Hence, it is critical to know that the decisions made by NLP models are free of unfair bias toward certain subpopulation groups. In this paper, we propose a novel framework employing metamorphic testing, a well-established software testing scheme, to test NLP models and find discriminatory inputs that provoke fairness violations. Furthermore, inspired by recent breakthroughs in the certified robustness of machine learning, we formulate NLP model fairness in a practical setting as (o, k)-fairness and accordingly smooth the model predictions to mitigate fairness violations. We demonstrate our technique using popular (commercial) NLP models, and successfully flag thousands of discriminatory inputs that can cause fairness violations. We further enhance the evaluated models by adding certified fairness guarantee at a modest cost. © 2020 Inst. Sci. inf., Univ. Defence in Belgrade. All rights reserved.||Artificial intelligence; Software testing; Well testing; Credit scoring; Fairness guarantee; Know-that; Metamorphic testing; Model prediction; NAtural language processing; Sensitive application; Natural language processing systems|Conference paper|Final||Scopus|2-s2.0-85097348746
scopus|Ghimis B.; Paduraru M.; Stefanescu A.|Ghimis, Bogdan (57211243300); Paduraru, Miruna (57210841881); Stefanescu, Alin (57188811190)|57211243300; 57210841881; 57188811190|RIVER 2.0: An open-source testing framework using AI techniques|2020|LANGETI 2020 - Proceedings of the 1st ACM SIGSOFT International Workshop on Languages and Tools for Next-Generation Testing, Co-located with ESEC/FSE 2020||||13|18|5|3|10.1145/3416504.3424335|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096994618&doi=10.1145%2f3416504.3424335&partnerID=40&md5=95790c8b80f50fb1c589847b124d09ad|This paper presents the latest updates to the RIVER open-source testing platform for x86 programs, focusing on how artificial intelligence (AI) techniques can be used to improve the automated testing processes. It is also important to mention that RIVER is the first open-source platform that offers a concolic execution engine with reinforcement learning capabilities. On the industry side, this can allow security software engineers to test their applications with fewer costs, while for the research community, it can help prototyping new ideas faster. As a secondary contribution, our work makes a summary of the AI techniques that were used for testing processes either in our previous work or other existing work in the field. The presentation describes technical aspects, challenges, and future work.  © 2020 ACM.|concolic; deep learning; execution; neural networks; Reinforcement learning; SMT; symbolic; tainting; testing; x86|Application programs; Open source software; Reinforcement learning; Rivers; Automated testing; Concolic execution; Open source platforms; Research communities; Technical aspects; Testing framework; Testing platforms; Testing process; Software testing|Conference paper|Final||Scopus|2-s2.0-85096994618
scopus|Eivazpour Z.; Keyvanpour M.R.|Eivazpour, Z. (57209642079); Keyvanpour, Mohammad Reza (24476189600)|57209642079; 24476189600|Adversarial Samples for Improving Performance of Software Defect Prediction Models|2020|Lecture Notes on Data Engineering and Communications Technologies|45|||299|310|11|4|10.1007/978-3-030-37309-2_24|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083439338&doi=10.1007%2f978-3-030-37309-2_24&partnerID=40&md5=838922ba46ab45cdcd23771f3cfb6868|Software defect prediction (SDP) is a valuable tool since it can help to software quality assurance team through predicting defective code locations in the software testing phase for improving software reliability and saving budget. This leads to growth in the usage of machine learning techniques to SDP. However, the imbalanced class distribution within SDP datasets is a severe problem for conventional machine learning classifiers, since result in the models with poor performance. Over-sampling the minority class is one of the good solutions to overcome the class imbalance issue. In this paper, we propose a novel over-sampling method, which trained a generative adversarial nets (GANs) to generate synthesized data aimed for output mimicked minority class samples, which were then combined with training data into an increased training dataset. In the tests, we investigated ten freely accessible defect datasets from the PROMISE repository. We assessed the performance of our offered method by comparing it with standard over-sampling techniques including SMOTE, Random Over-sampling, ADASYN, and Borderline-SMOTE. Based on the test results, the proposed method provides better mean performance of SDP models among all tested techniques. © 2020, Springer Nature Switzerland AG.|Class imbalance; Generative Adversarial Nets; Over-sampling; Software defect prediction|Budget control; Classification (of information); Computer software selection and evaluation; Defects; Forecasting; Machine learning; Predictive analytics; Software quality; Software reliability; Class imbalance; Conventional machines; Imbalanced class; Improving performance; Machine learning techniques; Poor performance; Software defect prediction; Training dataset; Software testing|Book chapter|Final||Scopus|2-s2.0-85083439338
scopus|Guo Q.; Xie X.; Li Y.; Zhang X.; Liu Y.; Li X.; Shen C.|Guo, Qianyu (57221017262); Xie, Xiaofei (55268560900); Li, Yi (55894800200); Zhang, Xiaoyu (57214915278); Liu, Yang (56911879800); Li, Xiaohong (57022407900); Shen, Chao (36446592900)|57221017262; 55268560900; 55894800200; 57214915278; 56911879800; 57022407900; 36446592900|Audee: Automated Testing for Deep Learning Frameworks|2020|Proceedings - 2020 35th IEEE/ACM International Conference on Automated Software Engineering, ASE 2020|||9286000|486|498|12|83|10.1145/3324884.3416571|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099256881&doi=10.1145%2f3324884.3416571&partnerID=40&md5=e2c2ee6028e1cf0162885592a3731aea|Deep learning (DL) has been applied widely, and the quality of DL system becomes crucial, especially for safety-critical applications. Existing work mainly focuses on the quality analysis of DL models, but lacks attention to the underlying frameworks on which all DL models depend. In this work, we propose Audee, a novel approach for testing DL frameworks and localizing bugs. Audee adopts a search-based approach and implements three different mutation strategies to generate diverse test cases by exploring combinations of model structures, parameters, weights and inputs. Audee is able to detect three types of bugs: logical bugs, crashes and Not-a-Number (NaN) errors. In particular, for logical bugs, Audee adopts a cross-reference check to detect behavioural inconsistencies across multiple frameworks (e.g., TensorFlow and PyTorch), which may indicate potential bugs in their implementations. For NaN errors, Audee adopts a heuristic-based approach to generate DNNs that tend to output outliers (i.e., too large or small values), and these values are likely to produce NaN. Furthermore, Audee leverages a causal-testing based technique to localize layers as well as parameters that cause inconsistencies or bugs. To evaluate the effectiveness of our approach, we applied Audee on testing four DL frameworks, i.e., TensorFlow, PyTorch, CNTK, and Theano. We generate a large number of DNNs which cover 25 widely-used APIs in the four frameworks. The results demonstrate that Audee is effective in detecting inconsistencies, crashes and NaN errors. Intotal, 26 unique unknown bugs were discovered, and 7 of them have already been confirmed or fixed by the developers. © 2020 ACM.|Bug detection; Deep learning frameworks; Deep learning testing|Automation; Errors; Model structures; Quality control; Safety engineering; Sodium compounds; Software engineering; Well testing; Automated testing; Learning frameworks; Mutation strategy; Not a numbers; Reference check; Safety critical applications; Search-based; Test case; Deep learning|Conference paper|Final|All Open Access; Green Open Access|Scopus|2-s2.0-85099256881
scopus|Spieker H.; Gotlieb A.|Spieker, Helge (57189329650); Gotlieb, Arnaud (56247674500)|57189329650; 56247674500|Learning to Generate Fault-revealing Test Cases in Metamorphic Testing|2020|Lecture Notes in Informatics (LNI), Proceedings - Series of the Gesellschaft fur Informatik (GI)|P-310|||99|100|1|0|10.18420/SE2021_37|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126621869&doi=10.18420%2fSE2021_37&partnerID=40&md5=72f4a5b61f17d8cf1033d0e70c7ce5f4|Metamorphic Testing is a software testing paradigm which aims at using necessary properties of a system under test, called metamorphic relations (MR), to either check its expected outputs, or to generate new test cases [Se16]. Metamorphic Testing has been successful to test programs for which a full oracle is unavailable or to test programs with uncertainties on expected outputs such as learning systems. In this paper, we formulate the effective selection of MRs as a reinforcement learning problem, based on contextual bandits. Our method Adaptive Metamorphic Testing sequentially selects a MR that is expected to provide the highest payoff, i.e., that is most likely to reveal faults. Which MRs are likely to reveal faults is learned from successive exploration trials. The bandit explores the available MRs and evaluates the fault landscape of the system under test, thereby providing valuable information to the tester. We present experimental results over two applications in machine learning, namely image classification and object detection, where Adaptive Metamorphic Testing efficiently identifies weaknesses of the tested systems. The original paper”Adaptive Metamorphic Testing with Contextual Bandits” first appeared in the Journal of Systems and Software (2020) [SG20]. © 2020 Gesellschaft fur Informatik (GI). All rights reserved.|Contextual Bandits; Machine Learning; Metamorphic Testing; Software Testing|Learning systems; Object detection; Reinforcement learning; Testing; Contextual banditti; Machine-learning; Metamorphic relations; Metamorphic testing; Property; Software testings; Systems under tests; Test case; Test projects; Uncertainty; Software testing|Conference paper|Final||Scopus|2-s2.0-85126621869
scopus|Haensel J.; Adriano C.M.; Dyck J.; Giese H.|Haensel, Joachim (36141587600); Adriano, Christian M. (57211568101); Dyck, Johannes (42861108600); Giese, Holger (7006595209)|36141587600; 57211568101; 42861108600; 7006595209|Collective risk minimization via a bayesian model for statistical software testing|2020|Proceedings - 2020 IEEE/ACM 15th International Symposium on Software Engineering for Adaptive and Self-Managing Systems, SEAMS 2020||||45|56|11|4|10.1145/3387939.3388616|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093107940&doi=10.1145%2f3387939.3388616&partnerID=40&md5=4a01e72760b4e56dd396f62802f93686|In the last four years, the number of distinct autonomous vehicles platforms deployed in the streets of California increased 6-fold, while the reported accidents increased 12-fold. This can become a trend with no signs of subsiding as it is fueled by a constant stream of innovations in hardware sensors and machine learning software. Meanwhile, if we expect the public and regulators to trust the autonomous vehicle platforms, we need to find better ways to solve the problem of adding technological complexity without increasing the risk of accidents. We studied this problem from the perspective of reliability engineering in which a given risk of an accident has severity and probability of occurring. Timely information on accidents is important for engineers to anticipate and reuse previous failures to approximate the risk of accidents in a new city. However, this is challenging in the context of autonomous vehicles because of the sparse nature of data on the operational scenarios (driving trajectories in a new city). Our approach was to mitigate data sparsity by reducing the state space through monitoring of multiple-vehicles operations. We then minimized the risk of accidents by determining proper allocation of tests for each equivalence class. Our contributions comprise (1) a set of strategies to monitor the operational data of multiple autonomous vehicles, (2) a Bayesian model that estimates changes in the risk of accidents, and (3) a feedback control-loop that minimizes these risks by real-locating test effort. Our results are promising in the sense that we were able to measure and control risk for a diversity of changes in the operational scenarios. We evaluated our models with data from two real cities with distinct traffic patterns and made the data available for the community.  © 2020 ACM.||Autonomous vehicles; Bayesian networks; Computer hardware description languages; Control systems; Equivalence classes; Risk assessment; Risk perception; Software testing; Statistical tests; Feedback control loops; Machine learning software; Measure and controls; Multiple autonomous vehicles; Operational scenario; Reliability engineering; Statistical software testing; Technological complexity; Accidents|Conference paper|Final|All Open Access; Green Open Access|Scopus|2-s2.0-85093107940
scopus|Malhotra R.; Chauhan A.|Malhotra, Ruchika (15758058000); Chauhan, Akanksha (57218135947)|15758058000; 57218135947|Application of XGBoost algorithm and deep learning techniques for severity assessment of software defect reports|2020|Indian Journal of Computer Science and Engineering|11|3||267|276|9|2|10.21817/indjcse/2020/v11i3/201103236|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088024126&doi=10.21817%2findjcse%2f2020%2fv11i3%2f201103236&partnerID=40&md5=e2b7d3f4594c1cb7b4b05769aee50670|Software is present in every aspect of our everyday life, and defects are bound to be found during the testing of the software, no matter how small. It is therefore imperative for software testing engineers to assess the severity of software defects to allocate proper resources for the correction of the defects and prevent software crashes. In this paper, we have proposed the use of the Extreme Gradient Boosting Technique (XGBoost) and deep learning techniques: CNN (Convolutional Neural Network) and RNN (Recur-rent Neural Network) to predict the severity of the defects occurring in the software. AUC and sensitivity are the metrics used to evaluate the results. All three techniques: XGBoost algorithm, CNN and RNN have performed really well in predicting the severities for all the defects. It has also been noted that XGBoost algorithm is the most efficient in predicting high severity defects, while the performance of deep learning techniques is excellent for the highest as well as the lowest severity defects. For the rest of the severity values, the performance of all the three classifiers is fairly consistent. © 2020, Engg Journals Publications. All rights reserved.|Deep learning; Severity; Severity assessment; Software defects||Article|Final|All Open Access; Gold Open Access|Scopus|2-s2.0-85088024126
scopus|Yatskiv N.; Yatskiv S.; Vasylyk A.|Yatskiv, Nataliya (24179417600); Yatskiv, Solomiya (57204937166); Vasylyk, Anatoliy (57219602290)|24179417600; 57204937166; 57219602290|Method of Robotic Process Automation in Software Testing Using Artificial Intelligence|2020|Proceedings - International Conference on Advanced Computer Information Technologies, ACIT|||9208806|501|504|3|21|10.1109/ACIT49673.2020.9208806|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094147750&doi=10.1109%2fACIT49673.2020.9208806&partnerID=40&md5=cbf5eb0fadb483eb2b6297c143cf00ca|Robotic process automation (RPA) offers numerous benefits over typical software for test automation. It allows saving money and freeing up human resources without any modifications in the processes and implemented solutions. Despite many advantages, RPA solution has limited functionality and it is not able to automatically adapt to changes in the system without human interaction. One of the technologies that may be used to leverage these disadvantages is Artificial Intelligence (AI). AI can facilitate process automation by using the intelligent decision making and interface analysis. In this paper the main approaches of RPA usage, their advantages and disadvantages are investigated. This paper describes the proposed method for software test automation with RPA which allows to make RPA software more flexible and decrease human involvement in the support processes. © 2020 IEEE.|Artificial Intelligence; Robotic process automation; test automation|Decision making; Intelligent robots; Process control; Automation solutions; Decision making analysis; Humaninteraction; Intelligent decision-making; Interface analysis; Process automation; Robotic process automation; Software test automation; Software testings; Test Automation; Software testing|Conference paper|Final||Scopus|2-s2.0-85094147750
scopus||||Proceedings - 2020 IEEE/ACM 15th International Symposium on Software Engineering for Adaptive and Self-Managing Systems, SEAMS 2020|2020|Proceedings - 2020 IEEE/ACM 15th International Symposium on Software Engineering for Adaptive and Self-Managing Systems, SEAMS 2020||||||205|0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093071672&partnerID=40&md5=5d3b582a71c424a923b8d18ac97276ba|The proceedings contain 26 papers. The topics discussed include: a hybrid approach combining control theory and AI for engineering self-adaptive systems; applying deep learning to reduce large adaptation spaces of self-adaptive systems with multiple types of goals; towards classes of architectural dependability assurance for machine-learning-based systems; supporting viewpoints to review the lack of requirements in space systems with machine learning; collective risk minimization via a Bayesian model for statistical software testing; leveraging test logs for building a self-adaptive path planner; a framework for the analysis of adaptive systems using Bayesian statistics; and a platform to enable self-adaptive cloud applications using trustworthiness properties.|||Conference review|Final||Scopus|2-s2.0-85093071672
scopus|Lima R.; Da Cruz A.M.R.; Ribeiro J.|Lima, Rui (59678935900); Da Cruz, Antonio Miguel Rosado (24484607700); Ribeiro, Jorge (57338745200)|59678935900; 24484607700; 57338745200|Artificial Intelligence Applied to Software Testing: A Literature Review|2020|Iberian Conference on Information Systems and Technologies, CISTI|2020-June||9141124||||24|10.23919/CISTI49556.2020.9141124|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089024595&doi=10.23919%2fCISTI49556.2020.9141124&partnerID=40&md5=4016cb3f9b6b6ade61673ec17fb83247|In the last few years Artificial Intelligence (AI) algorithms and Machine Learning (ML) approaches have been successfully applied in real-world scenarios like commerce, industry and digital services, but they are not a widespread reality in Software Testing. Due to the complexity of software testing, most of the work of AI/ML applied to it is still academic. This paper briefly presents the state of the art in the field of software testing, applying ML approaches and AI algorithms. The progress analysis of the AI and ML methods used for this purpose during the last three years is based on the Scopus Elsevier, web of Science and Google Scholar databases. Algorithms used in software testing have been grouped by test types. The paper also tries to create relations between the main AI approaches and which type of tests they are applied to, in particular white-box, grey-box and black-box software testing types. We conclude that black-box testing is, by far, the preferred method of software testing, when AI is applied, and all three methods of ML (supervised, unsupervised and reinforcement) are commonly used in black-box testing being the 'clustering' technique, Artificial Neural Networks and Genetic Algorithms applied to 'fuzzing' and regression testing. © 2020 AISTI.|Artificial Intelligence; Artificial Neural Network; Genetic Algorithm; Machine Learning; Software Testing; Test Pattern|Clustering algorithms; Genetic algorithms; Information services; Information systems; Information use; Machine learning; Service industry; Digital services; Google scholar; Literature reviews; Neural networks and genetic algorithms; Real-world scenario; Regression testing; State of the art; Web of Science; Black-box testing|Conference paper|Final||Scopus|2-s2.0-85089024595
scopus|de Lima L.F.; Peres L.M.; Grégio A.R.A.; Silva F.|de Lima, Luis F. (57219228304); Peres, Leticia M. (54908204000); Grégio, André R.A. (22957901300); Silva, Fabiano (23391072500)|57219228304; 54908204000; 22957901300; 23391072500|A systematic literature mapping of artificial intelligence planning in software testing|2020|ICSOFT 2020 - Proceedings of the 15th International Conference on Software Technologies||||152|159|7|3||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091786285&partnerID=40&md5=be1c602489c5d24f8a3c61ed6bf8f756|Software testing is one of the most expensive software development processes. So, techniques to automate this process are fundamental to reduce software cost and development time. Artificial intelligence (AI) planning technique has been applied to automate part of the software testing process. We present in this paper a systematic literature mapping (SLM), using Petersen et al. (2015) approach of methods, techniques and tools regarding AI planning in software testing. Using the mapping, we identify 16 papers containing methods, techniques, frameworks and tools proposals, besides a survey. We identify testing techniques, testing phases, artifacts, AI planning techniques, AI planning tools, support tools, and generated plans in these selected papers. By mapping data analyses we identify a deficiency in the use of white-box and error-based testing techniques, besides the recent use of AI planning in security testing. Copyright © 2020 by SCITEPRESS – Science and Technology Publications, Lda. All rights reserved.|AI planning; Artificial intelligence planning; Planning technique; Software testing|Artificial intelligence; Mapping; Software design; Testing; Artificial intelligence planning; Development time; Planning techniques; Security testing; Software cost; Software development process; Techniques and tools; Testing technique; Software testing|Conference paper|Final||Scopus|2-s2.0-85091786285
scopus|Mulla N.; Jayakumar N.|Mulla, Nilofar (57205730644); Jayakumar, Naveenkumar (57191282068)|57205730644; 57191282068|The Potent Combo of Software Testing and NLP|2020|Lecture Notes in Electrical Engineering|601|||1623|1632|9|1|10.1007/978-981-15-1420-3_169|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085477467&doi=10.1007%2f978-981-15-1420-3_169&partnerID=40&md5=192f2b910e386452989cb07cf3caa62a|In the case of the agile software development environment, the key challenge is to generate test cases applying user stories. The newly designed “User story Processor (USP) algorithm” can be used to pre-process the user stories using Natural Language Processing (NLP). This Paper also presents the clear flow for execution for future development. This is ongoing research and as the future scope for real-time run, plug-in with other testing software will be very efficient. Such plug-in can be deployed for agile software tools as an added functionality as each agile project can contain different modules of the project which need multiple types of testing. © 2020, Springer Nature Singapore Pte Ltd.|Agile development; NLP; QA; TDD; User story|Learning algorithms; Machine learning; Natural language processing systems; Software design; Agile software development; Agile softwares; NAtural language processing; Plug-ins; Real time; Test case; Testing software; User stories; Software testing|Conference paper|Final||Scopus|2-s2.0-85085477467
scopus|Qin F.; Wan X.; Yin B.|Qin, Fangyun (57027052800); Wan, Xiaohui (57205599089); Yin, Beibei (16242881200)|57027052800; 57205599089; 16242881200|An empirical study of factors affecting cross-project aging-related bug prediction with TLAP|2020|Software Quality Journal|28|1||107|134|27|14|10.1007/s11219-019-09460-7|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074566426&doi=10.1007%2fs11219-019-09460-7&partnerID=40&md5=d2de6b5e32a293ce3fd1c694aaa2373c|Software aging is a phenomenon in which long-running software systems show an increasing failure rate and/or progressive performance degradation. Due to their nature, Aging-Related Bugs (ARBs) are hard to discover during software testing and are also challenging to reproduce. Therefore, automatically predicting ARBs before software release can help developers reduce ARB impact or avoid ARBs. Many bug prediction approaches have been proposed, and most of them show effectiveness in within-project prediction settings. However, due to the low presence and reproducing difficulty of ARBs, it is usually hard to collect sufficient training data to build an accurate prediction model. A recent work proposed a method named Transfer Learning based Aging-related bug Prediction (TLAP) for performing cross-project ARB prediction. Although this method considerably improves cross-project ARB prediction performance, it has been observed that its prediction result is affected by several key factors, such as the normalization methods, kernel functions, and machine learning classifiers. Therefore, this paper presents the first empirical study to examine the impact of these factors on the effectiveness of cross-project ARB prediction in terms of single-factor pattern, bigram pattern, and triplet pattern and validates the results with the Scott-Knott test technique. We find that kernel functions and classifiers are key factors affecting the effectiveness of cross-project ARB prediction, while normalization methods do not show statistical influence. In addition, the order of values in three single-factor patterns is maintained in three bigram patterns and one triplet pattern to a large extent. Similarly, the order of values in the three bigram patterns is also maintained in the triplet pattern. © 2019, Springer Science+Business Media, LLC, part of Springer Nature.|Aging-related bugs; Cross-project; Empirical study; Software aging|Failure analysis; Learning systems; Program debugging; Software testing; Aging-related bugs; Cross-project; Empirical studies; Increasing failure rate; Normalization methods; Performance degradation; Prediction performance; Software aging; Forecasting|Article|Final||Scopus|2-s2.0-85074566426
scopus|Mannarswamy S.; Roy S.; Chidambaram S.|Mannarswamy, Sandya (16230525500); Roy, Shourya (8454170300); Chidambaram, Saravanan (57196798352)|16230525500; 8454170300; 57196798352|Tutorial on software testing & quality assurance for machine learning applications from research bench to real world|2020|ACM International Conference Proceeding Series||||373|374|1|1|10.1145/3371158.3371233|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078413837&doi=10.1145%2f3371158.3371233&partnerID=40&md5=0e10f3b393f9f8ef8aca7f7ce568b1eb|Rapid progress in Machine Learning (ML) has seen a swift translation to real world commercial deployment. While research and development of ML applications have progressed at an exponential pace, the required software engineering process for ML applications and the corresponding eco-system of testing and quality assurance tools which enable software reliable, trustworthy and safe and easy to deploy, have sadly lagged behind. Specifically, the challenges and gaps in quality assurance (QA) and testing of AI applications have largely remained unaddressed contributing to a poor translation rate of ML applications from research to real world. Unlike traditional software, which has a well-defined software testing methodology, ML applications have largely taken an ad-hoc approach to testing. ML researchers and practitioners either fall back to traditional software testing approaches, which are inadequate for this domain, due to its inherent probabilistic and data dependent nature, or rely largely on non-rigorous self-defined QA methodologies. These issues have driven the ML and Software Engineering research communities to develop of newer tools and techniques designed specifically for ML. These research advances need to be publicized and practiced in real world in ML development and deployment for enabling successful translation of ML from research prototypes to real world. This tutorial intends to address this need. © 2020 Copyright held by the owner/author(s). 978-1-4503-7738-6/20/01.|Machine Learning; Quality Assurance; Software Testing|Application programs; Learning systems; Machine learning; Quality assurance; Software quality; Well testing; Commercial deployment; Machine learning applications; Quality assurance tools; Research and development; Research prototype; Software engineering process; Testing methodology; Tools and techniques; Software testing|Conference paper|Final||Scopus|2-s2.0-85078413837
scopus||||15th International Conference On Virtual Learning, ICVL 2020|2020|Proceedings of the International Conference on Virtual Learning||||||560|0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168617187&partnerID=40&md5=f79ec4037c5c14b42cc136fb2aeb7073|The proceedings contain 77 papers. The special focus in this conference is on Virtual Learning. The topics include: Some Educational Applications of Artificial Intelligence to Real World Problem Solving; Learning about ICT-based Collaborative Practices in Urban Regeneration; Feedforward for University Geographical Online Education during the COVID-19 Pandemic; valorization of Educational Platforms in Teaching-Learning-Evaluation in Romania. Comparative Study; the Use of Animation Film in Studying Some Natural Phenomena and Forming Representations; educational Films in Understanding the Relations of Organisms with Their Living Environment; selecting Photographs from Web Sources for Online Learning Activities. Working with Representations; e-learning Natural Sciences and Visual Imagery; learning through Discovery in the Online Environment. Examples, Principles, Advantages, and Difficulties. A Case Study on Renewable Energy; experiential Learning. Students’ Design and Production of Films on Zoom Platform; guiding the Creation of Graphic Organizers through Films; trends shaping education- measuring students attitudes (thinking skills) bringing technology in the classroom; challenges of teaching - personalized students learning by using video tools to improve thinking skills; applied Digital Competences in the Innovative Didactic Methods: an overview study; online School from the Student's Perspective; effective Online Assessment in Software Testing Education; eTwinning projects, European memory and democratic participation of the youth in society; using Microsoft Teams for Teaching Romanian to Foreign Medical Students - A Comparative Skill-focused Analysis of Online vs. Onsite Progress in Learning; microlearning as a Facilitator of Learning Delivery; online Teaching and Learning - An Educational Paradigm; e-Portfolio as a Tool for Reflective Learning; data Privacy Aspects of E-learning.|||Conference review|Final||Scopus|2-s2.0-85168617187
scopus||||QANSWER 2020 - Short Papers Proceedings of the 1st International Workshop on the QuANtum SoftWare Engineering and pRogramming|2020|CEUR Workshop Proceedings|2561|||||77|0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081694188&partnerID=40&md5=f2f3d9b5cf55598caa1a5beee93e509d|The proceedings contain 9 papers. The topics discussed include: the Talavera manifesto for quantum software engineering and programming; quantum technology impact: the necessary workforce for developing quantum software; introduction to quantum development; quantum algorithms for near-term devices; quantum machine learning: benefits and practical examples; quantum software testing; reengineering of information systems toward classical-quantum systems; and adapting service delivery for quantum programming.|||Conference review|Final||Scopus|2-s2.0-85081694188
scopus||||19th International Conference on Modeling and Applied Simulation, MAS 2020|2020|19th International Conference on Modeling and Applied Simulation, MAS 2020||||||191|0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097739383&partnerID=40&md5=f2e7fc5e501e46f0f05d6c81f6cb5926|The proceedings contain 23 papers. The topics discussed include: women entrepreneurship in developing countries: simulation based fuzzy TOPSIS approach; dynamic control of multiple vehicles moving along the same rail in automated vehicle storage and retrieval systems; discrete event simulation applied to the software testing in a bank; using a virtual dataset for deep learning: improving real-world environment re-creation for human training; effective use of verification and validation resources; an experimental and modeling approach to estimate the minimum miscibility pressure of nitrogen-crude oil using dead oil samples; and hyper-parameter handling for Gaussian processes in efficient global optimization.|||Conference review|Final||Scopus|2-s2.0-85097739383
scopus|Xiao L.; Miao H.; Shi T.; Hong Y.|Xiao, Lei (57193073480); Miao, Huaikou (16176008900); Shi, Tingting (57216749612); Hong, Yu (57216747449)|57193073480; 16176008900; 57216749612; 57216747449|LSTM-based deep learning for spatial–temporal software testing|2020|Distributed and Parallel Databases|38|3||687|712|25|18|10.1007/s10619-020-07291-1|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084417507&doi=10.1007%2fs10619-020-07291-1&partnerID=40&md5=876a388fd5ebd14d1e0abbe871fd1093|Continuous integration (CI) software development practice has become more and more popular. Regression testing occurs very frequently in CI. Test case suites constantly change since new test cases are inserted and obsolete test case are removed in each cycle. The software developer hunts for quick-feedback of faults because of time constraint. An embedded software usually includes the spatial–temporal data in CI. The efficiency of regression testing for the embedded software is related to the space–time. To achieve ideal regression testing goals for the embedded software in CI, this paper proposes a novel test case prioritization approach using LSTM-Based (Long short-term memory) deep learning. LSTM is a time series prediction model. It can predict the probability of each test case detection fault in the next cycle according to the testing history information of all the previous CI cycles. The priority of test case can be obtained dynamically under the guidance of the probability. The experiments are conducted on two industrial data sets. The results verify that compared with some exiting test case prioritization approaches, our approach has better performance for embedded software as follows: (1) improve the prioritization effectiveness, (2) increase the fault detection rate in CI environment, and (3) decrease the testing execution time through automatic reduction the obsolete test cases. © 2020, Springer Science+Business Media, LLC, part of Springer Nature.|Continuous integration; Long short-term memory; Regression testing; Test case prioritization|Deep learning; Embedded software; Fault detection; Long short-term memory; Regression analysis; Software design; Continuous integrations; Fault detection rate; History informations; Regression testing; Software developer; Software development practices; Test case prioritization; Time series prediction; Software testing|Article|Final||Scopus|2-s2.0-85084417507
scopus|Saputra M.C.; Katayama T.|Saputra, Mochamad Chandra (57193243542); Katayama, Tetsuro (57193065334)|57193243542; 57193065334|Code Coverage Similarity Measurement Using Machine Learning for Test Cases Minimization|2020|2020 IEEE 9th Global Conference on Consumer Electronics, GCCE 2020|||9291990|287|291|4|3|10.1109/GCCE50665.2020.9291990|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099375360&doi=10.1109%2fGCCE50665.2020.9291990&partnerID=40&md5=9ff3f0700cd0dfcf56bca337ee36da67|Machine learning approach for minimizing the number of test cases on the test suite is an interesting research area on software testing. The research tries to minimize the number of test cases on the test suite by minimizing redundant test cases based on similarity classification. The Support Vector Machine, K-Nearest Neighbour, and Decision tree classify similar test cases by comparing the lines executed by test cases. The result has shown that the support vector machine is the highest score on accuracy and the lowest score on error rate comparing with K-Nearest Neighbour, and Decision tree. Minimize the redundant test cases increase the quality of the test cases, and reducing time on the testing process.  © 2020 IEEE.|K-Nearest Neighbour Decision Tree; Similarity; Support Vector Machine; Test Case|Decision trees; Learning systems; Nearest neighbor search; Support vector machines; Testing; Code coverage; Error rate; K-nearest neighbours; Machine learning approaches; Minimizing the number of; Redundant tests; Similarity measurements; Testing process; Software testing|Conference paper|Final||Scopus|2-s2.0-85099375360
scopus|Ahuja M.K.; Belaid M.-B.; Bernab P.; Collet M.; Gotlieb A.; Lal C.; Marijan D.; Sen S.; Sharif A.; Spieker H.|Ahuja, Mohit Kumar (57218949684); Belaid, Mohamed-Bachir (57208898379); Bernab, Pierre (57219759577); Collet, Mathieu (57209274580); Gotlieb, Arnaud (56247674500); Lal, Chhagan (46661734600); Marijan, Dusica (34872942800); Sen, Sagar (36840881900); Sharif, Aizaz (57218950297); Spieker, Helge (57189329650)|57218949684; 57208898379; 57219759577; 57209274580; 56247674500; 46661734600; 34872942800; 36840881900; 57218950297; 57189329650|Opening the software engineering toolbox for the assessment of trustworthy AI|2020|CEUR Workshop Proceedings|2659|||67|70|3|0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090901906&partnerID=40&md5=053ba6b4c8911ffab65c6cb88fe8c0ac|Trustworthiness is a central requirement for the acceptance and success of human-centered artificial intelligence (AI). To deem an AI system as trustworthy, it is crucial to assess its behaviour and characteristics against a gold standard of Trustworthy AI, consisting of guidelines, requirements, or only expectations. While AI systems are highly complex, their implementations are still based on software. The software engineering community has a long-established toolbox for the assessment of software systems, especially in the context of software testing. In this paper, we argue for the application of software engineering and testing practices for the assessment of trustworthy AI. We make the connection between the seven key requirements as defined by the European Commission's AI high-level expert group and established procedures from software engineering and raise questions for future work. © 2020 for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).||Application programs; Software testing; AI systems; Engineering community; European Commission; Gold standards; Software systems; Artificial intelligence|Conference paper|Final||Scopus|2-s2.0-85090901906
scopus|Horbiichuk M.L.; Bila O.T.; Zaiachuk Y.I.; Humeniuk T.V.|Horbiichuk, M.L. (57188683740); Bila, O.T. (57210361693); Zaiachuk, Y.I. (57210412270); Humeniuk, T.V. (57195202215)|57188683740; 57210361693; 57210412270; 57195202215|Method for evaluating technical condition of aggregates based on artificial intelligence|2020|Naukovyi Visnyk Natsionalnoho Hirnychoho Universytetu|2020|2||119|125|6|0|10.33271/nvngu/2020-2/119|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084825917&doi=10.33271%2fnvngu%2f2020-2%2f119&partnerID=40&md5=b9a099d1c0858bd07c0f94eab7a959ff|Purpose. Enhancing operational efficiency of natural gas pumping units by applying artificial intelligence methods to assess their technical condition. Methodology. The artificial neural networks theory, in particular, the counter-propagation network with two layers of Kohonen and Grossberg, was used to recognize aggregate states. The structure choice and calculation of the separation line coefficients was carried out using genetic algorithms. Findings. The task of evaluating the aggregate technical state is formed as a pattern recognition task. An analysis of literary sources has shown that the problem of pattern recognition relates to difficult-to-formulize tasks, and their solution requires new approaches, based on artificial intelligence methods. The artificial neural networks of counter propagation are proposed to use for recognizing the aggregate technical states. The article shows advisability of using the LVQ-network type, which has two layers of Kohonen and Grossberg in its composition, for this assessment. The efficiency of the network is confirmed by a test case. A genetic algorithm that allows choosing both the polynomial structure and its parameters is used to construct a diving line separating one class of signs from another. The technical condition of the lubricating system of the natural gas pumping aggregate is estimated, as an example of the developed methodology application. Originality. The AI-based method for assessing the technical state of gas-pumping units has been further developed to evaluate their state in operating mode and, based on this, develop effective algorithms for optimal loading of parallel operating aggregates. Practical value. Algorithmic and software testing was developed on the test case, based on the proposed method for assessing the aggregate technical condition. The proposed method, which effectively solves the problem of partitioning the signs planes into classes each of which characterizes its certain state, has been shown as an example of the technical state evaluation of the gas turbine engine lubrication system. © Horbiichuk M. l., Bila O. T., Zaiachuk Y. I., Humeniuk T. V., 2020.|Gas pumping unit; Genetic algorithm; Neural network; Pattern recognition; Technical condition||Article|Final|All Open Access; Gold Open Access|Scopus|2-s2.0-85084825917
scopus|Ardito L.; Coppola R.; Leonardi S.; Morisio M.; Buy U.|Ardito, Luca (36184897700); Coppola, Riccardo (57191261885); Leonardi, Simone (57216288391); Morisio, Maurizio (6701428565); Buy, Ugo (6603047581)|36184897700; 57191261885; 57216288391; 6701428565; 6603047581|Automated Test Selection for Android Apps Based on APK and Activity Classification|2020|IEEE Access|8||3029735|187648|187670|22|20|10.1109/ACCESS.2020.3029735|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095454300&doi=10.1109%2fACCESS.2020.3029735&partnerID=40&md5=b7127b4d65d05a3cf405a38eb82e9d23|Several techniques exist for mobile test automation, from script-based techniques to automated test generation based on GUI models. Most techniques fall short in being adopted extensively by practitioners because of the very costly definition (and maintenance) of test cases. We present a novel testing framework for Android apps that allows a developer to write effective test scripts without having to know the implementation details and the user interface of the app under test. The main goal of the framework is to generate adaptive tests that can be executed on a significant number of apps, or different releases of the same app, without manual editing of the tests. The frameworks consists of: (1) a Test Scripting Language, that allows the tester to write generic test scripts tailored to activity and app categories; (2) a State Graph Modeler, that creates a model of the app's GUI, identifying activities (i.e., screens) and widgets; (3) an app classifier that determines the type of application under test; (4) an activity classifier that determines the purpose of each screen; (5) a test adapter that executes test scripts that are compatible with the specific app and activity, automatically tailoring the test scripts to the classes of the app and the activities under test. We evaluated empirically the components of our testing framework. The classifiers were able to outperform available approaches in the literature. The developed testing frameworkwas able to correctly adapt high-level test cases to 28 out of 32 applications, and to reduce the LOCs of the test scripts of around 90%.We conclude that machine learning can be fruitfully applied to the creation of high-level, adaptive test cases for Android apps. Our framework is modular in nature and allows expansions through the addition of new commands to be executed on the classified apps and activities. © 2020 BMJ Publishing Group. All rights reserved.||Automation; Graphical user interfaces; Modeling languages; Testing; Activity classifications; Adaptive test case; Adaptive tests; Application under tests; Automated test; Automated test generations; Scripting languages; Testing framework; Android (operating system)|Article|Final|All Open Access; Gold Open Access; Green Open Access|Scopus|2-s2.0-85095454300
scopus|Shulga T.; Sytnik A.; Danilov N.; Palashevskii D.|Shulga, Tatiana (57189023844); Sytnik, Alexander (36817223300); Danilov, Nikita (57189034016); Palashevskii, Denis (57212471983)|57189023844; 36817223300; 57189034016; 57212471983|Ontology-Based Model of User Activity Data for Cyber-Physical Systems|2020|Studies in Systems, Decision and Control|259|||205|216|11|2|10.1007/978-3-030-32579-4_16|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076775151&doi=10.1007%2f978-3-030-32579-4_16&partnerID=40&md5=6aea6b92a8a80623ed871f17af12f5b5|The chapter focuses on the issue of modeling of user interaction with the graphical interface of cyber-physical systems. The primary subject of the presented study is users activity data, that is the user’s actions with system graphical interface and their characteristics. This data is collected during the process of software testing or experimental operation. An overview of existing ontologies of domain «Information Systems Graphic Interface» is given. We propose an open model of user activity data in the form of ontology based on the OWL 2 DL language. The main classes, properties, and axioms of this model are covered in the report. This model differs from the other existing ontologies in that it is focused on user activity data rather than the interface and its elements. In addition, it is based on description logic SHOIQ (D), which makes it possible to draw logical conclusions in the process of analysis by experts of the system usability. We also present the structure of software developed for user activity data collection which allows filling the ontology with specific data on the user experience with the interface. As an example, we describe possible tasks where the model and collected data can be used. © 2020, Springer Nature Switzerland AG.|Description logics; OWL ontology; Usability; User activity data; User interface||Book chapter|Final||Scopus|2-s2.0-85076775151
scopus|Tahvili S.; Hatvani L.; Ramentol E.; Pimentel R.; Afzal W.; Herrera F.|Tahvili, Sahar (37093975500); Hatvani, Leo (36696277600); Ramentol, Enislay (35303359200); Pimentel, Rita (57191900753); Afzal, Wasif (24832739300); Herrera, Francisco (7102347190)|37093975500; 36696277600; 35303359200; 57191900753; 24832739300; 7102347190|A novel methodology to classify test cases using natural language processing and imbalanced learning|2020|Engineering Applications of Artificial Intelligence|95||103878||||31|10.1016/j.engappai.2020.103878|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089416670&doi=10.1016%2fj.engappai.2020.103878&partnerID=40&md5=a4f298102ad1f065e676a33f25599c97|Detecting the dependency between integration test cases plays a vital role in the area of software test optimization. Classifying test cases into two main classes – dependent and independent – can be employed for several test optimization purposes such as parallel test execution, test automation, test case selection and prioritization, and test suite reduction. This task can be seen as an imbalanced classification problem due to the test cases’ distribution. Often the number of dependent and independent test cases is uneven, which is related to the testing level, testing environment and complexity of the system under test. In this study, we propose a novel methodology that consists of two main steps. Firstly, by using natural language processing we analyze the test cases’ specifications and turn them into a numeric vector. Secondly, by using the obtained data vectors, we classify each test case into a dependent or an independent class. We carry out a supervised learning approach using different methods for handling imbalanced datasets. The feasibility and possible generalization of the proposed methodology is evaluated in two industrial projects at Bombardier Transportation, Sweden, which indicates promising results. © 2020 The Authors|Artificial intelligence; Doc2Vec; IFROWANN; Imbalanced classification; Natural language processing; Optimization; Software testing|Learning systems; Natural language processing systems; Testing; Bombardier Transportation; Imbalanced classification; Imbalanced Data-sets; Imbalanced Learning; NAtural language processing; Supervised learning approaches; Test case selection; Test suite reduction; Software testing|Article|Final|All Open Access; Green Open Access; Hybrid Gold Open Access|Scopus|2-s2.0-85089416670
scopus|Li J.J.; Ulrich A.; Bai X.; Bertolino A.|Li, J. Jenny (57196156442); Ulrich, Andreas (35744004900); Bai, Xiaoying (15060098000); Bertolino, Antonia (7006797074)|57196156442; 35744004900; 15060098000; 7006797074|Advances in test automation for software with special focus on artificial intelligence and machine learning|2020|Software Quality Journal|28|1||245|248|3|20|10.1007/s11219-019-09472-3|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076506880&doi=10.1007%2fs11219-019-09472-3&partnerID=40&md5=fab155363ad053bd270a6d5188e95fa2|[No abstract available]|||Editorial|Final|All Open Access; Bronze Open Access|Scopus|2-s2.0-85076506880
scopus|Trudova A.; Dolezel M.; Buchalcevova A.|Trudova, Anna (57218223206); Dolezel, Michal (36715874000); Buchalcevova, Alena (25122521900)|57218223206; 36715874000; 25122521900|Artificial intelligence in software test automation: A systematic literature review|2020|ENASE 2020 - Proceedings of the 15th International Conference on Evaluation of Novel Approaches to Software Engineering||||181|192|11|15||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088383019&partnerID=40&md5=67678f742c69103932c85b1f2be699c3|Artificial intelligence (AI) has made a considerable impact on the software engineering field, and the area of software testing is not an exception. In theory, AI techniques could help to achieve the highest possible level of software test automation. The goal of this Systematic Literature Review (SLR) paper is to highlight the role of artificial intelligence in the software test automation area through cataloguing AI techniques and related software testing activities to which the techniques can be applied. Specifically, the potential influence of AI on those activities was explored. To this end, the SLR was performed with the focus on research studies reporting the implementation of AI techniques in software test automation. Out of 34 primary studies that were included in the final set, 9 distinct software testing activities were identified. These activities had been reportedly improved by applying the AI techniques mostly from the machine learning and computer vision fields. According to the reviewed primary studies, the improvement was achieved in terms of reusability of test cases, manual effort reduction, improved coverage, improved fault and vulnerability detection. Several publicly accessible AI-enhanced tools for software test automation were discovered during the review as well. Their short summary is presented. © Copyright 2020 by SCITEPRESS - Science and Technology Publications, Lda. All rights reserved.|Artificial Intelligence; Literature Study; Software Testing; Test Automation; Test Tools|Automation; Reusability; Software testing; AI techniques; Publicly accessible; Research studies; Software test automation; Systematic literature review; Systematic literature review (SLR); Test case; Vulnerability detection; Artificial intelligence|Conference paper|Final||Scopus|2-s2.0-85088383019
scopus|Almaghairbe R.; Roper M.; Almabruk T.|Almaghairbe, Rafig (56926672300); Roper, Marc (7005191257); Almabruk, Tahani (57039189500)|56926672300; 7005191257; 57039189500|Machine learning techniques for automated software fault detection via dynamic execution data: Empirical evaluation study|2020|ACM International Conference Proceeding Series|||3410747||||1|10.1145/3410352.3410747|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090912080&doi=10.1145%2f3410352.3410747&partnerID=40&md5=32867fad639d8885b84e5cc147e916da|The biggest obstacle of automated software testing is the construction of test oracles. Today, it is possible to generate enormous amount of test cases for an arbitrary system that reach a remarkably high level of coverage, but the effectiveness of test cases is limited by the availability of test oracles that can distinguish failing executions. Previous work by the authors has explored the use of unsupervised and semi-supervised learning techniques to develop test oracles so that the correctness of software outputs and behaviours on new test cases can be predicated [1], [2], [10], and experimental results demonstrate the promise of this approach. In this paper, we present an evaluation study for test oracles based on machine-learning approaches via dynamic execution data (firstly, input/output pairs and secondly, amalgamations of input/output pairs and execution traces) by comparing their effectiveness with existing techniques from the specification mining domain (the data invariant detector Daikon [5]). The two approaches are evaluated on a range of mid-sized systems and compared in terms of their fault detection ability and false positive rate. The empirical study also discuss the major limitations and the most important properties related to the application of machine learning techniques as test oracles in practice. The study also gives a road map for further research direction in order to tackle some of discussed limitations such as accuracy and scalability. The results show that in most cases semi-supervised learning techniques performed far better as an automated test classifier than Daikon (especially in the case that input/output pairs were augmented with their execution traces). However, there is one system for which our strategy struggles and Daikon performed far better. Furthermore, unsupervised learning techniques performed on a par when compared with Daikon in several cases particularly when input/output pairs were used together with execution traces. © 2020 ACM.|Automated Testing Oracles; Empirical Study; Machine Learning Techniques; Specification Mining|Automation; Fault detection; Metals; Semi-supervised learning; Software testing; Testing; Automated software testing; Empirical evaluations; Empirical studies; False positive rates; Machine learning techniques; Semi-supervised learning techniques; Software fault detection; Specification mining; Learning systems|Conference paper|Final|All Open Access; Green Open Access|Scopus|2-s2.0-85090912080
scopus|Rosenbauer L.; Stein A.; Pätzel D.; Hähner J.|Rosenbauer, Lukas (57218600362); Stein, Anthony (56226088700); Pätzel, David (57203392600); Hähner, Jörg (20436196300)|57218600362; 56226088700; 57203392600; 20436196300|XCSF for Automatic Test Case Prioritization|2020|International Joint Conference on Computational Intelligence|1|||49|58|9|0|10.5220/0010105700490058|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190666580&doi=10.5220%2f0010105700490058&partnerID=40&md5=a1acd92e4174ec65b3264564283e8696|Testing is a crucial part in the development of a new product. Due to the change from manual testing to automated testing, companies can rely on a higher number of tests. There are certain cases such as smoke tests where the execution of all tests is not feasible and a smaller test suite of critical test cases is necessary. This prioritization problem has just gotten into the focus of reinforcement learning. A neural network and an XCS classifier system have been applied to this task. Another evolutionary machine learning approach is the XCSF which produces, unlike XCS, continuous outputs. In this work we show that XCSF is superior to both the neural network and XCS for this problem. © 2020 by SCITEPRESS – Science and Technology Publications, Lda. All rights reserved.|Evolutionary Machine Learning; Learning Classifier Systems; Reinforcement Learning; Testing|Learning systems; Reinforcement learning; Automated testing; Evolutionary machine learning; Learning classifier system; Machine-learning; Manual testing; Neural-networks; Reinforcement learnings; Smoke test; Test case; Test case prioritization; Smoke|Conference paper|Final|All Open Access; Green Open Access; Hybrid Gold Open Access|Scopus|2-s2.0-85190666580
scopus|Mendiratta V.B.|Mendiratta, Veena B. (8213250300)|8213250300|Reliability analysis in telecommunications|2020|Notices of the American Mathematical Society|67|6||867|875|8|1|10.1090/noti2095|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090625299&doi=10.1090%2fnoti2095&partnerID=40&md5=fc203f759af7decc1d0739116572c7f7|In this paper we provided a characterization of telecom systems with respect to reliability, and presented examples to illustrate the types of mathematical modeling and analyses that are done in an industrial setting in the process of building a reliable telecom system. The models were presented in terms of the different phases of the product realization process. As telecommunications systems have stringent reliability requirements, modeling is an important part of the development process, starting with models to evaluate alternative architectures, to predicting the expected field reliability at the end of the testing phase. A range of techniques is used, ranging from classic (and simpler) techniques, such as reliability block diagrams, fault trees, and Markov models, to more complex approaches, such as stochastic Petri nets and Bayesian belief networks. An overview of ML-based approaches was presented which can be used when there is a large volume of data available, such as from automated testing or from telemetry data and log data for deployed systems. © 2020, American Mathematical Society. All rights reserved.|||Article|Final|All Open Access; Bronze Open Access|Scopus|2-s2.0-85090625299
scopus|Usman M.; Wang W.; Wang K.; Yelen C.; Dini N.; Khurshid S.|Usman, Muhammad (57203225965); Wang, Wenxi (57190262754); Wang, Kaiyuan (57193337833); Yelen, Cagdas (57195391618); Dini, Nima (57193358895); Khurshid, Sarfraz (56231912700)|57203225965; 57190262754; 57193337833; 57195391618; 57193358895; 56231912700|A study of learning likely data structure properties using machine learning models|2020|International Journal on Software Tools for Technology Transfer|22|5||601|615|14|1|10.1007/s10009-020-00577-w|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086127192&doi=10.1007%2fs10009-020-00577-w&partnerID=40&md5=c4418242271a8a7e85375f8c1d99f3cd|Data structure properties are important for many testing and analysis tasks. For example, model checkers use these properties to find program faults. These properties are often written manually which can be error prone and lead to false alarms. This paper presents the results of controlled experiments performed using existing machine learning (ML) models on various data structures. These data structures are dynamic and reside on the program heap. We use ten data structure subjects and ten ML models to evaluate the learnability of data structure properties. The study reveals five key findings. One, most of the ML models perform well in learning data structure properties, but some of the ML models such as quadratic discriminant analysis and Gaussian naive Bayes are not suitable for learning data structure properties. Two, most of the ML models have high performance even when trained on just 1% of data samples. Three, certain data structure properties such as binary heap and red black tree are more learnable than others. Four, there are no significant differences between the learnability of varied-size (i.e., up to a certain size) and fixed-size data structures. Five, there can be significant differences in performance based on the encoding used. These findings show that using machine learning models to learn data structure properties is very promising. We believe that these properties, once learned, can be used to provide a run-time check to see whether a program state at a particular point satisfies the learned property. Learned properties can also be employed in the future to automate static and dynamic analysis, which would enhance software testing and verification techniques. © 2020, Springer-Verlag GmbH Germany, part of Springer Nature.|Data structure invariants; Korat; Learnability; Machine learning|Binary trees; Discriminant analysis; Machine learning; Model checking; Software testing; Trees (mathematics); Controlled experiment; Machine learning models; Performance based; Quadratic discriminant analysis; Run-time checks; Static and dynamic analysis; Structure property; Verification techniques; Structural properties|Article|Final||Scopus|2-s2.0-85086127192
scopus|Tan S.H.; Li Z.|Tan, Shin Hwei (42162322300); Li, Ziqiang (57219605878)|42162322300; 57219605878|Collaborative bug finding for android apps|2020|Proceedings - International Conference on Software Engineering|||3380349|1335|1347|12|21|10.1145/3377811.3380349|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094130539&doi=10.1145%2f3377811.3380349&partnerID=40&md5=873f69ddfabf0e2b9d2b504c590c8f8d|Many automated test generation techniques have been proposed for finding crashes in Android apps. Despite recent advancement in these approaches, a study shows that Android app developers prefer reading test cases written in natural language. Meanwhile, there exist redundancies in bug reports (written in natural language) across different apps that have not been previously reused. We propose collaborative bug finding, a novel approach that uses bugs in other similar apps to discover bugs in the app under test. We design three settings with varying degrees of interactions between programmers: (1) bugs from programmers who develop a different app, (2) bugs from manually searching for bug reports in GitHub repositories, (3) bugs from a bug recommendation system, Bugine. Our studies of the first two settings in a software testing course show that collaborative bug finding helps students who are novice Android app testers to discover 17 new bugs. As students admit that searching for relevant bug reports could be time-consuming, we introduce Bugine, an approach that automatically recommends relevant GitHub issues for a given app. Bugine uses (1) natural language processing to find GitHub issues that mention common UI components shared between the app under test and other apps in our database, and (2) a ranking algorithm to select GitHub issues that are of the best quality. Our results show that Bugine is able to find 34 new bugs. In total, collaborative bug finding helps us find 51 new bugs, in which eight have been confirmed and 11 have been fixed by the developers. These results confirm our intuition that our proposed technique is useful in discovering new bugs for Android apps.  © 2020 Association for Computing Machinery.|Android apps; Collaborative programming; Recommendation system; Test generation|Application programs; Natural language processing systems; Program debugging; Software testing; Android apps; Automated test generations; Bug finding; Bug reports; NAtural language processing; Natural languages; Ranking algorithm; UI components; Android (operating system)|Conference paper|Final||Scopus|2-s2.0-85094130539
scopus|Chen L.-K.; Chen Y.-H.; Chang S.-F.; Chang S.-C.|Chen, Lin-Kung (56666238700); Chen, Yen-Hung (56034163900); Chang, Shu-Fang (55494244200); Chang, Shun-Chieh (57219387487)|56666238700; 56034163900; 55494244200; 57219387487|A long/short-term memory based automated testing model to quantitatively evaluate game design|2020|Applied Sciences (Switzerland)|10|19|6704||||2|10.3390/APP10196704|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092455243&doi=10.3390%2fAPP10196704&partnerID=40&md5=60d4fdbc7ae5530e6b570ab2245cc406|"The mobile casual game application lifespan is getting shorter. Acompany has to shorten the game testing procedure to avoid being squeezed out of the game market share. There is no sufficient testing indicator to objectively evaluate the operability of different game designs. Many automated testing methodologies are proposed, but they adopt rule-based approaches and cannot provide quantitative analysis to statistically evaluate gameplay experience. This study suggests applying ""Learning Time"" as a testing indicator and using the learning curve to identify the operability of different game designs. This study also proposes a Long/Short-Term Memory based automated testing model (called LSTM-Testing) to statistically testing game experience through end-to-end functionality (Input: game image; Output: game action) without any manual intervention. The experiment results demonstrate LSTM-Testing can provide quantitative testing data by using learning time as the control variable, game design as the independent variable, and time to complete game as the dependent variable. This study also demonstrates how LSTM-Testing evaluates the effectiveness of different gameplay learning strategies, e.g., reviewing the newest decisions, reviewing the correct decision, or reviewing the wrong decisions. The contributions of LSTM-Testing are (1) providing an objective and quantitative analytical game-testing framework, (2) reducing the labor cost of inefficient and subjective manual game testing, and (3) allowing game company boosts software development by focusing on game intellectual property and leaves game testing to artificial intelligence (AI). © 2020 by the authors."|Artificial intelligence; Artificial neural networks; Quality management; Software measurement; Software testing||Article|Final|All Open Access; Gold Open Access|Scopus|2-s2.0-85092455243
scopus|Yalla M.; Sunil A.|Yalla, Muralidhar (57219516812); Sunil, Asha (57219515448)|57219516812; 57219515448|AI-driven conversational bot test automation using industry specific data cartridges|2020|Proceedings - 2020 IEEE/ACM 1st International Conference on Automation of Software Test, AST 2020||||105|107|2|4|10.1145/3387903.3389306|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093532027&doi=10.1145%2f3387903.3389306&partnerID=40&md5=3deb462a3420a3b33562995f7ce18b3e|The paper describes an in-house accelerator to generate alternate synonymous sentences and similar intent from sample utterances, the generated data can be applied as test input for conversational AI bots (either text or voice-based). Its NLP-driven sentence generator exposes a RESTful service, which can be consumed by automated testing tools/frameworks such as Katalon, Selenium, and so on. The paper presents building an accelerator to quickly teach and test adaptive conversational AI bots. The approach helps to analyze user inputs and extract intent, the bot developer should ensure a variety of possible utterances are coded. In the traditional manual approach, it is difficult to conceive every possible user utterance before deploying the bot and hence the bot has an early failure rate. This may diminish the usefulness of the bot and the users may stop using the same. Here we propose an AI-driven bot test automation approach using a patent-pending in-house accelerator referenced as LemmaCartridge (LC) in this paper. Testing tools or frameworks can consume LC's data cartridge API for testing the bot AUT and analyze the responses using automated tools/frameworks like Katalon, Selenium and so on until the bot demonstrates desired outcomes under the supervised train, test and adaptive repeatable testing methods yielding quality@speed for the single major goal of testing conversational AI bots. An example of a program used in experiment is described and the results obtained, especially train and test state machines, industry-specific data cartridges that enable to unearth errors in the AI bot under test, are presented.  © 2020 Association for Computing Machinery.|Conversational AI Bot; NLP Automation; Test Data Generation|Automation; Botnet; Failure analysis; Projectiles; Selenium; Testing; Automated testing tools; Automated tools; Early failure; RESTful Services; State machine; Test Automation; Testing method; Testing tools; Software testing|Conference paper|Final||Scopus|2-s2.0-85093532027
scopus|Demir S.; Eniser H.F.; Sen A.|Demir, Samet (57218576598); Eniser, Hasan Ferit (56814994200); Sen, Alper (36467092300)|57218576598; 56814994200; 36467092300|DeepSmartFuzzer: Reward guided test generation for deep learning|2020|CEUR Workshop Proceedings|2640||||||6||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089622003&partnerID=40&md5=a13b22734eccd68db36da11e20f9e02e|Testing Deep Neural Network (DNN) models has become more important than ever with the increasing usage of DNN models in safety-critical domains such as autonomous cars. Traditionally, DNN testing relies on the performance on a dedicated subset of the available data, namely test set. However, DNNs require more thorough testing approaches to exercise corner-case behaviors. Coverage-guided fuzzing (CGF) which is a common practice in software testing aims to produce new test inputs by mutating existing ones to achieve high coverage on a test adequacy criterion. CGF has been an effective method for finding error inducing inputs by satisfying a well-established criterion. In this paper, we propose a novel CGF algorithm for structural testing of DNNs. The proposed algorithm employs Monte Carlo Tree Search to drive the coverage-guided search. In our evaluation, we show that the inputs generated by our method result in higher coverage than the inputs produced by the previously introduced CGF techniques on various criteria in a fixed amount of time. © 2020 for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).||Deep neural networks; Digital storage; Safety engineering; Safety testing; Software testing; Trees (mathematics); Corner case; Guided search; Monte-Carlo tree searches; Safety-critical domain; Structural testing; Test adequacy criteria; Test generations; Test inputs; Deep learning|Conference paper|Final||Scopus|2-s2.0-85089622003
scopus|Glavinić V.|Glavinić, Vlado (6602430733)|6602430733|Editorial|2020|Journal of Computing and Information Technology|28|3||1|2|1|0||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111317998&partnerID=40&md5=1413a21ba905a9d254f47c8fdce248e4|This third issue (September 2020) of CIT. Journal of Computing and Information Technology comprises four papers from the regular section, tackling topics from the areas of software testing and debugging, machine learning, natural language processing and business management processing. © 2020, Journal of Computing and Information Technology. All Rights Reserved.|||Editorial|Final||Scopus|2-s2.0-85111317998
scopus|Rosenbauer L.; Stein A.; Pätzel D.; Hähner J.|Rosenbauer, Lukas (57218600362); Stein, Anthony (56226088700); Pätzel, David (57203392600); Hähner, Jörg (20436196300)|57218600362; 56226088700; 57203392600; 20436196300|XCSF for automatic test case prioritization|2020|IJCCI 2020 - Proceedings of the 12th International Joint Conference on Computational Intelligence||||49|58|9|5||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099712808&partnerID=40&md5=743c820d75d616e5bfcaa2a514908593|Testing is a crucial part in the development of a new product. Due to the change from manual testing to automated testing, companies can rely on a higher number of tests. There are certain cases such as smoke tests where the execution of all tests is not feasible and a smaller test suite of critical test cases is necessary. This prioritization problem has just gotten into the focus of reinforcement learning. A neural network and an XCS classifier system have been applied to this task. Another evolutionary machine learning approach is the XCSF which produces, unlike XCS, continuous outputs. In this work we show that XCSF is superior to both the neural network and XCS for this problem. Copyright © 2020 by SCITEPRESS - Science and Technology Publications, Lda. All rights reserved|Evolutionary machine learning; Learning classifier systems; Reinforcement learning; Testing|Intelligent computing; Neural networks; Pattern recognition systems; Reinforcement learning; Smoke; Automated testing; Machine learning approaches; Manual testing; Prioritization; Smoke test; Test case; Test case prioritization; XCS classifier systems; Learning systems|Conference paper|Final||Scopus|2-s2.0-85099712808
scopus|Mi W.; Li Y.; Wang S.|Mi, Wenbo (57221133849); Li, Yong (57188935137); Wang, Shibo (57221131544)|57221133849; 57188935137; 57221131544|Empirical evaluation of the active learning strategies on software defects prediction|2020|Proceedings - 2020 6th International Symposium on System and Software Reliability, ISSSR 2020|||9265897|83|89|6|3|10.1109/ISSSR51244.2020.00021|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098322417&doi=10.1109%2fISSSR51244.2020.00021&partnerID=40&md5=7b0a9b5114659871f23fe695ddb04b98|Software defect prediction is a popular technical method in software engineering. In order to reduce the cost of a software defects, problems existing in the software are found by testing software products. Software defect prediction often uses machine learning techniques to improve the performance of software testing but requires enough labeled data when training the model. Because the cost of obtaining data is different from the label, the data is easy to obtain, but the label is cumbersome and expensive. In order to demonstrate software defect prediction, after the data obtained active learning algorithm is introduced to query the data, and the most valuable data is selected for expert annotation and then put into the model for training. However, it is not clear which active learning query strategy to choose the most effective in the software defect prediction model. We use different active learning strategy software defect prediction models for comparison. Experiment on the NASA dataset, using Naive Bayes and SVM, Linear Regression as the classifier. Comprehensive research results show that the Density-weighted strategy has a significant effect on the data set.  © 2020 IEEE.|Active learning; Machine learning; Query strategy; Software defect prediction|Classification (of information); Defects; Learning algorithms; NASA; Software testing; Support vector machines; Active Learning; Active learning strategies; Defect prediction models; Empirical evaluations; Machine learning techniques; Query strategies; Software defect prediction; Software defects; Software products; Testing software; Forecasting|Conference paper|Final||Scopus|2-s2.0-85098322417
scopus|Guidotti R.; Monreale A.|Guidotti, Riccardo (56506805200); Monreale, Anna (35113703300)|56506805200; 35113703300|Data-agnostic local neighborhood generation|2020|Proceedings - IEEE International Conference on Data Mining, ICDM|2020-November||9338395|1040|1045|5|4|10.1109/ICDM50108.2020.00122|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100906806&doi=10.1109%2fICDM50108.2020.00122&partnerID=40&md5=74354847c55f44c0951e3fa0ae9e189b|Synthetic data generation has been widely adopted in software testing, data privacy, imbalanced learning, machine learning explanation, etc. In such contexts, it is important to generate data samples located within 'local' areas surrounding specific instances. Local synthetic data can help the learning phase of predictive models, and it is fundamental for methods explaining the local behavior of obscure classifiers. The contribution of this paper is twofold. First, we introduce a method based on generative operators allowing the synthetic neighborhood generation by applying specific perturbations on a given input instance. The key factor consists in performing a data transformation that makes applicable to any type of data, i.e., data-agnostic. Second, we design a framework for evaluating the goodness of local synthetic neighborhoods exploiting both supervised and unsupervised methodologies. A deep experimentation shows the effectiveness of the proposed method. © 2020 IEEE.|Data Mining; Data-Agnostic Generator; Explainable Machine Learning; Synthetic Neighborhood Generation|Learning systems; Metadata; Predictive analytics; Privacy by design; Software testing; Data transformation; Imbalanced Learning; Key factors; Learning phase; Local neighborhoods; Predictive models; Synthetic data; Synthetic data generations; Data mining|Conference paper|Final||Scopus|2-s2.0-85100906806
scopus|Deresu E.; Velmurugan L.; Manoharan S.|Deresu, Eshetu (57219422006); Velmurugan, L. (57213608587); Manoharan, S. (57708907700)|57219422006; 57213608587; 57708907700|Pharmacovigilance based artificial intelligence and machine learning in software testing-an empirical view|2020|International Journal of Pharmaceutical Research|12|4||3807|3810|3|0|10.31838/ijpr/2020.12.04.520|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105697251&doi=10.31838%2fijpr%2f2020.12.04.520&partnerID=40&md5=28dc9d4029a00c7f81f80f437bdc88b0|The test cycle in software engineering process would progress if testing is automated and thus consequences in improvement in automatic data access, test run and testing cycle. The process of test creation and increase in case coverage can be done through new contexts and procedures to improve quality assurance. Introducing the self-learning algorithms will move the testing mechanism to next new level by incorporating many automated tools and thus usage of test automation is in high demand. This paper reveals and explores the areas and tools in software testing where pharmacovigilance based artificial intelligence/machine learning integration can be used for quality assurance. © 2020, Advanced Scientific Research. All rights reserved.|DevOps; Machine Learning; Pharmacovigilance based artificial intelligence; Test Automation|article; artificial intelligence; automation; machine learning; pharmacovigilance; quality control; software|Article|Final||Scopus|2-s2.0-85105697251
scopus|Pavanetto S.; Brambilla M.|Pavanetto, Silvio (57217293941); Brambilla, Marco (57226223274)|57217293941; 57226223274|Generation of realistic navigation paths for web site testing using recurrent neural networks and generative adversarial neural networks|2020|Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)|12128 LNCS|||244|258|14|1|10.1007/978-3-030-50578-3_17|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087016613&doi=10.1007%2f978-3-030-50578-3_17&partnerID=40&md5=65ed30a5d7390a14ca47aa1b4cf748b5|A robust technique for generating web navigation logs could be fundamental for applications not yet released, since developers could evaluate their applications as if they were used by real clients. This could allow to test and improve the applications faster and with lower costs, especially with respect to the usability and interaction aspects. In this paper we propose the application of deep learning techniques, like recurrent neural networks (RNN) and generative adversarial neural networks (GAN), aimed at generating high-quality weblogs, which can be used for automated testing and improvement of Web sites even before their release. © Springer Nature Switzerland AG 2020.|Data mining; Deep learning; Generative adversarial networks; Recurrent neural networks; Testing; Web engineering|Websites; Automated testing; High quality; Learning techniques; Navigation paths; Recurrent neural network (RNN); Robust technique; Site-testing; Web navigation; Recurrent neural networks|Conference paper|Final||Scopus|2-s2.0-85087016613
scopus|Khan F.; Kanwal S.; Alamri S.; Mumtaz B.|Khan, Faiza (57215031941); Kanwal, Summrina (54384474400); Alamri, Sultan (55309049800); Mumtaz, Bushra (57215046485)|57215031941; 54384474400; 55309049800; 57215046485|Hyper-parameter optimization of classifiers, using an artificial immune network and its application to software bug prediction|2020|IEEE Access|8||8966271|20954|20964|10|53|10.1109/ACCESS.2020.2968362|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079752229&doi=10.1109%2fACCESS.2020.2968362&partnerID=40&md5=3ffd3e5ff326eff09797d4b1236897f3|Software testing is an important task in software development activities, and it requires most of the resources, namely, time, cost and effort. To minimize this fatigue, software bug prediction (SBP) models are applied to improve the software quality assurance (SQA) processes by predicting buggy components. The bug prediction models use machine learning classifiers so that bugs can be predicted in software components in some software metrics. These classifiers are characterized by some configurable parameters, called hyper-parameters that need to be optimized to ensure better performance. Many methods have been proposed by researchers to predict the defective components but these classifiers sometimes not perform well when default settings are used for machine learning classifiers. In this paper, software bug prediction model is proposed which uses machine learning classifiers in conjunction with the Artificial Immune Network (AIN) to improve bug prediction accuracy through its hyper-parameter optimization. For this purpose, seven machine learning classifiers, such as support vector machine Radial base function (SVM-RBF), K-nearest neighbor (KNN) (Minkowski metric), KNN (Euclidean metric), Naive Bayes (NB), Decision Tree (DT), Linear discriminate analysis (LDA), Random forest (RF) and adaptive boosting (AdaBoost), were used. The experiment was carried out on bug prediction dataset. The results showed that hyper-parameter optimization of machine learning classifiers, using AIN and its applications for software bug prediction, performed better than when classifiers with their default hyper-parameters were used. © 2013 IEEE.|Artificial immune network (AIN); artificial immune system (AIS); hyper-parameter optimization; optimized artificial immune network (opt-aiNet); software bug prediction (SBP)|Adaptive boosting; Application programs; Barium compounds; Computer software selection and evaluation; Decision trees; Forecasting; Machine components; Nearest neighbor search; Program debugging; Quality assurance; Random forests; Software design; Software quality; Software testing; Support vector machines; Artificial immune networks; Artificial Immune System; Hyper-parameter optimizations; Opt-aiNet; Software bug; Learning systems|Article|Final|All Open Access; Gold Open Access|Scopus|2-s2.0-85079752229
scopus|Bahaweres R.B.; Agustian F.; Hermadi I.; Suroso A.I.; Arkeman Y.|Bahaweres, Rizal Broer (55625202600); Agustian, Fajar (57220892952); Hermadi, Irman (23967933100); Suroso, Arif Imam (53864020700); Arkeman, Yandra (55946558300)|55625202600; 57220892952; 23967933100; 53864020700; 55946558300|Software defect prediction using neural network based smote|2020|International Conference on Electrical Engineering, Computer Science and Informatics (EECSI)|2020-October|||71|76|5|23|10.23919/EECSI50503.2020.9251874|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097808866&doi=10.23919%2fEECSI50503.2020.9251874&partnerID=40&md5=149763ce4f76cad6c46403b843ed1ece|Software defect prediction is a practical approach to improve the quality and efficiency of time and costs for software testing by focusing on defect modules. The dataset of software defect prediction naturally has a class imbalance problem with very few defective modules compared to non-defective modules. This situation has a negative impact on the Neural Network, which can lead to overfitting and poor accuracy. Synthetic Minority Over-sampling Technique (SMOTE) is one of the popular techniques that can solve the problem of class imbalance. However, Neural Network and SMOTE both have hyperparameters which must be determined by the user before the modelling process. In this study, we applied the Neural Networks Based SMOTE, a combination of Neural Network and SMOTE with each hyperparameter of SMOTE and Neural Network that are optimized using random search to solve the class imbalance problem in the six NASA datasets. The results use a 5*5 cross-validation show that increases Bal by 25.48% and Recall by 45.99% compared to the original Neural Network. We also compare the performance of Neural Network-based SMOTE with ”Traditional” Machine Learning-based SMOTE. The Neural Network-based SMOTE takes first place in the average rank. © 2020 Institute of Advanced Engineering and Science (IAES). All Rights Reserved.|Class Imbalance; Neural Network; Software Defect Prediction; Synthetic Minority Over-sampling Technique||Conference paper|Final||Scopus|2-s2.0-85097808866
scopus|Ko I.-Y.; Baek K.D.; Kwon J.-H.; Lira H.; Moon H.C.|Ko, In-Young (7005391573); Baek, KyeongDeok (57194522988); Kwon, Jung-Hyun (56727298500); Lira, Hernan (57225964217); Moon, HyeongCehol (57208674618)|7005391573; 57194522988; 56727298500; 57225964217; 57208674618|Environment-Aware and Human-Centric Software Testing Framework for Cyber-Physical Systems|2020|Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)|11609 LNCS|||104|115|11|0|10.1007/978-3-030-51253-8_11|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088254234&doi=10.1007%2f978-3-030-51253-8_11&partnerID=40&md5=cecea1bdef240bd03e7a1c56659d6736|The functionalities, actuations and effects that are produced by an application of a cyber physical system (CPS) are usually consumed by users while they perform their daily activities. Therefore, it is critical to ensure that they do not interfere with human activities and do not harm the people who are involved in the CPS. In this paper, we propose a framework to test and verify the reliability and safety of CPS applications in the perspectives of CPS environments and users. The framework provides an environment-aware testing method by which the efficiency of testing CPS applications can be improved by prioritizing CPS environments, and by applying machine learning techniques. The framework also includes a metric and an algorithm by which we can test and choose the most effective services that can deliver effects from their associated physical devices to users. In addition, the framework provides a computational model to test whether a CPS application may cause a cognitive depletion or contention problems for users. © 2020, Springer Nature Switzerland AG.|Environment-aware testing; Human cognitive resources; Service effects; Service-oriented CPS software|Cyber Physical System; Embedded systems; Knowledge representation; Learning systems; Computational model; Cyber-physical systems (CPS); Efficiency of testing; Human activities; Machine learning techniques; Physical devices; Reliability and safeties; Testing framework; Software testing|Conference paper|Final||Scopus|2-s2.0-85088254234
scopus|Toure F.; Badri M.|Toure, Fadel (36460375500); Badri, Mourad (57203205678)|36460375500; 57203205678|Unit testing effort prioritization using combined datasets and deep learning: A cross-systems validation|2020|Proceedings of the International Conference on Software Engineering and Knowledge Engineering, SEKE|PartF162440|||359|364|5|0|10.18293/SEKE2020-150|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090508661&doi=10.18293%2fSEKE2020-150&partnerID=40&md5=4dac9fe8e56d7197ccf913c3c2ad0f2d|Unit testing plays a crucial role in object-oriented software quality assurance. Software testing is often conducted under tight time and resource constraints. Hence, testers do not usually cover all software classes. Testing needs to be prioritized and testing effort to be focused on critical components. The research we present in this paper is part of the development of a collaborative decision support tool allowing the developers' community to pool their unit testing experiences when selecting the candidate classes for unit tests. To achieve this, we proposed in our previous work a unit tests prioritization approach based on software information histories and software metrics. The goal is to suggest classes to be tested by building a classifier that matches the testers selection. Several machine learning classifiers have been previously considered. The current paper explores the deep neural network models with more software source code metrics including explicitly and implicitly tested classes. The training datasets that have been combined are from different systems. So, we considered metrics ranks. Using a cross systems validation technique, obtained results strongly suggest that deep neural network-based classifiers correctly reflect the tester's selections and could thus help in decision support during the selection of candidate classes for unit tests. © 2020 Knowledge Systems Institute Graduate School. All rights reserved.|Deep Learning; Deep Neural Network; Machine Learning Classifiers; Source Code Metrics; Tests Prioritization; Unit Tests|Computer software selection and evaluation; Decision support systems; Deep neural networks; Learning systems; Neural networks; Object oriented programming; Quality assurance; Software quality; Software testing; Collaborative decisions; Critical component; Information history; Neural network model; Object-oriented software qualities; Resource Constraint; Software source codes; Training data sets; Deep learning|Conference paper|Final||Scopus|2-s2.0-85090508661
scopus|Landing C.; Tahvili S.; Haggren H.; Langkvis M.; Muhammad A.; Loufi A.|Landing, Cristina (57219336825); Tahvili, Sahar (37093975500); Haggren, Hugo (57219342934); Langkvis, Martin (55986627900); Muhammad, Auwn (57219338184); Loufi, Amy (7004383993)|57219336825; 37093975500; 57219342934; 55986627900; 57219338184; 7004383993|Cluster-Based Parallel Testing Using Semantic Analysis|2020|Proceedings - 2020 IEEE International Conference on Artificial Intelligence Testing, AITest 2020|||9176809|99|106|7|8|10.1109/AITEST49225.2020.00022|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092313008&doi=10.1109%2fAITEST49225.2020.00022&partnerID=40&md5=607f10dc9ea694c29d9cea62d94ab303|Finding a balance between testing goals and testing resources can be considered as a most challenging issue, therefore test optimization plays a vital role in the area of software testing. Several parameters such as the objectives of the tests, test cases similarities and dependencies between test cases need to be considered, before attempting any optimization approach. However, analyzing corresponding testing artifacts (e.g. requirement specification, test cases) for capturing the mentioned parameters is a complicated task especially in a manual testing procedure, where the test cases are documented as a natural text written by a human. Thus, utilizing artificial intelligence techniques in the process of analyzing complex and sometimes ambiguous test data, is considered to be working in different industries. Test scheduling is one of the most popular and practical ways to optimize the testing process. Having a group of test cases which are required the same system setup, installation or testing the same functionality can lead to a more efficient testing process. In this paper, we propose, apply and evaluate a natural language processing-based approach that derives test cases' similarities directly from their test specification. The proposed approach utilizes the Levenshtein distance and converts each test case into a string. Test cases are then grouped into several clusters based on their similarities. Finally, a set of cluster-based parallel test scheduling strategies are proposed for execution. The feasibility of the proposed approach is studied by an empirical evaluation that has been performed on a Telecom use-case at Ericsson in Sweden and indicates promising results. © 2020 IEEE.|Clustering; Natural Language Processing; Semantic Similarity; Software Testing; Test Optimization|Artificial intelligence; Natural language processing systems; Scheduling; Semantics; Specifications; Testing; Artificial intelligence techniques; Empirical evaluations; Levenshtein distance; NAtural language processing; Optimization approach; Requirement specification; Test specifications; Testing resources; Software testing|Conference paper|Final||Scopus|2-s2.0-85092313008
scopus|Ibrahim S.; Hassan Y.F.; Kholief M.H.|Ibrahim, Shimaa (57225085113); Hassan, Yasser Fouad (7102596984); Kholief, Mohamed Hamed (6602356086)|57225085113; 7102596984; 6602356086|Specifying a program control path using flow diagram translated into description logic of ontology engineering|2020|ICIC Express Letters|14|5||497|504|7|0|10.24507/icicel.14.05.497|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082492410&doi=10.24507%2ficicel.14.05.497&partnerID=40&md5=7b3547fbe4bd1b414a160efa3f3f7357|Software testing plays a vital role in improving the performance of software by detecting and fixing bugs and faults which cause software failure. However, software testing is an expensive task, labor-intensive and time-consuming process in the software development life cycle. Every software product needs to be tested in order to make sure it achieves all of its goals and to detect any unexpected behaviour. One of the most critical features in structural testing is path testing which helps to find every possible executable path that helps to determine all faults lying within a piece of code. Any software pro-gram includes multiple entries and exit points. Testing each of these points is challenging as well as time-consuming. To reduce this complexity and time consuming, the use of ontologies might prove useful. Ontology is a technique used at one or more software lifecycle phases. Ontology allows for the definition of a common vocabulary and frame-work among users (either human or machines). Software development has benefited from this conceptual modelling, allowing a common understanding of the concepts involved in the software process. This paper is proposed to improve test path generation of control ow graph. The basic idea is to use OWL-DL ontology as the knowledge representation formalism, to model and specify control ow by adding semantics to control ow graph entities and adding semantics to the dynamic behaviour of control ow relations. © 2020 ICIC International. All rights reserved.|Basis path; Control flow graph (CFG); Cyclomatic complexity (CC); Ontology; OWL-DL; Software testing||Article|Final||Scopus|2-s2.0-85082492410
scopus|Li L.; Li Z.; Zhang W.; Zhou J.; Wang P.; Wu J.; He G.; Zeng X.; Deng Y.; Xie T.|Li, Linyi (57211756552); Li, Zhenwen (57219630237); Zhang, Weijie (57220183116); Zhou, Jun (57220188653); Wang, Pengcheng (59841753300); Wu, Jing (58419675500); He, Guanghua (57220178225); Zeng, Xia (57192096637); Deng, Yuetang (57192106631); Xie, Tao (55574210063)|57211756552; 57219630237; 57220183116; 57220188653; 59841753300; 58419675500; 57220178225; 57192096637; 57192106631; 55574210063|Clustering test steps in natural language toward automating test automation|2020|ESEC/FSE 2020 - Proceedings of the 28th ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering||||1285|1295|10|6|10.1145/3368089.3417067|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097171130&doi=10.1145%2f3368089.3417067&partnerID=40&md5=49349702584906e3e367a30c4c632c0b|For large industrial applications, system test cases are still often described in natural language (NL), and their number can reach thousands. Test automation is to automatically execute the test cases. Achieving test automation typically requires substantial manual effort for creating executable test scripts from these NL test cases. In particular, given that each NL test case consists of a sequence of NL test steps, testers first implement a test API method for each test step and then write a test script for invoking these test API methods sequentially for test automation. Across different test cases, multiple test steps can share semantic similarities, supposedly mapped to the same API method. However, due to numerous test steps in various NL forms under manual inspection, testers may not realize those semantically similar test steps and thus waste effort to implement duplicate test API methods for them. To address this issue, in this paper, we propose a new approach based on natural language processing to cluster similar NL test steps together such that the test steps in each cluster can be mapped to the same test API method. Our approach includes domain-specific word embedding training along with measurement based on Relaxed Word Mover'sDistance to analyze the similarity of test steps. Our approach also includes a technique to combine hierarchical agglomerative clustering and K-means clustering post-refinement to derive high-quality and manually-adjustable clustering results. The evaluation results of our approach on a large industrial mobile app, WeChat, show that our approach can cluster the test steps with high accuracy, substantially reducing the number of clusters and thus reducing the downstream manual effort. In particular, compared with the baseline approach, our approach achieves 79.8% improvement on cluster quality, reducing 65.9% number of clusters, i.e., the number of test API methods to be implemented. © 2020 ACM.|Clustering; Natural language processing; Software testing|Automation; Hierarchical clustering; K-means clustering; Natural language processing systems; Semantics; Software engineering; Clustering results; Evaluation results; Hierarchical agglomerative clustering; Large industrial applications; Measurement-based; NAtural language processing; Number of clusters; Semantic similarity; Testing|Conference paper|Final||Scopus|2-s2.0-85097171130
scopus|Trenquier H.; Ishikawa F.; Tokumoto S.|Trenquier, Henri (57219341749); Ishikawa, Fuyuki (33367760100); Tokumoto, Susumu (55383584000)|57219341749; 33367760100; 55383584000|Attribute-based Granular Evaluation for Performance of Machine Learning Models|2020|Proceedings - 2020 IEEE International Conference on Artificial Intelligence Testing, AITest 2020|||9176814|125|132|7|0|10.1109/AITEST49225.2020.00026|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092310530&doi=10.1109%2fAITEST49225.2020.00026&partnerID=40&md5=e9a98bc01aa78884848ff3d1ce766fb0|There is an increasing demand for quality assurance of machine learning (ML) models as more and more ML applications are investigated in various domains. This means that we need to explicitly take account of the requirements and environmental assumptions for quality evaluation and improvement of ML models. The traditional approach has been performance evaluation, typically in accuracy, for the target dataset. However, this approach only focuses on the global accuracy over the whole dataset and obfuscates performance for individual specific aspects in the requirements and environmental assumptions. We then lack insights necessary to deal with high-priority requirements and to detect risks or weaknesses in specific situations. In response to this problem, we investigate a testing method based on attributes that capture aspects in the requirements and environmental assumptions. We divide the input space into explicit and explainable sub-spaces, which allows the divide-and-conquer style in a granular manner as we have done for traditional software testing. We demonstrate our method with simple attributes for CIFAR-10 and BDD100K datasets. © 2020 IEEE.|data design; image classification; machine learning; requirements-based testing; testing|Machine learning; Quality assurance; Software testing; Attribute-based; Divide and conquer; Input space; Machine learning models; Quality evaluation; Sub-spaces; Testing method; Traditional approaches; Quality control|Conference paper|Final||Scopus|2-s2.0-85092310530
scopus|Jayasudha J.C.; Kumari S.L.|Jayasudha, J.C. (56584500600); Kumari, S.Lalitha (55440772000)|56584500600; 55440772000|Feature Analysis for characterization of Phased Array images based on Hilbert Transform|2020|Proceedings of the 2020 IEEE International Conference on Communication and Signal Processing, ICCSP 2020|||9182420|1204|1207|3|4|10.1109/ICCSP48568.2020.9182420|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091330253&doi=10.1109%2fICCSP48568.2020.9182420&partnerID=40&md5=ca1786d972340c09bf0327c5238e577a|Phased array is one of the most promising ultrasonic testing methods. Non-destructive testing finds its application in various industries, that includes online monitoring purpose, defect identification and so on. Both conventional and non-conventional testing methods are used in industries to carry on the detection process. Ultrasonic phased array testing finds its application in almost all the areas, which is a counterpart for radiography. In this paper, an automated testing method is proposed, which deals with weld flaw segmentation technique using hybrid clustering and Hilbert transform. In order to improve the quality of the obtained image, preprocessing steps are required and adaptive diffusion filter is proposed for removal of noise and pixel correction. In this proposed work, 2D-Hilbert Transform is implemented for the calculation of analytic images and satisfy the properties as in the case of 1D method. This technique provides a 2D spectrum equal to zero in one quadrant. After the process of segmenting the region of interest, the unique features are estimated using the Gray level co-occurrence GLCM. These unique features are fed as the input to deep learning for best classification of the defects in weldments. © 2020 IEEE.|2D adaptive fusion filter; 2D HT; GLCM; lag; phased array images|Deep learning; Defects; Image enhancement; Image segmentation; Mathematical transformations; Nondestructive examination; Ultrasonic transducers; Conventional testing; Defect identification; Gray level Co occurrences; Non destructive testing; Pre-processing step; Segmentation techniques; Ultrasonic phased array; Ultrasonic testing method; Ultrasonic testing|Conference paper|Final||Scopus|2-s2.0-85091330253
scopus|Nguyen D.P.; Maag S.|Nguyen, Duyen Phuc (57219227121); Maag, Stephane (55917333100)|57219227121; 55917333100|Codeless web testing using selenium and machine learning|2020|ICSOFT 2020 - Proceedings of the 15th International Conference on Software Technologies||||51|60|9|7||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091763126&partnerID=40&md5=c52b0f4e9c18c79c50e8d8b187168d25|Complexity of web systems lead to development processes always more tough to test. Testing phases are crucial in software and system engineering and are known to be very costly. While automated testing methods appear to take over the role of the human testers, the issues of reliability and the capability of the testing method still need to be solved. In our paper, we focus on the automation of functional tests of websites. A single web page may contain a huge set of important functionalities leading to the execution of critical web service operations. Besides, testing all of these functionalities implemented in a web page service is highly complex. Two current popular research areas for automation web-based testing are Codeless Functional Test Automation and Machine Learning/Artificial Intelligence (ML/AI) in test automation. We therefore define and implement a framework to figure out how to automate the web service product under test, the machine can detect or predict the change and adapt those changes to suitable generic test cases. In our work, we examine on Selenium and the benefits of using machine learning in automated web application testing. Copyright © 2020 by SCITEPRESS – Science and Technology Publications, Lda. All rights reserved.|Automation testing; Codeless testing; Machine learning; Selenium; SVM; Web testing|Automation; Cost engineering; Machine learning; Selenium; Testing; Web services; Websites; Automated testing; Development process; Functional test; Service products; Test Automation; Web application testing; Web service operations; Web-based testing; Software testing|Conference paper|Final||Scopus|2-s2.0-85091763126
scopus|Liu Y.; Ma C.; Dong Z.; Zhang T.; Cheng J.; Zhang J.|Liu, Ying (58398726500); Ma, Chunyan (36573708100); Dong, Zhanwei (57216948917); Zhang, Tao (55547105913); Cheng, Jing (56074776300); Zhang, Jie (57276975600)|58398726500; 36573708100; 57216948917; 55547105913; 56074776300; 57276975600|Research on Defect Priority Classification of Crowdsourcing Testing for Mobile Applications|2020|Journal of Physics: Conference Series|1518|1|12008||||0|10.1088/1742-6596/1518/1/012008|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085518664&doi=10.1088%2f1742-6596%2f1518%2f1%2f012008&partnerID=40&md5=c5b05efa9965ae0ad9108c3ae45eff28|Crowdsourcing testing technology has developed in recent years with the development of software testing, which can speed up releasing cycle and improve the quality of testing. It is of great practical value to study the priority classification and cause analysis of defect reports by using the potential information of crowdsourcing test defect reports. This paper combines the research of mobile application crowdsourcing test defect report with machine learning data analysis technology, studies the priority classification of mobile application crowdsourcing test defect report, and then carries out defect cause analysis on the basis of defect priority classification. Defect classification is an intuitive reflection of defect research. This paper takes defect priority classification as the breakthrough point of defect report research, uses σ-AdaBoostSVM classification algorithm to classify defect reports, and then carries out cause analysis after defect report classification, which is conducive to the faster location and repair of defects. The experimental verification results demonstrate the effectiveness of the proposed method. © 2020 Published under licence by IOP Publishing Ltd.||Classification (of information); Computer vision; Crowdsourcing; Mobile computing; Software testing; Testing; AdaboostSVM; Breakthrough point; Classification algorithm; Defect classification; Defect reports; Experimental verification; Mobile applications; Testing technology; Defects|Conference paper|Final|All Open Access; Gold Open Access|Scopus|2-s2.0-85085518664
scopus|Gula A.; Ellis C.; Bhattacharya S.; Fiondella L.|Gula, Aiden (57218851756); Ellis, Christian (57205549112); Bhattacharya, Saikath (56732315500); Fiondella, Lance (24766252300)|57218851756; 57205549112; 56732315500; 24766252300|Software and system reliability engineering for autonomous systems incorporating machine learning|2020|Proceedings - Annual Reliability and Maintainability Symposium|2020-January||9153595||||6|10.1109/RAMS48030.2020.9153595|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090461947&doi=10.1109%2fRAMS48030.2020.9153595&partnerID=40&md5=9933c335769917456a5e6ec907be4695|Artificial intelligence and machine learning have attracted significant interest as enablers of autonomous systems. However, these techniques are susceptible to a variety of failures as well as adversarial attacks, suggesting the need for formal reliability and resilience engineering methods. Tempered by the knowledge that machine learning is not a panacea and that private industry, infrastructure management, and defense systems are regularly subject to external attack, it is essential to assess the possible failures and corresponding consequences that these technologies may inadvertently introduce. This paper seeks to bridge the gap between traditional and emerging methods to support the engineering of autonomous systems incorporating machine learning. Toward this end we seek to synthesize methods from established fields such as system and reliability engineering as well as software testing with recent trends in the design and test of machine learning algorithms. The proposed approach should provide organizations with additional structure to comprehend and allocate their risk mitigation efforts in order to address issues that will inevitably arise from these less well understood technologies. © 2020 IEEE.|Autonomous system; FMECA; Machine learning; Software reliability; Software testing; System reliability|Bridges; Learning algorithms; Maintainability; Software reliability; Software testing; Well testing; Additional structures; Autonomous systems; Design and tests; Infrastructure managements; Private industries; Reliability engineering; Resilience engineerings; System reliability; Machine learning|Conference paper|Final||Scopus|2-s2.0-85090461947
scopus|Eldh S.|Eldh, Sigrid (19638689000)|19638689000|Test Automation Improvement Model - TAIM 2.0|2020|Proceedings - 2020 IEEE 13th International Conference on Software Testing, Verification and Validation Workshops, ICSTW 2020|||9155990|334|337|3|3|10.1109/ICSTW50294.2020.00060|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091796180&doi=10.1109%2fICSTW50294.2020.00060&partnerID=40&md5=f24b2047794ced140c6a686a041482bf|Test Automation Improvement Model (TAIM), has been used to guide assessments and describe patterns for aspects of automation in testing. In this paper, we have updated TAIM for the next generation of autonomous software and complemented the model to use as a driver for software quality. We bring some lessons learned and describe the evolution of the model. TAIM is heavily influenced by analytics approaches, i.e. AI or machine learning, as we now strive for autonomous systems. We describe the new levels in TAIM, their focus, quality and cost aspects. Key areas are addressed and some experiences of using the TAIM process and suggestions for further development are proposed. © 2020 IEEE.|Autonomous System; Datafication; Improvement Model; Machine Learning; Maturity; Test Automation|Automation; Computer software selection and evaluation; Software quality; User experience; Verification; Autonomous software; Autonomous systems; Test Automation; Software testing|Conference paper|Final||Scopus|2-s2.0-85091796180
scopus|Pribisalić M.|Pribisalić, Marko (57219173219)|57219173219|AUTOMATIC GENERATION OF TEST CASES FROM USE-CASE SPECIFICATION USING NATURAL LANGUAGE PROCESSING|2020|33rd Bled eConference: Enabling Technology for a Sustainable Society, BLED 2020 - Proceedings||||725|734|9|1|10.18690/978-961-286-362-3.52|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137978180&doi=10.18690%2f978-961-286-362-3.52&partnerID=40&md5=2c07938a81b0fdd4bf5db65f078f3a4b|"Software testing often targets natural language specification documents. The initial assumption is that automation of creating test cases from natural language specification is of benefit to speed up testing enabling a better coverage of all possible test scenarios. The proposed enabling principle for automatic generation of test cases is automatic retrieval of logic for the interaction with an application. After retrieving, interaction logics is transformed into decision tables. Next, from decision tables it is possible to automatically generate test cases. Because in our research we target Croatian natural language, the assumption is that is it necessary to create a new approach to achieve the set goal. The main research questions posed in this paper are: ""Is it possible to automatically generate test cases from use-case specifications written in the Croatian language?""; ""Natural language processing tools for automatic test-generation save the tester's time and effort while improving the quality and coverage of the test cases?"". The expected results are to defining the method that using test-case generation tools reduce the time and effort for software testers and improve the test coverage of requirements. © BLED 2020.All right reserved."|croatian language; logical specification; natural language processing; semantic analysis; test case|Natural language processing systems; Semantics; Software testing; Specifications; Automatic Generation; Croatian language; Language processing; Logical specifications; Natural language processing; Natural language specifications; Natural languages; Semantic analysis; Test case; Use case specifications; Decision tables|Conference paper|Final||Scopus|2-s2.0-85137978180
scopus|Marijan D.; Gotlieb A.|Marijan, Dusica (34872942800); Gotlieb, Arnaud (56247674500)|34872942800; 56247674500|Software testing for machine learning|2020|AAAI 2020 - 34th AAAI Conference on Artificial Intelligence||||13576|13582|6|21||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106485627&partnerID=40&md5=881ce2cbebadf3d31eed5553f46351ef|Machine learning has become prevalent across a wide variety of applications. Unfortunately, machine learning has also shown to be susceptible to deception, leading to errors, and even fatal failures. This circumstance calls into question the widespread use of machine learning, especially in safetycritical applications, unless we are able to assure its correctness and trustworthiness properties. Software verification and testing are established technique for assuring such properties, for example by detecting errors. However, software testing challenges for machine learning are vast and profuse - yet critical to address. This summary talk discusses the current state-of-the-art of software testing for machine learning. More specifically, it discusses six key challenge areas for software testing of machine learning systems, examines current approaches to these challenges and highlights their limitations. The paper provides a research agenda with elaborated directions for making progress toward advancing the state-ofthe- art on testing of machine learning.  © 2020, Association for the Advancement of Artificial Intelligence.||Machine learning; Verification; Research agenda; Safety critical applications; Software verification and testing; State of the art; Software testing|Conference paper|Final||Scopus|2-s2.0-85106485627
scopus|Trujillo M.; Linares-Vásquez M.; Escobar-Velásquez C.; Dusparic I.; Cardozo N.|Trujillo, Miller (57952705500); Linares-Vásquez, Mario (54684418100); Escobar-Velásquez, Camilo (57195248580); Dusparic, Ivana (11641263400); Cardozo, Nicolás (37040461800)|57952705500; 54684418100; 57195248580; 11641263400; 37040461800|Does Neuron Coverage Matter for Deep Reinforcement Learning?: A Preliminary Study|2020|Proceedings - 2020 IEEE/ACM 42nd International Conference on Software Engineering Workshops, ICSEW 2020||||215|220|5|17|10.1145/3387940.3391462|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093096419&doi=10.1145%2f3387940.3391462&partnerID=40&md5=9da86d0c4271542b94045f4a2b7be875|Deep Learning (DL) is powerful family of algorithms used for a wide variety of problems and systems, including safety critical systems. As a consequence, analyzing, understanding, and testing DL models is attracting more practitioners and researchers with the purpose of implementing DL systems that are robust, reliable, efficient, and accurate. First software testing approaches for DL systems have focused on black-box testing, white-box testing, and test cases generation, in particular for deep neural networks (CNNs and RNNs). However, Deep Reinforcement Learning (DRL), which is a branch of DL extending reinforcement learning, is still out of the scope of research providing testing techniques for DL systems. In this paper, we present a first step towards testing of DRL systems. In particular, we investigate whether neuron coverage (a widely used metric for white-box testing of DNNs) could be used also for DRL systems, by analyzing coverage evolutionary patterns, and the correlation with RL rewards.  © 2020 ACM.|Coverage analysis; Deep networks; Reinforcement learning; Testing|Black-box testing; Deep neural networks; Learning systems; Neural networks; Reinforcement learning; Safety engineering; Technical presentations; Testing; Safety critical systems; Test cases generation; Testing technique; White-box testing; Deep learning|Conference paper|Final||Scopus|2-s2.0-85093096419
scopus|Zong P.; Lv T.; Wang D.; Deng Z.; Liang R.; Chen K.|Zong, Peiyuan (57196403937); Lv, Tao (6603404297); Wang, Dawei (57219252430); Deng, Zizhuang (57219256299); Liang, Ruigang (57205634095); Chen, Kai (57051675000)|57196403937; 6603404297; 57219252430; 57219256299; 57205634095; 57051675000|FuzzGuard: Filtering out unreachable inputs in directed grey-box fuzzing through deep learning|2020|Proceedings of the 29th USENIX Security Symposium||||2255|2269|14|130||https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091023244&partnerID=40&md5=c068300947bc51a4c616e9968dbc74b8|Recently, directed grey-box fuzzing (DGF) becomes popular in the field of software testing. Different from coverage-based fuzzing whose goal is to increase code coverage for triggering more bugs, DGF is designed to check whether a piece of potentially buggy code (e.g., string operations) really contains a bug. Ideally, all the inputs generated by DGF should reach the target buggy code until triggering the bug. It is a waste of time when executing with unreachable inputs. Unfortunately, in real situations, large numbers of the generated inputs cannot let a program execute to the target, greatly impacting the efficiency of fuzzing, especially when the buggy code is embedded in the code guarded by various constraints. In this paper, we propose a deep-learning-based approach to predict the reachability of inputs (i.e., miss the target or not) before executing the target program, helping DGF filtering out the unreachable ones to boost the performance of fuzzing. To apply deep learning with DGF, we design a suite of new techniques (e.g., step-forwarding approach, representative data selection) to solve the problems of unbalanced labeled data and insufficient time in the training process. Further, we implement the proposed approach called FuzzGuard and equip it with the state-of-the-art DGF (e.g., AFLGo). Evaluations on 45 real vulnerabilities show that FuzzGuard boosts the fuzzing efficiency of the vanilla AFLGo up to 17.1×. Finally, to understand the key features learned by FuzzGuard, we illustrate their connection with the constraints in the programs. © 2020 by The USENIX Association. All Rights Reserved.||Codes (symbols); Efficiency; Software testing; Code coverage; Data Selection; Key feature; Learning-based approach; Reachability; Real situation; State of the art; Training process; Deep learning|Conference paper|Final||Scopus|2-s2.0-85091023244
scopus|Riccio V.; Jahangirova G.; Stocco A.; Humbatova N.; Weiss M.; Tonella P.|Riccio, Vincenzo (57214054052); Jahangirova, Gunel (57190973501); Stocco, Andrea (36882807000); Humbatova, Nargiz (57219011768); Weiss, Michael (57198623419); Tonella, Paolo (7003489194)|57214054052; 57190973501; 36882807000; 57219011768; 57198623419; 7003489194|Testing machine learning based systems: a systematic mapping|2020|Empirical Software Engineering|25|6||5193|5254|61|182|10.1007/s10664-020-09881-0|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091048368&doi=10.1007%2fs10664-020-09881-0&partnerID=40&md5=834dbb1627e3ff6b79e724005b1aba95|Context:: A Machine Learning based System (MLS) is a software system including one or more components that learn how to perform a task from a given data set. The increasing adoption of MLSs in safety critical domains such as autonomous driving, healthcare, and finance has fostered much attention towards the quality assurance of such systems. Despite the advances in software testing, MLSs bring novel and unprecedented challenges, since their behaviour is defined jointly by the code that implements them and the data used for training them. Objective:: To identify the existing solutions for functional testing of MLSs, and classify them from three different perspectives: (1) the context of the problem they address, (2) their features, and (3) their empirical evaluation. To report demographic information about the ongoing research. To identify open challenges for future research. Method:: We conducted a systematic mapping study about testing techniques for MLSs driven by 33 research questions. We followed existing guidelines when defining our research protocol so as to increase the repeatability and reliability of our results. Results:: We identified 70 relevant primary studies, mostly published in the last years. We identified 11 problems addressed in the literature. We investigated multiple aspects of the testing approaches, such as the used/proposed adequacy criteria, the algorithms for test input generation, and the test oracles. Conclusions:: The most active research areas in MLS testing address automated scenario/input generation and test oracle creation. MLS testing is a rapidly growing and developing research area, with many open challenges, such as the generation of realistic inputs and the definition of reliable evaluation metrics and benchmarks. © 2020, The Author(s).|Machine learning; Software testing; Systematic mapping; Systematic review|Machine learning; Mapping; Quality assurance; Safety engineering; Testing; Turing machines; Autonomous driving; Demographic information; Empirical evaluations; Functional testing; Research questions; Safety-critical domain; Systematic mapping; Systematic mapping studies; Software testing|Article|Final|All Open Access; Hybrid Gold Open Access|Scopus|2-s2.0-85091048368
scopus|Bahomaid A.A.; Alsewari A.A.; Zamli K.Z.; Alhendawi K.M.; Al-Janabi A.A.|Bahomaid, Ameen A. (57221539995); Alsewari, Abdulrahman A. (57215983138); Zamli, Kamal Z. (8701576800); Alhendawi, Kamal M. (55654514100); Al-Janabi, Ala Aldeen (57204155557)|57221539995; 57215983138; 8701576800; 55654514100; 57204155557|A Kidney Algorithm with Elitism for Combinatorial Testing Problem|2020|ACM International Conference Proceeding Series||||6|11|5|0|10.1145/3412953.3412970|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099416833&doi=10.1145%2f3412953.3412970&partnerID=40&md5=2d34c695ab8cf935291cc0e98df543de|Testing software is an important activity before delivering the software with high quality. Among the various approaches for software testing, Combinatorial interaction testing (CIT) is a proper and alternative testing approach for exhaustive testing that covers all possible interactions for a software's parameters. Generating an efficient test list with the optimal size is the most challenging problem in combinatorial interaction testing. Adopting Artificial Intelligence (AI) algorithms as the main algorithm for CIT strategies to generate the most optimal test lists. Kidney algorithm (KA) is a recent computational AI algorithm with sufficient optimization capability which outperforms the other AI algorithms (such as Genetic Algorithm (GA), Cuckoo Search (CS), Particle Swarm Optimization (PSO), Harmony Search (HS)) from some aspects. Although, KA may be easy to fall into local optima by keeping the worst solutions from the past generation as a new population with the best solutions. This study proposes to embed the elitism in the KA to preserve only the best solutions and swap the worsts by the new random solutions. Experimental results have been evidence that the proposed CIT strategy which called elitist KA Strategy (eKAS) produced sufficiently competitive results as compared with the original KA as well the existing CIT strategies. © 2020 ACM.|Combinatorial Interaction Testing; Elitism; Kidney Algorithm; Meta-heuristic|Artificial intelligence; Genetic algorithms; Particle swarm optimization (PSO); Combinatorial interaction testing; Combinatorial testing; Cuckoo searches; Exhaustive testing; Harmony search; Optimization capabilities; Random solutions; Testing software; Software testing|Conference paper|Final||Scopus|2-s2.0-85099416833
scopus|Gul S.; van Oort E.|Gul, Sercan (57201284001); van Oort, Eric (7003515532)|57201284001; 7003515532|A machine learning approach to filtrate loss determination and test automation for drilling and completion fluids|2020|Journal of Petroleum Science and Engineering|186||106727||||46|10.1016/j.petrol.2019.106727|https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076250522&doi=10.1016%2fj.petrol.2019.106727&partnerID=40&md5=06a8c3802acad3490198bec19c571057|Drilling fluid property characterization currently involves several manually executed analytical tests, conducted in accordance with American Petroleum Institute (API) recommended practices 13B-1 and 13B-2. Standard (API) and high-pressure, high-temperature (HPHT) filter press units are used for filtrate loss (FL) measurements. However, these test methods have certain important disadvantages. FL tests are conducted at standardized conditions that generally do not reflect downhole oil and gas well conditions in terms of downhole pressure, temperature and filter medium encountered, present safety concerns due to their elevated pressure and temperature, and are performed only infrequently by a human mud engineer. The human measurement also introduces concerns around inaccuracies due to inconsistent practices and interpretation bias of the results. In addition, FL measurements are hard to automate given their manual, human-centric operating tasks. In this paper, we investigate if it is really necessary to automate FL measurements, or if the (strictly qualitative) information they provide can be obtained in a smarter, more advanced way. For this purpose, the relationship between fluid properties was investigated in detail using machine learning and deep learning techniques. Random forest (RF), XGBoost (XGB), support vector machine (SVM), multilayer perceptron (MLP) and multi-linear regression models were trained and tested to predict API and HPHT FL of water-based muds (WBM) based on fluid property readings of rheology, density, and temperature. A similar approach was also used for HPHT filtrate loss prediction of oil-based muds (OBM), taking into account their electrical stability and water content. A key advantage of this approach is that these WBM and OBM fluid properties can be obtained in real-time with measurements that are relatively simple and easy to automate (e.g. obtaining fluid density automatically and continuously from a Coriolis mass-flow meter measurement). Thus, real-time assessment of API and HPHT FL becomes possible without ever having to actually carry out any filter press measurements, thereby also eliminating the need to directly automate these measurements. The models were verified by dedicated laboratory experiments. The developed models estimated API and HPHT FL of WBM, and HPHT FL of OBM with mean absolute errors (MAE) of 0.56 ml/30min, 1.15 ml/30min and 0.79 ml/30min respectively, well within the measurement accuracy of the observations by a human mud engineer. © 2019 Elsevier B.V.|Drilling fluid automation; Filtrate loss determination; Machine learning|Decision trees; Deep learning; Drilling fluids; Infill drilling; Learning systems; Machine learning; Oil well testing; Presses (machine tools); Regression analysis; Support vector machines; American Petroleum Institute; Coriolis mass flow meter; Drilling and completion fluids; Drilling fluid property; Filtrate loss; High temperature (HPHT); Machine learning approaches; Multi-linear regression; accuracy assessment; automation; drilling; high pressure; high temperature; machine learning; petroleum hydrocarbon; regression analysis; Flowmeters|Article|Final||Scopus|2-s2.0-85076250522
IEEE|V. Shah; P. Yadav|||The Future of Software Testing Automation: Innovations, Challenges, and Emerging Alternatives|2025|||||1588|1593|||10.1109/ICICI65870.2025.11069964|https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11069964|Software testing automation is seeing fast evolution, propelled by innovative developments in artificial intelligence (AI), machine learning (ML), and cloud computing technologies. These advances are transforming the software development environment, providing new opportunities to improve the effectiveness, precision, and adaptability of testing operation. This study investigates the future of software testing automation by analyzing the key advancements that are set to transform testing methodologies in the next years. Prominent advancements include AI-driven test generation methods that utilize machine learning algorithms to automatically produce test cases based on application behavior, as well as self-healing test scripts capable of autonomously identifying and adjusting to alterations in the application interface, thereby substantially minimizing maintenance burdens. Important developments include AI-driven test generation methods that utilize machine learning algorithms to automatically produce test cases based on application behavior, as well as self-healing test scripts that can independently identify and adjust to modifications in the application interface, thereby substantially decreasing maintenance burdens. The incorporation of continuous testing into DevOps pipelines is enhancing the agility and reliability of software delivery, enabling real-time feedback and expedited release cycles. Automation has many benefits, but implementing it is difficult. Maintaining automated test scripts may be complicated and resource-intensive, particularly for rapidly evolving codebases. Due to these constraints, low-code and no-code testing frameworks are becoming popular, democratizing automation by enabling testers without coding skills to build and execute automated tests. Combining these strategies with traditional automated techniques is improving software testing by offering a more complete and effective assessment framework. In research work focus on recent development in the area software testing also compare the different method which is involved in automated software testing.|Software Testing Automation;Artificial Intelligence High implementation costs and DevOps pipelines etc|Software testing;Technological innovation;Automation;Machine learning algorithms;Pipelines;Organizations;Software;Maintenance;Software reliability;Test pattern generators|||||
IEEE|M. Yalla; A. Sunil|||AI-Driven Conversational Bot Test Automation Using Industry Specific Data Cartridges|2020|||||105|107||||https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10186485|The paper describes an in-house accelerator to generate alternate synonymous sentences and similar intent from sample utterances, the generated data can be applied as test input for conversational AI bots (either text or voice-based). Its NLP-driven sentence generator exposes a RESTful service, which can be consumed by automated testing tools/frameworks such as Katalon, Selenium, and so on. The paper presents building an accelerator to quickly teach and test adaptive conversational AI bots. The approach helps to analyze user inputs and extract intent, the bot developer should ensure a variety of possible utterances are coded. In the traditional manual approach, it is difficult to conceive every possible user utterance before deploying the bot and hence the bot has an early failure rate. This may diminish the usefulness of the bot and the users may stop using the same. Here we propose an AI-driven bot test automation approach using a patent-pending in-house accelerator referenced as LemmaCartridge (LC) in this paper. Testing tools or frameworks can consume LC’s data cartridge API for testing the bot AUT and analyze the responses using automated tools/frameworks like Katalon, Selenium and so on until the bot demonstrates desired outcomes under the supervised train, test and adaptive repeatable testing methods yielding quality@speed for the single major goal of testing conversational AI bots. An example of a program used in experiment is described and the results obtained, especially train and test state machines, industry-specific data cartridges that enable to unearth errors in the AI bot under test, are presented.|Test Data Generation;Conversational AI Bot;NLP Automation|Industries;Automation;Life estimation;Manuals;Chatbots;Software;Generators|||||
IEEE|S. Abhichandani; N. R. T. Vadrevu; V. Bagmar|||AI-Driven Self-Healing in Test Automation: A Review of Autonomous Quality Assurance|2025|||||1601|1608|||10.1109/ICICI65870.2025.11069937|https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11069937|The rapid evolution of software systems has made traditional testing methods unsuitable to provide quality, speed, and responsiveness to applications in modern development. This paper presents a detailed overview of artificial intelligencebased self-healing test automation frameworks capable of automatically adapting to evolving applications and reducing human involvement. The frameworks utilize machine learning, anomaly detection, natural language processing, and reinforcement learning to develop, execute, and change test scripts. By maximizing test coverage and premonitory identification of defects, AI enhances fault tolerance, scalability, and dependability in CI/CD infrastructures. During this study, peer-reviewed scholarly papers released from 2021 through 2025 are evaluated comprehensively to identify the impact, implementation process, challenges, and emerging patterns of autonomous quality testing. The results reveal that frameworks using AI do not just enhance testing automation but also resilient, adaptive, and smart approaches of testing which suit dynamic scenarios. The research confirms AI's transformative role in modern software testing, offering substantial gains in efficiency, performance, and reliability across various software domains.|Artificial Intelligence;Self-Healing;Automation Testing;Machine Learning;Fault Prediction;Quality Assurance;Autonomous Testing|Software testing;Automation;Quality assurance;Reviews;Scalability;Reinforcement learning;Software systems;Natural language processing;Software reliability;Testing|||||
IEEE|P. A. Soha; B. Vancsics; T. Gergely; Á. Beszédes|||Flaky Tests in the AI Domain|2024|||||20|21||||https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10669633|In this position paper, we investigate how frequently is randomness the cause of flakiness in the traditional and in the AI-enabled software domains. Based on previous works, it seems that while in the general domain flakiness rarely stems from randomness, in the AI domain it is a frequent phenomenon. Thus, we urge a discussion about a classification scheme of flaky tests based on whether they are caused by the inherent randomness of the AI-enabled SUT or some other reason. This way, better identification, classification and proper handling of flakiness in such systems will be possible.CCS CONCEPTS• Software and its engineering → Software testing and debugging; • Theory of computation → Pseudorandomness and derandomization; • Computing methodologies → Artificial intelligence; Machine learning.|Flaky test;artificial intelligence;machine learning;randomness|Software testing;Conferences;Machine learning;Debugging;Software|||||
IEEE|Z. Chen|||Education Reform of Software Engineering in the Age of A.I: Keynote Address|2023|||||2|2|||10.1109/ICIS57766.2023.10210230|https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10210230|In the age of artificial intelligence (A.I.), software engineering is facing unprecedented changes. Software developers need to have a deep understanding of, especially large model technologies, since the traditional software development model cannot meet the new needs. Moreover, software engineering also needs to pay more attention to the value of data. The data-driven software development models are growing, and data analysis and machine learning technologies have also been widely used. Software development requires higher efficiency, quality, and flexibility. New methods such as agile development and DevOps have emerged. Software testing also needs to be more intelligent, and test automation has become an essential part in software engineering. This speech focuses on sharing the opportunities and challenges brought by GPT and other big models to software development and testing. It also looks forward to the changes brought by A.I. to software engineering education and how we coped. The reform of software engineering is an inevitable trend, and software developers need to constantly learn new technologies and master new methods in the age of A.I.||Software;Software engineering;Education;Software testing;Web and internet services;Optimization;Mobile applications|||||
IEEE|K. Baral; J. Johnson; J. Mahmud; S. Salma; M. Fazzini; J. Rubin; J. Offutt; K. Moran|||Automating GUI-based Test Oracles for Mobile Apps|2024|||||309|321||||https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10555784|In automated testing, test oracles are used to determine whether software behaves correctly on individual tests by comparing expected behavior with actual behavior, revealing incorrect behavior. Automatically creating test oracles is a challenging task, especially in domains where software behavior is difficult to model. Mobile apps are one such domain, primarily due to their event-driven, GUI-based nature, coupled with significant ecosystem fragmentation.This paper takes a step toward automating the construction of GUI-based test oracles for mobile apps, first by characterizing common behaviors associated with failures into a behavioral taxonomy, and second by using this taxonomy to create automated oracles. Our taxonomy identifies and categorizes common GUI element behaviors, expected app responses, and failures from 124 reproducible bug reports, which allow us to better understand oracle characteristics. We use the taxonomy to create app-independent oracles and report on their generalizability by analyzing an additional dataset of 603 bug reports. We also use this taxonomy to define an app-independent process for creating automated test oracles, which leverages computer vision and natural language processing, and apply our process to automate five types of app-independent oracles. We perform a case study to assess the effectiveness of our automated oracles by exposing them to 15 real-world failures. The oracles reveal 11 of the 15 failures and report only one false positive. Additionally, we combine our oracles with a recent automated test input generation tool for Android, revealing two bugs with a low false positive rate. Our results can help developers create stronger automated tests that can reveal more problems in mobile apps and help researchers who can use the understanding from the taxonomy to make further advances in test automation.CCS CONCEPTS• Software and its engineering → Software maintenance tools; Software testing and debugging; Software usability.|Mobile apps;Test Oracles;Software Testing;UI Analysis|Software testing;Software maintenance;Taxonomy;Computer bugs;Ecosystems;Natural language processing;Mobile applications|||||
IEEE|V. Singh; V. Tiwari|||A Survey on AI-Driven Software Testing in Healthcare: Enhancing Outcomes for Elderly Patients|2024|||||365|370|||10.1109/IEMCON62851.2024.11093568|https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11093568|As healthcare systems evolve, older adults, particularly those on Medicare, face increasing challenges related to chronic conditions and the need for specialized care. The integration of Artificial Intelligence (AI) in healthcare software testing offers significant opportunities to improve patient outcomes, reduce costs, and enhance system reliability. This paper explores key AIpowered technologies such as self-healing test scripts, predictive analytics, and AI-driven regression testing, which enable the automatic detection and resolution of software issues, minimizing manual intervention and improving the accuracy of diagnoses and treatment plans. Furthermore, AI’s role in usability testing showcases its potential to optimize healthcare interfaces for elderly patients, enhancing accessibility and engagement with telemedicine services. Despite these advancements, the adoption of AI in healthcare faces challenges, including regulatory hurdles, data privacy concerns, and integration with existing legacy systems. However, recent findings underscore the increasing importance of AI in healthcare, resulting in improved outcomes for elderly patients. The paper concludes by examining AI’s future potential in managing chronic diseases, personalizing care, and facilitating real-time health monitoring, highlighting its essential role in the advancement of Medicare and elderly care.|Artificial Intelligence;Healthcare;Software Testing;AI Automation|Software testing;Telemedicine;Medical services;Software;Artificial intelligence;Older adults;Usability;Predictive analytics;Medical diagnostic imaging;Faces|||||
IEEE|J. Offutt|||Test Automation: From Slow & Weak to Fast, Flaky, & Blind to Smart & Effective|2023|||||11|11|||10.1109/ICST57152.2023.00009|https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10132201|All technical fields add more automation over time as we replace human labor with innovative technologies. Automation comes with many advantages: It creates research opportunities, offers savings in practice, and reduces errors. Automation also comes with disruptive costs. Processes must change to accommodate the automation, and human laborers must adapt by learning new knowledge and skills. Automation also evolves over time as advances inspire more new ideas for automation. This presentation will reflect on automation through history and on years of experience inventing ways to automate software testing. The talk will review achievements in test automation, discuss challenges in cutting edge domains such as games and AI, and present open problems for future research and for practical applications.||Software testing;Automation;Costs;Games;History;Artificial intelligence|||||
IEEE|M. Ivanković; L. Rimanić; I. Budiselić; G. Petrović; G. Fraser; R. Just|||What Types of Automated Tests do Developers Write?|2025|||||80|90|||10.1109/AST66626.2025.00015|https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11081450|Software testing is a widely adopted quality assurance technique that assesses whether a software system meets a given specification. The overall goal of software testing is to develop effective tests that capture desired program behaviors and reveal defects. Automated software testing is an essential part of modern software development processes, in particular those that focus on continuous integration and deployment. Existing test classifications (e.g., unit vs. integration vs. system tests) and testing best practices offer general conceptual frameworks, but instantiating these conceptual models requires a definition of what is considered a unit, or even a test. These conceptual models are rarely explicated in the literature or documentation which makes interpretation and generalization of results (e.g., comparisons between unit and integration testing efficacy) difficult. Additionally, comparatively little is known about how developers operationalize software testing in modern industrial contexts, how they write and automate software tests, and how well those tests fit into existing classifications. Since software engineering processes have substantially evolved, it is time to revisit and refine test classifications to support future research on software testing efficacy and best practices. This is especially important with the advent of AI-generated test code, where those classifications may be used to automatically classify the types of generated tests or to formulate the desired test output.This paper presents a novel test classification framework, developed using insights and data on what types of tests developers write in practice. The data was collected in an industrial setting at Google and involves tens of thousands of developers and tens of millions of tests. The developed classification framework is precise enough that it can be encoded in an automated analysis. We describe our proof-of-concept implementation and report on the development approach and costs. We also report on the results of applying the automated classification to all tests in Google’s repository and on what types of automated tests developers write.|software testing;test automation;test classification|Software testing;Industries;Codes;Pipelines;Documentation;Continuous integration;Software systems;Internet;Best practices;Software engineering|||||
IEEE|H. G. Chintala; L. Alawneh; Z. A. Al-Sharif; S. Omari|||Enhancing Software Testing Using AI and Graph Similarity|2025|||||1|6|||10.1109/ICICS65354.2025.11073112|https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11073112|Software testing plays a vital role in the development lifecycle, ensuring the prevention of failures and the enhancement of software quality. Despite its importance, the testing phase is often resource-intensive, involving numerous test cases that can become redundant or overlapping over time-leading to increased complexity and prolonged testing durations. To address these inefficiencies, this paper proposes a novel approach that integrates graph similarity analysis with generative AI and deep learning to optimize test suites. By leveraging call graphs derived from test cases, the method identifies redundant and closely related test scenarios. A machine learning model is used to predict similarity scores between these call graphs, facilitating the classification and prioritization of test cases. Lower similarity scores correspond to test cases with more unique code coverage and are thus assigned higher priority. This prioritization enables test engineers to focus on a more diverse and effective subset of test cases, ensuring thorough code coverage while improving efficiency. The proposed framework ultimately reduces redundancy, lowers testing costs, and upholds high standards of software quality, offering a systematic solution for determining the optimal level of testing required to meet study objectives. While the current study experimentally validates the use of graph similarity metrics for test case prioritization, the application of generative AI models is proposed as part of future extensions.|Software Testing;Regression Testing;Redundant Test Cases;Call Graph;Graph Similarity;Similarity Scores;Test Case Prioritization|Software testing;Measurement;Codes;Systematics;Generative AI;Prevention and mitigation;Redundancy;Software quality;Resource management;Standards|||||
IEEE|V. Joshi; I. Band|||Disrupting Test Development with AI Assistants|2025|||||421|425|||10.1109/IAICT65714.2025.11101520|https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11101520|Recent advancements in large language models, including GPT-4 and its variants, and Generative AI-assisted coding tools like GitHub Copilot, ChatGPT, and Tabnine, have significantly transformed software development. This paper analyzes how these innovations impact productivity and software test development metrics. These tools enable developers to generate complete software programs with minimal human intervention before deployment. However, thorough review and testing by developers are still crucial. Utilizing the Test Pyramid concept, which categorizes tests into unit, integration, and end-to-end tests, we evaluate three popular AI coding assistants by generating and comparing unit tests for open-source modules. Our findings show that AIgenerated tests are of equivalent quality to original tests, highlighting differences in usage and results among the tools. This research enhances the understanding and capabilities of AI-assistant tools in automated testing.|Unit Testing;AI-assistant Tools;Generative AI;ChatGPT;Tabnine;LLMs;GitHub Copilot;Testing Automation;Testing Pyramid|Technological innovation;Standards organizations;Organizations;Documentation;Chatbots;Software;Test pattern generators;Thermal stability;Testing;Software development management|||||
IEEE|Z. Liu; M. Yan; Z. Gao; D. Li; X. Zhang; D. Yang|||AW4C: A Commit-Aware C Dataset for Actionable Warning Identification|2024|||||133|137||||https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10555810|Excessive non-actionable warnings generated by static program analysis tools can hinder developers from utilizing these tools effectively. Leveraging learning-based approaches for actionable warning identification has demonstrated promise in boosting developer productivity, minimizing the risk of bugs, and reducing code smells. However, the small sizes of existing datasets have limited the model choices for machine learning researchers, and the lack of aligned fix commits limits the scope of the dataset for research. In this paper, we present AW4C, an actionable warning C dataset that contains 38,134 actionable warnings mined from more than 500 repositories on GitHub. These warnings are generated via Cppcheck, and most importantly, each warning is precisely mapped to the commit where the corrective action occurred. To the best of our knowledge, this is the largest publicly available actionable warning dataset for C programming language to date. The dataset is suited for use in machine/deep learning models and can support a wide range of tasks, such as actionable warning identification and vulnerability detection. Furthermore, we have released our dataset1 and a general framework for collecting actionable warnings on GitHub2 to facilitate other researchers to replicate our work and validate their innovative ideas.CCS Concepts• Software and its engineering → Software maintenance tools; Software creation and management; Software testing and debugging;• Mathematics of computing → Data mining.|Static program analysis;Actionable warning identification|Software testing;Productivity;Software maintenance;Computer languages;Codes;Computer bugs;Mathematics|||||
IEEE|G. Zhao; S. Georgiou; Y. Zou; S. Hassan; D. Truong; T. Corbin|||Enhancing Performance Bug Prediction Using Performance Code Metrics|2024|||||50|62||||https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10555738|Performance bugs are non-functional defects that can significantly reduce the performance of an application (e.g., software hanging or freezing) and lead to poor user experience. Prior studies found that each type of performance bugs follows a unique code-based performance anti-pattern and proposed different approaches to detect such anti-patterns by analyzing the source code of a program. However, each approach can only recognize one performance anti-pattern. Different approaches need to be applied separately to identify different performance anti-patterns. To predict a large variety of performance bug types using a unified approach, we propose an approach that predicts performance bugs by leveraging various historical data (e.g., source code and code change history). We collect performance bugs from 80 popular Java projects. Next, we propose performance code metrics to capture the code characteristics of performance bugs. We build performance bug predictors using machine learning models, such as Random Forest, eXtreme Gradient Boosting, and Linear Regressions. We observe that: (1) Random Forest and eXtreme Gradient Boosting are the best algorithms for predicting performance bugs at a file level with a median of 0.84 AUC, 0.21 PR-AUC, and 0.38 MCC; (2) The proposed performance code metrics have the most significant impact on the performance of our models compared to code and process metrics. In particular, the median AUC, PR-AUC, and MCC of the studied machine learning models drop by 7.7%, 25.4%, and 20.2% without using the proposed performance code metrics; and (3) Our approach can predict additional performance bugs that are not covered by the anti-patterns proposed in the prior studies.CCS CONCEPTS•Software and its engineering Software testing and debugging; Software testing and debugging|Performance bugs;Performance anti-patterns;Performance code metrics;Performance bug prediction|Measurement;Software testing;Java;Codes;Machine learning algorithms;Source coding;Computer bugs|||||
IEEE|C. Minnick|||Finding and Eliminating Bugs|2024|||||167|193||||https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10950501.pdf&bkn=10950172&pdfType=chapter|Summary <p>This chapter shows how to use AI tools to assist us with the process of debugging our code. Many different methods are used to detect bugs in software. The most effective strategies for detecting bugs are code reviews, automated testing, static code analysis, debugging tools, and logging and monitoring. Bug reporting is how software developers and software development teams document and track bugs and potential bugs with software. Bug reports typically describe the current functioning of some aspect of the software and how it should perform. Linting fixes problems in our code that exist when the code is not running. Ideally, linting can eliminate the need for debugging. By integrating AI‐powered bug detection and fixes into our software development lifecycle, we can find and correct many types of bugs and security problems that can't be detected by linters.</p>||Computer bugs;Software;Codes;Artificial intelligence;Debugging;Browsers;Testing;Software development management;Encoding;Costs|||||
IEEE|Z. Wei; H. Wang; Z. Yang; W. K. Chan|||SEbox4DL: A Modular Software Engineering Toolbox for Deep Learning Models|2022|||||193|196|||10.1145/3510454.3516828|https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793795|Deep learning (DL) models are widely used in software applications. Novel DL models and datasets are published from time to time. Developers may also tempt to apply new software engineering (SE) techniques on their DL models. However, no existing tool supports the applications of software testing and debugging techniques on new DL models and their datasets without modifying the code. Developers should manually write code to glue every combination of models, datasets, and SE technique and chain them together.We propose SEbox4DL, a novel and modular toolbox that automatically integrates models, datasets, and SE techniques into SE pipelines seen in developing DL models. SEbox4DL exemplifies six SE pipelines and can be extended with ease. Each user-defined task in the pipelines is to implement a SE technique within a function with a unified interface so that the whole design of SEbox4DL is generic, modular, and extensible. We have implemented several SE techniques as user-defined tasks to make SEbox4DL off-the-shelf. Our experiments demonstrate that SEbox4DL can simplify the applications of software testing and repair techniques on the latest or popular DL models and datasets. The toolbox is open-source and published at https://github.com/Wsine/SEbox4DL. A video for demonstration is available at: https://youtu.be/EYeFFi4lswc.|neural networks;software engineering;toolbox;testing;repair|Software testing;Deep learning;Codes;Pipelines;Debugging;Writing;Maintenance engineering|||||
IEEE|A. Kumar; D. Saha; T. Yasue; K. Ono; S. Krishnan; S. Hans; F. Satoh; G. Mitchell; S. Kumar|||Automated Validation of COBOL to Java Transformation|2024|||||2415|2418||||https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10765025|Recent advances in Large Language Model (LLM) based Generative AI techniques have made it feasible to translate enterprise-level code from legacy languages such as COBOL to modern languages such as Java or Python. While the results of LLM-based automatic transformation are encouraging, the resulting code cannot be trusted to correctly translate the original code. We propose a framework and a tool to help validate the equivalence of COBOL and translated Java. The results can also help repair the code if there are some issues and provide feedback to the AI model to improve. We have developed a symbolic-execution-based test generation to automatically generate unit tests for the source COBOL programs which also mocks the external resource calls. We generate equivalent JUnit test cases with equivalent mocking as COBOL and run them to check semantic equivalence between original and translated programs. Demo Video: https://youtu.be/aqF_agNP-lUCCS CONCEPTS• Software and its engineering → Software testing and debugging.|Automatic Validation;COBOL to Java;External Resource Testing|Software testing;Java;Structured Query Language;Codes;Semantics;Software;Test pattern generators;Mainframes;Software engineering;Python|||||
IEEE|A. Marchetto|||Can explainability and deep-learning be used for localizing vulnerabilities in source code?|2024|||||110|119||||https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10556417|Security vulnerabilities are weaknesses of software due for instance to design flaws or implementation bugs that can be exploited and lead to potentially devastating security breaches. Traditionally, static code analysis is recognized as effective in the detection of software security vulnerabilities but at the expense of a high human effort required for checking a large number of produced false positive cases. Deep-learning methods have been recently proposed to overcome such a limitation of static code analysis and detect the vulnerable code by using vulnerability-related patterns learned from large source code datasets. However, the use of these methods for localizing the causes of the vulnerability in the source code, i.e., localize the statements that contain the bugs, has not been extensively explored. In this work, we experiment the use of deep-learning and explainability methods for detecting and localizing vulnerability-related statements in code fragments (named snippets). We aim at understanding if the code features adopted by deep-learning methods to identify vulnerable code snippets can also support the developers in debugging the code, thus localizing the vulnerability’s cause Our work shows that deep-learning methods can be effective in detecting the vulnerable code snippets, under certain conditions, but the code features that such methods use can only partially face the actual causes of the vulnerabilities in the code.CCS Concepts• Security and privacy $\rightarrow$ Vulnerability management; Systems security; Malware and its mitigation; $\cdot$ Software and its engineering $\rightarrow$ Software testing and debugging.|Cybersecurity;Vulnerability detection;Vulnerability localization|Training;Software testing;Privacy;Codes;Source coding;Computer bugs;Debugging|||||
IEEE|S. Tahvili; M. Borg|||Excel Isn’t a Process, and Not All ‘Intelligence’ Is Smart|2025||42|4||11|14|||10.1109/MS.2025.3559192|https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11024037|The relationship between requirements engineering and testing has been a key interest throughout my research career. It cannot be that requirements engineers are from Omicron Persei 7 and testers from Omicron Persei 9—we all live on the same planet. I’m happy to co-author this column with a former collaborator from a test automation EU project, now a manager at Ericsson. With this issue’s focus on AI-powered testing, we ask: How can we define corresponding tool and process requirements in practice? This column is twofold. First, Sahar shares her experience. Then, we connect her observations to findings from a longitudinal study on tool adoption. Together, the perspectives give a grounded view from the field.—Markus Borg||Automation;Requirements engineering;Software testing;Artificial intelligence;Machine learning;Deep learning;Computer bugs;Costs;Software tools;Problem-solving;Generative AI;Large language models|||||
IEEE|L. Traini; F. Di Menna; V. Cortellessa|||AI-driven Java Performance Testing: Balancing Result Quality with Testing Time|2024|||||443|454||||https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10765017|Performance testing aims at uncovering efficiency issues of software systems. In order to be both effective and practical, the design of a performance test must achieve a reasonable trade-off between result quality and testing time. This becomes particularly challenging in Java context, where the software undergoes a warm-up phase of execution, due to just-in-time compilation. During this phase, performance measurements are subject to severe fluctuations, which may adversely affect quality of performance test results. Both practitioners and researchers have proposed approaches to mitigate this issue. Practitioners typically rely on a fixed number of iterated executions that are used to warm-up the software before starting to collect performance measurements (state-of-practice). Researchers have developed techniques that can dynamically stop warm-up iterations at runtime (state-of-the-art). However, these approaches often provide suboptimal estimates of the warm-up phase, resulting in either insufficient or excessive warm-up iterations, which may degrade result quality or increase testing time. There is still a lack of consensus on how to properly address this problem. Here, we propose and study an AI-based framework to dynamically halt warm-up iterations at runtime. Specifically, our framework leverages recent advances in AI for Time Series Classification (TSC) to predict the end of the warm-up phase during test execution. We conduct experiments by training three different TSC models on half a million of measurement segments obtained from JMH microbenchmark executions. We find that our framework significantly improves the accuracy of the warm-up estimates provided by state-of-practice and state-of-the-art methods. This higher estimation accuracy results in a net improvement in either result quality or testing time for up to +35.3% of the microbenchmarks. Our study highlights that integrating AI to dynamically estimate the end of the warm-up phase can enhance the cost-effectiveness of Java performance testing.CCS CONCEPTS•Software and its engineering → Software performance; Software testing and debugging.|Microbenchmarking;JMH;Java;Time Series Classification|Training;Software testing;Java;Runtime;Accuracy;Time series analysis;Steady-state;Artificial intelligence;Tuning;Testing|||||
IEEE|H. Gudaparthi; R. Johnson; H. Challa; N. Niu|||Deep Learning for Smart Sewer Systems: Assessing Nonfunctional Requirements|2020|||||35|38||||https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9276508|Combined sewer overflows represent significant risks to human health as untreated water is discharged to the environment. Municipalities recently began collecting large amounts of water-related data and considering the adoption of deep learning solutions like recurrent neural network (RNN) for overflow prediction. In this paper, we contribute a novel metamorphic relation to characterize RNN robustness in the presence of missing data. We show how this relation drives automated testing of three implementation variants: LSTM, GRU, and IndRNN thereby uncovering deficiencies and suggesting more robust solutions for overflow prediction.|• Social and professional topics → Economic impact;• Computing methodologies → Machine learning|Robustness;Logic gates;Software;Neurons;Deep learning;Recurrent neural networks;Wastewater|||||
IEEE|Z. Wang; K. Liu; G. Li; Z. Jin|||HITS: High-coverage LLM-based Unit Test Generation via Method Slicing|2024|||||1258|1268||||https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10765010|Large language models (LLMs) have behaved well in generating unit tests for Java projects. However, the performance for covering the complex focal methods within the projects is poor. Complex methods comprise many conditions and loops, requiring the test cases to be various enough to cover all lines and branches. However, existing test generation methods with LLMs provide the whole method-to-test to the LLM without assistance on input analysis. The LLM has difficulty inferring the test inputs to cover all conditions, resulting in missing lines and branches. To tackle the problem, we propose decomposing the focal methods into slices and asking the LLM to generate test cases slice by slice. Our method simplifies the analysis scope, making it easier for the LLM to cover more lines and branches in each slice. We build a dataset comprising complex focal methods collected from the projects used by existing state-of-the-art approaches. Our experiment results show that our method significantly outperforms current test case generation methods with LLMs and the typical SBST method Evosuite regarding both line and branch coverage scores.CCS CONCEPTS• Software and its engineering → Software testing and debugging; • Computing methodologies → Natural language processing.|Unit Test Generation;Large Language Model;Program Decomposition;Program Slicing;Testing and Analysis;AI for SE|Software testing;Java;Analytical models;Large language models;Debugging;Software;Natural language processing;Test pattern generators;Software engineering|||||
IEEE|S. Feng; H. Lu; J. Jiang; T. Xiong; L. Huang; Y. Liang; X. Li; Y. Deng; A. Aleti|||Enabling Cost-Effective UI Automation Testing with Retrieval-Based LLMs: A Case Study in WeChat|2024|||||1973|1978||||https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10765004|UI automation tests play a crucial role in ensuring the quality of mobile applications. Despite the growing popularity of machine learning techniques to generate these tests, they still face several challenges, such as the mismatch of UI elements. The recent advances in Large Language Models (LLMs) have addressed these issues by leveraging their semantic understanding capabilities. However, a significant gap remains in applying these models to industrial-level app testing, particularly in terms of cost optimization and knowledge limitation. To address this, we introduce CAT to create cost-effective UI automation tests for industry apps by combining machine learning and LLMs with best practices. Given the task description, CAT employs Retrieval Augmented Generation (RAG) to source examples of industrial app usage as the few-shot learning context, assisting LLMs in generating the specific sequence of actions. CAT then employs machine learning techniques, with LLMs serving as a complementary optimizer, to map the target element on the UI screen. Our evaluations on the WeChat testing dataset demonstrate the CAT’s performance and cost-effectiveness, achieving 90% UI automation with $0.34 cost, outperforming the state-of-the-art. We have also integrated our approach into the real-world WeChat testing platform, demonstrating its usefulness in detecting 141 bugs and enhancing the developers’ testing process.CCS CONCEPTS• Software and its engineering → Software testing and debugging.|UI automation test;large language model;retrieval-augmented generation;cost optimization|Software testing;Automation;Costs;Social networking (online);Computer bugs;Message services;Mobile applications;Optimization;Testing;Software engineering|||||
IEEE|M. Radnejad; K. Kaur; H. Song; L. Zhang|||12 Methods and tools to improve quantum software quality: a survey|2024|||||245|272||||https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10790748.pdf&bkn=10783695&pdfType=chapter|With recent breakthroughs in quantum computing, it has become a coming reality instead of a promising future. Quantum computing applications offer revolutionary potential across multiple domains including artificial intelligence (AI), optimization, healthcare, energy, and space, known as quantum advantage. The power of quantum computing relies on novel quantum algorithms, quantum software, and hardware. Unlike classical software, quantum software has unique features because of quantum mechanics such as superposition and noncloning. This opens a new research field - quantum software engineering (QSE). While the software engineering (SE) research community became aware of this need in 2019, we noticed the lack of a comprehensive investigation of state-of-the-art technologies and tools to improve quantum software quality. Testing and debugging are the two most efficient approaches to assure software quality in classical SE. In QSE, testing and debugging quantum programs become challenging due to quantum mechanics. While we can leverage some best practices from the classical world, new techniques and tools are needed to address the concerns in QSE. In this chapter, we first conduct a survey study of the state-of-the-art technologies and tools for testing and debugging quantum software. This study includes but is not limited to quantum bug pattern analysis and detection, quantum software testing techniques and classification, and quantum debugging techniques. In the second place, we provide our visions and insights of testing and debugging quantum software in terms of challenges and opportunities for improving quantum software quality. This survey has the potential to foster a research community committed to developing novel methods and tools for QSE.||Computer bugs;Quantum computing;Software;Qubit;Debugging;Quantum mechanics;Surveys;Registers;Logic gates;Logic|||||
IEEE|M. Olsthoorn|||More Effective Test Case Generation with Multiple Tribes of AI|2022|||||286|290|||10.1145/3510454.3517066|https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793774|Software testing is a critical activity in the software development life cycle for quality assurance. Automated Test Case Generation (TCG) can assist developers by speeding up this process. It accomplishes this by evolving an initial set of randomly generated test cases over time to optimize for predefined coverage criteria. One of the key challenges for automated TCG approaches is navigating the large input space. Existing state-of-the-art TCG algorithms struggle with generating highly-structured input data and preserving patterns in test structures, among others. I hypothesize that combining multiple tribes of AI can improve the effectiveness and efficiency of automated TCG. To test this hypothesis, I propose using grammar-based fuzzing and machine learning to augment evolutionary algorithms for generating more structured input data and preserving promising patterns within test cases. Additionally, I propose to use behavioral modeling and interprocedural control dependency analysis to improve test effectiveness. Finally, I propose integrating these novel approaches into a testing framework to promote the adoption of automated TCG in industry.|Software and its engineering → Search-based software engineering; Software testing and debugging|Industries;Quality assurance;Machine learning algorithms;Navigation;Machine learning;Evolutionary computation;Fuzzing|||||
IEEE|K. Khadka; J. Chandrasekaran; Y. Lei; R. N. Kacker; D. Richard Kuhn|||A Combinatorial Approach to Hyperparameter Optimization|2024|||||140|149||||https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10556159|In machine learning, hyperparameter optimization (HPO) is essential for effective model training and significantly impacts model performance. Hyperparameters are predefined model settings which fine-tune the model’s behavior and are critical to modeling complex data patterns. Traditional HPO approaches such as Grid Search, Random Search, and Bayesian Optimization have been widely used in this field. However, as datasets grow and models increase in complexity, these approaches often require a significant amount of time and resources for HPO. This research introduces a novel approach using t-way testing—a combinatorial approach to software testing used for identifying faults with a test set that covers all t-way interactions—for HPO. -way testing substantially narrows the search space and effectively covers parameter interactions. Our experimental results show that our approach reduces the number of necessary model evaluations and significantly cuts computational expenses while still outperforming traditional HPO approaches for the models studied in our experiments.CCS CONCEPTS•Computing methodologies → Machine learning;•Software and its engineering → Software maintenance tools.|Hyperparameter Optimization;Combinatorial Testing;AutoML|Training;Software testing;Fault diagnosis;Software maintenance;Computational modeling;Hyperparameter optimization;Data models|||||
IEEE|C. Molinier; P. Temple; G. Perrouin|||FairPipes: Data Mutation Pipelines for Machine Learning Fairness|2024|||||224|234||||https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10769408|Machine Learning (ML) models are ubiquitous in decision-making applications impacting citizens’ lives: credit attribution, crime recidivism, etc. In addition to seeking high performance and generalization abilities, ensuring that ML models do not discriminate against citizens regarding their age, gender, or race is essential. To this end, researchers developed various fairness assessment techniques, comprising fairness metrics and mitigation approaches, notably at the model level. However, the sensitivity of ML models to fairness data perturbations has been less explored. This paper presents mutation-based pipelines to emulate fairness variations in the data once the model is deployed. FairPipes implements mutation operators that shuffle sensitive attributes, add new values, or affect their distribution. We evaluated FairPipes on seven ML models over three datasets. Our results highlight different fairness sensitivity behaviors across models, from the most sensitive perceptrons to the insensitive support vector machines. We also consider the role of model optimization in fairness performance, being variable across models. FairPipes automates fairness testing at deployment time, informing researchers and practitioners on the fairness sensitivity evolution of their ML models.CCS Concepts• Software and its engineering → Software testing and debugging; • Computing methodologies → Machine learning.|Machine Learning;Fairness;Mutation Testing|Software testing;Support vector machines;Adaptation models;Sensitivity;Computational modeling;Prevention and mitigation;Pipelines;Software algorithms;Data models;Software|||||
IEEE|P. Ram; R. Sibal|||A Novel Hybrid Approach to Enhance Software Quality by Using the Honey Badger Algorithm (HBA) and Support Vector Machine (SVM)|2025|||||1|6|||10.1109/ICECCC65144.2025.11064181|https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11064181|Software defect prediction is the process of identifying modules in software that are likely to be prone to defects. It used to improve software quality and its primary goal is to identify defective modules and send them for testing. Traditional methods of software testing are not capable of performing testing effectively. Effective testing plays a crucial role in software quality assurance. In this paper, we introduce a hybrid approach, Honey Badger Algorithm (HBA) with Support Vector Machine (SVM) for predicting software defects. The HBA finds the most relevant data from a large dataset. It explores all possible data combinations, removes redundancy, and reduces dimensionality. SVM is a supervised machine learning algorithm used for classification, regression, and outlier detection. It is widely used in various fields, including software defect prediction (SDP), due to its effectiveness in handling high-dimensional datasets and complex decision boundaries. When we perform experiments on a given dataset using a proposed model of HBA-SVM, it gives effective and better results than other machine learning algorithms SVM, KNN, and NB. It shows a remarkable number in accuracy 95 %, precision 98%, Recall 44%, F-measure 56%, and AUC score 76%. This result shows that the hybrid HBA-SVM model improves software defect prediction performance and reduces computational complexity.|Software Defect Prediction (SDP);Honey Badger algorithm (HBA);SVM;KNN;NB|Support vector machines;Software testing;Machine learning algorithms;Computational modeling;Software algorithms;Redundancy;Software quality;Nearest neighbor methods;Predictive models;Prediction algorithms|||||
IEEE|V. Garousi; N. Joy; D. Taibi|||AI-Powered Software Testing Tools: Full Autonomy Remains a Distant Goal|2025||42|4||98|111|||10.1109/MS.2025.3557895|https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11024082|As the new “Tools” column editor, I’m excited to kick off this role by exploring one of the most rapidly evolving areas in software engineering: AI-powered testing tools. These tools promise to transform the way we approach test automation by improving efficiency, reducing the maintenance effort of test code, and enhancing defect detection. —Davide Taibi||Software testing;Codes;Automation;Transforms;Maintenance engineering;Software engineering;Defect detection;Artificial intelligence;Software tools|||||
IEEE|N. P; S. A. Ratnam; S. Bhaskaran|||Comprehensive Study on Integrating AI-Powered Threat Intelligence Using Large Language Models|2025||3|||2141|2146|||10.1109/ICCSAI64074.2025.11063731|https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11063731|This paper presents a comprehensive analysis of algorithmic efficiency within automated testing tools, with a particular emphasis on integrating AI-powered threat intelligence through Large Language Models (LLMs) for enhanced penetration testing. The investigation focuses on measuring the time complexity, resource utilization, and various performance metrics of these tools. We extend our analysis to explore how LLMs and multi-agent systems can augment dynamic and static analysis during Automated Penetration Testing (APT). We rigorously quantify the performance of both in-house developed tools and existing automation frameworks, especially those that leverage LLMs. The primary goal is to evaluate the strengths and weaknesses of the algorithm by comparing the performance of the tool, analyzing the underlying algorithms, and evaluating critical aspects such as scalability, resource management, and optimization strategies to improve real-world applications, particularly in cybersecurity.|Large Language Models;Automated PenTesting;Docker;Cyber Security;Optimized Routing|Large language models;Static analysis;Software quality;Algorithmic efficiency;Time measurement;Resource management;Time complexity;Optimization;Testing;Penetration testing|||||
IEEE|S. Pavanetto; M. Brambilla|||Generation of Realistic Navigation Paths for Web Site Testing Using RNN and GAN|2021||20|8||2571|2604|||10.13052/jwe1540-9589.20816|https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10246917|For applications that have not yet been launched, a reliable way for creating online navigation logs may be crucial, enabling developers to test their products as though they were being used by real users. This might lead to faster and lower-cost program testing and enhancement, especially in terms of usability and interaction. In this work we propose a method for using deep learning approaches such as recurrent neural networks (RNN) and generative adversarial neural networks (GANN) to produce high-quality weblogs. Eventually, we can utilize the created data for automated testing and improvement of Web sites prior to their release with the aid of model-driven development tools such as IFML Editor.|Web engineering;deep learning;data mining;generative adversarial networks;recurrent neural networks;testing|Deep learning;Recurrent neural networks;Navigation;Generative adversarial networks;Web sites;Reliability;Usability|||||
IEEE|S. Bhatia; T. Gandhi; D. Kumar; P. Jalote|||Unit Test Generation using Generative AI : A Comparative Performance Analysis of Autogeneration Tools|2024|||||54|61||||https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10734640|Generating unit tests is a crucial task in software development, demanding substantial time and effort from programmers. The advent of Large Language Models (LLMs) introduces a novel avenue for unit test script generation. This research aims to experimentally investigate the effectiveness of LLMs, specifically exemplified by ChatGPT, for generating unit test scripts for Python programs, and how the generated test cases compare with those generated by an existing unit test generator (Pynguin). For experiments, we consider three types of code units: 1) Procedural scripts, 2) Function-based modular code, and 3) Class-based code. The generated test cases are evaluated based on criteria such as coverage, correctness, and readability. Our results show that ChatGPT's performance is comparable with Pynguin in terms of coverage, though for some cases its performance is superior to Pynguin. We also find that about a third of assertions generated by ChatGPT for some categories were incorrect. Our results also show that there is minimal overlap in missed statements between ChatGPT and Pynguin, thus, suggesting that a combination of both tools may enhance unit test generation performance. Finally, in our experiments, prompt engineering improved ChatGPT's performance, achieving a much higher coverage.CCS Concepts• Software and its engineering → Software testing and debugging; • Computing methodologies → Artificial intelligence.|Large Language Models;Unit Test Generation;ChatGPT;Generative AI|Software testing;Codes;Accuracy;Large language models;Scalability;Semantics;Chatbots;Software;Test pattern generators;Software development management|||||
IEEE|J. Zhang; C. Wang; A. Li; W. Wang; T. Li; Y. Liu|||VulAdvisor: Natural Language Suggestion Generation for Software Vulnerability Repair|2024|||||1932|1944||||https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10764852|Software vulnerabilities pose serious threats to the security of modern software systems. Deep Learning-based Automated Vulnerability Repair (AVR) has gained attention as a potential solution to accelerate the remediation of vulnerabilities. However, recent studies indicate that existing AVR approaches often only generate patches, which may not align with developers’ current repair practices or expectations. In this paper, we introduce VulAdvisor, an automated approach that generates natural language suggestions to guide developers or AVR tools in repairing vulnerabilities. VulAdvisor comprises two main components: oracle extraction and suggestion learning. To address the challenge of limited historical data, we propose an oracle extraction method facilitating ChatGPT to construct a comprehensive and high-quality dataset. For suggestion learning, we take the supervised fine-tuning CodeT5 model as the basis, integrating local context into Multi-Head Attention and introducing a repair action loss, to improve the relevance and meaningfulness of the generated suggestions. Extensive experiments on a large-scale dataset from real-world C/C++ projects demonstrate the effectiveness of VulAdvisor, surpassing several alternatives in terms of both lexical and semantic metrics. Moreover, we show that the generated suggestions enhance the patch generation capabilities of existing AVR tools. Human evaluations further validate the quality and utility of VulAdvisor’s suggestions, confirming their potential to improve software vulnerability repair practices.CCS CONCEPTS• Software and its engineering → Software maintenance tools; Software testing and debugging.|vulnerability repair;large language models;suggestion generation;program repair|Software testing;Software maintenance;Source coding;Natural languages;Semantics;Maintenance engineering;Chatbots;Software systems;Security;Software engineering|||||
IEEE|S. S. Canidate; H. R. Gracy; S. McIntosh; Y. Liu; R. Fisk-Hoffman; S. Rich; C. Mavian; R. L. Cook; M. Prosperi; M. Salemi|||What to consider when developing a new molecular HIV surveillance tool: Perspectives of key stakeholders working in HIV prevention and treatment|2025|||||588|597|||10.1109/ICHI64645.2025.00072|https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11081686|Developing and validating novel molecular HIV surveillance (MHS) tools capable of predicting the growth and trajectory of localized outbreaks driven by specific transmission clusters is key to the Ending the HIV Epidemic in the United States initiative. This study explored stakeholders' perspectives on HIV prevention and treatment regarding a developing deep-learning framework, DeepDynaForecast, and its ability to predict HIV transmission cluster trajectories and inform decision-making on HIV prevention and treatment scale-up approaches in Florida. We conducted five virtual focus group discussions with 16 clinical health professionals and state and local public health personnel. Focus group discussions were audio-recorded, transcribed using Zoom transcription, and manually coded using a reflexive thematic analysis approach. Overall, participants reported a high level of acceptability for using MHS tools. However, when exploring their perspectives on using the DeepDynaForecast tool, participants discussed their acceptance criteria, including key features that the DeepDynaForecast tool should have and the need to determine the data types the tool should generate to meet their needs and be deemed acceptable. Before implementation, participants felt the tool should undergo extensive software testing, followed by end-users receiving comprehensive training and the developers determining how the DeepDynaForecast tool could integrate with existing MHS tools. Likewise, participants discussed using the data generated by DeepDynaForecast to increase HIV prevention, education, outreach activities, and mobilization efforts in communities where the most HIV diagnoses occur, as well as increase behavioral change communication efforts. Participants also expressed concerns about HIV-related stigma, a potentially dangerous unintended consequence of using existing and new MHS tools. Current MHS tools have helped inform and evaluate HIV prevention and treatment efforts in the US. A novel MHS tool such as DeepDynaForecast may be critical to achieving the Ending the HIV Epidemic (EHE) goals and curbing the spread of HIV in Florida and in the US.|molecular epidemiology;surveillance;transmission clusters;HIV;Florida;qualitative research|Training;Software testing;Epidemics;Prevention and mitigation;Surveillance;Trajectory;Stakeholders;Personnel;Public healthcare;Informatics|||||
IEEE|Z. Zhao; T. Toda; T. Kitamura|||Approximation-guided Fairness Testing through Discriminatory Space Analysis|2024|||||1007|1018||||https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10764932|As machine learning (ML) systems are increasingly used in various fields, including tasks with high social impact, concerns about their fairness are growing. To address these concerns, individual fairness testing (IFT) has been introduced to identify individual discriminatory instances (IDIs) that indicate the violation of individual fairness in a given ML classifier. In this paper, we propose a black-box testing algorithm for IFT, named Aft (short for Approximation-guided Fairness Testing). Aft constructs approximate models based on decision trees, and generates test cases by sampling paths of the decision trees. Our evaluation by experiments confirms that Aft outperforms the state-of-the-art black-box IFT algorithm ExpGA both in efficiency (by 3.42 times) and diversity of IDIs identified by algorithms (by 1.16 times).CCS CONCEPTS• Software and its engineering → Software testing and debugging.|Machine Learning;Algorithmic Fairness;Fairness Testing;Decision Tree;Sampling Algorithm|Software testing;Machine learning algorithms;Software algorithms;Closed box;Machine learning;Approximation algorithms;Classification algorithms;Decision trees;Testing;Software engineering|||||
IEEE||||Message from the Program Co-Chairs|2020|||||i|i|||10.1109/AITEST49225.2020.00006|https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9176801|The Second IEEE International Conference on Artificial Intelligence Testing (AITest) is held in Oxford, UK, on April 13th-16th, 2020 as part of a set of joint conferences and workshops. The goal of organizing this event is to bring together researchers and practitioners to discuss new scientific results and solutions to the timely and challenging problem of testing artificial intelligence models and methods and, conversely, on the use of artificial intelligence in software testing. It is a great honor to have as a distinguished keynote speaker Professor Kerstin Eder from the University of Bristol, UK, an expert in design automation and verification with particular interest in robot trustworthiness and safety. We also have an invited talk from Dr Jie Zhang from UCL, UK, on the state of the art of testing machine learning models. As Program Co-Chairs of the conference, we have solicited two types of original contributions, long (eight pages) papers and short (two pages) papers. We finally selected 17 long papers and 3 short papers to be included into these proceedings from 49 abstract submissions and 41 papers eventually submitted. Each paper has been carefully reviewed by at least three members of the Program Committee, who provided informative and detailed reviews. These papers cover diverse aspects of software testing and artificial intelligence and carry strong scientific results in terms of innovation. Together with the keynote speech and invited talk they form a solid and ambitious scientific program for the conference.|||||||
WEB OF SCIENCE|Durrani, Usman Khan; Akpinar, Mustafa; Adak, Muhammed Fatih; Kabakus, Abdullah Talha; Ozturk, Muhammed Maruf; Saleh, Mohammed|||A Decade of Progress: A Systematic Literature Review on the Integration of AI in Software Engineering Phases and Activities (2013-2023)|2024|IEEE ACCESS|12|||171185|171204|||10.1109/ACCESS.2024.3488904||The synergy between software engineering (SE) and artificial intelligence (AI) catalyzes software development, as numerous recent studies illustrate an intensified intersection between these domains. This systematic literature review examines the integration of AI techniques or methodologies across SE phases and related activities spanning from 2013 to 2023, resulting in the selection of 110 research papers. Investigating the profound influence of AI techniques, including machine learning, deep learning, natural language processing, optimization algorithms, and expert systems, across various SE phases-such as planning, requirement engineering, design, development, testing, deployment, and maintenance-is the focal point of this study. Notably, the extensive adoption of machine learning and deep learning algorithms in the development and testing phases has enhanced software quality through defect prediction, code recommendation, and vulnerability detection initiatives. Furthermore, natural language processing's role in automating requirements classification and sentiment analysis has streamlined SE practices. Optimization algorithms have also demonstrated efficacy in refining SE activities such as feature location and software repair action predictions, augmenting precision and efficiency in maintenance endeavors. Prospective research emphasizes the imperative of interpretable AI models and the exploration of novel AI paradigms, including explainable AI and reinforcement learning, to promote ethical and efficient software development practices. This paper fills the gap identified in AI techniques dedicated to improving SE phases. The review concludes that AI in SE is revolutionizing the discipline, enhancing software quality, efficiency, and innovation, with ongoing efforts targeting the mitigation of identified limitations and the augmentation of AI capabilities for intelligent and dependable SE.|||Review||||
WEB OF SCIENCE|Ricca, Filippo; Garcia, Boni; Nass, Michel; Harman, Mark|||Next-Generation Software Testing: AI-Powered Test Automation|2025|IEEE SOFTWARE|42|4||25|33|||10.1109/MS.2025.3559194|||||Editorial Material||||
WEB OF SCIENCE|Udeshi, Sakshi; Chattopadhyay, Sudipta|||Grammar Based Directed Testing of Machine Learning Systems|2021|IEEE TRANSACTIONS ON SOFTWARE ENGINEERING|47|11||2487|2503|||10.1109/TSE.2019.2953066||The massive progress of machine learning has seen its application over a variety of domains in the past decade. But how do we develop a systematic, scalable and modular strategy to validate machine-learning systems? We present, to the best of our knowledge, the first approach, which provides a systematic test framework for machine-learning systems that accepts grammar-based inputs. Our Ogma approach automatically discovers erroneous behaviours in classifiers and leverages these erroneous behaviours to improve the respective models. Ogma leverages inherent robustness properties present in any well trained machine-learning model to direct test generation and thus, implementing a scalable test generation methodology. To evaluate our Ogma approach, we have tested it on three real world natural language processing (NLP) classifiers. We have found thousands of erroneous behaviours in these systems. We also compare Ogma with a random test generation approach and observe that Ogma is more effective than such random test generation by up to 489 percent.|||Article||||
WEB OF SCIENCE|Durrani, Usman Khan; Akpinar, Mustafa; Bektas, Hakan; Saleh, Mohammed|||Impact of Artificial Intelligence on Software Engineering Phases and Activities (2013-2024): A Quantitative Analysis Using Zero-Truncated Poisson Model|2025|IEEE ACCESS|13|||95535|95547|||10.1109/ACCESS.2025.3574462||This paper presents the results of a quantitative analysis derived from data collected in our earlier systematic literature review, focusing on integrating Artificial Intelligence (AI) techniques across various phases of Software Engineering (SE). Employing a Zero-Truncated Poisson (ZTP) model, we analyzed 120 selected research papers to assess the impact of AI methodologies on SE phases. The findings indicate significant improvements attributable to AI in different phases of SE. Specifically, AI techniques have been found to enhance the accuracy of the planning, requirement engineering, and development phases and improve the efficiency of the requirement engineering and design phases. Notably, AI's integration has markedly improved the accuracy and efficiency of the requirement engineering phase, underscoring AI's critical role in advancing SE practices. This study contributes to a deeper understanding of the quantitative impact of AI on SE, providing valuable insights for practitioners and researchers in understanding AI technologies to enhance SE phases.|||Review||||
WEB OF SCIENCE|Soremekun, Ezekiel; Udeshi, Sakshi; Chattopadhyay, Sudipta|||Astraea: Grammar-Based Fairness Testing|2022|IEEE TRANSACTIONS ON SOFTWARE ENGINEERING|48|12||5188|5211|||10.1109/TSE.2022.3141758||Software often produces biased outputs. In particular, machine learning (ML) based software is known to produce erroneous predictions when processing discriminatory inputs. Such unfair program behavior can be caused by societal bias. In the last few years, Amazon, Microsoft and Google have provided software services that produce unfair outputs, mostly due to societal bias (e.g., gender or race). In such events, developers are saddled with the task of conducting fairness testing. Fairness testing is challenging; developers are tasked with generating discriminatory inputs that reveal and explain biases. We propose a grammar-based fairness testing approach (called Astraea) which leverages context-free grammars to generate discriminatory inputs that reveal fairness violations in software systems. Using probabilistic grammars, Astraea also provides fault diagnosis by isolating the cause of observed software bias. Astraea's diagnoses facilitate the improvement of ML fairness. Astraea was evaluated on 18 software systems that provide three major natural language processing (NLP) services. In our evaluation, Astraea generated fairness violations at a rate of about 18%. Astraea generated over 573K discriminatory test cases and found over 102K fairness violations. Furthermore, Astraea improves software fairness by about 76% via model-retraining, on average.|||Article||||
WEB OF SCIENCE|Sofian, Hazrina; Yunus, Nur Arzilawati Md; Ahmad, Rodina|||Systematic Mapping: Artificial Intelligence Techniques in Software Engineering|2022|IEEE ACCESS|10|||51021|51040|||10.1109/ACCESS.2022.3174115||Artificial Intelligence (AI) has become a core feature of today's real-world applications, making it a trending topic within the software engineering (SE) community. The rise in the availability of AI techniques encompasses the capability to make rapid, automated, impactful decisions and predictions, leading to the adoption of AI techniques in SE. With industry revolution 4.0, the role of software engineering has become critical for developing productive, efficient, and quality software. Thus, there is a major need for AI techniques to be applied to enhance and improve the critical activities within the software engineering phases. Software is developed through intelligent software engineering phases. This paper concerns a systematic mapping study that aimed to characterize the publication landscape of AI techniques in software engineering. Gaps are identified and discussed by mapping these AI techniques against the SE phases to which they contributed. Many systematic mapping review papers have been produced only for a specific AI technique or a specific SE phase or activity. Hence, to our best of knowledge within the last decade, there is no systematic mapping review that has fully explored the overall trends in AI techniques and their application to all SE phases.|||Article||||
WEB OF SCIENCE|Ji, Pin; Feng, Yang; Zhang, Ruohao; Xue, Ruichen; Zhang, Yichi; Huang, Weitao; Liu, Jia; Zhao, Zhihong|||NLPLego: Assembling Test Generation for Natural Language Processing Applications|2025|ACM TRANSACTIONS ON SOFTWARE ENGINEERING AND METHODOLOGY|34|2|49|||||10.1145/3691631||With the development of Deep Learning, Natural Language Processing (NLP) applications have reached or even exceeded human-level capabilities in certain tasks. Although NLP applications have shown good performance, they can still have bugs like traditional software and even lead to serious consequences. Inspired by Lego blocks and syntax structure analysis, we propose an assembling test generation method for NLP applications or models and implement it in NLPLego. The key idea of NLPLego is to assemble the sentence skeleton and adjuncts in order by simulating the building of Lego blocks to generate multiple grammatically and semantically correct sentences based on one seed sentence. The sentences generated by NLPLego have derivation relations and different degrees of variation. These characteristics make it well-suited for integration with metamorphic testing theory, addressing the challenge of test oracle absence in NLP application testing. To validate NLPLego, we conduct experiments on three commonly used NLP tasks (i.e., machine reading comprehension, sentiment analysis, and semantic similarity measures), focusing on the efficiency of test generation and the quality and effectiveness of generated tests. We select five advanced NLP models and one popular industrial NLP software as the tested subjects. Given seed tests from SQUAD 2.0, SST, and QQP, NLPLego successfully detects 1,732, 3,140, and 261,879 incorrect behaviors with around 93.1% precision in three tasks, respectively. The experiment results show that NLPLego can efficiently generate high-quality tests for multiple NLP tasks to detect erroneous behaviors effectively. In the case study, we analyze the testing results provided by NLPLego to obtain intuitive representations of the different NLP capabilities of the tested subjects. The case study confirms that NLPLego can provide developers with clarity on the direction to improve NLP models or applications, laying the foundation for enhancing performance.|||Article||||
WEB OF SCIENCE|Nejati, Shiva|||Next-Generation Software Verification: An AI Perspective|2021|IEEE SOFTWARE|38|3||126|130|||10.1109/MS.2021.3049322|||||Article||||
WEB OF SCIENCE|Fontes, Afonso|||Context-Infused Automated Software Test Generation|2025||||||||||||||Dissertation/Thesis||||
WEB OF SCIENCE|Srinivasan, Madhusudan; Kanewala, Upulee|||Improving Early Fault Detection in Machine Learning Systems Using Data Diversity-Driven Metamorphic Relation Prioritization|2024|ELECTRONICS|13|17|3380|||||10.3390/electronics13173380||Metamorphic testing is a valuable approach to verifying machine learning programs where traditional oracles are unavailable or difficult to apply. This paper proposes a technique to prioritize metamorphic relations (MRs) in metamorphic testing for machine learning and deep learning systems, aiming to enhance early fault detection. We introduce five metrics based on diversity in source and follow-up test cases to prioritize MRs. The effectiveness of our proposed prioritization methods is evaluated on three machine learning and one deep learning algorithm implementation. We compare our approach against random-based, fault-based, and neuron activation coverage-based MR ordering. The results show that our data diversity-based prioritization performs comparably to fault-based prioritization, reducing fault detection time by up to 62% compared to random MR execution. Our proposed metrics outperformed neuron activation coverage-based prioritization, providing 5-550% higher fault detection effectiveness. Overall, our approach to prioritizing metamorphic relations leads to increased fault detection effectiveness and reduced average fault detection time. This improvement in efficiency can result in significant time and cost savings when applying metamorphic testing to machine learning and deep learning systems.|||Article||||
WEB OF SCIENCE|Karpurapu, Shanthi; Myneni, Sravanthy; Nettur, Unnati; Gajja, Likhit Sagar; Burke, Dave; Stiehm, Tom; Payne, Jeffery|||Comprehensive Evaluation and Insights Into the Use of Large Language Models in the Automation of Behavior-Driven Development Acceptance Test Formulation|2024|IEEE ACCESS|12|||58715|58721|||10.1109/ACCESS.2024.3391815||Behavior-driven development (BDD) is an Agile testing methodology fostering collaboration among developers, QA analysts, and stakeholders. In this manuscript, we propose a novel approach to enhance BDD practices using large language models (LLMs) to automate acceptance test generation. Our study uses zero and few-shot prompts to evaluate LLMs such as GPT-3.5, GPT-4, Llama-2-13B, and PaLM-2. The paper presents a detailed methodology that includes the dataset, prompt techniques, LLMs, and the evaluation process. The results demonstrate that GPT-3.5 and GPT-4 generate error-free BDD acceptance tests with better performance. The few-shot prompt technique highlights its ability to provide higher accuracy by incorporating examples for in-context learning. Furthermore, the study examines syntax errors, validation accuracy, and comparative analysis of LLMs, revealing their effectiveness in enhancing BDD practices. However, our study acknowledges that there are limitations to the proposed approach. We emphasize that this approach can support collaborative BDD processes and create opportunities for future research into automated BDD acceptance test generation using LLMs.|||Article||||
WEB OF SCIENCE||||Collaborative Research: SHF: Medium: Natural Language Models with Execution Data for Software Testing|2023|||||||||||Natural Language Processing (NLP) models have proven useful for various software engineering tasks, including code completion, comment generation and update, code review generation, and clone detection. Despite the importance of software testing in industry, there has been little work on using these Artificial Intelligence (AI) models for developing and maintaining test code, which is a key part of software testing in the real world. Test code differs in multiple ways from regular code: (1) Test code is structured in a specific way, with steps for setting up a test environment and comparing expected results; (2) Test code has richer context, such as the specific methods and code it is testing (code under test); (3) Test code uses different code elements than the code under test, i.e., it has a different control structure; (4) Test code has specific input values and expected results; (5) Unlike regular code, test code can be readily executed. The goal of this project is to increase the productivity of software engineers via NLP models that simplify the development and maintenance of tests (NLP4Test). Specifically, tasks include test generation and completion, test update (when the underlying code changes), and automatically migrating tests across different programming languages. This project explores testing both general codebases and emerging machine learning (ML) applications. The project targets a novel domain -- NLP4Test, and this domain requires innovative NLP models. The outcome of this project will include novel techniques, implementations of these techniques, and extensive evaluations on open-source projects. This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.|||Awarded Grant||||
WEB OF SCIENCE||||Collaborative Research: SHF: Medium: Natural Language Models with Execution Data for Software Testing|2023|||||||||||Natural Language Processing (NLP) models have proven useful for various software engineering tasks, including code completion, comment generation and update, code review generation, and clone detection. Despite the importance of software testing in industry, there has been little work on using these Artificial Intelligence (AI) models for developing and maintaining test code, which is a key part of software testing in the real world. Test code differs in multiple ways from regular code: (1) Test code is structured in a specific way, with steps for setting up a test environment and comparing expected results; (2) Test code has richer context, such as the specific methods and code it is testing (code under test); (3) Test code uses different code elements than the code under test, i.e., it has a different control structure; (4) Test code has specific input values and expected results; (5) Unlike regular code, test code can be readily executed. The goal of this project is to increase the productivity of software engineers via NLP models that simplify the development and maintenance of tests (NLP4Test). Specifically, tasks include test generation and completion, test update (when the underlying code changes), and automatically migrating tests across different programming languages. This project explores testing both general codebases and emerging machine learning (ML) applications. The project targets a novel domain -- NLP4Test, and this domain requires innovative NLP models. The outcome of this project will include novel techniques, implementations of these techniques, and extensive evaluations on open-source projects. This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.|||Awarded Grant||||
WEB OF SCIENCE||||SaTC: CORE: Small: Generalizing Adversarial Examples in Natural Language|2022|||||||||||Deep learning-based natural language processing (deep NLP) plays a crucial role in many security-critical domains, including advancing information understanding and analysis for healthcare, legal justice, e-commerce, and social media platforms. Consequently, it is essential to understand the robustness of deep NLP systems to adversarial attacks aimed at reducing their accuracy and security. To combat these attacks, this project introduces techniques to automatically evaluate and improve the adversarial robustness of deep NLP frameworks, as well as tools and datasets that can serve as useful community benchmarks and research resources. This topic is a new and exciting area that can contribute to multiple disciplines, including adversarial machine learning, natural language processing, and software testing; the project will support several graduate students in receiving advanced, interdisciplinary training in these areas. This award defines adversarial text examples as inputs to a deep NLP system that are maliciously designed to fool a predictive deep NLP model towards wrong predictions while simultaneously satisfying language-oriented constraints. The goal is to investigate the interplay between deep NLP and adversarial robustness in three dependent tasks. The first task is to build a comprehensive benchmark for generating adversarial text inputs across multiple NLP formulations. A library, TextAttack, will help researchers gauge their NLP models' robustness and provide a unified framework for attack designers to benchmark their attacks against the current state-of-the-art. The second task investigates the robustness of interpretation strategies in deep NLP and designs generalized adversarial text to reveal vulnerabilities in NLP interpretations. The third task adapts work from software testing to create criteria that define when an adequate set of adversarial text examples has been generated. In summary, this project studies how to evaluate the robustness of state-of-the-art NLP systems against an adversary and develop techniques to achieve both robust predictions and robust interpretations in deep NLP. This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.|||Awarded Grant||||
WEB OF SCIENCE|Terragni, Valerio; Vella, Annie; Roop, Partha; Blincoe, Kelly|||The Future of AI-Driven Software Engineering|2025|ACM TRANSACTIONS ON SOFTWARE ENGINEERING AND METHODOLOGY|34|5|120|||||10.1145/3715003||A paradigm shift is underway in Software Engineering, with AI systems such as LLMs playing an increasingly important role in boosting software development productivity. This trend is anticipated to persist. In the next years, we expect a growing symbiotic partnership between human software developers and AI. The Software Engineering research community cannot afford to overlook this trend; we must address the key research challenges posed by the integration of AI into the software development process. In this article, we present our vision of the future of software development in an AI-driven world and explore the key challenges that our research community should address to realize this vision. CCS Concepts: center dot Software and its engineering -> Software testing and debugging; Designing software; Software design engineering;|||Article||||
WEB OF SCIENCE|Guo, Yuejun; Hu, Qiang; Xie, Xiaofei; Cordy, Maxime; Papadakis, Mike; Le Traon, Yves|||KAPE: kNN-based Performance Testing for Deep Code Search|2024|ACM TRANSACTIONS ON SOFTWARE ENGINEERING AND METHODOLOGY|33|2|48|||||10.1145/3624735||Code search is a common yet important activity of software developers. An efficient code search model can largely facilitate the development process and improve the programming quality. Given the superb performance of learning the contextual representations, deep learning models, especially pre-trained language-models, have been widely explored for the code search task. However, studies mainly focus on proposing new architectures for ever-better performance on designed test sets but ignore the performance on unseen test data where only natural language queries are available. The same problem in other domains, e.g., CV and NLP, is usually solved by test input selection that uses a subset of the unseen set to reduce the labeling effort. However, approaches from other domains are not directly applicable and still require labeling effort. In this article, we propose the kNN-based performance testing (KAPE) to efficiently solve the problem without manually matching code snippets to test queries. The main idea is to use semantically similar training data to perform the evaluation. Extensive experiments on six programming language datasets, three state-of-the-art pre-trained models, and seven baseline methods demonstrate that KAPE can effectively assess the model performance (e.g., CodeBERT achieves MRR 0.5795 on JavaScript) with a slight difference (e.g., 0.0261).|||Article||||
WEB OF SCIENCE|Ben Braiek, Houssem; Reid, Thomas; Khomh, Foutse|||Physics-Guided Adversarial Machine Learning for Aircraft Systems Simulation|2023|IEEE TRANSACTIONS ON RELIABILITY|72|3||1161|1175|||10.1109/TR.2022.3196272||In the context of aircraft system performance assessment, deep learning technologies allow us to quickly infer models from experimental measurements, with less detailed system knowledge than usually required by physics-based modeling. However, this inexpensive model development also comes with new challenges regarding model trustworthiness. This article presents a novel approach, physics-guided adversarial machine learning (ML), which improves the confidence over the physics consistency of the model. The approach performs, first, a physics-guided adversarial testing phase to search for test inputs revealing behavioral system inconsistencies, while still falling within the range of foreseeable operational conditions. Then, it proceeds with a physics-informed adversarial training to teach the model the system-related physics domain foreknowledge through iteratively reducing the unwanted output deviations on the previously uncovered counterexamples. Empirical evaluation on two aircraft system performance models shows the effectiveness of our adversarial ML approach in exposing physical inconsistencies of both the models and in improving their propensity to be consistent with physics domain knowledge.|||Article||||
WEB OF SCIENCE|Treshcheva, Elena; Yavorsky, Rostislav; Itkin, Iosif|||Toward reducing the operational risk of emerging technologies adoption in central counterparties through end-to-end testing|2020|JOURNAL OF FINANCIAL MARKET INFRASTRUCTURES|8|3||51|74|||10.21314/JFMI.2019.123||Emerging technologies, such as artificial intelligence (AI) and distributed ledger technology, are increasingly being adopted by financial institutions, promising functional efficiency and cost reduction to stakeholders and users. However, the structural and functional changes associated with the technological transformation of software platforms pose significant operational risks. While some aspects of these risks are well known and studied (such as AI trustworthiness, data privacy and consistency, platform availability and information security), others are underestimated. The extreme complexity and nondeterministic nature of existing technology infrastructures still need to be addressed, as they will soon be inherited by the platforms built with new technologies. The only way to mitigate these risks is extensive endto-end professional testing. This paper discusses the software-testing challenges of traditional central counterparties as well as the risks, biases and problems related to new technologies. It also outlines a set of requirements for an end-to-end validation and verification solution aimed at the new generation of clearing platforms. Focusing on one of the most common use cases in the capital markets industry, this paper considers the challenges posed by the introduction of blockchain and AI into the post-trade area.|||Article||||
WEB OF SCIENCE|Job, Minimol Anil|||Automating and Optimizing Software Testing using Artificial Intelligence Techniques|2021|INTERNATIONAL JOURNAL OF ADVANCED COMPUTER SCIENCE AND APPLICATIONS|12|5||594|602|||||The final product of software development process is a software system and testing is one of the important stages in this process. The success of this process can be determined by how well it accomplishes its goal. Due to the advancement of technology, various software testing tools have been introduced in the software engineering discipline. The use of software is increasing day-by-day and complexity of software functions are challenging and there is need to release the software within the short quality evaluation period, there is a high demand in adopting automation in software testing. Emergence of automatic software testing tools and techniques helps in quality enhancement and reducing time and cost in the software development activity. Artificial Intelligence (AI) techniques are widely applied in different areas of Software engineering (SE). Application of AI techniques can help in achieving good performance in software Testing and increase the productivity of the software development firms. This paper briefly presents the state of the art in the field of software testing by applying AI techniques in software testing.|||Article||||
WEB OF SCIENCE||||SBIR Phase I: MuukTest Artificial Intelligence Powered Software Testing|2020|||||||||||The broader impact/commercial potential of this Small Business Innovation Research (SBIR) Phase I project will enable non-technical users to create complete and comprehensive software test automation. Additionally, it will enable growing software companies to ship their products faster with higher quality at a reasonable cost. Currently, these companies spend up to 50% of their resources on quality assurance (QA) and testing. This project will develop an automated process for testing software. This Small Business Innovation Research (SBIR) Phase I project will combine symbolic reasoning algorithms, deep learning, and reinforcement learning models to automate software quality assurance testing. The two problems being addressed by this project are (1) software development teams spend up to 50% of their time testing software, and (2) they have to hire skilled software engineers to automate these tests. The objective of this research is to use artificial intelligence (AI) to make software quality assurance testing faster and enable non-technical workers to create sophisticated tests without the need to code. The proposed research aims to create an AI prototype by (i) building a baseline of manual test scenarios, (ii) building tests using symbolic reasoning (SR), (iii) incorporating deep learning, and (iv) adding reinforcement learning to generate tests. This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.|||Awarded Grant||||
WEB OF SCIENCE|Chen, Xiangping; Hu, Xing; Huang, Yuan; Jiang, He; Ji, Weixing; Jiang, Yanjie; Jiang, Yanyan; Liu, Bo; Liu, Hui; Li, Xiaochen; Lian, Xiaoli; Meng, Guozhu; Peng, Xin; Sun, Hailong; Shi, Lin; Wang, Bo; Wang, Chong; Wang, Jiayi; Wang, Tiantian; Xuan, Jifeng; Xia, Xin; Yang, Yibiao; Yang, Yixin; Zhang, Li; Zhou, Yuming; Zhang, Lu|||Deep learning-based software engineering: progress, challenges, and opportunities|2025|SCIENCE CHINA-INFORMATION SCIENCES|68|1|111102|||||10.1007/s11432-023-4127-5||Researchers have recently achieved significant advances in deep learning techniques, which in turn has substantially advanced other research disciplines, such as natural language processing, image processing, speech recognition, and software engineering. Various deep learning techniques have been successfully employed to facilitate software engineering tasks, including code generation, software refactoring, and fault localization. Many studies have also been presented in top conferences and journals, demonstrating the applications of deep learning techniques in resolving various software engineering tasks. However, although several surveys have provided overall pictures of the application of deep learning techniques in software engineering, they focus more on learning techniques, that is, what kind of deep learning techniques are employed and how deep models are trained or fine-tuned for software engineering tasks. We still lack surveys explaining the advances of subareas in software engineering driven by deep learning techniques, as well as challenges and opportunities in each subarea. To this end, in this study, we present the first task-oriented survey on deep learning-based software engineering. It covers twelve major software engineering subareas significantly impacted by deep learning techniques. Such subareas spread out through the whole lifecycle of software development and maintenance, including requirements engineering, software development, testing, maintenance, and developer collaboration. As we believe that deep learning may provide an opportunity to revolutionize the whole discipline of software engineering, providing one survey covering as many subareas as possible in software engineering can help future research push forward the frontier of deep learning-based software engineering more systematically. For each of the selected subareas, we highlight the major advances achieved by applying deep learning techniques with pointers to the available datasets in such a subarea. We also discuss the challenges and opportunities concerning each of the surveyed software engineering subareas.|||Review||||
WEB OF SCIENCE|Zhu, Hong; Bayley, Ian|||Discovering boundary values of feature-based machine learning classifiers through exploratory datamorphic testing|2022|JOURNAL OF SYSTEMS AND SOFTWARE|187||111231|||||10.1016/j.jss.2022.111231||Testing has been widely recognised as difficult for AI applications. This paper proposes a set of testing strategies for testing machine learning applications in the framework of the datamorphism testing methodology. In these strategies, testing aims at exploring the data space of a classification or clustering application to discover the boundaries between classes that the machine learning application defines. This enables the tester to understand precisely the behaviour and function of the software under test. In the paper, three variants of exploratory strategies are presented with the algorithms implemented in the automated datamorphic testing tool Morphy. The correctness of these algorithms are formally proved. Their capability and cost of discovering borders between classes are evaluated via a set of controlled experiments with manually designed subjects and a set of case studies with real machine learning models. (C)& nbsp;2022 Elsevier Inc. All rights reserved.|||Article||||
WEB OF SCIENCE|Zhang, Jie M.; Harman, Mark; Ma, Lei; Liu, Yang|||Machine Learning Testing: Survey, Landscapes and Horizons|2022|IEEE TRANSACTIONS ON SOFTWARE ENGINEERING|48|1||1|36|||10.1109/TSE.2019.2962027||This paper provides a comprehensive survey of techniques for testing machine learning systems; Machine Learning Testing (ML testing) research. It covers 144 papers on testing properties (e.g., correctness, robustness, and fairness), testing components (e.g., the data, learning program, and framework), testing workflow (e.g., test generation and test evaluation), and application scenarios (e.g., autonomous driving, machine translation). The paper also analyses trends concerning datasets, research trends, and research focus, concluding with research challenges and promising research directions in ML testing.|||Article||||
WEB OF SCIENCE|Song, Chen|||Software Testing Resource Scheduling Based on Artificial Intelligence|2022||||||||||||||Dissertation/Thesis||||
WEB OF SCIENCE|Duckworth, Stephanie|||Mutation Testing Using Predictive Methods|2021||||||||||||||Dissertation/Thesis||||
WEB OF SCIENCE|Anderson, Catherine L; Willner, Marjorie R; Patsolic, Heather G; Brem, Larry; Aboye, Gelila; Smolyak, Daniel; Crowley, Kenyon|||A Comparison of LLMs for Use in Generating Synthetic Test Data for Automated Testing of a Patient-Focused, Survey-Based System.|2024|AMIA ... Annual Symposium proceedings. AMIA Symposium|2024|||142|151|||||In the context of a patient-focused, survey-based system, we demonstrated the potential of generative AI to create custom synthetic data using 2 different large language models (GPT 3.5 and Flan T5-XL) in AWS and Azure environments. While we improved test effectiveness and efficiency by synthetically generating many test cases, the experience included technical and communication challenges as well as complexities associated with balancing the desire for high utility and realism in the data with the available testing resources. Recommendations range from defining and gaining consensus on evaluation metrics early in the process as it influences technical questions like persona creation and prompt-engineering to encouraging test teams to build flexible frameworks from the start.|||Journal Article; Comparative Study||||
WEB OF SCIENCE|Widodo, Aris Puji; Wibowo, Adi; Kurniawan, Kabul|||Enhancing Software User Interface Testing Through Few Shot Deep Learning: A Novel Approach for Automated Accuracy and Usability Evaluation|2023|INTERNATIONAL JOURNAL OF ADVANCED COMPUTER SCIENCE AND APPLICATIONS|14|12||578|585|||||Traditional user interface (UI) testing methods in software development are time-consuming and prone to human error, requiring more efficient and accurate approaches. Moreover, deep learning requires extensive data training to develop accurate automated UI software testing. This paper proposes an efficient and accurate method for automating UI software testing using Deep learning with training data limitations. We propose a novel deep learning -based framework suitable for UI element analysis in data -scarce situations, focusing on Few -shot learning. Our framework initiates with several robust feature extraction modules that employ and compare sophisticated encoder models to be adept at capturing complex patterns from a sparse dataset. The methodology employs the Enrico and UI screen mistake datasets, overcoming training data limitations. Utilizing encoder models, including CNN, VGG-16, ResNet-50, MobileNet-V3, and EfficientNet-B1, the EfficientNet-B1 model excelled in the setting of Few -Shot learning with five -shot with an average accuracy of 76.05%. Our proposed model's accuracy was improved and compared to the state-of-the-art method. Our findings demonstrate the effectiveness of few -shot learning in UI screen classification, setting new benchmarks in software testing and usability evaluation, particularly in limited data scenarios.|||Article||||
WEB OF SCIENCE|Kim, Kinyun|||A Study on the Development Method About Automated End-to-End Testing of AI Voice Assistant by Using Audio Signal Data Interaction|2020|KIISE Transactions on Computing Practices|26|9||424|428|||10.5626/KTCP.2020.26.9.424||The AI voice assistant needs various testing as with other software to the verify software quality. In this paper, I explain the E2E (End-to-End) test automation for the AI voice assistant, one of the these various tests. For this purpose, I developed the E2E test automation for the AI voice assistant by using the speech synthesis API, speech recognition API, audio signal processing library and so on, and I explain the implementation method. Also, I executed the automated test that targeted a commercialized AI voice assistant for evaluating the performance of the developed E2E test automation. As a result, the E2E test automation I developed, showed that it can test automatically the complicated test case as well as the test case that consumes much time.|||research-article||||
WEB OF SCIENCE|Park, Jaekwan; Kim, Taekkyu; Koo, Seoryong|||Verification strategy for artificial intelligence components in nuclear plant instrumentation and control systems|2023|PROGRESS IN NUCLEAR ENERGY|164||104842|||||10.1016/j.pnucene.2023.104842||The application of artificial intelligence (AI) systems in nuclear power plants has the potential to facilitate significant advancements in the industry. However, nuclear system engineers and regulators have expressed concerns regarding the reliability of AI components owing to a lack of documentation and appropriate verification methods that differ from those used for traditional software. Accordingly, this study proposes a systematic approach for the verification and validation of AI components based on nuclear software regulatory guidelines. The proposed strategy includes process verification and functional testing activities specifically tailored to AI components for instrumentation and control systems. This approach serves as a foundation for fostering understanding and agreement among system engineers, operating licensees, and regulatory bodies on the use of AI components in nuclear power plants.|||Article||||
WEB OF SCIENCE|Chandrasekaran, Jaganmohan|||Testing Artificial Intelligence-Based Software Systems|2021||||||||||||||Dissertation/Thesis||||
WEB OF SCIENCE|Shafiq, Saad; Mashkoor, Atif; Mayr-Dorn, Christoph; Egyed, Alexander|||A Literature Review of Using Machine Learning in Software Development Life Cycle Stages|2021|IEEE ACCESS|9|||140896|140920|||10.1109/ACCESS.2021.3119746||The software engineering community is rapidly adopting machine learning for transitioning modern-day software towards highly intelligent and self-learning systems. However, the software engineering community is still discovering new ways how machine learning can offer help for various software development life cycle stages. In this article, we present a study on the use of machine learning across various software development life cycle stages. The overall aim of this article is to investigate the relationship between software development life cycle stages, and machine learning tools, techniques, and types. We attempt a holistic investigation in part to answer the question of whether machine learning favors certain stages and/or certain techniques.|||Review||||
WEB OF SCIENCE|Fatima, Sakina; Hemmati, Hadi; C. Briand, Lionel|||FlakyFix: Using Large Language Models for Predicting Flaky Test Fix Categories and Test Code Repair|2024|IEEE TRANSACTIONS ON SOFTWARE ENGINEERING|50|12||3146|3171|||10.1109/TSE.2024.3472476||Flaky tests are problematic because they non-deterministically pass or fail for the same software version under test, causing confusion and wasting development effort. While machine learning models have been used to predict flakiness and its root causes, there is much less work on providing support to fix the problem. To address this gap, in this paper, we focus on predicting the type of fix that is required to remove flakiness and then repair the test code on that basis. We do this for a subset of flaky tests where the root cause of flakiness is in the test itself and not in the production code. One key idea is to guide the repair process with additional knowledge about the test's flakiness in the form of its predicted fix category. Thus, we first propose a framework that automatically generates labeled datasets for 13 fix categories and trains models to predict the fix category of a flaky test by analyzing the test code only. Our experimental results using code models and few-shot learning show that we can correctly predict most of the fix categories. To show the usefulness of such fix category labels for automatically repairing flakiness, we augment the prompts of GPT 3.5 Turbo, a Large Language Model (LLM), with such extra knowledge to request repair suggestions. The results show that our suggested fix category labels, complemented with in-context learning, significantly enhance the capability of GPT 3.5 Turbo in generating fixes for flaky tests. Based on the execution and analysis of a sample of GPT-repaired flaky tests, we estimate that a large percentage of such repairs, (roughly between 51% and 83%) can be expected to pass. For the failing repaired tests, on average, 16% of the test code needs to be further changed for them to pass.|||Article||||
WEB OF SCIENCE|Bahi, Anas; Gharib, Jihane; Gahi, Youssef|||Integrating Generative AI for Advancing Agile Software Development and Mitigating Project Management Challenges|2024|INTERNATIONAL JOURNAL OF ADVANCED COMPUTER SCIENCE AND APPLICATIONS|15|3||54|61|||||Agile software development emphasizes iterative progress, adaptability, and stakeholder collaboration. It champions flexible planning, continuous improvement, and rapid delivery, aiming to respond swiftly to change and deliver value efficiently. Integrating Generative Artificial Intelligence (AI) into Agile software development processes presents a promising avenue for overcoming project management challenges and enhancing the efficiency and effectiveness of software development endeavors. This paper explores the potential benefits of leveraging Generative AI in Agile methodologies, aiming to streamline development workflows, foster innovation, and mitigate common project management challenges. By harnessing the capabilities of Generative AI for tasks such as code generation, automated testing, and predictive analytics, Agile teams can augment their productivity, accelerate delivery cycles, and improve the quality of software products. Additionally, Generative AI offers opportunities for enhancing collaboration, facilitating decision-making, and addressing uncertainties inherent in Agile project management. Through an in-depth analysis of the integration of Generative AI within Agile frameworks, this paper provides insights into how organizations can harness the transformative potential of AI to advance Agile software development practices and navigate the complexities of modern software projects more effectively.|||Article||||
WEB OF SCIENCE|Feng, Xiaoning; Han, Xiaohong; Chen, Simin; Yang, Wei|||LLMEffiChecker: : Understanding and Testing Efficiency Degradation of Large Language Models|2024|ACM TRANSACTIONS ON SOFTWARE ENGINEERING AND METHODOLOGY|33|7|186|||||10.1145/3664812||Large Language Models (LLMs) have received much recent attention due to their human-level accuracy. While existing works mostly focus on either improving accuracy or testing accuracy robustness, the computation efficiency of LLMs, which is of paramount importance due to often vast generation demands and real-time requirements, has surprisingly received little attention. In this article, we make the first attempt to understand and test potential computation efficiency robustness in state-of-the-art LLMs. By analyzing the working mechanism and implementation of 20,543 public-accessible LLMs, we observe a fundamental property in LLMs that could be manipulated in an adversarial manner to reduce computation efficiency significantly. Our interesting observation is that the output length determines the computation efficiency of LLMs instead of the input, where the output length depends on two factors: an often sufficiently large yet pessimistic pre-configured threshold controlling the max number of iterations and a runtime-generated end of sentence (EOS) token. Our key motivation is to generate test inputs that could sufficiently delay the generation of EOS such that LLMs would have to go through enough iterations to satisfy the pre-configured threshold. We present LLMEffiChecker, which can work under both white-box setting and black-box setting. In the white-box scenario, LLMEffiChecker develops a gradient-guided technique that searches for a minimal and unnoticeable perturbation at character-level, token-level, and structure-level. In the black-box scenario, LLMEffiChecker employs a causal inference-based approach to find critical tokens and similarly applies three levels of imperceptible perturbation to them. Both the white-box and black-box settings effectively delay the appearance of EOS, compelling these inputs to reach the naturally unreachable threshold. To demonstrate the effectiveness of LLMEffiChecker, we conduct a systematic evaluation on nine publicly available LLMs: Google T5, AllenAI WMT14, Helsinki-NLP translator, Facebook FairSeq, UNICAMP-DL translator, MarianMT, Google FLAN-T5, MBZUAI LaMini-GPT, and Salesforce CodeGen. Experimental results show that LLMEffiChecker can increase on average LLMs' response latency and energy consumption by 325% to 3,244% and 344% to 3,616%, respectively, by perturbing just one character or token in the input sentence. Our case study shows that inputs generated by LLMEffiChecker significantly affect the battery power in real-world mobile devices (i.e., drain more than 30 times battery power than normal inputs).|||Article||||
WEB OF SCIENCE|Viggiato, Markos; Paas, Dale; Buzon, Chris; Bezemer, Cor-Paul|||Identifying Similar Test Cases That Are Specified in Natural Language|2023|IEEE TRANSACTIONS ON SOFTWARE ENGINEERING|49|3||1027|1043|||10.1109/TSE.2022.3170272||Software testing is still a manual process in many industries, despite the recent improvements in automated testing techniques. As a result, test cases (which consist of one or more test steps that need to be executed manually by the tester) are often specified in natural language by different employees and many redundant test cases might exist in the test suite. This increases the (already high) cost of test execution. Manually identifying similar test cases is a time-consuming and error-prone task. Therefore, in this paper, we propose an unsupervised approach to identify similar test cases. Our approach uses a combination of text embedding, text similarity and clustering techniques to identify similar test cases. We evaluate five different text embedding techniques, two text similarity metrics, and two clustering techniques to cluster similar test steps and three techniques to identify similar test cases from the test step clusters. Through an evaluation in an industrial setting, we showed that our approach achieves a high performance to cluster test steps (an F-score of 87.39%) and identify similar test cases (an F-score of 86.13%). Furthermore, a validation with developers indicates several different practical usages of our approach (such as identifying redundant test cases), which help to reduce the testing manual effort and time.|||Article||||
WEB OF SCIENCE|Ma, Wei; Papadakis, Mike; Tsakmalis, Anestis; Cordy, Maxime; Le Traon, Yves|||Test Selection for Deep Learning Systems|2021|ACM TRANSACTIONS ON SOFTWARE ENGINEERING AND METHODOLOGY|30|2|13|||||10.1145/3417330||Testing of deep learning models is challenging due to the excessive number and complexity of the computations involved. As a result, test data selection is performed manually and in an ad hoc way. This raises the question of how we can automatically select candidate data to test deep learning models. Recent research has focused on defining metrics to measure the thoroughness of a test suite and to rely on such metrics to guide the generation of new tests. However, the problem of selecting/prioritising test inputs (e.g., to be labelled manually by humans) remains open. In this article, we perform an in-depth empirical comparison of a set of test selection metrics based on the notion of model uncertainty (model confidence on specific inputs). Intuitively, the more uncertain we are about a candidate sample, the more likely it is that this sample triggers a misclassification. Similarly, we hypothesise that the samples for which we are the most uncertain are the most informative and should be used in priority to improve the model by retraining. We evaluate these metrics on five models and three widely used image classification problems involving real and artificial (adversarial) data produced by five generation algorithms. We show that uncertainty-based metrics have a strong ability to identify misclassified inputs, being three times stronger than surprise adequacy and outperforming coverage-related metrics. We also show that these metrics lead to faster improvement in classification accuracy during retraining: up to two times faster than random selection and other state-of-the-art metrics on all models we considered.|||Article||||
WEB OF SCIENCE||||AI Testing Innovation|2023|||||||||||This transformative project addresses the theme **Artificial Intelligence Assurance,** providing game-changing support for more robust testing of Artificial Intelligence (AI) as well as a solid base to audit the testing and suitability of an AI system for an application. There are significant challenges in testing AI systems, especially those involved in Machine Learning (ML), Deep Learning and adaptive systems. These problems are highlighted in the excellent book Artificial intelligence and software testing by Leon-Smith et al (2022 -- published by BCS), and further captured in the Systematic literature review on software quality for AI-based software by Gezici & Tarhan (2022 - Empirical Software Engineering vol27:66). This is not to say that AI is not tested -- developing new AI algorithms would go through testing and refinement to show it 'performs better' (quicker, more efficiently) that other algorithms. But AI is different to normal software in that it can adapt and change and come up with new answers, making it difficult to robustly test, such as examining 'exceptions' and checking for errors -- which are key if we want to use AI on safety critical systems. We address these testing weaknesses by capturing the Affordances -- these are all the different attributes, qualities, or property of an object that defines its possible uses in a context. So Affordance Modelling (AM), in AI objects would cover all the training data used, the algorithms and base algorithms, any limitation or biases, any testing applications. We put these together into a Bound of Applicability (BoA) to show where we have confidence on the boundary where AI objects can or can't be used. We also do wider/system testing using Temporal Scenario testing -- effectively exploring how the AI use will change over time performing measures of exception testing. These extra testing and assurance supports are game-changing providing much needed rigorous testing for safety/mission critical AI systems. The project also provides tools for AI assurance and auditing. We use Metadata, which is effectively the data/information **about** the AI Objects (the AM, BoA etc). We expand the Learning Object Metadata (LOM) IEEE standard into LOM-AI. We also develop software tools to help capture all the AM, BoA and scenario testing data into LOM-AI records into a repository, providing a standard auditable database of the testing and suitability of AI objects for an application. This is transformative in providing robust semi-automated tools for AI assurance.|||Awarded Grant||||
WEB OF SCIENCE|Lonnfaelt, Albin; Tu, Viktor; Gay, Gregory; Singh, Animesh; Tahvili, Sahar|||An intelligent test management system for optimizing decision making during software testing|2025|JOURNAL OF SYSTEMS AND SOFTWARE|219||112202|||||10.1016/j.jss.2024.112202||To ensure the proper testing of any software product, it is imperative to cover various functional and nonfunctional requirements at different testing levels (e.g., unit or integration testing). Ensuring appropriate testing requires making a series of decisions-e.g., assigning features to distinct Continuous Integration (CI) configurations or determining which test specifications to automate. Such decisions are generally made manually and require in-depth domain knowledge. This study introduces, implements, and evaluates ITMOS (Intelligent Test Management Optimization System), an intelligent test management system designed to optimize decision-making during the software testing process. ITMOS efficiently processes new requirements presented in natural language, segregating each requirement into appropriate CI configurations based on predefined quality criteria. Additionally, ITMOS has the capability to suggest a set of test specifications for test automation. The feasibility and potential applicability of the proposed solution were empirically evaluated in an industrial telecommunications project at Ericsson. In this context, ITMOS achieved accurate results for decision-making tasks, exceeding the requirements set by domain experts.|||Article||||
WEB OF SCIENCE|Csuvik, Viktor|||The Role of Software Testing and Machine Learning in Automated Program Repair|2024||||||||||||||Dissertation/Thesis||||
WEB OF SCIENCE|Liu, Shuang; Dou, Shujie; Chen, Junjie; Zhang, Zhirun; Lu, Ye|||Differential Testing of Machine Translators Based on Compositional Semantics|2023|IEEE TRANSACTIONS ON SOFTWARE ENGINEERING|49|12||5046|5059|||10.1109/TSE.2023.3323969||Powered by the advances of deep neural networks, machine translation software has achieved rapid progresses recently. Machine translators are widely adopted in people's daily lives, e.g., for information consumption, medical consumption and online shopping. However, machine translators are far from robust, and may produce wrong translations, which could potentially cause misunderstandings or even serious consequences. It is thus critical to detect errors in machine translators, and provide informative feedback for developers. In this work, we adopt the differential testing method to test machine translators. In particular, we use mature commercial translators as reference machine translation engines. Based on the principle of compositionality, which specifies that the meaning of a complex expression is determined by the meanings of its constituent expressions and the syntactic rules used to combine them, we design the oracle which conducts similarity comparison guided by syntactic structure and semantic encoding. In particular, we employ the constituency parsing to obtain the part-whole structure relation between a sentence and one of its component. Then we compute the semantic similarity of each sentence part with pre-trained language model and expert knowledge. We implement our approach into a tool named DCS, conduct experiments on three popular machine translators, i.e., Google translate, Baidu translate and Microsoft Bing translate, and compare DCS with two state-of-the-art approaches, i.e., CIT and CAT. The experiment results show that DCS achieves 8.6% and 35.4% higher precision, respectively. Moreover, the errors reported by DCS have the lowest redundancy in terms of the duplicated error locations in the source sentence. DCS can be used in complement with existing approaches and achieve higher detection precision. It also shows comparable efficiency with state-of-the-art approaches.|||Article||||
WEB OF SCIENCE|Moghadam, Mahshid Helali; Saadatmand, Mehrdad; Borg, Markus; Bohlin, Markus; Lisper, Bjorn|||An autonomous performance testing framework using self-adaptive fuzzy reinforcement learning|2022|SOFTWARE QUALITY JOURNAL|30|1||127|159|||10.1007/s11219-020-09532-z||Test automation brings the potential to reduce costs and human effort, but several aspects of software testing remain challenging to automate. One such example is automated performance testing to find performance breaking points. Current approaches to tackle automated generation of performance test cases mainly involve using source code or system model analysis or use-case-based techniques. However, source code and system models might not always be available at testing time. On the other hand, if the optimal performance testing policy for the intended objective in a testing process instead could be learned by the testing system, then test automation without advanced performance models could be possible. Furthermore, the learned policy could later be reused for similar software systems under test, thus leading to higher test efficiency. We propose SaFReL, a self-adaptive fuzzy reinforcement learning-based performance testing framework. SaFReL learns the optimal policy to generate performance test cases through an initial learning phase, then reuses it during a transfer learning phase, while keeping the learning running and updating the policy in the long term. Through multiple experiments in a simulated performance testing setup, we demonstrate that our approach generates the target performance test cases for different programs more efficiently than a typical testing process and performs adaptively without access to source code and performance models.|||Article||||
WEB OF SCIENCE|Cerf, Vinton G.|||Building Safer and Interoperable AI systems|2025|COMMUNICATIONS OF THE ACM|68|2||5|5|||10.1145/3709744|||||Editorial Material||||
WEB OF SCIENCE|Oz, Mert; Kaya, Caner; Olmezogullari, Erdi; Aktas, Mehmet S.|||On the Use of Generative Deep Learning Approaches for Generating Hidden Test Scripts|2021|INTERNATIONAL JOURNAL OF SOFTWARE ENGINEERING AND KNOWLEDGE ENGINEERING|31|10||1447|1468|||10.1142/S0218194021500480||With the advent of web 2.0, web application architectures have been evolved, and their complexity has grown enormously. Due to the complexity, testing of web applications is getting time-consuming and intensive process. In today's web applications, users can achieve the same goal by performing different actions. To ensure that the entire system is safe and robust, developers try to test all possible user action sequences in the testing phase. Since the space of all the possibilities is enormous, covering all user action sequences can be impossible. To automate the test script generation task and reduce the space of the possible user action sequences, we propose a novel method based on long short-term memory (LSTM) network for generating test scripts from user clickstream data. The experiment results clearly show that generated hidden test sequences are user-like sequences, and the process of generating test scripts with the proposed model is less time-consuming than writing them manually.|||Article||||
WEB OF SCIENCE|Henriques, Cláudio Filipe Carvalho|||Modelos de Maturidade de Testes de Software e o Futuro Utilizando Machine Learning e Inteligência ArtificialSoftware Testing Maturity Models and Future Using Machine Learning and Artificial Intelligence|2021||||||||||||||Dissertation/Thesis||||
WEB OF SCIENCE|Cao, Jialun|||Towards Automatic Testing and Fault Localization in Natural Language Processing Systems|2024||||||||||||||Dissertation/Thesis||||
WEB OF SCIENCE|Khan, Bilal; Naseem, Rashid; Alam, Iftikhar; Khan, Inayat; Alasmary, Hisham; Rahman, Taj|||Analysis of Tree-Family Machine Learning Techniques for Risk Prediction in Software Requirements|2022|IEEE ACCESS|10|||98220|98231|||10.1109/ACCESS.2022.3206382||Risk prediction is the most sensitive and critical activity in the Software Development Life Cycle (SDLC). It might determine whether the project succeeds or fails. To increase the success probability of a software project, the risk should be predicted at the early stages. This study proposed a novel model based on the requirement risk dataset to predict software requirement risks using Tree-Family -Machine-Learning (TF-ML) approaches. Moreover, the proposed model is compared with the state-of-the-art models to determine the best-suited methodology based on the nature of the dataset. These strategies are assessed and evaluated using a variety of metrics. The findings of this study may be reused as a baseline for future studies and research, allowing the results of any proposed approach, model, or framework to be benchmarked and easily checked.|||Article||||
WEB OF SCIENCE|Abrecht, Stephanie; Gauerhof, Lydia; Gladisch, Christoph; Groh, Konrad; Heinzemann, Christian; Woehrle, Matthias|||Testing Deep Learning-based Visual Perception for Automated Driving|2021|ACM TRANSACTIONS ON CYBER-PHYSICAL SYSTEMS|5|4|37|||||10.1145/3450356||Due to the impressive performance of deep neural networks (DNNs) for visual perception, there is an increased demand for their use in automated systems. However, to use deep neural networks in practice, novel approaches are needed, e.g., for testing. In this work, we focus on the question of how to test deep learning-based visual perception functions for automated driving. Classical approaches for testing are not sufficient: A purely statistical approach based on a dataset split is not enough, as testing needs to address various purposes and not only average case performance. Additionally, a complete specification is elusive due to the complexity of the perception task in the open context of automated driving. In this article, we review and discuss existing work on testing DNNs for visual perception with a special focus on automated driving for test input and test oracle generation as well as test adequacy. We conclude that testing of DNNs in this domain requires several diverse test sets. We show how such tests sets can be constructed based on the presented approaches addressing different purposes based on the presented methods and identify open research questions.|||Article||||
WEB OF SCIENCE|Bai, Xue; Zhou, Hua; Yang, Hongji; Wang, Dong|||Connecting historical changes for cross-version software defect prediction|2020|INTERNATIONAL JOURNAL OF COMPUTER APPLICATIONS IN TECHNOLOGY|63|4||371|383|||||In the whole software life cycle, software defects are inevitable and increase the cost of software development and evolution. Cross-Version Software Defect Prediction (CVSDP) aims at learning the defect patterns from the historical data of previous software versions to distinguish buggy software modules from clean ones. In CVSDP, metrics are intrinsic properties associated with the external manifestation of defects. However, traditional software defect measures ignore the sequential information of changes during software evolution process which may play a crucial role in CVSDP. Therefore, researchers tried to connect traditional metrics across versions as a new kind of evolution metrics. This study proposes a new way to connect historical sequence of metrics based on change sequence named HCSM and designs a novel deep learning algorithm GDNN as a classifier to process it. Compared to the traditional metrics approaches and other relevant approaches, the proposed approach fits in projects with stable and orderly defect control trend.|||Article||||
WEB OF SCIENCE|Zhao, Yin; Fan, Xingyuan; Dong, Jun; Zhou, Mi; Zhou, Xiaodong|||Automatic generation of test cases for intelligent measurement terminal applications based on natural language processing|2025|JOURNAL OF COMPUTATIONAL METHODS IN SCIENCES AND ENGINEERING|25|3||2300|2309|||10.1177/14727978241312993||Intelligent Measurement Terminals (IMTs) are pivotal components within the power grid measurement system. Conducting thorough testing of IMT applications before their deployment is a critical step in ensuring the safety of the power grid. To enhance the efficiency of application testing, this paper proposes an automated test case generation method for IMT applications based on natural language processing (NLP) techniques. First, the hierarchical relationships among various application functions are represented as a directed graph based on the Chinese requirements specifications of the application under test. Subsequently, the action flow of each function is analyzed through a four-step process: Chinese word segmentation, part-of-speech tagging, named entity recognition, and syntactic structure analysis. Finally, black-box function test cases are automatically generated according to the directed graph and the analyzed action flow. The proposed method is tested on two requirements specifications for IMT applications. The experimental results show that the proposed method achieves comparable test coverage and success rates to manual test case writing while demonstrating much less time costs.|||Article||||
WEB OF SCIENCE|Wu, Cheng-Yang; Huang, Chin-Yu|||A Study of Incorporation of Deep Learning Into Software Reliability Modeling and Assessment|2021|IEEE TRANSACTIONS ON RELIABILITY|70|4||1621|1640|||10.1109/TR.2021.3105531||Software is widely used in many application domains. The most popular software are used by millions every day. How to accurately predict and assess the reliability of developed software is becoming increasingly important for project managers and developers. Previous studies have primarily used the software reliability growth model (SRGM) to evaluate and predict software reliability, but prediction results cannot be accurate at particular times or in particular situations. One of the main reasons is that simplified assumptions and abstractions are usually made to simplify the problem when developing SRGMs. Selecting an appropriate SRGM should depend on the key characteristics of the software project. In this article, we propose a deep learning-based approach for software reliability prediction and assessment. Specifically, we clearly demonstrate how to derive mathematical expressions from the computational methods of deep learning models and how to determine the correlation between them and the mathematical formula of SRGMs, and then, we use the back-propagation algorithm to obtain the SRGM parameters. Furthermore, we further integrate some deep learning-based SRGMs and also propose a method for the weighted assignment of combinations. Three real open source software failure datasets are used to evaluate the performance of the proposed models compared to selected SRGMs. The experimental results reveal that our proposed deep learning-based models and their combinations perform better than several classical SRGMs.|||Article||||
WEB OF SCIENCE|An, Jaehyung; Mikhaylov, Alexey; Kim, Keunwoo|||Machine Learning Approach in Heterogeneous Group of Algorithms for Transport Safety-Critical System|2020|APPLIED SCIENCES-BASEL|10|8|2670|||||10.3390/app10082670||This article presents a machine learning approach in a heterogeneous group of algorithms in a transport type model for the optimal distribution of tasks in safety-critical systems (SCS). Applied systems in the working area identify the determination of their parameters. Accordingly, in this article, machine learning models are implemented on various subsets of our transformed data and repeatedly calculated the bounds for 90 percent tolerance intervals, each time noting whether or not they contained the actual value of X. This approach considers the features of algorithms for solving such important classes of problem management as the allocation of limited resources in multi-agent SCS and their most important properties. Modeling for the error was normally distributed. The results are obtained, including the situation requiring solutions, recorded and a sample is made out of the observations. This paper summarizes the literature review on the machine learning approach into new implication research. The empirical research shows the effect of the optimal algorithm for transport safety-critical systems.|||Article||||
WEB OF SCIENCE|Mori, Ken T.; Liang, Xu; Elster, Lukas; Peters, Steven|||The Inadequacy of Discrete Scenarios in Assessing Deep Neural Networks|2022|IEEE ACCESS|10|||118236|118242|||10.1109/ACCESS.2022.3220904||Many recent approaches for automated driving (AD) functions currently include components relying on deep neural networks (DNNs). One approach in order to test AD functions is the scenario-based approach. This work formalizes and evaluates the parameter discretization process required in order to yield concrete scenarios for which an AD function can be tested. Using a common perception algorithm for camera images, a simulation case study is conducted for a simple static scenario containing one other vehicle. The results are analyzed with methods akin to those applied in the domain of computational fluid dynamics (CFD). The performance of the perception algorithm shows strong fluctuations even for small input changes and displays unpredictable outliers even at very small discretization steps. The convergence criteria as known from CFD fail, meaning that no parametrization is found which is sufficient for the validation of the perception component. Indeed, the results do not indicate consistent improvement with a finer discretization. These results agree well with theoretical attributes known for existing neural networks. However, the impact appears to be large even for the most basic scenario without malicious input. This indicates the necessity of directing more attention towards the parameter discretization process of the scenario-based testing approach to enable the safety argumentation of AD functions.|||Article||||
WEB OF SCIENCE|Al-Masri, Ohood; Al-Sorori, Wedad|||Object-Oriented Test Case Generation Using Teaching Learning-Based Optimization (TLBO) Algorithm|2022|IEEE ACCESS|10|||110879|110888|||10.1109/ACCESS.2022.3214841||Researchers are currently seeking effective methods for automated software testing to reduce time, avoid test case redundancy, and create comprehensive test cases to cover (paths, benches, conditions, and statements). Generating a minimum number of test cases and covering all code paths is challenging in automated test case generation. Therefore, the use of optimization algorithms has become a popular trend for generating test cases to achieve many goals. In this study, we used a teaching-learning-based optimization algorithm to generate the minimum number of test cases. We compared our results with those of other state-of-the-art methods based on the path coverage for ten Java programs. The motive for using this algorithm is to optimize the number of test cases that cover all code paths in the unit test. The results emphasize that the proposed algorithm generates the minimum number of test cases and covers all paths in the code at a full-coverage rate.|||Article||||
WEB OF SCIENCE|Wang, Jiannan; Pham, Hung Viet; Li, Qi; Tan, Lin; Guo, Yu; Aziz, Adnan; Meijer, Erik|||D3: Differential Testing of Distributed Deep Learning With Model Generation|2025|IEEE TRANSACTIONS ON SOFTWARE ENGINEERING|51|1||38|52|||10.1109/TSE.2024.3461657||Deep Learning (DL) techniques have been widely deployed in many application domains. The growth of DL models' size and complexity demands distributed training of DL models. Since DL training is complex, software implementing distributed DL training is error-prone. Thus, it is crucial to test distributed deep learning software to improve its reliability and quality. To address this issue, we propose a differential testing technique-D-3, which leverages a distributed equivalence rule that we create to test distributed deep learning software. The rationale is that the same model trained with the same model input under different distributed settings should produce equivalent prediction output within certain thresholds. The different output indicates potential bugs in the distributed deep learning software. D-3 automatically generates a diverse set of distributed settings, DL models, and model input to test distributed deep learning software. Our evaluation on two of the most popular DL libraries, i.e., PyTorch and TensorFlow, shows that D-3 detects 21 bugs, including 12 previously unknown bugs.|||Article||||
WEB OF SCIENCE|Panyam, Sriram; Gujar, Praveen|||How AI Agents Are Transforming Software Engineering and the Future of Product Development|2025|COMPUTER|58|5||71|77|||10.1109/MC.2024.3488378||Artificial Intelligence (AI) agents are revolutionizing software engineering, boosting productivity while creating new demands for skilled engineers and raising critical ethical challenges.|||Editorial Material||||
WEB OF SCIENCE|Vitorino, Joao; Dias, Tiago; Fonseca, Tiago; Maia, Eva; Praca, Isabel|||Constrained adversarial learning for automated software testing: a literature review|2025|DISCOVER APPLIED SCIENCES|7|6|547|||||10.1007/s42452-025-07073-3||It is imperative to safeguard computer applications and information systems against the growing number of cyber-attacks. Automated software testing can be a promising solution to quickly analyze many lines of code and detect vulnerabilities and possible attack vectors by generating function-specific testing data. This process draws similarities to the constrained adversarial examples generated by adversarial learning methods, so there could be significant benefits to the integration of these methods in testing tools. Therefore, this literature review is focused on the current state-of-the-art of constrained data generation methods applied for adversarial learning and software testing, aiming to guide researchers and developers to enhance software testing tools with adversarial testing methods and improve the resilience and robustness of their information systems. The found constrained data generation applications were systematized, and the advantages and limitations of approaches specific for white-box, grey-box, and black-box testing were analyzed, identifying research gaps and opportunities to improve automated testing tools with data generated by adversarial attacks.|||Review||||
WEB OF SCIENCE|Liu, Haiyi; Liu, Shaoying; Wen, Chenglong; Wong, W. Eric|||TBEM: Testing-Based GPU-Memory Consumption Estimation for Deep Learning|2022|IEEE ACCESS|10|||39674|39680|||10.1109/ACCESS.2022.3164510||Deep Learning (DL) has been successfully implemented and deployed to various software service applications. During the training process of DL, a large amount of GPU computing resources is required, but it is difficult for developers to accurately calculate the GPU resources that the model may consume before running, which brings great inconvenience to the development of DL systems. Especially in today's cloud-based model training. Therefore, it is very important to estimate the GPU memory resources that the DL model may use in a certain computing framework. Existing work has focused on static analysis methods to assess GPU memory consumption, highly coupled with the framework, and lack of research on low-coupled GPU memory consumption of the framework. In this article, we propose TBEM, which is a test-based method for estimating the memory usage of the DL model. First, TBEM generates enough DL models using an orthogonal array testing strategy and a classical neural network design pattern. Then, TBEM generates DL model tested in a real environment to obtain the real-time GPU memory usage values corresponding to the model. After obtaining the data of different models and corresponding GPU usage values, the data is analyzed by regression.|||Article||||
WEB OF SCIENCE|Blasi, Arianna; Gorla, Alessandra; Ernst, Michael D.; Pezze, Mauro; Carzaniga, Antonio|||MeMo: Automatically identifying metamorphic relations in Javadoc comments for test automation|2021|JOURNAL OF SYSTEMS AND SOFTWARE|181||111041|||||10.1016/j.jss.2021.111041||Software testing depends on effective oracles. Implicit oracles, such as checks for program crashes, are widely applicable but narrow in scope. Oracles based on formal specifications can reveal application-specific failures, but specifications are expensive to obtain and maintain. Metamorphic oracles are somewhere in-between. They test equivalence among different procedures to detect semantic failures. Until now, the identification of metamorphic relations has been a manual and expensive process, except for few specific domains where automation is possible. We present MeMo, a technique and a tool to automatically derive metamorphic equivalence relations from natural language documentation, and we use such metamorphic relations as oracles in automatically generated test cases. Our experimental evaluation demonstrates that 1) MeMo can effectively and precisely infer equivalence metamorphic relations, 2) MeMo complements existing state-of-the-art techniques that are based on dynamic program analysis, and 3) metamorphic relations discovered with MeMo effectively detect defects when used as test oracles in automatically-generated or manually-written test cases. (C) 2021 The Author(s). Published by Elsevier Inc.|||Article||||
WEB OF SCIENCE|Alzahrani, Musaad|||Using Machine Learning Techniques to Predict Bugs in Classes: An Empirical Study|2022|INTERNATIONAL JOURNAL OF ADVANCED COMPUTER SCIENCE AND APPLICATIONS|13|5||891|897|||||Software bug prediction is an important step in the software development life cycle that aims to identify bug-prone software modules. Identification of such modules can reduce the overall cost and effort of the software testing phase. Many approaches have been introduced in the literature that have investigated the performance of machine learning techniques when used in software bug prediction activities. However, in most of these approaches, the empirical investigations were conducted using bug datasets that are small or have erroneous data leading to results with limited generality. Therefore, this study empirically investigates the performance of 8 commonly used machine learning techniques based on the Unified Bug Dataset which is a large and clean bug dataset that was published recently. A set of experiments are conducted to construct bug prediction models using the considered machine learning techniques. Each constructed model is evaluated using three performance metrics: accuracy, area under the curve, and F-measure. The results of the experiments show that logistic regression has better performance for bug prediction compared to other considered techniques.|||Article||||
WEB OF SCIENCE|Alazzam, Iyad; Aleroud, Ahmed; Al Latifah, Zainab; Karabatis, George|||Automatic Bug Triage in Software Systems Using Graph Neighborhood Relations for Feature Augmentation|2020|IEEE TRANSACTIONS ON COMPUTATIONAL SOCIAL SYSTEMS|7|5||1288|1303|||10.1109/TCSS.2020.3017501||Bug triaging is the process of prioritizing bugs based on their severity, frequency, and risk in order to be assigned to appropriate developers for validation and resolution. This article introduces a graph-based feature augmentation approach for enhancing bug triaging systems using machine learning. A new feature augmentation approach that utilizes graph partitioning based on neighborhood overlap is proposed. Neighborhood overlap is a quite effective approach for discovering relationships in social graphs. Terms of bug summaries are represented as nodes in a graph, which is then partitioned into clusters of terms. Terms in strong clusters are augmented to the original feature vectors of bug summaries based on the similarity between the terms in each cluster and a bug summary. We employed other techniques such as term frequency, term correlation, and topic modeling to identify latent terms and augment them to the original feature vectors of bug summaries. Consequently, we utilized frequency, correlation, and neighborhood overlap techniques to create another feature augmentation approach that enriches the feature vectors of bug summaries to use them for bug triaging. The new modified vectors are used to classify bug reports into different priorities. Bug Triage in this context is to correctly recognize the priority of new bugs. Several classification algorithms are tested using the proposed methods. Experimental results on a data set with Eclipse bug reports extracted from the Bugzilla tracking system have shown that our approach outperformed the existing bug triaging systems including modern techniques that utilize deep learning.|||Article||||
WEB OF SCIENCE|Conrad, Stefan; Auth, Philipp; Masselter, Tom; Speck, Thomas|||Lowering the Entrance Hurdle for Lab Automation: An Artificial Intelligence-Supported, Interactive Robotic Arm for Automated, Repeated Testing Procedures|2025|ADVANCED INTELLIGENT SYSTEMS||||||||10.1002/aisy.202401086||Laboratory automation is crucial for improving efficiency and enhancing reproducibility in scientific workflows. However, industrial solutions mostly do not fit the needs of scientific institutions, such as cost efficiency, customizability, and flexibility in fast iteration cycles. This study presents a laboratory automation system that integrates affordable robotics and artificial intelligence (AI)-driven functionalities in a modular architecture to address key challenges in research environments. The system uses a robotic arm and a large language model (LLM) as a lab assistant, enabling natural language interaction and task orchestration. In contrast to fully autonomous systems, this approach emphasizes a collaborative human-in-the-loop model, ensuring adaptability and reducing reliance on artificial intelligence for task planning. Key innovations include meta-tools for dynamic task recording and playback, low-level information management to reduce cognitive load on the LLM, and AI-assisted data reading for real-time measurement extraction. The system's ability to automate complex workflows is validated in three experimental scenarios, involving sample preparation, error handling, and multi-step measurements. The system demonstrates the ability to perform tasks with minimal user input while maintaining flexibility and adaptability to changing experimental conditions. The findings pave the way for the future of laboratory automation, where human and AI-driven systems work seamlessly together in optimized scientific workflows.|||Article; Early Access||||
WEB OF SCIENCE|Jurkiewicz, Piotr|||flow-models 2.2: Efficient and parallel elephant flow modeling with machine learning|2024|SOFTWAREX|28||101920|||||10.1016/j.softx.2024.101920||This article introduces the latest version of the flow-models framework for IP network flow analysis. Key improvements include support for Dask to enable parallel computing, dataset reduction techniques for efficient training, and new modules for entropy analysis and granular flow table simulations. The codebase has been refined, with improved documentation and the incorporation of automated testing via ruff. The framework is now compatible with forthcoming releases of Python and NumPy, making it a useful resource for researchers and professionals involved in network flow analysis and machine learning-driven traffic classification.|||Article||||
WEB OF SCIENCE|Borana, Kamal; Sharma, Meena; Abhyankar, Deepak|||A Novel Software Quality Characteristic Recommendation Model to Handle the Dynamic Requirements of Software Projects that Improves Service Quality and Cost|2023|INTERNATIONAL JOURNAL OF ADVANCED COMPUTER SCIENCE AND APPLICATIONS|14|7||561|569|||||The software is created and constructed to address particular issues in the applied field. In this context, there is a need to be aware of the crucial characteristics to assess the quality of software. But not all software requires checking all the quality-of-service parameters, resulting in effort loss and time consumption. Therefore, it is required to develop software quality characteristics recommendation model to address and resolve the issue. The proposed work involved in this paper can be subdivided into three main parts (1) a review of popular software quality models and their comparison to create a complete set of predictable, and (2) the design of an ML-based recommendation model for recommending the software quality model and software quality characteristics (3) performance analysis. The proposed recommendation system utilizes the different software quality of service attributes as well as the software attributes where these models are suitably applied to satisfy the demands. Profiling of applications and their essential requirements have been performed Based on the different quality of service parameters and the requirements of applications. These profiles are learned by machine learning algorithms for distinguishing the application-based requirement and recommending the essential attributes. The implementation of the proposed technique has been done using Python technology. The simulation aims to demonstrate how to minimize the cost of software testing and improve time and accuracy by utilizing the appropriate quality matrix. Finally, a conclusion has been drawn and the future extension of the proposed model has been reported.|||Article||||
WEB OF SCIENCE||||SBIR Phase II: Artificial Intelligence Powered Software Testing|2023|||||||||||The broader/commercial impact of the Small Business Innovation Research (SBIR) Phase II project reduce the cost and speed of software quality assurance (SQA) end-to-end testing by enabling artificial intelligence (AI) to automate tests without the need for coding or highly experienced coders. As innovative high-growth Software as a Service (SaaS) companies go to market faster with more confidence and fewer software defects, industries will benefit economically by saving time and money. This SBIR Phase II project will build an AI solution which, although used by less experienced software engineers, will allow software companies to identify software defects with minimal user interactions. The real-time and guided process gathers information directly from the web browsers, handling traditional and unresolved problems with test automation such as software test design, automation, coverage, and maintenance. The AI solution will make SQA highly efficient by performing two major tasks: simulating real-time users' exploration of web applications and identifying unexpected behaviors. The architecture enables AI agents to self-learn and interact with the application, improving on each observation. The AI learning cycle implements thorough communication within the system as it communicates requests to apply specific actions based on its own knowledge analyzing the resulting effect. Phase I research proved that the architecture can be upgraded to a commercial version, providing value to customers looking to improve software quality in their products and go to market faster. The anticipated technical results in Phase II will enhance the categorization of unexpected software behaviors, optimize the data analysis time, and reduce the learning cycle. This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.|||Awarded Grant||||
WEB OF SCIENCE|Ma, Dongning; Rosing, Tajana Simunic; Jiao, Xun|||Testing and Enhancing Adversarial Robustness of Hyperdimensional Computing|2023|IEEE TRANSACTIONS ON COMPUTER-AIDED DESIGN OF INTEGRATED CIRCUITS AND SYSTEMS|42|11||4052|4064|||10.1109/TCAD.2023.3263120||Brain-inspired hyperdimensional computing (HDC), also known as vector symbolic architecture (VSA), is an emerging non-von Neumann computing scheme that imitates human brain functions to process information or perform learning tasks using abstract and high-dimensional patterns. Compared with deep neural networks (DNNs), HDC shows advantages, such as compact model size, energy efficiency, and few-shot learning. Despite of those advantages, one under-investigated area of HDC is the adversarial robustness; existing works have shown that HDC is vulnerable to adversarial attacks where attackers can add minor perturbations onto the original inputs to fool HDC models, producing wrong predictions. In this article, we systematically study the adversarial robustness of HDC by developing a systematic approach to test and enhance the robustness of HDC against adversarial attacks with two main components: 1) TestHD, which is a highly automated testing tool that can generate high-quality adversarial data for a given HDC model and 2) GuardHD, which utilizes the adversarial data generated by TestHD to enhance the adversarial robustness of HDC models. The core idea of TestHD is built on top of fuzz testing method. We customize the fuzzing approach by proposing a similarity-based coverage metric to guide TestHD to continuously mutate original inputs to generate new inputs that can trigger incorrect behaviors of HDC model. Thanks to the use of differential testing, TestHD does not require knowing the labels of the samples beforehand. For enhancing the adversarial robustness, we design, implement, and evaluate GuardHD to defend HDC models against adversarial data. The core idea of GuardHD is an adversarial detector which can be trained by TestHD-generated adversarial samples. During inference, once an adversarial sample is detected, GuardHD will override the prediction result with an invalid signal. We evaluate the proposed methods on four datasets and five adversarial attack scenarios with six adversarial generation strategies and two defense mechanisms, and compare the performance correspondingly. GuardHD is able to differentiate between benign and adversarial inputs with over 90% accuracy, which is up to 55% higher than adversarial training-based baselines. To the best of our knowledge, this article presents the first comprehensive effort in systematically testing and enhancing the robustness against adversarial data of this emerging brain-inspired computational model.|||Article||||
WEB OF SCIENCE|Singh, Shikhar|||Exploring Synergies between Program Synthesis and Machine Learning|2022||||||||||||||Dissertation/Thesis||||
WEB OF SCIENCE|Pontillo, Valeria; Palomba, Fabio; Ferrucci, Filomena|||Static test flakiness prediction: How Far Can We Go?|2022|EMPIRICAL SOFTWARE ENGINEERING|27|7|187|||||10.1007/s10664-022-10227-1||Test flakiness is a phenomenon occurring when a test case is non-deterministic and exhibits both a passing and failing behavior when run against the same code. Over the last years, the problem has been closely investigated by researchers and practitioners, who all have shown its relevance in practice. The software engineering research community has been working toward defining approaches for detecting and addressing test flakiness. Despite being quite accurate, most of these approaches rely on expensive dynamic steps, e.g., the computation of code coverage information. Consequently, they might suffer from scalability issues that possibly preclude their practical use. This limitation has been recently targeted through machine learning solutions that could predict the flakiness of tests using various features, like source code vocabulary or a mixture of static and dynamic metrics computed on individual snapshots of the system. In this paper, we aim to perform a step forward and predict test flakiness only using static metrics. We propose a large-scale experiment on 70 Java projects coming from the iDFlakies and FlakeFlagger datasets. First, we statistically assess the differences between flaky and non-flaky tests in terms of 25 test and production code metrics and smells, analyzing both their individual and combined effects. Based on the results achieved, we experiment with a machine learning approach that predicts test flakiness solely based on static features, comparing it with two state-of-the-art approaches. The key results of the study show that the static approach has performance comparable to those of the baselines. In addition, we found that the characteristics of the production code might impact the performance of the flaky test prediction models.|||Article||||
WEB OF SCIENCE|Guglielmi, Emanuela; Rosa, Giovanni; Scalabrino, Simone; Bavota, Gabriele; Oliveto, Rocco|||Help Them Understand: Testing and Improving Voice User Interfaces|2024|ACM TRANSACTIONS ON SOFTWARE ENGINEERING AND METHODOLOGY|33|6|143|||||10.1145/3654438||Voice-based virtual assistants are becoming increasingly popular. Such systems provide frameworks to developers for building custom apps. End-users can interact with such apps through a Voice User Interface (VUI), which allows the user to use natural language commands to perform actions. Testing such apps is not trivial: The same command can be expressed in different semantically equivalent ways. In this article, we introduce VUI-UPSET, an approach that adapts chatbot-testing approaches to VUI-testing. We conducted an empirical study to understand how VUI-UPSET compares to two state-of-the-art approaches (i.e., a chatbot testing technique and ChatGPT) in terms of (i) correctness of the generated paraphrases, and (ii) capability of revealing bugs. To this aim, we analyzed 14,898 generated paraphrases for 40 Alexa Skills. Our results show that VUI-UPSET generates more bug-revealing paraphrases than the two baselines with, however, ChatGPT being the approach generating the highest percentage of correct paraphrases. We also tried to use the generated paraphrases to improve the skills. We tried to include in the voice interaction models of the skills (i) only the bug-revealing paraphrases, (ii) all the valid paraphrases. We observed that including only bug-revealing paraphrases is sometimes not sufficient to make all the tests pass.|||Article||||
WEB OF SCIENCE|Attaoui, Mohammed Oualid; Pastore, Fabrizio; Briand, Lionel C.|||Search-Based DNN Testing and Retraining With GAN-Enhanced Simulations|2025|IEEE TRANSACTIONS ON SOFTWARE ENGINEERING|51|4||1086|1103|||10.1109/TSE.2025.3540549||In safety-critical systems (e.g., autonomous vehicles and robots), Deep Neural Networks (DNNs) are becoming a key component for computer vision tasks, particularly semantic segmentation. Further, since DNN behavior cannot be assessed through code inspection and analysis, test automation has become an essential activity to gain confidence in the reliability of DNNs. Unfortunately, state-of-the-art automated testing solutions largely rely on simulators, whose fidelity is always imperfect, thus affecting the validity of test results. To address such limitations, we propose to combine meta-heuristic search, used to explore the input space using simulators, with Generative Adversarial Networks (GANs), to transform the data generated by simulators into realistic input images. Such images can be used both to assess the DNN accuracy and to retrain the DNN more effectively. We applied our approach to a state-of-the-art DNN performing semantic segmentation, in two different case studies, and demonstrated that it outperforms a state-of-the-art GAN-based testing solution and several other baselines. Specifically, it leads to the largest number of diverse images leading to the worst DNN accuracy. Further, the images generated with our approach, lead to the highest improvement in DNN accuracy when used for retraining. In conclusion, we suggest to always integrate a trained GAN to transform test inputs when performing search-driven, simulator-based testing.|||Article||||
WEB OF SCIENCE|Farahanchi, Hamed|||A Natural Language Processing Model to Improve the Software Testing Process under an Agile Methodology|2023||||||||||||||Dissertation/Thesis||||
WEB OF SCIENCE|Cetiner, Gokhan; Yayan, Ugur; Yazici, Ahmet|||Mutation-Based White Box Testing of Deep Neural Networks|2024|IEEE ACCESS|12|||160156|160174|||10.1109/ACCESS.2024.3482114||Deep Neural Networks (DNNs) are used in many critical areas, such as autonomous vehicles, generative AI systems, etc. Therefore, testing DNNs is vital, especially for models used in critical areas. Mutation-based testing is a very successful technique for testing DNNs by mutating their complex structures. Deep Mutation Module was developed to address mutation-based testing and the robustness challenges of DNNs. It analyses the structures of DNNs in detail. It tests models by applying mutation to parameters and structures using its fault library. Testing DNN structures and detecting faults is a highly complex and open-ended challenge. The method proposed in this study applies mutations to DNN parameters to expose faults and weaknesses in the models, thereby testing their robustness. The paper focuses on mutation-based tests of an Reinforce Learning (RL) model developed for electric vehicle routing, a Long Short-Term Memory (LSTM) model developed for prognostic predictions, and a Transformer-based neural network model for electric vehicle routing tasks. The best mutation scores for the LSTM model were measured as 96%, 91.02%, 71.19%, and 68.77%. The test results for the RL model resulted in mutation scores of 93.20%, 72.13%, 77.47%, 79.28%, and 55.74%. The mutation scores of the Transformer model were 75.87%, 76.36%, and 74.93%. These results show that the module can successfully test the targeted models and generate mutants classified as survived mutants that outperform the original models. In this way, it provides critical information to researchers to improve the overall performance of the models. Conducting these tests before using them in real-world applications minimizes faults and maximizes model success.|||Article||||
WEB OF SCIENCE|Liu, Jiawei; Huang, Yuheng; Wang, Zhijie; Ma, Lei; Fang, Chunrong; Gu, Mingzheng; Zhang, Xufan; Chen, Zhenyu|||Generation-based Differential Fuzzing for Deep Learning Libraries|2024|ACM TRANSACTIONS ON SOFTWARE ENGINEERING AND METHODOLOGY|33|2|50|||||10.1145/3628159||Deep learning (DL) libraries have become the key component in developing and deploying DL-based software nowadays. With the growing popularity of applying DL models in both academia and industry across various domains, any bugs inherent in the DL libraries can potentially cause unexpected server outcomes. As such, there is an urgent demand for improving the software quality of DL libraries. Although there are some existing approaches specifically designed for testing DL libraries, their focus is usually limited to one specific domain, such as computer vision (CV). It is still not very clear how the existing approaches perform in detecting bugs of different DL libraries regarding different task domains and to what extent. To bridge this gap, we first conduct an empirical study on four representative and state-of-the-art DL library testing approaches. Our empirical study results reveal that it is hard for existing approaches to generalize to other task domains. We also find that the test inputs generated by these approaches usually lack diversity, with only a few types of bugs. What is worse, the false-positive rate of existing approaches is also high (up to 58%). To address these issues, we propose a guided differential fuzzing approach based on generation, namely, Gandalf. To generate testing inputs across diverse task domains effectively, Gandalf adopts the context-free grammar to ensure validity and utilizes a Deep Q-Network to maximize the diversity. Gandalf also includes 15 metamorphic relations to make it possible for the generated test cases to generalize across different DL libraries. Such a design can decrease the false positives because of the semantic difference for different APIs. We evaluate the effectiveness of Gandalf on nine versions of three representative DL libraries, covering 309 operators from computer vision, natural language processing, and automated speech recognition. The evaluation results demonstrate that Gandalf can effectively and efficiently generate diverse test inputs. Meanwhile, Gandalf successfully detects five categories of bugs with only 3.1% false-positive rates. We report all 49 new unique bugs found during the evaluation to the DL libraries' developers, and most of these bugs have been confirmed. Details about our empirical study and evaluation results are available on our project website.(1)|||Article||||
WEB OF SCIENCE|Ollando, Raphael; Shin, Seung Yeob; Briand, Lionel C.|||Learning Failure-Inducing Models for Testing Software-Defined Networks|2024|ACM TRANSACTIONS ON SOFTWARE ENGINEERING AND METHODOLOGY|33|5|113|||||10.1145/3641541||Software-defined networks (SDN) enable flexible and effective communication systems that are managed by centralized software controllers. However, such a controller can undermine the underlying communication network of an SDN-based system and thus must be carefully tested. When an SDN-based system fails, in order to address such a failure, engineers need to precisely understand the conditions under which it occurs. In this article, we introduce a machine learning-guided fuzzing method, named FuzzSDN, aiming at both (1) generating effective test data leading to failures in SDN-based systems and (2) learning accurate failure-inducing models that characterize conditions under which such system fails. To our knowledge, no existing work simultaneously addresses these two objectives for SDNs. We evaluate FuzzSDN by applying it to systems controlled by two open-source SDN controllers. Furthermore, we compare FuzzSDN with two state-of-the-art methods for fuzzing SDNs and two baselines for learning failure-inducing models. Our results show that (1) compared to the state-of-the-art methods, FuzzSDN generates at least 12 times more failures, within the same time budget, with a controller that is fairly robust to fuzzing and (2) our failure-inducing models have, on average, a precision of 98% and a recall of 86%, significantly outperforming the baselines.|||Article||||
WEB OF SCIENCE|Mindom, Paulina Stevia Nouwou; Nikanjam, Amin; Khomh, Foutse|||A comparison of reinforcement learning frameworks for software testing tasks|2023|EMPIRICAL SOFTWARE ENGINEERING|28|5|111|||||10.1007/s10664-023-10363-2||Software testing activities scrutinize the artifacts and the behavior of a software product to find possible defects and ensure that the product meets its expected requirements. Although various approaches of software testing have shown to be very promising in revealing defects in software, some of them lack automation or are partly automated which increases the testing time, the manpower needed, and overall software testing costs. Recently, Deep Reinforcement Learning (DRL) has been successfully employed in complex testing tasks such as game testing, regression testing, and test case prioritization to automate the process and provide continuous adaptation. Practitioners can employ DRL by implementing from scratch a DRL algorithm or using a DRL framework. DRL frameworks offer well-maintained implemented state-of-the-art DRL algorithms to facilitate and speed up the development of DRL applications. Developers have widely used these frameworks to solve problems in various domains including software testing. However, to the best of our knowledge, there is no study that empirically evaluates the effectiveness and performance of implemented algorithms in DRL frameworks. Moreover, some guidelines are lacking from the literature that would help practitioners choose one DRL framework over another. In this paper, therefore, we empirically investigate the applications of carefully selected DRL algorithms (based on the characteristics of algorithms and environments) on two important software testing tasks: test case prioritization in the context of Continuous Integration (CI) and game testing. For the game testing task, we conduct experiments on a simple game and use DRL algorithms to explore the game to detect bugs. Results show that some of the selected DRL frameworks such as Tensorforce outperform recent approaches in the literature. To prioritize test cases, we run extensive experiments on a CI environment where DRL algorithms from different frameworks are used to rank the test cases. We find some cases where our DRL configurations outperform the implementation of the baseline. Our results show that the performance difference between implemented algorithms in some cases is considerable, motivating further investigation. Moreover, empirical evaluations on some benchmark problems are recommended for researchers looking to select DRL frameworks, to make sure that DRL algorithms perform as intended.|||Article||||
WEB OF SCIENCE|Zou, Yinglong; Sun, Haofeng; Fang, Chunrong; Liu, Jiawei; Zhang, Zhenping|||Deep learning framework testing via hierarchical and heuristic model generation|2023|JOURNAL OF SYSTEMS AND SOFTWARE|201||111681|||||10.1016/j.jss.2023.111681||Deep learning frameworks are the foundation of deep learning model construction and inference. Many testing methods using deep learning models as test inputs are proposed to ensure the quality of deep learning frameworks. However, there are still critical challenges in model generation, model instantiation, and result analysis. To bridge the gap, we propose Ramos, a hierarchical heuristic deep learning framework testing method. To generate diversified models, we design a novel hierarchical structure to represent the building block of the model. Based on this structure, new models generated by the mutation method. To trigger more precision bugs in deep learning frameworks, design a heuristic method to increase the error triggered by models and guide the subsequent model generation. To reduce false positives, we propose an API mapping rule between different frameworks to aid model instantiation. Further, we design different test oracles for crashes and precision bugs respectively. We conduct experiments under three widely-used frameworks (TensorFlow, PyTorch, and MindSpore) to evaluate the effectiveness of Ramos. The results show that Ramos can effectively generate diversified models and detect more deep learning framework bugs, including crashes and precision bugs, with fewer false positives. Additionally, 14 of 15 are confirmed by developers.(c) 2023 Elsevier Inc. All rights reserved.|||Article||||
WEB OF SCIENCE|Pandey, Sushant Kumar; Rathee, Deevashwer; Tripathi, Anil Kumar|||Software defect prediction using K-PCA and various kernel-based extreme learning machine: an empirical study|2020|IET SOFTWARE|14|7||768|782|||10.1049/iet-sen.2020.0119||Predicting defects during software testing reduces an enormous amount of testing effort and help to deliver a high-quality software system. Owing to the skewed distribution of public datasets, software defect prediction (SDP) suffers from the class imbalance problem, which leads to unsatisfactory results. Overfitting is also one of the biggest challenges for SDP. In this study, the authors performed an empirical study of these two problems and investigated their probable solution. They have conducted 4840 experiments over five different classifiers using eight NASA projects and 14 PROMISE repository datasets. They suggested and investigated the varying kernel function of an extreme learning machine (ELM) along with kernel principal component analysis (K-PCA) and found better results compared with other classical SDP models. They used the synthetic minority oversampling technique as a sampling method to address class imbalance problems and k-fold cross-validation to avoid the overfitting problem. They found ELM-based SDP has a high receiver operating characteristic curve over 11 out of 22 datasets. The proposed model has higher precision and F-score values over ten and nine, respectively, compared with other state-of-the-art models. The Mathews correlation coefficient (MCC) of 17 datasets of the proposed model surpasses other classical models' MCC.|||Article||||
WEB OF SCIENCE|Challa, Harshitha|||Multivariate Time-Series Data Requirements in Deep Learning Models|2021||||||||||||||Dissertation/Thesis||||
WEB OF SCIENCE|Ramos, Tafline; Dean, Amanda; Mcgregor, David|||AI-Augmented Software Engineering: Revolutionizing or Challenging Software Quality and Testing?|2025|JOURNAL OF SOFTWARE-EVOLUTION AND PROCESS|37|2||||||10.1002/smr.2741||With organizations seeking faster, cheaper, and smarter ways of delivering higher quality software, many are looking towards generative artificial intelligence (AI) to drive efficiencies and innovation throughout the software development lifecycle. However, generative AI can suffer from several fundamental issues, including a lack of traceability in concept generation and decision-making, the potential for making incorrect inferences (hallucinations), shortcomings in response quality, and bias. Quality engineering (QE) has long been utilized to enable more efficient and effective delivery of higher quality software. A core aspect of QE is adopting quality models to support various lifecycle practices, including requirements definition, quality risk assessments, and testing. In this position paper, we introduce the application of QE to AI systems, consider shortcomings in existing AI quality models from the International Organization for Standardization (ISO), and propose extensions to ISO models based on the results of a survey. We also reflect on skills that IT graduates may need in the future, to support delivery of better-quality AI.|||Article||||
WEB OF SCIENCE||||Conversational AI Audiology: Remote, natural and automated testing of hearing and fitting|2022|||||||||||Conversational artificial intelligence (AI), i.e. technology that a patient can talk to, has the potential to remove barriers from access to healthcare and in particular hearing healthcare. Imagine that people who worry about their hearing would not need to visit a GP or an audiologist for a first diagnosis but could just ask their home assistant Please check my hearing. This could lead to an increasing awareness of hearing loss and uptake of hearing aids by the 1.5 billion people (2.5 billion in 2050) who suffer from a hearing loss. It is estimated that at least 6 million people in the UK would benefit from a hearing aid but only 2 million have one, and uptake among them is low and slow. A hearing test that takes place as a conversation with a technical device has further advantages to conventional technologies: First, it tests real-world sounds (speech) rather than the audibility of faint synthetic sounds (pure tones in an audiogram). Second, a conversational AI system can directly simulate the speech that would be delivered through a hearing aid and thus quantify the benefit that the best hearing-aid setting would give. Third, remote testing does not only remove barriers in accessing healthcare but is also of benefit to vulnerable patients. In this project we will apply text-to-speech (TTS) and automatic speech recognition (ASR) to hearing tests in order to achieve these goals. TTS and ASR will allow the patient to interact easily with the test system, which is an additional benefit for those who struggle with graphical user interfaces, in particular some elderly patients. The communication between patient and AI will be driven by the goals to have a more natural interaction than in conventional tests and to characterise a hearing loss in short time. The candidate should have an interest in healthcare and is expected to have a background in deep learning and other fields of artificial intelligence, obtained from a first degree in engineering, computer science, mathematics, physics or similar. The candidate will acquire skills in TTS, ASR and active learning. Collaborations with other young researchers and activities like journal clubs will contribute to establishing a basic knowledge in audiology and clinical testing. The candidate will produce research outputs that are published in machine-learning conferences (NeurIPS, ICML, Interspeech, ICASSP) and leading hearing journals (Trends in Hearing, IJA, Hearing Research). Further references: Schlittenlacher, J., Baer, T. (2021) Text-to-speech for the hearing impaired, arXiv, 2012.02174|||Awarded Grant||||
WEB OF SCIENCE|Dai, Hepeng; Sun, Chang-Ai; Liu, Huai; Zhang, Xiangyu|||DFuzzer: Diversity-Driven Seed Queue Construction of Fuzzing for Deep Learning Models|2024|IEEE TRANSACTIONS ON RELIABILITY|73|2||1075|1089|||10.1109/TR.2023.3322406||In light of high-performance computer processing, massive datasets, and mighty algorithms, we are rapidly entering an age where the advanced deep learning (DL) capabilities are integrated into the contemporary software systems to fulfill critical tasks. Like traditional software, DL systems are not immune to faults, some of which may even cause catastrophic disasters. As a mainstream testing technique for DL systems, fuzzing attempts to generate a large amount of semirandom yet syntactically valid test cases, from which the so-called adversarial inputs can be found, indicating the detection of faults. Test cases in fuzzing are generated based on a seed queue, which is constructed by randomly selecting seeds from the existing test suite (that is, the set of test cases). In this article, we propose a diversity-driven approach, namely DFuzzer, for constructing seed queues in fuzzing. We particularly develop two algorithms, namely DFuzzer-IB and DFuzzer-FB, based on the information theory and deep features, respectively, to improve the diversity of seed queues. Experimental studies have been conducted to evaluate the proposed techniques based on five fuzzers, three datasets, and seven DL models. The experimental results show that both strategies can significantly improve the performance of the state-of-the-art fuzzers for DL, including DeepXplore, DLFuzz, Tensorfuzz, DeepHunter, and DeepSmartFuzzer, not only in terms of finding more adversarial inputs for triggering faults but also achieving higher coverage. Our article demonstrates that the improved diversity of seed queues and the resultant test cases can help achieve a high testing effectiveness of fuzzing.|||Article||||
WEB OF SCIENCE|Afeltra, Angelo; Cannavale, Alfonso; Pecorelli, Fabiano; Pontillo, Valeria; Palomba, Fabio|||A Large-Scale Empirical Investigation Into Cross-Project Flaky Test Prediction|2024|IEEE ACCESS|12|||131255|131265|||10.1109/ACCESS.2024.3458184||Test flakiness arises when a test case exhibits inconsistent behavior by alternating between passing and failing states when executed against the same code. Previous research showed the significance of the problem in practice, proposing empirical studies into the nature of flakiness and automated techniques for its detection. Machine learning models emerged as a promising approach for flaky test prediction. However, existing research has predominantly focused on within-project scenarios, where models are trained and tested using data from a single project. On the contrary, little is known about how flaky test prediction models may be adapted to software projects lacking sufficient historical data for effective prediction. In this paper, we address this gap by proposing a large-scale assessment of flaky test prediction in cross-project scenarios, i.e., in situations where predictive models are trained using data coming from external projects. Leveraging a dataset of 1,385 flaky tests from 29 open-source projects, we examine static test flakiness prediction models and evaluate feature- and instance-based filtering methods for cross-project predictions. Our study underscores the difficulties in utilizing cross-project flaky test data and underscores the significance of filtering methods in enhancing prediction accuracy. Notably, we find that the TrAdaBoost filtering method significantly reduces data heterogeneity, leading to an F-Measure of 70%.|||Article||||
WEB OF SCIENCE|Nass, Michel; Alegroth, Emil; Feldt, Robert|||Improving Web Element Localization by Using a Large Language Model|2024|SOFTWARE TESTING VERIFICATION & RELIABILITY|34|7||||||10.1002/stvr.1893||Web-based test automation heavily relies on accurately finding web elements. Traditional methods compare attributes but do not grasp the context and meaning of elements and words. The emergence of large language models (LLMs) like GPT-4, which can show human-like reasoning abilities on some tasks, offers new opportunities for software engineering and web element localization. This paper introduces and evaluates VON Similo LLM, an enhanced web element localization approach. Using an LLM, it selects the most likely web element from the top-ranked ones identified by the existing VON Similo method, ideally aiming to get closer to human-like selection accuracy. An experimental study was conducted using 804 web element pairs from 48 real-world web applications. We measured the number of correctly identified elements as well as the execution times, comparing the effectiveness and efficiency of VON Similo LLM against the baseline algorithm. In addition, motivations from the LLM were recorded and analysed for 140 instances. VON Similo LLM demonstrated improved performance, reducing failed localizations from 70 to 40 (out of 804), a 43% reduction. Despite its slower execution time and additional costs of using the GPT-4 model, the LLM's human-like reasoning showed promise in enhancing web element localization. LLM technology can enhance web element localization in GUI test automation, reducing false positives and potentially lowering maintenance costs. However, further research is necessary to fully understand LLMs' capabilities, limitations and practical use in GUI testing.This study introduces VON Similo LLM, which combines the precision of the VON Similo algorithm with the language understanding and reasoning abilities of large language models (LLMs) to improve web element localization in GUI-based software testing. It ranks web elements using VON Similo, selects the top 10 and uses the LLM to identify the element most similar to the target, enhancing accuracy through understanding element context and properties in a human-like manner. image|||Article||||
WEB OF SCIENCE||||CAREER: Advancing Neural Testing and Debugging of Software|2023|||||||||||Software is an integral part of every life, from cell phones in everyone's pocket to autonomous cars that have already driven millions of miles to embedded software enabling smart home appliances. Developers are prone to making mistakes and introducing bugs to the software, making automated software validation techniques essential to ensure delivering reliable software. Software testing is the activity of finding and fixing software bugs is an important activity for software developers. With the advent of Artificial Intelligence (AI) and the potential power of Machine Learning (ML) in understanding and predicting bug patterns in code, software testing and debugging are gradually moving towards learning-based techniques, i.e., neural testing and debugging of software. This research project will address fundamental challenges in automated software testing and debugging by leveraging AI, and will develop new insights for semantically robust and interpretable neural testing and debugging. Combining theory building, empirical data-driven research, and tool building, this research aims to (1) design semantically robust neural models of code and develop systematic approaches for high-quality dataset generation, (2) develop several techniques to construct deep test oracles for functional and non-functional testing, and (3) design interpretation techniques for extracting and reusing the knowledge of neural models to unify testing and debugging. These overarching ideas can make software testing and debugging smarter and faster, significantly impacting how researchers and practitioners improve software quality. This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.|||Awarded Grant||||
WEB OF SCIENCE|Wozniak, Anne-Laure; Segura, Sergio; Mazo, Raul|||Robustness Assessment of AI-Based 2D Object Detection Systems: A Method and Lessons Learned from Two Industrial Cases|2024|ELECTRONICS|13|7|1368|||||10.3390/electronics13071368||The reliability of AI-based object detection models has gained interest with their increasing use in safety-critical systems and the development of new regulations on artificial intelligence. To meet the need for robustness evaluation, several authors have proposed methods for testing these models. However, applying these methods in industrial settings can be difficult, and several challenges have been identified in practice in the design and execution of tests. There is, therefore, a need for clear guidelines for practitioners. In this paper, we propose a method and guidelines for assessing the robustness of AI-based 2D object detection systems, based on the Goal Question Metric approach. The method defines the overall robustness testing process and a set of recommended metrics to be used at each stage of the process. We developed and evaluated the method through action research cycles, based on two industrial cases and feedback from practitioners. Thus, the resulting method addresses issues encountered in practice. A qualitative evaluation of the method by practitioners was also conducted to provide insights that can guide future research on the subject.|||Article||||
WEB OF SCIENCE|Arshad, Noor; Butt, Talal Ashraf; Iqbal, Muhammad|||A Comprehensive Framework for Intelligent, Scalable, and Performance-Optimized Software Development|2025|IEEE ACCESS|13|||74062|74077|||10.1109/ACCESS.2025.3564139||Integrating Artificial Intelligence (AI) into the Software Development Life Cycle (SDLC) has become necessary to enhance efficiency, scalability, and performance in modern software systems. Instead of incorporating the AI functionality into their SDLC, traditional SDLC models typically add-on the AI software functionality after they have integrated AI functionality into their application or software process. Because of this, developers undergo inefficiencies in their development workflows, experience performance bottlenecks during testing, and experience challenges of incorporating AI to improve an application's performance through optimization. This paper proposes a new AI-Optimized Software Development Life Cycle (AI-SDLC), which is a holistic and comprehensive framework that encases the embedded AI capabilities and optimization strategies throughout the SDLC process during every stage of the system development, so that requirements-gathering, development, testing, and maintenance are hybrid software processes and not dictated by AI vs. traditional software development processes. AI-SDLC presents new development roles, such as AI Integration Specialist, Code Optimizer, and UX Optimization Specialist, which helps developers work across disciplines and increases collaborative interaction between traditional developers and AI engineers. AI-SDLC also utilizes an AI-driven automated hybrid software process in areas such as requirement elicitation, design/architecture validation, testing, deployment monitoring, and scalability to produce robust high-performance systems in all areas of practicing software development life cycle work. The discourse includes a rich case study based on a Smart Logistics Management System to demonstrate practical implementation of the AI-SDLC and how it facilitates improvement in system efficiency and improved user experience. Additionally, the discussion also highlights the possibilities of AI-SDLC practical implementation in other industrial domain areas such as e-Commerce, finance, aviation and enterprise solution based projects with practical considerations for implementation. In conclusion, the discussion provides findings that support AI-SDLC as a structured and intelligence-driven approach to Software Development Life Cycle implementation that addresses the weaknesses of traditional software design and development frameworks.|||Article||||
WEB OF SCIENCE|Navaei, Maryam|||A Performance Analysis on Machine Learning Algorithms to Predict Mobile Application’s Star Rating by Its User Interface Features|2022||||||||||||||Dissertation/Thesis||||
WEB OF SCIENCE|Meng, Linghan; Li, Yanhui; Chen, Lin; Ma, Mingliang; Zhou, Yuming; Xu, Baowen|||Hybrid mutation driven testing for natural language inference|2024|JOURNAL OF SOFTWARE-EVOLUTION AND PROCESS|36|10||||||10.1002/smr.2694||Natural language inference (NLI) is a task to infer the relationship between the premise and hypothesis sentences, whose models have essential applications in the many natural language processing (NLP) fields, for example, machine reading comprehension and recognizing textual entailment. Due to the data-driven programming paradigm, bugs inevitably occur in NLI models during the application process, which calls for novel automatic testing techniques to deal with NLI testing challenges. The main difficulty in achieving automatic testing for NLI models is the oracle problem; that is, it may be too expensive to label NLI model inputs manually and hence be too challenging to verify the correctness of model outputs. To tackle the oracle problem, this study proposes a novel automatic testing method hybrid mutation driven testing (HMT), which extends the mutation idea applied in other NLP domains successfully. Specifically, as there are two sets of sentences, that is, premise and hypothesis, to be mutated, we propose four mutation operators to achieve the hybrid mutation strategy, which mutate the premise and the hypothesis sentences jointly or individually. We assume that the mutation would not affect the outputs; that is, if the original and mutated outputs are inconsistent, inconsistency bugs could be detected without knowing the true labels. To evaluate our method HMT, we conduct experiments on two widely used datasets with two advanced models and generate more than 520,000 mutations by applying our mutation operators. Our experimental results show that (a) our method, HMT, can effectively generate mutated testing samples, (b) our method can effectively trigger the inconsistency bugs of the NLI models, and (c) all four mutation operators can independently trigger inconsistency bugs.We propose a novel automatic testing method, hybrid mutation driven testing (HMT), which extends the mutation idea in natural language inference (NLI). We apply four mutation operators to achieve the hybrid mutation strategy, mutating the premise and the hypothesis in the samples jointly or individually. The experimental results show that HMT can effectively generate mutations and trigger the inconsistency bugs of NLI models, with independent bugs for four mutation operators. image|||Article||||
WEB OF SCIENCE|Reyna Pena, Ricardo|||Improving Test Case Diversity for Functional Testing in Computer Vision-Based Systems|2025||||||||||||||Dissertation/Thesis||||
WEB OF SCIENCE|Kicsi, Andras; Csuvik, Viktor; Vidacs, Laszlo|||Large Scale Evaluation of Natural Language Processing Based Test-to-Code Traceability Approaches|2021|IEEE ACCESS|9|||79089|79104|||10.1109/ACCESS.2021.3083923||Traceability information can be crucial for software maintenance, testing, automatic program repair, and various other software engineering tasks. Customarily, a vast amount of test code is created for systems to maintain and improve software quality. Today's test systems may contain tens of thousands of tests. Finding the parts of code tested by each test case is usually a difficult and time-consuming task without the help of the authors of the tests or at least clear naming conventions. Recent test-to-code traceability research has employed various approaches but textual methods as standalone techniques were investigated only marginally. The naming convention approach is a well-regarded method among developers. Besides their often only voluntary use, however, one of its main weaknesses is that it can only identify one-to-one links. With the use of more versatile text-based methods, candidates could be ranked by similarity, thus producing a number of possible connections. Textual methods also have their disadvantages, even machine learning techniques can only provide semantically connected links from the text itself, these can be refined with the incorporation of structural information. In this paper, we investigate the applicability of three text-based methods both as a standalone traceability link recovery technique and regarding their combination possibilities with each other and with naming conventions. The paper presents an extensive evaluation of these techniques using several source code representations and meta-parameter settings on eight real, medium-sized software systems with a combined size of over 1.25 million lines of code. Our results suggest that with suitable settings, text-based approaches can be used for test-to-code traceability purposes, even where naming conventions were not followed.|||Article||||
WEB OF SCIENCE|Xie, Siqi|||Feature-Guided Analysis of Neural Networks|2023||||||||||||||Dissertation/Thesis||||
WEB OF SCIENCE|Zohdinasab, Tahereh; Riccio, Vincenzo; Gambi, Alessio; Tonella, Paolo|||Efficient and Effective Feature Space Exploration for Testing Deep Learning Systems|2023|ACM TRANSACTIONS ON SOFTWARE ENGINEERING AND METHODOLOGY|32|2|49|||||10.1145/3544792||Assessingthe quality of Deep Learning (DL) systems is crucial, as they are increasingly adopted in safetycritical domains. Researchers have proposed several input generation techniques for DL systems. While such techniques can expose failures, they do not explain which features of the test inputs influenced the system's (mis-) behaviour. DeepHyperion was the first test generator to overcome this limitation by exploring the DL systems' feature space at large. In this article, we propose DeepHyperion-CS, a test generator for DL systems that enhances DeepHyperion by promoting the inputs that contributed more to feature space exploration during the previous search iterations. We performed an empirical study involving two different test subjects (i.e., a digit classifier and a lane-keeping system for self-driving cars). Our results proved that the contribution-based guidance implemented within DeepHyperion-CS outperforms state-of-the-art tools and significantly improves the efficiency and the effectiveness of DeepHyperion. DeepHyperion-CS exposed significantly more misbehaviours for five out of six feature combinations and was up to 65% more efficient than DeepHyperion in finding misbehaviour-inducing inputs and exploring the feature space. DeepHyperion-CS was useful for expanding the datasets used to train the DL systems, populating up to 200% more feature map cells than the original training set.|||Article||||
WEB OF SCIENCE|Alqasrawi, Yousef; Azzeh, Mohammad; Elsheikh, Yousef|||Analyzing the Role of Class Rebalancing Techniques in Software Defect Prediction|2024|INTERNATIONAL JOURNAL OF INFORMATION TECHNOLOGY & DECISION MAKING|23|6||2167|2207|||10.1142/S0219622023500724||Predicting software defects is an important task during software testing phase, especially for allocating appropriate resources and prioritizing testing tasks. Typically, classification algorithms are used to accomplish this task by using previously collected datasets. However, these datasets suffer from imbalanced label distribution where clean modules outnumber defective modules. Traditional classification algorithms cannot handle this nature in defect datasets because they assume the datasets are balanced. Failing to address this problem, the classification algorithm will produce a prediction biased towards the majority label. In the literature, there are several techniques designed to address this problem and most of them focus on data re-balancing. Recently, ensemble class imbalance techniques have emerged as an opposing approach to data rebalancing approaches. Regarding the software defect prediction, there are no studies examining the performance of ensemble class imbalance learning against data re-balancing approaches. This paper investigates the efficiency of ensemble class imbalance learning for software defect prediction. We conducted a comprehensive experiment that involved 12 datasets, six classifiers, nine class imbalance techniques, and 10 evaluation metrics. The experiments showed that ensemble approaches, particularly the Under Bagging technique, outperform traditional data re-balancing approaches, particularly when dealing with datasets that have high defect ratios.|||Article||||
WEB OF SCIENCE|Du, Xiaoli; Zeng, Hongwei; Chen, Shengbo; Lei, Zhou|||RNNCon: Contribution Coverage Testing for Stacked Recurrent Neural Networks|2023|ENTROPY|25|3|520|||||10.3390/e25030520||Recurrent Neural Networks (RNNs) are applied in safety-critical fields such as autonomous driving, aircraft collision detection, and smart credit. They are highly susceptible to input perturbations, but little research on RNN-oriented testing techniques has been conducted, leaving a threat to a large number of sequential application domains. To address these gaps, improve the test adequacy of RNNs, find more defects, and improve the performance of RNNs models and their robustness to input perturbations. We aim to propose a test coverage metric for the underlying structure of RNNs, which is used to guide the generation of test inputs to test RNNs. Although coverage metrics have been proposed for RNNs, such as the hidden state coverage in RNN-Test, they ignore the fact that the underlying structure of RNNs is still a fully connected neural network but with an additional delayer that records the network state at the time of data input. We use the contributions, i.e., the combination of the outputs of neurons and the weights they emit, as the minimum computational unit of RNNs to explore the finer-grained logical structure inside the recurrent cells. Compared to existing coverage metrics, our research covers the decision mechanism of RNNs in more detail and is more likely to generate more adversarial samples and discover more flaws in the model. In this paper, we redefine the contribution coverage metric applicable to Stacked LSTMs and Stacked GRUs by considering the joint effect of neurons and weights in the underlying structure of the neural network. We propose a new coverage metric, RNNCon, which can be used to guide the generation of adversarial test inputs. And we design and implement a test framework prototype RNNCon-Test. 2 datasets, 4 LSTM models, and 4 GRU models are used to verify the effectiveness of RNNCon-Test. Compared to the current state-of-the-art study RNN-Test, RNNCon can cover a deeper decision logic of RNNs. RNNCon-Test is not only effective in identifying defects in Deep Learning (DL) systems but also in improving the performance of the model if the adversarial inputs generated by RNNCon-Test are filtered and added to the training set to retrain the model. In the case where the accuracy of the model is already high, RNNCon-Test is still able to improve the accuracy of the model by up to 0.45%.|||Article||||
WEB OF SCIENCE|Vos, Tanja E. J.; Aho, Pekka; Ricos, Fernando Pastor; Rodriguez-Valdes, Olivia; Mulders, Ad|||testar - scriptless testing through graphical user interface|2021|SOFTWARE TESTING VERIFICATION & RELIABILITY|31|3|e1771|||||10.1002/stvr.1771||Covering all the possible paths of the graphical user interface (GUI) with test scripts would take too much effort and result in serious maintenance issues. We propose complementing scripted testing with scriptless test automation using the open-source testar tool. This paper gives a comprehensive overview of testar and its latest extensions together with the ongoing and future research. With this paper, we hope we can help and encourage other researchers to use testar for their GUI testing-related research and pave the way for an international research agenda in GUI testing built upon stable and open-source infrastructure.|||Article||||
WEB OF SCIENCE|Cha, Sooyoung; Hong, Seongjoon; Bak, Jiseong; Kim, Jingyoung; Lee, Junhee; Oh, Hakjoo|||Enhancing Dynamic Symbolic Execution by Automatically Learning Search Heuristics|2022|IEEE TRANSACTIONS ON SOFTWARE ENGINEERING|48|9||3640|3663|||10.1109/TSE.2021.3101870||We present a technique to automatically generate search heuristics for dynamic symbolic execution. A key challenge in dynamic symbolic execution is how to effectively explore the program's execution paths to achieve high code coverage in a limited time budget. Dynamic symbolic execution employs a search heuristic to address this challenge, which favors exploring particular types of paths that are most likely to maximize the final coverage. However, manually designing a good search heuristic is nontrivial and typically ends up with suboptimal and unstable outcomes. The goal of this paper is to overcome this shortcoming of dynamic symbolic execution by automatically learning search heuristics. We define a class of search heuristics, namely a parametric search heuristic, and present an algorithm that efficiently finds an optimal heuristic for each subject program. Experimental results with industrial-strength symbolic execution tools (e.g., KLEE) show that our technique can successfully generate search heuristics that significantly outperform existing manually-crafted heuristics in terms of branch coverage and bug-finding.|||Article||||
WEB OF SCIENCE|mingu, Heo; Park, ChangHoon|||Measuring gameplay similarity between human and reinforcement learning artificial intelligence|2020|Journal of Korea Game Society|20|6||63|73|||||Recently, research on automating game tests using artificial intelligence agents instead of humans is attracting attention. This paper aims to collect play data from human and artificial intelligence and analyze their similarity as a preliminary study for game balancing automation. At this time, constraints were added at the learning stage in order to create artificial intelligence that can play similar to humans. Play datas obtained 14 people and 60 artificial intelligence by playing Flippy bird games 10 times each. The collected datas compared and analyzed for movement trajectory, action position, and dead position using the cosine similarity method. As a result of the analysis, an artificial intelligence agent with a similarity of 0.9 or more with humans was found.|||research-article||||
WEB OF SCIENCE|Tang, Bo; Shah, Vijay K.; Marojevic, Vuk; Reed, Jeffrey H.|||AI Testing Framework for Next-G O-RAN Networks: Requirements, Design, and Research Opportunities|2023|IEEE WIRELESS COMMUNICATIONS|30|1||70|77|||10.1109/MWC.001.2200213||Openness and intelligence are two enabling features to be introduced in next generation wireless networks, for example, Beyond 5G and 6G, to support service heterogeneity, open hardware, optimal resource utilization, and on-demand service deployment. The open radio access network (O-RAN) is a promising RAN architecture to achieve both openness and intelligence through virtualized network elements and well-defined interfaces. While deploying artificial intelligence (AI) models is becoming easier in O-RAN, one significant challenge that has been long neglected is the comprehensive testing of their performance in realistic environments. This article presents a general automated, distributed and AI-enabled testing framework to test AI models deployed in O-RAN in terms of their decision-making perfor-mance, vulnerability and security. This framework adopts a master-actor architecture to manage a number of end devices for distributed testing. More importantly, it leverages AI to automatically and intelligently explore the decision space of AI models in O-RAN. Both software simulation testing and software-defined radio hardware testing are supported, enabling rapid proof of concept research and experimental research on wireless research platforms.|||Article||||
WEB OF SCIENCE|Radic, Nikola|||Automated Translation of Legal Instruments to Smart Contracts Using Large Language Models|2025||||||||||||||Dissertation/Thesis||||
WEB OF SCIENCE|Yang, Yuxuan; Chen, Xin|||Crowdsourced Test Report Prioritization Based on Text Classification|2022|IEEE ACCESS|10|||92692|92705|||10.1109/ACCESS.2021.3128726||In crowdsourced testing, crowd workers from different places help developers conduct testing and submit test reports for the observed abnormal behaviors. Developers manually inspect each test report and make an initial decision for the potential bug. However, due to the poor quality, test reports are handled extremely slowly. Meanwhile, due to the limitation of resources, some test reports are not handled at all. Therefore, some researchers attempt to resolve the problem of test report prioritization and have proposed many methods. However, these methods do not consider the impact of duplicate test reports. In this paper, we focus on the problem of test report prioritization and present a new method named DivClass by combining a diversity strategy and a classification strategy. First, we leverage Natural Language Processing (NLP) techniques to preprocess crowdsourced test reports. Then, we build a similarity matrix by introducing an asymmetric similarity computation strategy. Finally, we combine the diversity strategy and the classification strategy to determine the inspection order of test reports. To validate the effectiveness of DivClass, experiments are conducted on five crowdsourced test report datasets. Experimental results show that DivClass achieves 0.8887 in terms of APFD (Average Percentage of Fault Detected) and improves the state-of-the-art technique DivRisk by 14.12% on average. The asymmetric similarity computation strategy can improve DivClass by 4.82% in terms of APFD on average. In addition, empirical results show that DivClass can greatly reduce the number of inspected test reports.|||Article||||
WEB OF SCIENCE|Lee, In-Kyoun; Jin, Min-Seong; Lee, Gwang-Woon; GUNWOO, PARK|||Test Cases Generation and Transformer Language Models Performance Comparison for Korean Natural Language Processing-based AI SW|2024|The International Journal of Advanced Culture Technology|12|4||408|417|||||Since the emergence of ChatGPT, transformer-based language models have become highly popular. This study utilizes a transformer-based approach to measure Korean sentence similarity for software testing. By doing so, we propose test cases using metamorphic relationships. The performance of the transformer models is then compared using similarity measures. First, we create a test set by transforming sentences from the Defense Daily according to specific rules. We then input these transformed sentences into the RoBERTa, Electra, and T5 models. We check whether the similarity measure between the original sentence and its variant satisfies the metamorphic relationship. The performance of each model is then compared using a similarity measure. In our experiments, the RoBERTa model satisfied metamorphic relations in MR5 and MR6, which involved transforming nouns and verbs into synonyms, and in MR7, which involved altering sentence order, with accuracy rates of 80%, 85%, and 88%, respectively. All tests passed except MR7 (77%) for the Electra model and MR1 (73%) for the T5 model. Finally, we compared the performance of each model. In the comparison, the Electra model outperformed the T5 model (99.96%) and the RoBERTa model (99.62%) with an accuracy of 99.97%.|||research-article||||
WEB OF SCIENCE|Parry, Owain; Kapfhammer, Gregory M.; Hilton, Michael; McMinn, Phil|||Empirically evaluating flaky test detection techniques combining test case rerunning and machine learning models|2023|EMPIRICAL SOFTWARE ENGINEERING|28|3|72|||||10.1007/s10664-023-10307-w||A flaky test is a test case whose outcome changes without modification to the code of the test case or the program under test. These tests disrupt continuous integration, cause a loss of developer productivity, and limit the efficiency of testing. Many flaky test detection techniques are rerunning-based, meaning they require repeated test case executions at a considerable time cost, or are machine learning-based, and thus they are fast but offer only an approximate solution with variable detection performance. These two extremes leave developers with a stark choice. This paper introduces CANNIER, an approach for reducing the time cost of rerunning-based detection techniques by combining them with machine learning models. The empirical evaluation involving 89,668 test cases from 30 Python projects demonstrates that CANNIER can reduce the time cost of existing rerunning-based techniques by an order of magnitude while maintaining a detection performance that is significantly better than machine learning models alone. Furthermore, the comprehensive study extends existing work on machine learning-based detection and reveals a number of additional findings, including (1) the performance of machine learning models for detecting polluter test cases; (2) using the mean values of dynamic test case features from repeated measurements can slightly improve the detection performance of machine learning models; and (3) correlations between various test case features and the probability of the test case being flaky.|||Article||||
WEB OF SCIENCE|Olsina, Luis; Lew, Philip; Becker, Pablo|||Comparative analysis of the syntactic and semantic consistency of terms in software testing glossaries|2024|SOFTWARE QUALITY JOURNAL|32|1||27|52|||10.1007/s11219-023-09638-0||This paper addresses terminological consistency issues of three software testing glossaries used in academia and industry. The evaluation focus mainly deals with a sub-characteristic of information quality such as consistency, which includes syntactic and semantic consistency. To systematically conduct this study, we have established a set of activities or steps. These include defining the evaluation goal and scope, selecting the glossaries, conceiving the terminological categories, classifying the glossary terms into categories, calculating syntactic and semantic similarities, analyzing consistency, and making recommendations. For instance, for the testing domain, eight terminological categories were conceived, in which, for each selected glossary, a corresponding term is included in a category, considering the semantics intended by the authors of these standard documents. To count the occurrence frequency of a term in the glossaries, a tool was built that also takes into account the matching of synonyms. Then, a comparative analysis of syntactic and semantic consistency was carried out for all the terms ending in the word testing, which enables us to give recommendations. This exploratory study identifies some inconsistencies that might deserve further attention and efforts to promote agreement and harmonization among the authors/editors of these glossaries in order to provide their readers with the most consistent and easiest way to understand and learn software testing concepts.|||Article||||
WEB OF SCIENCE|Wei, Chenhao; Xiao, Lu; Yu, Tingting; Chen, Xinyu; Wang, Xiao; Wong, Sunny; Clune, Abigail|||Automatically Tagging the AAA Pattern in Unit Test Cases Using Machine Learning Models|2023|IEEE TRANSACTIONS ON SOFTWARE ENGINEERING|49|5||3305|3324|||10.1109/TSE.2023.3252442||The AAA pattern (i.e., Arrange-Act-Assert) is a common and natural layout to create a test case. Following this pattern in test cases may benefit comprehension, debugging, and maintenance. The AAA structure of real-life test cases, however, may not be clear due to their high complexity. Manually labeling AAA statements in test cases is tedious. Thus, we envision that an automated approach for labeling AAA statements in existing test cases could benefit new developers and projects that practice collective code ownership and test-driven development. This paper contributes an automatic approach based on machine learning models. The secret sauce of this approach is a set of three learning features that are based on the semantic, syntax, and context information in test cases, derived from the manual tagging process. Thus, our approach mimics how developers may manually tag the AAA pattern of a test case. We assess the precision, recall, and F-1 score of our approach based on 449 test cases, containing about 16,612 statements, across 4 Apache open source projects. To achieve the best performance in our approach, we explore the usage of six machine learning models; the contribution of the SMOTE data balancing technique; the comparison of the three learning features; and the comparison of five different methods for calculating the semantic feature. The results show our approach is able to identify Arrangement, Action, and Assertion statements with a precision upwards of 92%, and recall up to 74%. We also summarize some experience based on our experiments-regarding the choice of machine learning models, data balancing algorithm, and feature engineering methods-which could potentially provide some reference to related future research.|||Article||||
WEB OF SCIENCE|Hanfati, Kirana; Sukaridhoto, Sritrusta; Rante, Hestiasari; Budiarti, Rizqi Putri Nourma; Nadatien, Ima|||Application of mixed reality and artificial intelligence to assist medical students in learning injection technique|2023|BALI MEDICAL JOURNAL|12|3||3363|3369|||10.15562/bmj.v12i3.4425||Introduction: The usage of immersive technology has advanced in a number of areas of life because of the development of technology that keeps pace with the times. Another immersive technology that combines VR and AR is mixed reality (MR), which enables us to interact with 3-dimensional objects in the real world. Since MR technology gives a more nuanced experience, the market is highly promising. This study aims to evaluate the application of mixed reality and artificial intelligence to assist medical students in learning injection technique. Methods: This type of research is analytic with a quantitative and qualitative approach to prove the purpose of the research. This research involved 40 students. Due to the creative nature of immersive technology, it must be combined with other technologies to produce an even more complicated and engaging experience. In order to enhance the quality of the user experience, we will merge MR immersive technology with AI in this research for medical educational field. The integration of these two technologies via an application that can be launched on a Hololens 2 and Magic Leap 1 device and can identify person in a laboratory to support in student learning. Results: For instance, students can utilize artificial intelligence (AI) to learn the names of objects in the lab and do simulation about injection technique. The study 's outcomes are presented in software testing (FPS, CPU, GPU, and load scene) an in the form of user testing utilizing the PIECES Framework (Performance, Information and Data, Economy, Control and Security, Efficiency, and Service), which evaluates the application's utility or significance as well as the satisfaction of its users. Conclusion: The system was able to develop a combining application of artificial intelligence and mixed reality for detecting objects in laboratories to assist learning students, according to the study's conclusions.|||Article||||
WEB OF SCIENCE|Astorga, Angello; Saha, Shambwaditya; Dinkins, Ahmad; Wang, Felicia; Madhusudan, P.; Xie, Tao|||Synthesizing Contracts Correct Modulo a Test Generator|2021|PROCEEDINGS OF THE ACM ON PROGRAMMING LANGUAGES-PACMPL|5||104|||||10.1145/3485481||We present an approach to learn contracts for object-oriented programs where guarantees of correctness of the contracts are made with respect to a test generator. Our contract synthesis approach is based on a novel notion of tight contracts and an online learning algorithm that works in tandem with a test generator to synthesize tight contracts. We implement our approach in a tool called Precis and evaluate it on a suite of programs written in C#, studying the safety and strength of the synthesized contracts, and compare them to those synthesized by DAIKON.|||Article||||
WEB OF SCIENCE|Liu, Chien-Hung; You, Shingchern D.; Chiu, Ying-Chieh|||A Reinforcement Learning Approach to Guide Web Crawler to Explore Web Applications for Improving Code Coverage|2024|ELECTRONICS|13|2|427|||||10.3390/electronics13020427||Web crawlers are widely used to automatically explore and test web applications. However, navigating the pages of a web application can be difficult due to dynamic page generation. In particular, the inputs for the web form fields can affect the resulting pages and subsequent navigation. Therefore, choosing the inputs and the order of clicks on a web page is essential for an effective web crawler to achieve high code coverage. This paper proposes a set of actions to quickly fill in web form fields and uses reinforcement learning algorithms to train a convolutional neural network (CNN). The trained agent, named iRobot, can autonomously select actions to guide the web crawler to maximize code coverage. We experimentally compared different reinforcement learning algorithms, neural networks, and actions. The results show that our CNN network with the proposed actions performs better than other neural networks in terms of branch coverage using the Deep Q-learning (DQN) or proximal policy optimization (PPO) algorithm. Furthermore, compared to previous studies, iRobot can increase branch coverage by about 1.7% while reducing training time to 12.54%.|||Article||||
WEB OF SCIENCE|Shin, Jiho; Hemmati, Hadi; Wei, Moshi; Wang, Song|||Assessing Evaluation Metrics for Neural Test Oracle Generation|2024|IEEE TRANSACTIONS ON SOFTWARE ENGINEERING|50|9||2337|2349|||10.1109/TSE.2024.3433463||Recently, deep learning models have shown promising results in test oracle generation. Neural Oracle Generation (NOG) models are commonly evaluated using static (automatic) metrics which are mainly based on textual similarity of the output, e.g. BLEU, ROUGE-L, METEOR, and Accuracy. However, these textual similarity metrics may not reflect the testing effectiveness of the generated oracle within a test suite, which is often measured by dynamic (execution-based) test adequacy metrics such as code coverage and mutation score. In this work, we revisit existing oracle generation studies plus gpt-3.5 to empirically investigate the current standing of their performance in textual similarity and test adequacy metrics. Specifically, we train and run four state-of-the-art test oracle generation models on seven textual similarity and two test adequacy metrics for our analysis. We apply two different correlation analyses between these two different sets of metrics. Surprisingly, we found no significant correlation between the textual similarity metrics and test adequacy metrics. For instance, gpt-3.5 on the jackrabbit-oak project had the highest performance on all seven textual similarity metrics among the studied NOGs. However, it had the lowest test adequacy metrics compared to all the studied NOGs. We further conducted a qualitative analysis to explore the reasons behind our observations. We found that oracles with high textual similarity metrics but low test adequacy metrics tend to have complex or multiple chained method invocations within the oracle's parameters, making them hard for the model to generate completely, affecting the test adequacy metrics. On the other hand, oracles with low textual similarity metrics but high test adequacy metrics tend to have to call different assertion types or a different method that functions similarly to the ones in the ground truth. Overall, this work complements prior studies on test oracle generation with an extensive performance evaluation on textual similarity and test adequacy metrics and provides guidelines for better assessment of deep learning applications in software test generation in the future.|||Article||||
WEB OF SCIENCE|Tao, Chuanqi; Guo, Hongjing; Zhang, Jingxuan; Huang, Zhiqiu|||Supporting maintenance and testing for AI functions of mobile apps based on user reviews: An empirical study on plant identification apps|2023|JOURNAL OF SOFTWARE-EVOLUTION AND PROCESS|35|11|e2444|||||10.1002/smr.2444||Despite the tremendous development of artificial intelligence (AI)-based mobile apps, they suffer from quality issues. Data-driven AI software poses challenges for maintenance and quality assurance. Metamorphic testing has been successfully adopted to AI software. However, most previous studies require testers to manually identify metamorphic relations in an ad hoc and arbitrary manner, thereby encountering difficulties in reflecting real-world usage scenarios. Previous work showed that information available in user reviews is effective for maintenance and testing tasks. Yet, there is a lack of studies leveraging reviews to facilitate AI function maintenance and testing activities. This paper proposes METUR, a novel approach to supporting maintenance and testing for AI functions based on reviews. Firstly, METUR automatically classifies reviews that can be exploited for supporting AI function maintenance and evolution activities. Then, it identifies test contexts from reviews in the usage scenario category. METUR instantiates the metamorphic relation pattern for deriving concrete metamorphic relations based on test contexts. The follow-up test dataset is constructed for conducting metamorphic testing. Empirical studies on plant identification apps indicate that METUR effectively categorizes reviews that are related to AI functions. METUR is feasible and effective in detecting inconsistent behaviors by using the metamorphic relations constructed based on reviews.|||Article||||
WEB OF SCIENCE|Μιχαηλίδης, Δημήτριος|||Έλεγχος Λογισμικού με Χρήση Εφαρμογών Τεχνητής Νοημοσύνης (AI)Software Control Using Artificial Intelligence (AI) Applications|2024|||||||||10.26267/unipi_dione/3704|||||Dissertation/Thesis||||
WEB OF SCIENCE|Sakhrawi, Zaineb; Labidi, Taher|||Test case selection and prioritization approach for automated regression testing using ontology and COSMIC measurement|2024|AUTOMATED SOFTWARE ENGINEERING|31|2|51|||||10.1007/s10515-024-00447-8||Regression testing is an important activity that aims to provide information about the quality of the software product under test when changes occur. The two primary techniques for optimizing regression testing are test case selection and prioritization. To identify features affected by a change and determine the best test cases for selection and prioritization, techniques allowing the semantic representation and the quantification of testing concepts are required. The goal of this paper is threefold. Firstly, we proposed an ontology-based test case selection model that enables automated regression testing by dynamically selecting appropriate test cases. The selection of test cases is based on a semantic mapping between change requests and their associated test suites and test cases. Secondly, the selected test cases are prioritized based on their functional size. The functional size is determined using the COmmon Software Measurement International Consortium (COSMIC) Functional Size Measurement (FSM) method. The test case prioritization attempts to reorganize test case execution in accordance with its goal. One common goal is fault detection, in which test cases with a higher functional size (i.e., with a higher chance of detecting a fault) are run first, followed by the remaining test cases. Thirdly, we built an automated testing tool using the output of the aforementioned processes to validate the robustness of our proposed research methodology. Results from a case study in the automotive industry domain show that semantically presenting change requests and using standardized FSM methods to quantify their related test cases are the most interesting metrics. Obviously, they assist in the automation of regression testing and, therefore, in all the software testing processes.|||Article||||
WEB OF SCIENCE|Nikanjam, Amin; Morovati, Mohammad Mehdi; Khomh, Foutse; Ben Braiek, Houssem|||Faults in deep reinforcement learning programs: a taxonomy and a detection approach|2022|AUTOMATED SOFTWARE ENGINEERING|29|1|8|||||10.1007/s10515-021-00313-x||A growing demand is witnessed in both industry and academia for employing Deep Learning (DL) in various domains to solve real-world problems. Deep reinforcement learning (DRL) is the application of DL in the domain of Reinforcement Learning. Like any software system, DRL applications can fail because of faults in their programs. In this paper, we present the first attempt to categorize faults occurring in DRL programs. We manually analyzed 761 artifacts of DRL programs (from Stack Overflow posts and GitHub issues) developed using well-known DRL frameworks (OpenAI Gym, Dopamine, Keras-rl, Tensorforce) and identified faults reported by developers/users. We labeled and taxonomized the identified faults through several rounds of discussions. The resulting taxonomy is validated using an online survey with 19 developers/researchers. To allow for the automatic detection of faults in DRL programs, we have defined a meta-model of DRL programs and developed DRLinter, a model-based fault detection approach that leverages static analysis and graph transformations. The execution flow of DRLinter consists in parsing a DRL program to generate a model conforming to our meta-model and applying detection rules on the model to identify faults occurrences. The effectiveness of DRLinter is evaluated using 21 synthetic and real faulty DRL programs. For synthetic samples, we injected faults observed in the analyzed artifacts from Stack Overflow and GitHub. The results show that DRLinter can successfully detect faults in both synthesized and real-world examples with a recall of 75% and a precision of 100%.|||Article||||
WEB OF SCIENCE|Raamesh, Lilly; Jothi, S.; Radhika, S.|||Test case minimization and prioritization for regression testing using SBLA-based adaboost convolutional neural network|2022|JOURNAL OF SUPERCOMPUTING|78|16||18379|18403|||10.1007/s11227-022-04540-1||The software engineers retain the test cases they create for specific software for future usage. This form of test case reuse is called regression testing and this step mainly improves the software testing efficiency. The test case minimization and prioritization for regression testing raise different issues such as higher time consumption and heavier resource utilization. To overcome this problem, this paper presents a Side-blotched lizard optimized AdaBoost Convolutional Neural Network (SBLA-AdaBoost CNN) model. The proposed technique mainly aims to discover the faults initially and minimize the test case execution cost. The proposed model is evaluated using the Defects4J dataset. Our proposed method tends to be cost-effective since it integrates test case selection, prioritization, and minimization. The proposed methodology can be also utilized to arrange the test cases during their initial stages of software testing. The results demonstrate that the proposed methodology is efficient in identifying the changes in different parts of the source code, minimizing resource utilization, and time consumption. The precision and recall score obtained by the proposed methodology is 98.5% and 99% which is relatively higher than the state-of-art techniques. The time taken by the proposed methodology to evaluate a total of 50 test cases is 19.14 s.|||Article||||
WEB OF SCIENCE|Chahar, Vikas; Bhatia, Pradeep Kumar|||Performance Analysis of Software Test Effort Estimation using Genetic Algorithm and Neural Network|2022|INTERNATIONAL JOURNAL OF ADVANCED COMPUTER SCIENCE AND APPLICATIONS|13|10||376|383|||||In present scenario, the software companies are frequently involving software test effort estimation to allocate the resources efficiently during the software development process. Different machine learning models are developed to estimate the total effort that would be required before the software product could be delivered. These computational models are used to use the past data to estimate the efforts. In the current studies, test effort estimation for software is predicted using the Genetic algorithm and Neural Network. The attributes are selected using the Genetic algorithm and similarity measure between the attribute values has been computed using the Cosine Similarity measure. The simulation experiments were done using the PROMISE and Kaggle repository and implementation was done using the MATLAB software. The performance metrics namely, precision, recall, and accuracy are computed to evaluate against the existing techniques. The accuracy of the proposed model is 91.3% and results are improved by 8.9% in comparison to existing technique and comparison has been made for superiority to predict the test effort for software development.|||Article||||
WEB OF SCIENCE|Toohey, Jack; Raunak, M. S.; Binkley, Dave|||From Neuron Coverage to Steering Angle: Testing Autonomous Vehicles Effectively|2021|COMPUTER|54|8||77|85|||10.1109/MC.2021.3079921||A deep neural network (DNN)-based system is a black box of complex interactions, resulting in a classification or prediction. We investigate the use of realistic transformations to create new images for testing a trained autonomous vehicle DNN as well as their impact on neuron coverage.|||Article||||
WEB OF SCIENCE|Zhang, Zhiyi; Wang, Yichun; Yao, Yongming; Wang, Ziyuan; Huang, Zhiqiu|||A fine-grained evaluation of mutation operators to boost mutation testing for deep learning systems|2025|EMPIRICAL SOFTWARE ENGINEERING|30|3|63|||||10.1007/s10664-025-10613-5||The extensive application of deep learning (DL) makes ensuring its reliability crucial, especially in the safety-critical domain. Mutation testing has been used to assess the test data quality for DL systems, but generating substantial mutants makes it expensive. The cost could be reduced by excluding mutation operators that are not beneficial. However, what DL mutation operators contribute to test effectiveness is still unknown. Therefore, determining which mutation operators are helpful is challenging. In this paper, we provide a fine-grained evaluation of DL mutation operators usefulness by introducing two measures that incorporate the classification results: Redundancy Score (RS), which qualities the redundancy of mutation operators, and Quality Score (QS), which qualities the ability of mutation operators in guiding the generation of high-quality test cases. Our empirical evaluation suggests that RS and QS could evaluate DL mutation operators from a dual perspective. In the context of selective mutation, utilizing RS and QS to prioritize DL mutation operators provides the benefit of reducing a significant number of mutants while maintaining high test effectiveness, thus helping optimize DL mutation testing. Additionally, for a more comprehensive analysis of selective mutation, we introduce the definition of FaultType for DL mutation testing and further evaluate the performance of the measures in aiding the detection of diverse faults. Experimental results show that RS and QS could also expedite the detection of various fault types in DL models, which contributes to a more thorough evaluation of test data.|||Article||||
WEB OF SCIENCE|Bartlett, Antony; Liem, Cynthia C. S.; Panichella, Annibale|||Multi-objective differential evolution in the generation of adversarial examples|2024|SCIENCE OF COMPUTER PROGRAMMING|238||103169|||||10.1016/j.scico.2024.103169||Adversarial examples remain a critical concern for the robustness of deep learning models, showcasing vulnerabilities to subtle input manipulations. While earlier research focused on generating such examples using white-box strategies, later research focused on gradient-based black-box strategies, as models' internals often are not accessible to external attackers. This paper extends our prior work by exploring a gradient-free search-based algorithm for adversarial example generation, with particular emphasis on differential evolution (DE). Building on top of the classic DE operators, we propose five variants of gradient-free algorithms: a singleobjective approach ( GA DE ), two multi-objective variations ( NSGA-II DE and MOEA/D DE ), and two many-objective strategies ( NSGA-III DE and AGE-MOEA DE ). Our study on five canonical image classification models shows that whilst GA DE variant remains the fastest approach, NSGA-II DE consistently produces more minimal adversarial attacks (i.e., with fewer image perturbations). Moreover, we found that applying a post-process minimization to our adversarial images, would further reduce the number of changes and overall delta variation (image noise).|||Article||||
WEB OF SCIENCE|Jammalamadaka, Kiran; Parveen, Nikhat|||Testing coverage criteria for optimized deep belief network with search and rescue|2021|JOURNAL OF BIG DATA|8|1|59|||||10.1186/s40537-021-00453-7||A new data-driven programming model is defined by the deep learning (DL) that makes the internal structure of a created neuron system over a fixed of training data. DL testing structure only depends on the data labeling and manual group. Nowadays, a lot of coverage criteria have been developed, but these criteria basically count the neurons' quantity whose activation during the implementation of a DL structure fulfilled certain properties. Also, existing criteria are not adequately fine-grained to capture delicate behaviors. This paper develops an optimized deep belief network (DBN) with a search and rescue (SAR) algorithm for testing coverage criteria. For an optimal selection of DBN structure, the SAR algorithm is introduced. The main objective is to test the DL structure using different criteria to enhance the coverage accuracy. The different coverage criteria such as KMNC, NBC, SNAC, TKNC, and TKNP are used for the testing of DBN. Using the generated test inputs, the criteria is validated and the developed criteria are capable to capture undesired behaviors in the DBN structure. The developed approach is implemented by Python platform using three standard datasets like MNIST, CIFAR-10, and ImageNet. For analysis, the developed approach is compared with the three LeNet models like LeNet-1, LeNet-4 and LeNet-5 for the MNIST dataset, the VGG-16, and ResNet-20 models for the CIFAR-10 dataset, and the VGG-19 and ResNet-50 models for the ImageNet dataset. These models are tested on the four adversarial test input generation approaches like BIM, JSMA, FGSM, and CW, and one DL testing method like DeepGauge to validate the efficiency of the suggested approach. The simulation results proved that the proposed approach obtained high coverage accuracy for each criterion on four adversarial test inputs and one DL testing method as compared to other models.|||Article||||
WEB OF SCIENCE|Zheng, Wei; Lin, Lidan; Wu, Xiaoxue; Chen, Xiang|||An Empirical Study on Correlations Between Deep Neural Network Fairness and Neuron Coverage Criteria|2024|IEEE TRANSACTIONS ON SOFTWARE ENGINEERING|50|3||391|412|||10.1109/TSE.2023.3349001||Recently, with the widespread use of deep neural networks (DNNs) in high-stakes decision-making systems (such as fraud detection and prison sentencing), concerns have arisen about the fairness of DNNs in terms of the potential negative impact they may have on individuals and society. Therefore, fairness testing has become an important research topic in DNN testing. At the same time, the neural network coverage criteria (such as criteria based on neuronal activation) is considered as an adequacy test for DNN white-box testing. It is implicitly assumed that improving the coverage can enhance the quality of test suites. Nevertheless, the correlation between DNN fairness (a test property) and coverage criteria (a test method) has not been adequately explored. To address this issue, we conducted a systematic empirical study on seven coverage criteria, six fairness metrics, three fairness testing techniques, and five bias mitigation methods on five DNN models and nine fairness datasets to assess the correlation between coverage criteria and DNN fairness. Our study achieved the following findings: 1) with the increase in the size of the test suite, some of the coverage and fairness metrics changed significantly, as the size of the test suite increased; 2) the statistical correlation between coverage criteria and DNN fairness is limited; and 3) after bias mitigation for improving the fairness of DNN, the change pattern in coverage criteria is different; 4) Models debiased by different bias mitigation methods have a lower correlation between coverage and fairness compared to the original models. Our findings cast doubt on the validity of coverage criteria concerning DNN fairness (i.e., increasing the coverage may even have a negative impact on the fairness of DNNs). Therefore, we warn DNN testers against blindly pursuing higher coverage of coverage criteria at the cost of test properties of DNNs (such as fairness).|||Article||||
WEB OF SCIENCE|Pan, Xi; Huan, Zhan; Li, Yimang; Cao, Yingying|||Enhancement of GUI Display Error Detection Using Improved Faster R-CNN and Multi-Scale Attention Mechanism|2024|APPLIED SCIENCES-BASEL|14|3|1144|||||10.3390/app14031144||Graphical user interfaces (GUIs) hold an irreplaceable position in modern software and applications. Users can interact through them. Due to different terminal devices, there are sometimes display errors, such as component occlusion, image loss, text overlap, and empty values during software rendering. To address the aforementioned common four GUI display errors, a target detection algorithm based on the improved Faster R-CNN is proposed. Specifically, ResNet-50 is used instead of the traditional VGG-16 as the feature extraction network. The feature pyramid network (FPN) and the enhanced multi-scale attention (EMA) algorithm are introduced to improve accuracy. ROI-Align is used instead of ROI-Pooling to enhance the generalization capability of the network. Since training models require a large number of labeled screenshots of errors, there is currently no publicly available dataset with GUI display problems. Therefore, a training data generation algorithm has been developed, which can automatically generate screenshots with GUI display problems based on the Rico dataset. Experimental results show that the improved Faster R-CNN achieves a detection accuracy of 87.3% in the generated GUI problem dataset, which is a 7% improvement compared to the previous version.|||Article||||
WEB OF SCIENCE|Temple, Paul; Perrouin, Gilles; Acher, Mathieu; Biggio, Battista; Jezequel, Jean-Marc; Roli, Fabio|||Empirical assessment of generating adversarial configurations for software product lines|2021|EMPIRICAL SOFTWARE ENGINEERING|26|1|6|||||10.1007/s10664-020-09915-7||Software product line (SPL) engineering allows the derivation of products tailored to stakeholders' needs through the setting of a large number of configuration options. Unfortunately, options and their interactions create a huge configuration space which is either intractable or too costly to explore exhaustively. Instead of covering all products, machine learning (ML) approximates the set of acceptable products (e.g., successful builds, passing tests) out of a training set (a sample of configurations). However, ML techniques can make prediction errors yielding non-acceptable products wasting time, energy and other resources. We apply adversarial machine learning techniques to the world of SPLs and craft new configurations faking to be acceptable configurations but that are not and vice-versa. It allows to diagnose prediction errors and take appropriate actions. We develop two adversarial configuration generators on top of state-of-the-art attack algorithms and capable of synthesizing configurations that are both adversarial and conform to logical constraints. We empirically assess our generators within two case studies: an industrial video synthesizer (MOTIV) and an industry-strength, open-source Web-app configurator (JHipster). For the two cases, our attacks yield (up to) a 100% misclassification rate without sacrificing the logical validity of adversarial configurations. This work lays the foundations of a quality assurance framework for ML-based SPLs.|||Article||||
WEB OF SCIENCE|Odabasi, Merve; Gul, Ensar|||The Effect of Environmental Metrics on Software Fault Prediction|2023|INTERNATIONAL JOURNAL OF SOFTWARE ENGINEERING AND KNOWLEDGE ENGINEERING|33|1||85|108|||10.1142/S021819402250067X||In this study, besides the software metrics, the environmental metrics such as experience of software engineer, similar project experience, size of the project, programming language, time spent on analysis and development are also explored to see whether they also affect the results of software fault prediction and what would be the success rates. The dataset for this study was generated from combining various data from 10 projects. A total of 36 metrics and 6676 test cases were evaluated. The errors occurred in the test cases are not just considered as an error, their priority and cases that cannot be tested are also taken into consideration. Nine fault levels are employed in models. Models are created with four different algorithms which have achieved a success rate of; 76% by the decision tree algorithm, 94% by the nearest neighbors algorithm, 90% by the random forests algorithm and 73% by the Adaboost Classifier Algorithm. It was observed that environmental metrics are indeed effective in software fault prediction and when applied with machine learning algorithms a high rate of success can be achieved.|||Article||||
WEB OF SCIENCE|Zhang, Xiaoyu; Zhai, Juan; Ma, Shiqing; Guan, Xiaohong; Shen, Chao|||DREAM: Debugging and Repairing AutoML Pipelines|2025|ACM TRANSACTIONS ON SOFTWARE ENGINEERING AND METHODOLOGY|34|4|95|||||10.1145/3702992||Deep Learning models have become an integrated component of modern software systems. In response to the challenge of model design, researchers proposed Automated Machine Learning (AutoML) systems, which automatically search for model architecture and hyperparameters for a given task. Like other software systems, existing AutoML systems have shortcomings in their design. We identify two common and severe shortcomings in AutoML, performance issue (i.e., searching for the desired model takes an unreasonably long time) and ineffective search issue (i.e., AutoML systems are not able to find an accurate enough model). After analyzing the workflow of AutoML, we observe that existing AutoML systems overlook potential opportunities in search space, search method, and search feedback, which results in performance and ineffective search issues. Based on our analysis, we design and implement DREAM, an automatic and general-purpose tool to alleviate and repair the shortcomings of AutoML pipelines and conduct effective model searches for diverse tasks. It monitors the process of AutoML to collect detailed feedback and automatically repairs shortcomings by expanding search space and leveraging a feedback-driven search strategy. Our evaluation results show that DREAM can be applied on two state-of-the-art AutoML pipelines and effectively and efficiently repair their shortcomings.|||Article||||
WEB OF SCIENCE|Zaidi, Syed Farhan Alam; Woo, Honguk; Lee, Chan-Gun|||A Graph Convolution Network-Based Bug Triage System to Learn Heterogeneous Graph Representation of Bug Reports|2022|IEEE ACCESS|10|||20677|20689|||10.1109/ACCESS.2022.3153075||Many bugs and defects occur during software testing and maintenance. These bugs should be resolved as soon as possible, to improve software quality. However, bug triage aims to solve these bugs by assigning the reported bugs to an appropriate developer or list of developers. It is an arduous task for a human triager to assign an appropriate developer to a bug report, when there are several developers with different skills, and several automated and semi-automated triage systems have been proposed in the last decade. Some recent techniques have suggested possibilities for the development of an effective triage system. However, these techniques require improvement. In previous work, we proposed a heterogeneous graph representation for bug triage, using word-word edges and word-bug document co-occurrences to build a heterogeneous graph of bug data. Cosine similarity is used to weight the word-word edges. Then, a graph convolution network is used to learn a heterogeneous graph representation. This paper extends our previous work by adopting different similarity metrics and correlation metrics for weighting word-word edges. The method was validated using different small and large datasets obtained from large-scale open-source projects. The top-k accuracy metric was used to evaluate the performance of the bug triage system. The experimental results showed that the point-wise mutual information of the proposed model was better than that of other word-word weighting methods, and our method had better accuracy for large datasets than other recent state-of-the-art methods. The proposed method with point-wise mutual information showed 3% to 6% higher top-1 accuracy than state-of-the-art methods for large datasets.|||Article||||
WEB OF SCIENCE|Sharma, Shilpa; Raja, Linesh; Bhatt, Devershi Pallavi|||Role of ontology in software testing|2020|JOURNAL OF INFORMATION & OPTIMIZATION SCIENCES|41|2||641|649|||10.1080/02522667.2020.1733196||Software testing is a multifaceted and essential method to achieve the quality of product. Its significance has been increasing and well accepted, so there is an emergent concern in improving the attainment of this practice. In this perspective, Knowledge Management (KM) emerged as an key sustaining method for improving the software testing process. However, managing relevant testing knowledge according to the influencing factors requires an effective way to represent and to correlate to a huge number of testing aspects. To address this concern, we have analyzed an impact of ontology on software testing across influenced asects of software testing. Ontology provides a standard conceptualization of the software testing domain that can construct a knowledge base, establishing a common vocabulary for knowledge owners about the testing domain, structured testing knowledge databases, identification of testing knowledge objects, and making it easier to search for relevant information. In this paper, we present factors affecting software testing direct or indirect influenced aspects. Moreover, we discuss how ontology helps in alleviating the software testing.|||Article||||
WEB OF SCIENCE|Pan, Rongqi; Bagherzadeh, Mojtaba; Ghaleb, Taher A.; Briand, Lionel|||Test case selection and prioritization using machine learning: a systematic literature review|2022|EMPIRICAL SOFTWARE ENGINEERING|27|2|29|||||10.1007/s10664-021-10066-6||Regression testing is an essential activity to assure that software code changes do not adversely affect existing functionalities. With the wide adoption of Continuous Integration (CI) in software projects, which increases the frequency of running software builds, running all tests can be time-consuming and resource-intensive. To alleviate that problem, Test case Selection and Prioritization (TSP) techniques have been proposed to improve regression testing by selecting and prioritizing test cases in order to provide early feedback to developers. In recent years, researchers have relied on Machine Learning (ML) techniques to achieve effective TSP (ML-based TSP). Such techniques help combine information about test cases, from partial and imperfect sources, into accurate prediction models. This work conducts a systematic literature review focused on ML-based TSP techniques, aiming to perform an in-depth analysis of the state of the art, thus gaining insights regarding future avenues of research. To that end, we analyze 29 primary studies published from 2006 to 2020, which have been identified through a systematic and documented process. This paper addresses five research questions addressing variations in ML-based TSP techniques and feature sets for training and testing ML models, alternative metrics used for evaluating the techniques, the performance of techniques, and the reproducibility of the published studies. We summarize the results related to our research questions in a high-level summary that can be used as a taxonomy for classifying future TSP studies.|||Review||||
WEB OF SCIENCE|Sinha, Aman|||Safety-Critical Machine Learning: Development and Testing|2020||||||||||||||Dissertation/Thesis||||
WEB OF SCIENCE|Lee, Jubin; Kim, Taeho; Ma, Yuseung|||Approximating the Accuracy of Classification Models Using Self-differential Testing|2022|Journal of KIISE|49|12||1143|1153|||10.5626/JOK.2022.49.12.1143||Differential testing is a traditional software testing technique that detects errors by observing whether similar applications generate different outputs for the same input. Differential testing is also used in artificial intelligence systems. Existing research involves the cost of finding a high-quality reference neural network with the same function as the target neural network but different architectures. We propose a self-differential testing technique that evaluates a classification model by making a reference model using a target neural network without the need to find the neural network of another architecture when differential testing. Experiments confirmed that self-differential testing produced similar effects at a lower cost than the existing research that requires other reference models.In addition, we propose an accuracy approximation method for classification models using self-differential analysis, which is an application of self-differential testing. The approximate accuracy through self-differential testing was confirmed to show a small difference of 0.0002 to 0.09 from the actual accuracy in experiments using similar datasets of MNIST and CIFAR10.|||research-article||||
WEB OF SCIENCE|Jung, Jee Woo; Kim, Taeho; Kwon, Taekyoung|||A Study of Machine Learning-Based Scheduling Strategy for Fuzzing|2024|Journal of The Korea Institute of Information Security and Cryptology|34|5||973|980|||10.13089/JKIISC.2024.34.5.973||Fuzzing is an automated testing technique that generates a lot of testcases and monitors for exceptions to test a program. Recently, fuzzing research using machine learning has been actively proposed to solve various problems in the fuzzing process, but a comprehensive evaluation of fuzzing research using machine learning is lacking. In this paper, we analyze recent research that applies machine learning to scheduling techniques for fuzzing, categorizing them into reinforcement learning-based and supervised learning-based fuzzers. We evaluated the coverage performance of the analyzed machine learning-based fuzzers against real-world programs with four different file formats and bug detection performance against the LAVA-M dataset. The results showed that AFL-HIER, which applied seed clustering and seed scheduling with reinforcement learning outperformed in coverage and bug detection. In the case of supervised learning, it showed high coverage on tcpdumps with high code complexity, and its superior bug detection performance when applied to hybrid fuzzing. This research shows that performance of machine learning-based fuzzer is better when both machine learning and additional fuzzing techniques are used to optimize the fuzzing process. Future research is needed on practical and robust machine learning-based fuzzing techniques that can be effectively applied to programs that handle various input formats.|||research-article||||
WEB OF SCIENCE|Li, Hui; Liu, Yong; Qi, Xuexin; Yu, Xi; Guo, Shikai|||Structuring meaningful bug-fixing patches to fix software defect|2023|IET SOFTWARE|17|4||566|581|||10.1049/sfw2.12140||Currently, software projects require a significant amount of time, effort and other resources to be invested in software testing to reduce the number of code defects. However, this process decreases the efficiency of software development and leads to a significant waste of workforce and resources. To address this challenge, researchers developed various solutions utilising deep neural networks. However, these solutions are frequently challenged by issues, such as a vast vocabulary, network training difficulties and elongated training processes resulting from the handling of redundant information. To overcome these limitations, the authors proposed a new neural network-based model named HopFix, designed to detect software defects that may be introduced during the coding process. HopFix consists of four parts: data preprocessing, encoder, decoder and code generation components, which were used for preprocessing data, extracting information about software defects, analysing defect information, generating software patches and controlling the generation process of software patches, respectively. Experimental studies on Bug-Fix Pairs (BFP) show that HopFix correctly fixed 47.2% (BFPsmall datasets) and 25.7% (BFPmedium datasets) of software defects.|||Article||||
WEB OF SCIENCE|Fraser, Gordon; Arcuri, Andrea|||A Retrospective on Whole Test Suite Generation: On the Role of SBST in the Age of LLMs|2025|IEEE TRANSACTIONS ON SOFTWARE ENGINEERING|51|3||874|878|||10.1109/TSE.2025.3539458||This paper presents a retrospective of the article Whole Test Suite Generation, published in the IEEE Transactions on Software Engineering, in 2012. We summarize its main contributions, and discuss how this work impacted the research field of Search-Based Software Testing (SBST) in the last 12 years. The novel techniques presented in the paper were implemented in the tool EvoSuite, which has been so far the state-of-the-art in unit test generation for Java programs using SBST. SBST has shown practical and impactful applications, creating the foundations to open the doors to tackle several other software testing problems besides unit testing, like for example system testing of Web APIs with EvoMaster. We conclude our retrospective with our reflections on what lies ahead, especially considering the important role that SBST still plays even in the age of Large Language Models (LLMs).|||Article||||
WEB OF SCIENCE|Soucha, Michal; Bogdanov, Kirill|||Observation Tree Approach: Active Learning Relying on Testing|2020|COMPUTER JOURNAL|63|9||1298|1310|||10.1093/comjnl/bxz056||The correspondence of active learning and testing of finite-state machines (FSMs) has been known for a while; however, it was not utilized in the learning. We propose a new framework called the observation tree approach that allows one to use the testing theory to improve the performance of active learning. The improvement is demonstrated on three novel learning algorithms that implement the observation tree approach. They outperform the standard learning algorithms, such as the L* algorithm, in the setting where a minimally adequate teacher provides counterexamples. Moreover, they can also significantly reduce the dependency on the teacher using the assumption of extra states that is well-established in the testing of FSMs. This is immensely helpful as a teacher does not have to be available if one learns a model of a black box, such as a system only accessible via a network.|||Article||||
WEB OF SCIENCE|Majumder, Suvodeep; Chakraborty, Joymallya; Bai, Gina R.; Stolee, Kathryn T.; Menzies, Tim|||Fair Enough: Searching for Sufficient Measures of Fairness|2023|ACM TRANSACTIONS ON SOFTWARE ENGINEERING AND METHODOLOGY|32|6|134|||||10.1145/3585006||Testing machine learning software for ethical bias has become a pressing current concern. In response, recent research has proposed a plethora of new fairness metrics, for example, the dozens of fairness metrics in the IBM AIF360 toolkit. This raises the question: How can any fairness tool satisfy such a diverse range of goals? While we cannot completely simplify the task of fairness testing, we can certainly reduce the problem. This article shows that many of those fairness metrics effectively measure the same thing. Based on experiments using seven real-world datasets, we find that (a) 26 classification metrics can be clustered into seven groups and (b) four dataset metrics can be clustered into three groups. Further, each reduced set may actually predict different things. Hence, it is no longer necessary (or even possible) to satisfy all fairness metrics. In summary, to simplify the fairness testing problem, we recommend the following steps: (1) determine what type of fairness is desirable (and we offer a handful of such types), then (2) lookup those types in our clusters, and then (3) just test for one item per cluster.For the purpose of reproducibility, our scripts and data are available at https://github.com/Repoanonymous/Fairness_Metrics.|||Article||||
WEB OF SCIENCE|Madeyski, Lech; Stradowski, Szymon|||Predicting test failures induced by software defects: A lightweight alternative to software defect prediction and its industrial application☆|2025|JOURNAL OF SYSTEMS AND SOFTWARE|223||112360|||||10.1016/j.jss.2025.112360||Context: Machine Learning Software Defect Prediction (ML SDP) is a promising method to improve the quality and minimise the cost of software development. Objective: We aim to: (1) apropose and develop a Lightweight Alternative to SDP (LA2SDP) that predicts test failures induced by software defects to allow pinpointing defective software modules thanks to available mapping of predicted test failures to past defects and corrected modules, (2) preliminary evaluate the proposed method in a real-world Nokia 5G scenario. Method: We train machine learning models using test failures that come from confirmed software defects already available in the Nokia 5G environment. We implement LA2SDP using five supervised ML algorithms, together with their tuned versions, and use eXplainable AI (XAI) to provide feedback to stakeholders and initiate quality improvement actions. Results: We have shown that LA2SDP is feasible in vivo using test failure-to-defect report mapping readily available within the Nokia 5G system-level test process, achieving good predictive performance. Specifically, CatBoost Gradient Boosting turned out to perform the best and achieved satisfactory Matthew's Correlation Coefficient (MCC) results for our feasibility study. Conclusions: Our efforts have successfully defined, developed, and validated LA2SDP, using the sliding and expanding window approaches on an industrial data set.|||Article||||
WEB OF SCIENCE|Gao, Honghao; Dai, Baobin; Miao, Huaikou; Yang, Xiaoxian; Barroso, Ramon J. Duran; Walayat, Hussain|||A Novel GAPG Approach to Automatic Property Generation for Formal Verification: The GAN Perspective|2023|ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS|19|1|16|||||10.1145/3517154||Formal methods have been widely used to support software testing to guarantee correctness and reliability. For example, model checking technology attempts to ensure that the verification property of a specific formal model is satisfactory for discovering bugs or abnormal behavior from the perspective of temporal logic. However, because automatic approaches are lacking, a software developer/tester must manually specify verification properties. A generative adversarial network (GAN) learns features from input training data and outputs new data with similar or coincident features. GANs have been successfully used in the image processing and text processing fields and achieved interesting and automatic results. Inspired by the power of GANs, in this article, we propose a GAN-based automatic property generation (GAPG) approach to generate verification properties supporting model checking. First, the verification properties in the form of computational tree logic (CTL) are encoded and used as input to the GAN. Second, we introduce regular expressions as grammar rules to check the correctness of the generated properties. These rules work to detect and filter meaningless properties that occur because the GAN learning process is uncontrollable and may generate unsuitable properties in real applications. Third, the learning network is further trained by using labeled information associated with the input properties. These are intended to guide the training process to generate additional new properties, particularly those that map to corresponding formal models. Finally, a series of comprehensive experiments demonstrate that the proposed GAPG method can obtain new verification properties from two aspects: (1) using only CTL formulas and (2) using CTL formulas combined with Kripke structures.|||Article||||
WEB OF SCIENCE|Braun, David; Marb, Michael M.; Angelov, Jorg; Wechner, Maximilian; Holzapfel, Florian|||Worst-Case Analysis of Complex Nonlinear Flight Control Designs Using Deep Q-Learning|2023|JOURNAL OF GUIDANCE CONTROL AND DYNAMICS|46|7||1365|1377|||10.2514/1.G007335||With the objective of exposing hidden design deficiencies in complex nonlinear systems, this paper presents the use of reinforcement learning techniques for application in flight control law development and testing. Following the idea of worst-case testing, a deep Q-network agent is trained to identify input sequences that lead to detrimental system behavior. Because the analysis is based directly on the repeated interaction between the agent and the investigated system, no model simplifications are required, making the presented method applicable to highly complex systems. The capability of the learning-based worst-case analysis is demonstrated for the speed protection function of the hover flight control law of an electric vertical takeoff and landing (eVTOL) aircraft. The analysis discovers possible piloted maneuvers that violate the implemented protection algorithm. A root cause analysis of the emerging behavior reveals the neglect of an important flight mechanical coupling term in the design of the protection algorithm and ultimately leads to the revision and improvement of the controller. This demonstrates the benefits of the presented testing method for the design, verification, and validation of complex systems. The application to a high-fidelity system used for control law development of an actual eVTOL prototype currently under construction demonstrates the relevance of the method beyond academia.|||Article||||
WEB OF SCIENCE|Lee, Minsoo; Gun, Lee Chan|||Evaluating Test Data for Deep Learning Using Mutation Software Testing|2020|KIISE Transactions on Computing Practices|26|3||173|177|||10.5626/KTCP.2020.26.3.173||Recently, various studies for effective deep neural network testing have been actively conducted to automatically generate test data uncovering the cases wherein deep neural networks misbehave and measure the diversity and quality of data sets. In this paper, we propose a method for automatically generating high quality test data for a bug fixer recommendation system based on deep neural networks, and evaluate and analyze the quality of automatically generated data by applying mutation software testing. We also analyze the quality by comparing the actual error situation for the generated data and the actual error situation for original data from the bug fixer recommendation system.|||research-article||||
WEB OF SCIENCE|Wang, Zhongmin; Xi, Kang; Gao, Cong; Jin, Xiaomin; Chen, Yanping; Lu, Chen|||A real-time object detection method for electronic screen GUI test systems|2024|JOURNAL OF SUPERCOMPUTING|80|15||22803|22835|||10.1007/s11227-024-06319-y||Automated testing of GUI elements on electronic screens by machine vision is widely used in smart manufacturing production lines. However, in the complex environment of factories, interference factors such as light reflection, platform vibration, and placement angle make it difficult for testing robots to recognize and locate GUI elements on the equipment's screen to be tested. In addition, the recognition algorithms based on screen GUI elements currently have problems such as slow detection speed and large model size, which limit the deployment of detection models on test robots. To address these problems, this paper proposes a lightweight model that can overcome the interference of the factory environment based on the YOLOv5 algorithm for recognizing GUI elements. First, a reinforced position and channel attention module (PCA) is proposed to enhance the extraction and fusion ability of weak feature elements affected by interference; then, a three-way feature pyramid network (TWFPN) module is constructed at the intermediate feature layer of the neck structure to provide more accurate localization information. Meanwhile, the loss function of the original algorithm is replaced with SIoU to improve the convergence speed. Finally, a lightweight structure combining the Ghost module and PConv is introduced into the model to reduce the model parameters and improve the detection speed. The method was evaluated on the constructed feature-enhanced GUI (FE_GUI) dataset. The final model shows a 2.7% improvement in average accuracy (mAP@0.5), a 30% reduction in model weight, and an increase in detection speed to 85 FPS compared to the original YOLOv5. The results demonstrate that the method solves the issues of element recognition and model deployment for a vision test system and surpasses existing models in terms of recognition accuracy and detection speed.|||Article||||
WEB OF SCIENCE|Prado Lima, Jackson A.; Mendonca, Willian D. F.; Vergilio, Silvia R.; Assuncao, Wesley K. G.|||Cost-effective learning-based strategies for test case prioritization in continuous integration of highly-configurable software|2022|EMPIRICAL SOFTWARE ENGINEERING|27|6|133|||||10.1007/s10664-021-10093-3||Highly-Configurable Software (HCSs) testing is usually costly, as a significant number of variants need to be tested. This becomes more problematic when Continuous Integration (CI) practices are adopted. CI leads the software to be integrated and tested multiple times a day, subject to time constraints (budgets). To address CI challenges, a learning-based test case prioritization approach named COLEMAN has been successfully applied. COLEMAN deals with test case volatility, in which some test cases can be included/removed over the CI cycles. Nevertheless, such an approach does not consider HCS particularities such as, by analogy, the volatility of variants. Given such a context, this work introduces two strategies for applying COLEMAN in the CI of HCS: the Variant Test Set Strategy (VTS) that relies on the test set specific for each variant; and the Whole Test Set Strategy (WST) that prioritizes the test set composed by the union of the test cases of all variants. Both strategies are applied to two real-world HCSs, considering three test budgets. Independently of the time budget, the proposed strategies using COLEMAN have the best performance in comparison with solutions generated randomly and by another learning approach from the literature. Moreover, COLEMAN produces, in more than 92% of the cases, reasonable solutions that are near to the optimal solutions obtained by a deterministic approach. Both strategies spend less than one second to execute. WTS provides better results in the less restrictive budgets, and VTS the opposite. WTS seems to better mitigate the problem of beginning without knowledge, and is more suitable when a new variant to be tested is added.|||Article||||
WEB OF SCIENCE|Ressurreição, Bruna|||Application of Machine Learning Models to Software Test Automation Processes|2022||||||||||||||Dissertation/Thesis||||
WEB OF SCIENCE|Pasca, Emil Marian; Delinschi, Daniela; Erdei, Rudolf; Matei, Oliviu|||LLM-Driven, Self-Improving Framework for Security Test Automation: Leveraging Karate DSL for Augmented API Resilience|2025|IEEE ACCESS|13|||56861|56886|||10.1109/ACCESS.2025.3554960||Modern software architectures heavily rely on APIs, yet face significant security challenges, particularly with Broken Object Level Authorization (BOLA) vulnerabilities, which remain the most critical API security risk according to OWASP. This paper introduces Karate-BOLA-Guard, an innovative framework leveraging Large Language Models (LLMs) and Retrieval-Augmented Generation (RAG) techniques to automate security-focused test case generation for APIs. Our approach integrates vector databases for context retrieval, multiple LLM models for test generation, and observability tools for process monitoring. Initial experiments were carried out on three deliberately vulnerable APIs (VAmPI, Crapi, and OWASP Juice Shop), with subsequent validation on fifteen additional production APIs spanning diverse domains including social media, version control systems, financial services, and transportation services. Our evaluation metrics show Llama 3 8B achieving consistent performance (Accuracy: 3.1-3.4, Interoperability: 3.7-4.3) with an average processing time of 143.76 seconds on GPU. Performance analysis revealed significant GPU acceleration benefits, with 20-25x improvement over CPU processing times. Smaller models demonstrated efficient processing, with Phi-3 Mini averaging 69.58 seconds and Mistral 72.14 seconds, while maintaining acceptable accuracy scores. Token utilization patterns showed Llama 3 8B using an average of 36,591 tokens per session, compared to Mistral's 25,225 and Phi-3 Mini's 31,007. Our framework's effectiveness varied across APIs, with notably strong performance in complex platforms (Instagram: A = 4.3, I = 4.4) while maintaining consistent functionality in simpler implementations (VAmPI: A = 3.6, I = 4.3). The iterative refinement process, evaluated through comprehensive metrics including Accuracy (A), Complexity (C), and Interoperability (I), represents a significant advancement in automated API security testing, offering an efficient, accurate, and adaptable approach to detecting BOLA vulnerabilities across diverse API architectures.|||Article||||
WEB OF SCIENCE|Lee, Inkyoun; Kang, Dongsu|||Generating Metamorphic Test Cases for Transformer-based Korean Summary|2023|KIISE Transactions on Computing Practices|29|11||509|517|||10.5626/KTCP.2023.29.11.509||Recently, AI-based software such as ChatGPT has become popular. Consequently, interest in quality assurance testing of software is increasing. This study proposes a test case using a metamorphic relationship for a transformer-based Korean summary for software testing. First, the test set using the Defense Daily is transformed using certain rules and then entered into the T5 model.After inputting the transformed test set, we checked whether the output result according to the input and the existing output result satisfy the metamorphic relationship. We then evaluated the performance of the model using the document summary performance metrics Rouge and Rdass. The experimental results showed that MR1, which transforms names or nouns, and MR5 and MR6, which transform nouns/verbs into synonyms, satisfy the metamorphic relationship with 82%. In addition, the summarization performance of the T5 improved by 13% compared to the models in the previous study.After that, We used Rouge-u, Rouge-su, and Rdass scores. These are the scores that were not covered in the previous studies. Through these scores, the types of performance scores that evaluate the Korean summaries were expanded.|||research-article||||
WEB OF SCIENCE|Yaraghi, Ahmadreza Saboor; Bagherzadeh, Mojtaba; Kahani, Nafiseh; Briand, Lionel C.|||Scalable and Accurate Test Case Prioritization in Continuous Integration Contexts|2023|IEEE TRANSACTIONS ON SOFTWARE ENGINEERING|49|4||1615|1639|||10.1109/TSE.2022.3184842||Continuous Integration (CI) requires efficient regression testing to ensure software quality without significantly delaying its CI builds. This warrants the need for techniques to reduce regression testing time, such as Test Case Prioritization (TCP) techniques that prioritize the execution of test cases to detect faults as early as possible. Many recent TCP studies employ various Machine Learning (ML) techniques to deal with the dynamic and complex nature of CI. However, most of them use a limited number of features for training ML models and evaluate the models on subjects for which the application of TCP makes little practical sense, due to their small regression testing time and low number of failed builds. In this work, we first define, at a conceptual level, a data model that captures data sources and their relations in a typical CI environment. Second, based on this data model, we define a comprehensive set of features that covers all features previously used by related studies. Third, we develop methods and tools to collect the defined features for 25 open-source software systems with enough failed builds and whose regression testing takes at least five minutes. Fourth, relying on the collected dataset containing a comprehensive feature set, we answer four research questions concerning data collection time, the effectiveness of ML-based TCP, the impact of the features on effectiveness, the decay of ML-based TCP models over time, and the trade-off between data collection time and the effectiveness of ML-based TCP techniques.|||Article||||
WEB OF SCIENCE|Guo, Xiujing; Okamura, Hiroyuki; Dohi, Tadashi|||Automated Software Test Data Generation With Generative Adversarial Networks|2022|IEEE ACCESS|10|||20690|20700|||10.1109/ACCESS.2022.3153347||With the rapid increase of software scale and complexity, the cost of traditional software testing methods will increase faster than the scale of software. In order to improve test efficiency, it is particularly important to automatically generate high-quality test cases. This paper introduces a framework for automatic test data generation based on the generative adversarial network (GAN). GAN is employed to train a generative model over execution path information to learn the behavior of the software. Then we can use the trained generative model to produce new test data, and select the test data that can improve the branch coverage according to our proposed selection strategy. Compared to prior work, our proposed method is able to handle programs under test with large-scale branches without analyzing branch expressions. In the experiment, we exhibit the performance of our method by using two modules in GNU Scientific Library. In particular, we consider the application of our method in two testing scenarios; unit testing and integration testing, and conduct a series of experiments to compare the performance of three types of GAN models. Results indicate that the WGAN-GP shows the best performance in our framework. Compared with the random testing method, the WGAN-GP based framework improves the test coverage of five functions out of the seven in the unit testing.|||Article||||
WEB OF SCIENCE|Kim,, Hyeon Soo; 이상인|||Test Case Generation Based on Use Cases Using ChatGPT : Experimental Evaluation|2024|Journal of Defense Quality Society (J. Def. Qual. Soc.)|6|1||73|82|||||In this study, we investigate the potential of ChatGPT, which is a generative AI tool, in automating test case generation. Based on systematic experiments, we analyze the response of ChatGPT to myriad use-case information structures to obtain insights into its behavior and output. The primary aim is to devise strategies for harnessing generative AIs, such as ChatGPT, in test case generation and broader software testing. The findings provide clearer understanding into the manner by which AI contributes to test case generation, thus suggesting a direction for future endeavors in integrating such models into software quality assurance.|||research-article||||
WEB OF SCIENCE|Xu, Junzhuo; Shi, Guoqing; Li, Bingqin; Fischer, Thomas B.; Zhang, Ruilian; Yan, Dengcai; Jiang, Jingjun; Yang, Qi; Sun, Zhonggen|||Skills' sets and shared benefits: perceptions of resettled people from the Yangtze-Huai River Diversion Project in China|2021|IMPACT ASSESSMENT AND PROJECT APPRAISAL|39|5||429|438|||10.1080/14615517.2020.1848242||Development induced displacement and resettlement (DIDR) projects should share their benefits with those affected by them. This paper shows that in the case of the Yangtze-Huai River Diversion Project in China perceptions of compensation received differs amongst different groups of resettled people even if levels of compensation are similar. Based on a survey with displaced people, a fuzzy comprehensive evaluation concludes that those with generic skills' sets are the most satisfied, mainly because they are able to find new work and re-establish livelihoods after resettlement more quickly. On the other hand, those with only agricultural skills find it difficult to re-establish their livelihood and are often dissatisfied. Finally, those who did not have any work before resettlement were found to be satisfied overall as their life quality is said to have improved. The skills of those affected are therefore a key explanatory factor for satisfaction with compensation following resettlement.|||Article||||
WEB OF SCIENCE|Sutter, Thomas; Kehrer, Timo; Rennhard, Marc; Tellenbach, Bernhard; Klein, Jacques|||Dynamic Security Analysis on Android: A Systematic Literature Review|2024|IEEE ACCESS|12|||57261|57287|||10.1109/ACCESS.2024.3390612||Dynamic analysis is a technique that is used to fully understand the internals of a system at runtime. On Android, dynamic security analysis involves real-time assessment and active adaptation of an app's behaviour, and is used for various tasks, including network monitoring, system-call tracing, and taint analysis. The research on dynamic analysis has made significant progress in the past years. However, to the best of our knowledge, there is a lack in secondary studies that analyse the novel ideas and common limitations of current security research. The main aim of this work is to understand dynamic security analysis research on Android to present the current state of knowledge, highlight research gaps, and provide insights into the existing body of work in a structured and systematic manner. We conduct a systematic literature review (SLR) on dynamic security analysis for Android. The systematic review establishes a taxonomy, defines a classification scheme, and explores the impact of advanced Android app testing tools on security solutions in software engineering and security research. The study's key findings centre on tool usage, research objectives, constraints, and trends. Instrumentation and network monitoring tools play a crucial role, with research goals focused on app security, privacy, malware detection, and software testing automation. Identified limitations include code coverage constraints, security-related analysis obstacles, app selection adequacy, and non-deterministic behaviour. Our study results deepen the understanding of dynamic analysis in Android security research by an in-depth review of 43 publications. The study highlights recurring limitations with automated testing tools and concerns about detecting or obstructing dynamic analysis.|||Article||||
WEB OF SCIENCE|Morovati, Mohammad Mehdi; Nikanjam, Amin; Khomh, Foutse; Jiang, Zhen Ming (Jack)|||Bugs in machine learning-based systems: a faultload benchmark|2023|EMPIRICAL SOFTWARE ENGINEERING|28|3|62|||||10.1007/s10664-023-10291-1||The rapid escalation of applying Machine Learning (ML) in various domains has led to paying more attention to the quality of ML components. There is then a growth of techniques and tools aiming at improving the quality of ML components and integrating them into the ML-based system safely. Although most of these tools use bugs' lifecycle, there is no standard benchmark of bugs to assess their performance, compare them and discuss their advantages and weaknesses. In this study, we firstly investigate the reproducibility and verifiability of the bugs in ML-based systems and show the most important factors in each one. Then, we explore the challenges of generating a benchmark of bugs in ML-based software systems and provide a bug benchmark namely defect4ML that satisfies all criteria of standard benchmark, i.e. relevance, reproducibility, fairness, verifiability, and usability. This faultload benchmark contains 100 bugs reported by ML developers in GitHub and Stack Overflow, using two of the most popular ML frameworks: TensorFlow and Keras. defect4ML also addresses important challenges in Software Reliability Engineering of ML-based software systems, like: 1) fast changes in frameworks, by providing various bugs for different versions of frameworks, 2) code portability, by delivering similar bugs in different ML frameworks, 3) bug reproducibility, by providing fully reproducible bugs with complete information about required dependencies and data, and 4) lack of detailed information on bugs, by presenting links to the bugs' origins. defect4ML can be of interest to ML-based systems practitioners and researchers to assess their testing tools and techniques.|||Article||||
WEB OF SCIENCE|Rajan, Sai Sathiesh; Soremekun, Ezekiel; Le Traon, Yves; Chattopadhyay, Sudipta|||Distribution-aware fairness test generation|2024|JOURNAL OF SYSTEMS AND SOFTWARE|215||112090|||||10.1016/j.jss.2024.112090||Ensuring that all classes of objects are detected with equal accuracy is essential in AI systems. For instance, being unable to identify any one class of objects could have fatal consequences in autonomous driving systems. Hence, ensuring the reliability of image recognition systems is crucial. This work addresses how to validate group fairness in image recognition software . We propose a distribution-aware fairness testing approach (called DistroFair ) that systematically exposes class-level fairness violations in image classifiers via a synergistic combination of out-of-distribution (OOD) testing and semantic-preserving image mutation . DistroFair automatically learns the distribution (e.g., number/orientation) of objects in a set of images. Then it systematically mutates objects in the images to become OOD using three semantic-preserving image mutations - object deletion , object insertion and object rotation . We evaluate DistroFair using two well-known datasets (CityScapes and MS-COCO) and three major, commercial image recognition software (namely, Amazon Rekognition, Google Cloud Vision and Azure Computer Vision). Results show that about 21% of images generated by DistroFair reveal class-level fairness violations using either ground truth or metamorphic oracles. DistroFair is up to 2.3 x more effective than two main baselines , i.e., (a) an approach which focuses on generating images only within the distribution (ID) and (b) fairness analysis using only the original image dataset. We further observed that DistroFair is efficient, it generates 460 images per hour, on average. Finally, we evaluate the semantic validity of our approach via a user study with 81 participants, using 30 real images and 30 corresponding mutated images generated by DistroFair . We found that images generated by DistroFair are 80% as realistic as real-world images.|||Article||||
WEB OF SCIENCE|Muthuhetti Gamage, Shalika Udeshini|||Enhancing Software Refactoring in the Sri Lankan Software Development Industry through Machine Learning Techniques:Challenges, and Intentions|2024||||||||||||||Dissertation/Thesis||||
WEB OF SCIENCE|Yang, Yanming; Xia, Xin; Lo, David; Bi, Tingting; Grundy, John; Yang, Xiaohu|||Predictive Models in Software Engineering: Challenges and Opportunities|2022|ACM TRANSACTIONS ON SOFTWARE ENGINEERING AND METHODOLOGY|31|3|56|||||10.1145/3503509||Predictive models are one of the most important techniques that are widely applied in many areas of software engineering. There have been a large number of primary studies that apply predictive models and that present well-performed studies in various research domains, including software requirements, software design and development, testing and debugging, and software maintenance. This article is a first attempt to systematically organize knowledge in this area by surveying a body of 421 papers on predictive models published between 2009 and 2020. We describe the key models and approaches used, classify the different models, summarize the range of key application areas, and analyze research results. Based on our findings, we also propose a set of current challenges that still need to be addressed in future work and provide a proposed research road map for these opportunities.|||Article||||
WEB OF SCIENCE||||Research on improving coverage of machine learning based software testing|2022||||||||||||||Awarded Grant||||
WEB OF SCIENCE|Alonso, Juan C.; Martin-Lopez, Alberto; Segura, Sergio; Garcia, Jose Maria; Ruiz-Cortes, Antonio|||ARTE: Automated Generation of Realistic Test Inputs for Web APIs|2023|IEEE TRANSACTIONS ON SOFTWARE ENGINEERING|49|1||348|363|||10.1109/TSE.2022.3150618||Automated test case generation for web APIs is a thriving research topic, where test cases are frequently derived from the API specification. However, this process is only partially automated since testers are usually obliged to manually set meaningful valid test inputs for each input parameter. In this article, we present ARTE, an approach for the automated extraction of realistic test data for web APIs from knowledge bases like DBpedia. Specifically, ARTE leverages the specification of the API parameters to automatically search for realistic test inputs using natural language processing, search-based, and knowledge extraction techniques. ARTE has been integrated into RESTest, an open-source testing framework for RESTful APIs, fully automating the test case generation process. Evaluation results on 140 operations from 48 real-world web APIs show that ARTE can efficiently generate realistic test inputs for 64.9% of the target parameters, outperforming the state-of-the-art approach SAIGEN (31.8%). More importantly, ARTE supported the generation of over twice as many valid API calls (57.3%) as random generation (20%) and SAIGEN (26%), leading to a higher failure detection capability and uncovering several real-world bugs. These results show the potential of ARTE for enhancing existing web API testing tools, achieving an unprecedented level of automation.|||Article||||
WEB OF SCIENCE|Dakhel, Arghavan Moradi; Nikanjam, Amin; Majdinasab, Vahid; Khomh, Foutse; Desmarais, Michel C.|||Effective test generation using pre-trained Large Language Models and mutation testing|2024|INFORMATION AND SOFTWARE TECHNOLOGY|171||107468|||||10.1016/j.infsof.2024.107468||Context: One of the critical phases in the software development life cycle is software testing. Testing helps with identifying potential bugs and reducing maintenance costs. The goal of automated test generation tools is to ease the development of tests by suggesting efficient bug-revealing tests. Recently, researchers have leveraged Large Language Models (LLMs) of code to generate unit tests. While the code coverage of generated tests was usually assessed, the literature has acknowledged that the coverage is weakly correlated with the efficiency of tests in bug detection. Objective: To improve over this limitation, in this paper, we introduce MuTAP (Mutation Mu tation T est case generation using A ugmented P rompt) for improving the effectiveness of test cases generated by LLMs in terms of revealing bugs by leveraging mutation testing. Methods: Our goal is achieved by augmenting prompts with surviving mutants, as those mutants highlight the limitations of test cases in detecting bugs. MuTAP is capable of generating effective test cases in the absence of natural language descriptions of the Program Under Test (PUTs). We employ different LLMs within MuTAP and evaluate their performance on different benchmarks. Results: Our results show that our proposed method is able to detect up to 28% more faulty human-written code snippets. Among these, 17% remained undetected by both the current state-of-the-art fully-automated test generation tool (i.e., Pynguin) and zero-shot/few-shot learning approaches on LLMs. Furthermore, MuTAP achieves a Mutation Score (MS) of 93.57% on synthetic buggy code, outperforming all other approaches in our evaluation. Conclusion: Our findings suggest that although LLMs can serve as a useful tool to generate test cases, they require specific post-processing steps to enhance the effectiveness of the generated test cases which may suffer from syntactic or functional errors and may be ineffective in detecting certain types of bugs and testing corner cases in PUT s.|||Article||||
WEB OF SCIENCE|Yousefizadeh, Hossein; Gu, Shenghui; Briand, Lionel C.; Nasr, Ali|||Using Cooperative Co-Evolutionary Search to Generate Metamorphic Test Cases for Autonomous Driving Systems|2025|IEEE TRANSACTIONS ON SOFTWARE ENGINEERING|51|6||1882|1911|||10.1109/TSE.2025.3570897||Autonomous Driving Systems (ADSs) rely on Deep Neural Networks, allowing vehicles to navigate complex, open environments. However, the unpredictability of these scenarios highlights the need for rigorous system-level testing to ensure safety, a task usually performed with a simulator in the loop. Though one important goal of such testing is to detect safety violations, there are many undesirable system behaviors, that may not immediately lead to violations, that testing should also be focusing on, thus detecting more subtle problems and enabling a finer-grained analysis. This paper introduces Cooperative Co-evolutionary MEtamorphic test Generator for Autonomous systems (CoCoMEGA), a novel automated testing framework aimed at advancing system-level safety assessments of ADSs. CoCoMEGA combines Metamorphic Testing (MT) with a search-based approach utilizing Cooperative Co-Evolutionary Algorithms (CCEA) to efficiently generate a diverse set of test cases. CoCoMEGA emphasizes the identification of test scenarios that present undesirable system behavior, that may eventually lead to safety violations, captured by Metamorphic Relations (MRs). When evaluated within the CARLA simulation environment on the Interfuser ADS, CoCoMEGA consistently outperforms baseline methods, demonstrating enhanced effectiveness and efficiency in generating severe, diverse MR violations and achieving broader exploration of the test space. Further expert assessments of these violations confirmed that most represent real safety risks, which validates their practical relevance. These results underscore CoCoMEGA as a promising, more scalable solution to the inherent challenges in ADS testing with a simulator in the loop. Future research directions may include extending the approach to additional simulation platforms, applying it to other complex systems, and exploring methods for further improving testing efficiency such as surrogate modeling.|||Article||||
WEB OF SCIENCE|Kramer, Jeff|||Reflections of a Former Editor-in-Chief of TSE|2025|IEEE TRANSACTIONS ON SOFTWARE ENGINEERING|51|3||673|676|||10.1109/TSE.2024.3521306||This interview with Jeff Kramer offers an insight into his experiences and challenges as an Editor-in-Chief of IEEE TSE. It also provides some consideration of how the software engineering landscape was viewed during his tenure. Finally it offers some thoughts on the future of the journal and of the field of software engineering.|||Article||||
WEB OF SCIENCE|Haq, Southun Najjas Najmul; Medagedara, Nimali T.|||Artificial Intelligence Approach to Reduce PCR Tests|2023|ENGINEER-JOURNAL OF THE INSTITUTION OF ENGINEERS SRI LANKA|56|1||||||10.4038/engineer.v56i1.7569||Nowadays, the Covid- 19 crisis is the biggest global challenge to control. All scientists have been working during the last two years to find solutions for this crisis in numerous ways. Therefore, identifying a person having Covid-19, before entering public places and mainly to the hospitals is a timely need to reduce the transmission of the virus. Polymerase chain reaction (PCR) test is the primary diagnostic tool used to identify Covid-19 patients. However, due to the vast number of patients, the demand for PCR diagnostic assays cannot be met. This research study was primarily concerned with eliminating PCR testing to a certain extent through intelligent approaches. This paper discusses a model using computer vision-based approaches for detecting Covid-19. The automated testing technique, which is based on a questionnaire and eye color scanning, was performed with artificial intelligence-based image processing. This device is capable of recognizing the Covid-19 patients before they enter into hospitals or public locations. The CNN model was developed using an open-source data set provided by the world health organization (WHO). The result demonstrates an 89% accuracy, concluding that this system indicates an excellent prediction performance for the Covid-19 diagnosis.|||Article||||
WEB OF SCIENCE|Watson, Cody Allen|||Deep Learning in Software Engineering|2020||||||||||||||Dissertation/Thesis||||
WEB OF SCIENCE|Bodke, Saurabh|||Hybrid Test-Smell Based Approach for Prediction of Flaky Tests|2023||||||||||||||Dissertation/Thesis||||
WEB OF SCIENCE|Alqurashi, Saja Salem|||Towards Automated Security and Privacy Policies Specification and Analysis|2024||||||||||||||Dissertation/Thesis||||
WEB OF SCIENCE|Sun, Zhe; Hu, Chi; Li, Chunlei; Wu, Linbo|||Domain Ontology Construction and Evaluation for the Entire Process of Software Testing|2020|IEEE ACCESS|8|||205374|205385|||10.1109/ACCESS.2020.3037188||As an important part of software engineering, software testing is a knowledge-intensive work. In the process of software testing, inconsistent knowledge expression, diverse knowledge carriers, and a few experienced people have mastered most of the knowledge, which hinders the transfer and sharing of domain knowledge. Ontology is widely used in various stages of software engineering to define the semantic relationship between relevant information and knowledge. To solve the problem of knowledge silo in the process of software testing, this article forms an Entire Process Ontology on Software Testing (EPOST). EPOST covers the concepts and relationships of software testing process information, software test object information, and software defect information. The concepts and terms in the ontology are extracted from ISTQB, SWEBOK, IEEE std.829-2008 standard, and IEEE std.610.12-1990 standard. We adopt a comprehensive ontology construction method based on Dev. 101 method and Methontology method. The developed ontology is successfully evaluated by using validation and verification tests. Ontology verification uses an improved FOCA evaluation method by adding a cohesion metric. The evaluation result infers that EPOST has a high quality of ontology and good domain coverage, and achieves the purpose of ontology construction. Finally, we make a case study on the role of EPOST in software testing process. The results show that ontology-based application in the software testing process can promote the sharing and transmission of domain knowledge, and improve the testing process and testing quality.|||Article||||
WEB OF SCIENCE|chi, Jung won|||Study on Software Security Testing: Focused on Methodology|2024|Journal of Convergence Science, Technology, and Society|3|2||21|26|||10.56366/jcsts.2024.3.2.21||This paper emphasizes the importance of combining software testing and security checks. Software testing is a key process for finding and fixing internal defects, which improves the stability and reliability of the software. At the same time, today’s software faces security threats that can be more serious than typical functional errors, meaning security checks should happen throughout the entire Software Development Life Cycle (SDLC). AI-based code generation tools have become common, and they can lead to new and unpredictable defects in development. Therefore, it is necessary to move beyond traditional testing methods by verifying AI-generated code and detecting security risks early. This paper outlines various security approaches, including vulnerability assessments, penetration testing, and secure coding reviews, and explains how to integrate them into existing testing processes. By using this combined methodcalled Integrated Quality Assurancesoftware teams can achieve both reliability and security at the same time.|||research-article||||
WEB OF SCIENCE|Jordan, Benoit; Gorji, Maysam B.; Mohr, Dirk|||Neural network model describing the temperature- and rate-dependent stress-strain response of polypropylene|2020|INTERNATIONAL JOURNAL OF PLASTICITY|135||102811|||||10.1016/j.ijplas.2020.102811||A machine learning based model is proposed to describe the temperature and strain rate dependent response of polypropylene. A hybrid modeling approach is taken by combining mechanism-based and data-based modeling. The big data required for machine learning is generated using a custom-made robot-assisted testing system. Numerous large deformation experiments are performed on mildly-notched tensile specimens for temperatures ranging from 20 to 80 degrees C, and strain rates ranging from 10(-3) to 10(-1)/s. Without making any a priori assumptions on the specific mathematical form, the function relating the stress to the viscous strain, the viscous strain rate and temperature is identified using machine learning. In particular, a back propagation algorithm with Bayesian regularization is employed to identify a suitable neural network function based on the results from more than 40 experiments. The neural network model is employed in series with a temperature-dependent spring to describe the stress-strain response of polypropylene. The resulting constitutive equations are solved numerically to demonstrate that the identified model is capable to predict the experimentally-observed stress-strain response for strains of up to 0.6.|||Article||||
WEB OF SCIENCE|Swillus, Mark; Zaidman, Andy|||Sentiment overflow in the testing stack: Analyzing software testing posts on Stack Overflow|2023|JOURNAL OF SYSTEMS AND SOFTWARE|205||111804|||||10.1016/j.jss.2023.111804||Software testing is an integral part of modern software engineering practice. Past research has not only underlined its significance, but also revealed its multi-faceted nature. The practice of software testing and its adoption is influenced by many factors that go beyond tools or technology. This paper sets out to investigate the context of software testing from the practitioners' point of view by mining and analyzing sentimental posts on the widely used question and answer website Stack Overflow. By qualitatively analyzing sentimental expressions of practitioners, which we extract from the Stack Overflow dataset using sentiment analysis tools, we discern factors that help us to better understand the lived experience of software engineers with regards to software testing. Grounded in the data that we have analyzed, we argue that sentiments like insecurity, despair and aspiration, have an impact on practitioners' attitude towards testing. We suggest that they are connected to concrete factors like the level of complexity of projects in which software testing is practiced. Editor's note: Open Science material was validated by the Journal of Systems and Software Open Science Board.& COPY; 2023 The Author(s). Published by Elsevier Inc. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).|||Article||||
WEB OF SCIENCE|Saravanan, Akash; Guzdial, Matthew|||A Framework for Predicting the Impact of Game Balance Changes Through Meta Discovery|2024|IEEE TRANSACTIONS ON GAMES|16|4||821|830|||10.1109/TG.2024.3457822||A metagame is a collection of knowledge that goes beyond the rules of a game. In competitive, team-based games, such as Pokemon or League of Legends, it refers to the set of current dominant characters and/or strategies within the player base. Developer changes to the balance of the game can have drastic and unforeseen consequences on these sets of meta characters. A framework for predicting the impact of balance changes could aid developers in making more informed balance decisions. In this article, we present such a meta discovery framework, leveraging reinforcement learning for automated testing of balance changes. Our results demonstrate the ability to predict the outcome of balance changes in Pokemon Showdown, a collection of competitive Pokemon tiers, with high accuracy.|||Article||||
WEB OF SCIENCE|Aghamohammadi, Alireza; Mirian-Hosseinabadi, Seyed-Hassan|||An ensemble-based predictive mutation testing approach that considers impact of unreached mutants|2021|SOFTWARE TESTING VERIFICATION & RELIABILITY|||e1784|||||10.1002/stvr.1784||Predictive mutation testing (PMT) is a technique to predict whether a mutant is killed, using machine learning approaches. Researchers have proposed various methods for PMT over the years. However, the impact of unreached mutants on PMT is not fully addressed. A mutant is unreached if the statement on which the mutant is generated is not executed by any test cases. We aim at showing that unreached mutants can inflate PMT results. Moreover, we propose an alternative approach to PMT, suggesting a different interpretation for PMT. To this end, we replicated the previous PMT research. We empirically evaluated the suggested approach on 654 Java projects provided by prior literature. Our results indicate that the performance of PMT drastically decreases in terms of area under a receiver operating characteristic curve (AUC) from 0.833 to 0.517. Furthermore, PMT performs worse than random guesses on 27% of the projects. The proposed approach improves the PMT results, achieving the average AUC value of 0.613. As a result, we recommend researchers to remove unreached mutants when reporting the results.|||Article; Early Access||||
WEB OF SCIENCE|Valueian, M.; Attar, N.; Haghighi, H.; Vahidi-Asl, M.|||Constructing automated test oracle for low observable software|2020|SCIENTIA IRANICA|27|3||1333|1351|||10.24200/sci.2019.51494.2219||The application of machine learning techniques for constructing automated test oracles has been successful in recent years. However, existing machine learning based oracles are characterized by a number of deficiencies when applied to software systems with low observability, such as embedded software, cyber-physical systems, multimedia software programs, and computer games. This paper proposes a new black box approach to construct automated oracles that can be applied to software systems with low observability. The proposed approach employs an Artificial Neural Network algorithm that uses input values and corresponding pass/fail outcomes of the program under test as the training set. To evaluate the performance of the proposed approach, extensive experiments were carried out on several benchmarks. The results manifest the applicability of the proposed approach to software systems with low observability and its higher accuracy than a well-known machine learning based method. This study also assessed the effect of different parameters on the accuracy of the proposed approach. (C) 2020 Sharif University of Technology. All rights reserved.|||Article||||
WEB OF SCIENCE|Wang, Fujun; Cao, Zining; Tan, Lixing; Zong, Hui|||Survey on Learning-Based Formal Methods: Taxonomy, Applications and Possible Future Directions|2020|IEEE ACCESS|8|||108561|108578|||10.1109/ACCESS.2020.3000907||Formal methods play an important role in testing and verifying software quality, especially in modern society with rapid technological updates. Learning-based techniques have been extensively applied to learn (a model or model-free) for formal verification and to learn system specifications, and resulted in numerous contributions. Due to the fact that adequate system models are often difficult to design manually and manual definition of specifications for such software systems gets infeasible, which motivate new research directions in learning models and/or specifications from observed system behaviors automatically. This paper mainly concentrates on learning-based techniques in formal methods area. An up-to-date overview of the current state-of-the-art in learning-based formal methods is provided in the paper. This paper is not a comprehensive survey of learning-based techniques in formal methods area, but rather as a survey of the taxonomy, applications and possible future directions in learning-based formal methods.|||Article||||
WEB OF SCIENCE|Giamattei, Luca; Guerriero, Antonio; Pietrantuono, Roberto; Russo, Stefano|||Causality-driven Testing of Autonomous Driving Systems|2024|ACM TRANSACTIONS ON SOFTWARE ENGINEERING AND METHODOLOGY|33|3|74|||||10.1145/3635709||Testing Autonomous Driving Systems (ADS) is essential for safe development of self-driving cars. For thorough and realistic testing, ADS are usually embedded in a simulator and tested in interaction with the simulated environment. However, their high complexity and the multiple safety requirements lead to costly and ineffective testing. Recent techniques exploit many-objective strategies and ML to efficiently search the huge input space. Despite the indubitable advances, the need for smartening the search keep being pressing. This article presents CART (CAusal-Reasoning-driven Testing), a new technique that formulates testing as a causal reasoning task. Learning causation, unlike correlation, allows assessing the effect of actively changing an input on the output, net of possible confounding variables. CART first infers the causal relations between test inputs and outputs, then looks for promising tests by querying the learnt model. Only tests suggested by the model are run on the simulator. An extensive empirical evaluation, using Pylot as ADS and CARLA as simulator, compares CART with state-of-the-art algorithms used recently on ADS. CART shows a significant gain in exposing more safety violations and does so more efficiently. More broadly, the work opens to a wider exploitation of causal learning beside (or on top of) ML for testing-related tasks.|||Article||||
WEB OF SCIENCE|Sun, Weifeng; Guo, Zhenting; Yan, Meng; Liu, Zhongxin; Lei, Yan; Zhang, Hongyu|||Method-Level Test-to-Code Traceability Link Construction by Semantic Correlation Learning|2024|IEEE TRANSACTIONS ON SOFTWARE ENGINEERING|50|10||2656|2676|||10.1109/TSE.2024.3449917||Test-to-code traceability links (TCTLs) establish links between test artifacts and code artifacts. These links enable developers and testers to quickly identify the specific pieces of code tested by particular test cases, thus facilitating more efficient debugging, regression testing, and maintenance activities. Various approaches, based on distinct concepts, have been proposed to establish method-level TCTLs, specifically linking unit tests to corresponding focal methods. Static methods, such as naming-convention-based methods, use heuristic- and similarity-based strategies. However, such methods face the following challenges: (1) Developers, driven by specific scenarios and development requirements, may deviate from naming conventions, leading to TCTL identification failures. (2) Static methods often overlook the rich semantics embedded within tests, leading to erroneous associations between tests and semantically unrelated code fragments. Although dynamic methods achieve promising results, they require the project to be compilable and the tests to be executable, limiting their usability. This limitation is significant for downstream tasks requiring massive test-code pairs, as not all projects can meet these requirements. To tackle the abovementioned limitations, we propose a novel static method-level TCTL approach, named TestLinker. For the first challenge of existing static approaches, TestLinker introduces a two-phase TCTL framework to accommodate different project types in a triage manner. As for the second challenge, we employ the semantic correlation learning, which learns and establishes the semantic correlations between tests and focal methods based on Pre-trained Code Models (PCMs). TestLinker further establishes mapping rules to accurately link the recommended function name to the concrete production function declaration. Empirical evaluation on a meticulously labeled dataset reveals that TestLinker significantly outperforms traditional static techniques, showing average F1-score improvements ranging from 73.48% to 202.00%. Moreover, compared to state-of-the-art dynamic methods, TestLinker, which only leverages static information, demonstrates comparable or even better performance, with an average F1-score increase of 37.40%.|||Article||||
WEB OF SCIENCE|Suman; Khan, Raees Ahmad|||An optimized neural network for prediction of security threats on software testing|2024|COMPUTERS & SECURITY|137||103626|||||10.1016/j.cose.2023.103626||Software testing involves evaluating and confirming a software program or product to ensure it operates according to its intended functionality. Testing offers advantages like bug prevention, reduced development expenses, and improved performance. The problems are dialogue gap, ecological danger, creation of software quickly, cost of operation and upkeep, inadequate assessment, and incorrect testing estimates. The structure was initially educated using internet presentation data that included intrusion information. A novel Dove Swarmbased Deep Neural Method (DSbDNM) with the required traits and stages of processing has been developed. Moving forward, feature extraction and malicious behaviour forecast have both been completed. Also, the different types of assaults and negative behaviours were categorized. The developed prediction model is also examined by initiating and detecting an unidentified assault. Finally, the performance measures' accuracy, error rate, Precision, Recall and f-measure were computed. Moreover, the proposed system implementation is done in Python. Therefore, the proposed work performance can be enhanced and attain high accuracy in low computational time. For the DSbDNM dataset, the designed prototypical achieved 94.65 accuracy, 94.95 precision, 90.16 Recall and 92.02 F-measure for the NF-UQ-NIDS-v2 Dataset. Moreover, the Intrusion Detection Dataset attained an accuracy of 98, Precision of 98.8, Recall of 94.2, and F-score of 96 in the developed model. Subsequently, the Network Intrusion Detection Dataset attained an accuracy of 99, a precision of 99.2, a Recall of 95.8 and an F-measure of 97.1|||Article||||
WEB OF SCIENCE|Chouhan, Satyendra Singh; Rathore, Santosh Singh|||Generative Adversarial Networks-Based Imbalance Learning in Software Aging-Related Bug Prediction|2021|IEEE TRANSACTIONS ON RELIABILITY|70|2||626|642|||10.1109/TR.2021.3052510||Software aging refers to a problem of performance decay in the software systems, which are running for a long period. The primary cause of this phenomenon is the accumulation of run-time errors in the software, which are also known as aging-related bugs (ARBs). Many efforts have been reported earlier to predict the origin of ARBs in the software so that these bugs can be identified and fixed during testing. Imbalanced dataset, where the representation of ARBs patterns is very less as compared to the representation of the non-ARBs pattern significantly hinders the performance of the ARBs prediction models. Therefore, in this article, we present an oversampling approach, generative adversarial networks-based synthetic data generation-based ARBs prediction models. The approach uses generative adversarial networks to generate synthetic samples for the ARBs patterns in the given datasets implicitly and build the prediction models on the processed datasets. To validate the performance of the presented approach, we perform an experimental study for the seven ARBs datasets collected from the public repository and use various performance measures to evaluate the results. The experimental results showed that the presented approach led to the improved performance of prediction models for the ARBs prediction as compared to the other state-of-the-art models.|||Article||||
WEB OF SCIENCE|Gaaloul, Khouloud; Menghi, Claudio; Nejati, Shiva; Briand, Lionel C.; Parache, Yago Isasi|||Combining Genetic Programming and Model Checking to Generate Environment Assumptions|2022|IEEE TRANSACTIONS ON SOFTWARE ENGINEERING|48|9||3664|3685|||10.1109/TSE.2021.3101818||Software verification may yield spurious failures when environment assumptions are not accounted for. Environment assumptions are the expectations that a system or a component makes about its operational environment and are often specified in terms of conditions over the inputs of that system or component. In this article, we propose an approach to automatically infer environment assumptions for Cyber-Physical Systems (CPS). Our approach improves the state-of-the-art in three different ways: First, we learn assumptions for complex CPS models involving signal and numeric variables; second, the learned assumptions include arithmetic expressions defined over multiple variables; third, we identify the trade-off between soundness and coverage of environment assumptions and demonstrate the flexibility of our approach in prioritizing either of these criteria. We evaluate our approach using a public domain benchmark of CPS models from Lockheed Martin and a component of a satellite control system from LuxSpace, a satellite system provider. The results show that our approach outperforms state-of-the-art techniques on learning assumptions for CPS models, and further, when applied to our industrial CPS model, our approach is able to learn assumptions that are sufficiently close to the assumptions manually developed by engineers to be of practical value.|||Article||||
WEB OF SCIENCE||||Frameworks: Garden: A FAIR Framework for Publishing and Applying AI Models for Translational Research in Science, Engineering, Education, and Industry|2022|||||||||||Harnessing powerful new advances in machine learning (ML) and artificial intelligence (AI) is key to 1) maintaining and building national competitiveness in the sciences and engineering, 2) realizing breakthroughs in health and medicine, 3) enabling the creation of industries of the future, and 4) increasing economic growth and opportunity. Today, researchers are achieving exciting results with these new ML/AI methods in applications ranging from materials discovery, chemistry, and drug discovery to high energy physics, weather prediction, advanced manufacturing, and health. Yet, much work remains. These new methods and results are not easily applied by others due to the specialized expertise and resources needed to understand, develop, share, adapt, test, deploy, and run the resulting ML/AI models. To overcome these barriers to progress, this project seeks to develop methods and tools for constructing and creating Model Gardens, collections of curated and tested ML/AI models linked with the data and computing resources required to advance the work of a specific research community. Such new methods, software, and tools can make it simple for model producers to publish models in forms that are easily consumed by others, and for model consumers to discover published models and integrate them into their applications in academia or industry. The project connects researchers in materials science, physics, and chemistry enabling the establishment of Model Gardens for their communities and empowering key research centers to collect and provide broad access to new methods and models resulting from their work. Further, the project facilitates the connection of aspiring researchers with scientific problems, engaging hundreds of students from diverse backgrounds (including rural community college partners) in learning and contributing to software development, model publication, development of new AI/ML applications, and training of a next-generation ML/AI-empowered workforce through hosted workshops, open office hours, and development of a new engagement platform. This project overcomes the barriers to the dissemination and application of new ML/AI methods by creating a new CSSI framework���the Garden Framework to support the construction and operation of Model Gardens: collections of curated models linked with the data and computing resources required to advance the work of specific communities. By reducing the friction associated with model publication, discovery, access, and deployment; providing for the disciplined and structured organization and linking of data, models, and code; associating appropriate metadata with models to promote reuse and discoverability, and applying quality assessment measures (e.g., automated testing, uncertainty quantification) to support model comparison; supporting the development of communities around specific model classes and research challenges; and permitting easy access to models without (and with) download and installation, established Model Gardens reduce barriers to the use of ML/AI methods and promote the nucleation of communities around specific datasets, methods, and models. This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.|||Awarded Grant||||
WEB OF SCIENCE|Rostami, Taha; Jalili, Saeed|||FrMi: Fault-revealing Mutant Identification using killability severity|2023|INFORMATION AND SOFTWARE TECHNOLOGY|164||107307|||||10.1016/j.infsof.2023.107307||Context: Mutation testing is a powerful method used in software testing for various activities, such as guidance for test case generation and test suite quality assessment. However, a vast number of mutants, most unrelated to real faults, threaten the scalability and validity of the method. Over the decades, researchers have proposed various approaches to alleviate these problems, most of which have almost the same performance in practice. To overcome this issue, recently predicting a category of mutants named fault-revealing mutants has been proposed, which outperforms other methods in terms of real-fault revelation ability. Although recent research shows the usefulness of targeting this type of mutant, they are scarce, which makes predictions of them with higher accuracy challengingObjective: This paper aims to propose a method that can predict fault-revealing mutants with higher accuracy compared to the state-of-the-art method.Methods: To tackle this challenge, a feature representing the difficulty of killing a mutant is added as a new feature to complement the state-of-the-art feature set. Then a method based on ensemble learning is proposed that uses this feature for fault-revealing mutants' prediction.Results: According to our experimental results, the proposed method outperforms the state-of-the-art method regarding area under a receiver operating characteristic curve (AUC) value on the Codeflaws and CoRBench data sets by 7.09% and 8.97%, respectively. Conclusion: It is concluded that the proposed method, which includes a new feature and an ensemble-learning approach, enhances the accuracy of predicting fault-revealing mutants in software testing. This is achieved by incorporating the difficulty of killing a mutant as a feature, which complements the existing feature set used in state-of-the-art methods. The experimental results demonstrate that the proposed method outperforms the state-of-the-art method on two datasets, Codeflaws and CoRBench, indicating that it has the potential to be applied in practical software testing scenarios.|||Article||||
WEB OF SCIENCE|Morovati, Mohammad Mehdi; Nikanjam, Amin; Tambon, Florian; Khomh, Foutse; Jiang, Zhen Ming (Jack)|||Bug characterization in machine learning-based systems|2024|EMPIRICAL SOFTWARE ENGINEERING|29|1|14|||||10.1007/s10664-023-10400-0||The rapid growth of applying Machine Learning (ML) in different domains, especially in safety-critical areas, increases the need for reliable ML components, i.e., a software component operating based on ML. Since corrective maintenance, i.e. identifying and resolving systems bugs, is a key task in the software development process to deliver reliable software components, it is necessary to investigate the usage of ML components, from the software maintenance perspective. Understanding the bugs' characteristics and maintenance challenges in ML-based systems can help developers of these systems to identify where to focus maintenance and testing efforts, by giving insights into the most error-prone components, most common bugs, etc. In this paper, we investigate the characteristics of bugs in ML-based software systems and the difference between ML and non-ML bugs from the maintenance viewpoint. We extracted 447,948 GitHub repositories that used one of the three most popular ML frameworks, i.e., TensorFlow, Keras, and PyTorch. After multiple filtering steps, we select the top 300 repositories with the highest number of closed issues. We manually investigate the extracted repositories to exclude non-ML-based systems. Our investigation involved a manual inspection of 386 sampled reported issues in the identified ML-based systems to indicate whether they affect ML components or not. Our analysis shows that nearly half of the real issues reported in ML-based systems are ML bugs, indicating that ML components are more error-prone than non-ML components. Next, we thoroughly examined 109 identified ML bugs to identify their root causes, and symptoms, and calculate their required fixing time. The results also revealed that ML bugs have significantly different characteristics compared to non-ML bugs, in terms of the complexity of bug-fixing (number of commits, changed files, and changed lines of code). Based on our results, fixing ML bugs is more costly and ML components are more error-prone, compared to non-ML bugs and non-ML components respectively. Hence, paying significant attention to the reliability of the ML components is crucial in ML-based systems. These results deepen the understanding of ML bugs and we hope that our findings help shed light on opportunities for designing effective tools for testing and debugging ML-based systems.|||Article||||
WEB OF SCIENCE|Guillette, Daniel|||Application of Machine Learning for Predicting IEMI Upset in Multi-Architecture Microcontrollers|2022||||||||||||||Dissertation/Thesis||||
WEB OF SCIENCE|Sharma, Kamal Kant; Sinha, Amit; Sharma, Arun|||Software Defect Prediction using Deep Learning by Correlation Clustering of Testing Metrics|2022|INTERNATIONAL JOURNAL OF ELECTRICAL AND COMPUTER ENGINEERING SYSTEMS|13|10||953|960|||||The software industry has made significant efforts in recent years to enhance software quality in businesses. The use of proactively defect prediction in the software will assist programmers and white box testing in detecting issues early, saving time and money. Conventional software defect prediction methods focus on traditional source code metrics such as code complexities, lines of code, and so on. These capabilities, unfortunately, are unable to retrieve the semantics of source code. In this paper, we have presented a novel Correlation Clustering fine-tuned CNN (CCFT-CNN) model based on testing Metrics. CCFT-CNN can predict the regions of source code that contain faults, errors, and bugs. Abstract Syntax Tree (AST) tokens are extracted as testing Metrics vectors from the source code. The correlation among AST testing Metrics is performed and clustered as a more relevant feature vector and fed into Convolutional Neural Network (CNN). Then, to enhance the accuracy of defect prediction, fine-tuning of the CNN model is performed by applying hyperparameters. The result analysis is performed on the PROMISE dataset that contains samples of open-source Java applications such as Camel Dataset, Jedit dataset, Poi dataset, Synapse dataset, Xerces dataset, and Xalan dataset. The result findings show that the CCFTCNN model increases the average F-measure by 2% when compared to the baseline model.|||Article||||
WEB OF SCIENCE|Colin, Lee Song Haw; Mohan, Purnima Murali; Pan, Jonathan; Keong, Peter Loh Kok|||An Integrated Smart Contract Vulnerability Detection Tool Using Multi-Layer Perceptron on Real-Time Solidity Smart Contracts|2024|IEEE ACCESS|12|||23549|23567|||10.1109/ACCESS.2024.3364351||perceptron (MLP). We use feature vectors from the Opcodes and CFG for the machine learning (ML) model training. The existing ML-based approaches for analyzing the smart contract code are constrained by the vulnerability detection space, significantly varying Solidity versions, and no unified approach to verify against the ground truth. The primary contributions in this paper are 1) a standardized pre-processing method for smart contract training data, 2) introducing bugs to create a balanced dataset of flawed files across Solidity versions using AST, and 3) standardizing vulnerability identification using the Smart Contract Weakness Classification (SWC) registry. The ML models employed for benchmarking the proposed MLP, and a multi-input model combining MLP and Long short-term memory (LSTM) in our study are Random forest (RF), XGBoost (XGB), Support vector machine (SVM). The performance evaluation on real-time smart contracts deployed on the Ethereum Blockchain show an accuracy of up to 91% using MLP with the lowest average False Positive Rate (FPR) among all tools and models, measuring at 0.0125.|||Article||||
WEB OF SCIENCE|Li, Ying; Zhong, Ye; Yang, Lijuan; Wang, Yanbo; Zhu, Penghua|||LLM-Guided Crowdsourced Test Report Clustering|2025|IEEE ACCESS|13|||24894|24904|||10.1109/ACCESS.2025.3530960||This paper proposes a clustering method for crowdsourced test reports based on a large language model to solve the limitations of existing methods in processing repeated reports and utilizing multi-modal information. Existing crowdsourced test report clustering methods have significant shortcomings in handling duplicate reports, ignoring the semantic information of screenshots, and underutilizing the relationship between text and images. The emergence of LLM provides a new way to solve these problems. By integrating the semantic understanding ability of LLM, key information can be extracted from the test report more accurately, and the semantic relationship between screenshots and text descriptions can be used to guide the clustering process, thus improving the accuracy and effectiveness of clustering. The method in this paper uses a pre-trained LLM (such as GPT-4) to encode the text in the test report, and uses a visual model such as CLIP to encode the application screenshots, converting the text descriptions and images into high-dimensional semantic vectors. The cosine similarity is then used to calculate the similarity between the vectors, and semantic binding rules are constructed to guide the clustering process, ensuring that semantically related reports are assigned to the same cluster and semantically different reports are assigned to different clusters. Through experimental verification, this method is significantly superior to traditional methods in several evaluation indicators, demonstrating its great potential in improving the efficiency and quality of crowdsourced test report processing. In the future, this method is expected to be widely used in the process of software testing and maintenance, and further promote technological progress.|||Article||||
WEB OF SCIENCE|Song, Yi; Zhang, Xihao; Xie, Xiaoyuan; Chen, Songqiang; Liu, Quanming; Gao, Ruizhi|||SURE: A Visualized Failure Indexing Approach Using Program Memory Spectrum|2024|ACM TRANSACTIONS ON SOFTWARE ENGINEERING AND METHODOLOGY|33|8|210|||||10.1145/3676958||This work was partially supported by the National Natural Science Foundation of China under the grant number 62250610224.|||Article||||
WEB OF SCIENCE|Perera, Anjana; Aleti, Aldeida; Tantithamthavorn, Chakkrit; Jiarpakdee, Jirayus; Turhan, Burak; Kuhn, Lisa; Walker, Katie|||Search-based fairness testing for regression-based machine learning systems|2022|EMPIRICAL SOFTWARE ENGINEERING|27|3|79|||||10.1007/s10664-022-10116-7||Context Machine learning (ML) software systems are permeating many aspects of our life, such as healthcare, transportation, banking, and recruitment. These systems are trained with data that is often biased, resulting in biased behaviour. To address this issue, fairness testing approaches have been proposed to test ML systems for fairness, which predominantly focus on assessing classification-based ML systems. These methods are not applicable to regression-based systems, for example, they do not quantify the magnitude of the disparity in predicted outcomes, which we identify as important in the context of regression-based ML systems. Method: We conduct this study as design science research. We identify the problem instance in the context of emergency department (ED) wait-time prediction. In this paper, we develop an effective and efficient fairness testing approach to evaluate the fairness of regression-based ML systems. We propose fairness degree, which is a new fairness measure for regression-based ML systems, and a novel search-based fairness testing (SBFT) approach for testing regression-based machine learning systems. We apply the proposed solutions to ED wait-time prediction software. Results: We experimentally evaluate the effectiveness and efficiency of the proposed approach with ML systems trained on real observational data from the healthcare domain. We demonstrate that SBFT significantly outperforms existing fairness testing approaches, with up to 111% and 190% increase in effectiveness and efficiency of SBFT compared to the best performing existing approaches. Conclusion: These findings indicate that our novel fairness measure and the new approach for fairness testing of regression-based ML systems can identify the degree of fairness in predictions, which can help software teams to make data-informed decisions about whether such software systems are ready to deploy. The scientific knowledge gained from our work can be phrased as a technological rule; to measure the fairness of the regression-based ML systems in the context of emergency department wait-time prediction use fairness degree and search-based techniques to approximate it.|||Article||||
WEB OF SCIENCE|Yazıcı, Mahmut Burak|||Software Quality Prediction with Artificial Intelligence and Machine Learning Methods|2023||||||||||||||Dissertation/Thesis||||
WEB OF SCIENCE|Dadkhah, Mahboubeh; Araban, Saeed; Paydar, Samad|||A systematic literature review on semantic web enabled software testing|2020|JOURNAL OF SYSTEMS AND SOFTWARE|162||110485|||||10.1016/j.jss.2019.110485||Software testing, as a major verification and validation activity which revolves around quality tests, is a knowledge-intensive activity. Hence, it is reasonable to expect that it can be improved by effective application of semantic web technologies, e.g., ontologies, which have been frequently used in knowledge engineering activities.The objective of this work is to investigate and provide a better understanding of how semantic web enabled techniques, i.e., the techniques that are based on the effective application of the semantic web technologies, have been used to support software testing activities. For this purpose, a Systematic Literature Review based on a predefined procedure is conducted. A total of 52 primary studies were identified as relevant, which have undergone a thorough meta-analysis with regards to our posed research questions.This study indicates the benefits of semantic web enabled software testing in both industry and academia. It also identifies main software testing activities that can benefit from the semantic web enabled techniques. Furthermore, contributions of such techniques to the testing process are thoroughly examined. Finally, potentials and difficulties of applying these techniques to software testing, along with the promising research directions are discussed. (C) 2019 Elsevier Inc. All rights reserved.|||Review||||
WEB OF SCIENCE|Kumar, Jullius; Gupta, Dharmendra Lal; Umrao, Lokendra Singh|||Fault-Tolerant Algorithm for Software Preduction Using Machine Learning Techniques|2022|INTERNATIONAL JOURNAL OF SOFTWARE SCIENCE AND COMPUTATIONAL INTELLIGENCE-IJSSCI|14|1||||||10.4018/IJSSCI.309425||Many software reliability algorithms have been used to predict and approximate the reliability of software. One general expectation of these traditional algorithms is to predict the fault and automatically delete the observed faults. This presumption will not be reasonable in practice and may not always exist. In this paper, the various algorithms have been used such as probabilistic neural network (PNN), generalized neural network (GRNN), linear regression, support vector machine (SVM), bagging, decision trees (DTs), and k-nearest neighbor (KNN) to measure the accuracy of various data and comparison has been done. The proposed algorithm has been used for predicting the reliability of software and the algorithms have been implemented to check the accuracy while using different machine learning (ML) techniques. Experimental studies based on actual failure evidence indicate that the proposed algorithm can more effectively explain the change in failure data and predict the software development behavior than conventional techniques.|||Article||||
WEB OF SCIENCE|Zohdinasab, Tahereh; Riccio, Vincenzo; Tonella, Paolo|||Focused Test Generation for Autonomous Driving Systems|2024|ACM TRANSACTIONS ON SOFTWARE ENGINEERING AND METHODOLOGY|33|6|152|||||10.1145/3664605||Testing Autonomous Driving Systems (ADSs) is crucial to ensure their reliability when navigating complex environments. ADSs may exhibit unexpected behaviours when presented, during operation, with driving scenarios containing features inadequately represented in the training dataset. To address this shift from development to operation, developers must acquire new data with the newly observed features. This data can be then utilised to fine tune the ADS, so as to reach the desired level of reliability in performing driving tasks. However, the resource-intensive nature of testing ADSs requires efficientmethodologies for generating targeted and diverse tests.In this work, we introduce a novel approach, DeepAtash-LR, that incorporates a surrogate model into the focused test generation process. This integration significantly improves focused testing effectiveness and applicability in resource-intensive scenarios. Experimental results show that the integration of the surrogate model is fundamental to the success of DeepAtash-LR. Our approach was able to generate an average of up to 60x more targeted, failure-inducing inputs compared to the baseline approach. Moreover, the inputs generated by DeepAtash-LR were useful to significantly improve the quality of the original ADS through fine tuning.|||Article||||
WEB OF SCIENCE|Wang, Wenxuan|||Testing and Evaluation of Large Language Models: Correctness, Non-Toxicity, and Fairness|2024||||||||||||||Dissertation/Thesis||||
WEB OF SCIENCE|Kaur, Khushdeep|||Quantum Software Testing and Quantum Cryptography Education|2024||||||||||||||Dissertation/Thesis||||
WEB OF SCIENCE|Tamizharasi, A.; Ezhumalai, P.|||Hybrid whale optimized crow search algorithm and multi-SVM classifier for effective system level test case selection|2024|JOURNAL OF INTELLIGENT & FUZZY SYSTEMS|46|2||4191|4207|||10.3233/JIFS-232700||A novel approach to enhance software testing through intelligent test case selection is proposed in this work. The proposed method combines feature extraction, clustering, and a hybrid optimization algorithm to improve testing effectiveness while reducing resource overhead. It employs a context encoder to extract relevant features from software code, enhancing the accuracy of subsequent testing. Through the use of Fuzzy C-means (FCM) clustering, the test cases are classified into groups, streamlining the testing process by identifying similar cases. To optimize feature selection, a Hybrid Whale Optimized Crow Search Algorithm (HWOCSA), which intelligently combines the strengths of both Whale Optimization Algorithm (WOA) and Crow Search Algorithm (CSA) is introduced. This hybrid approach mitigates limitations while maximizing the selection of pertinent features for testing. The ultimate contribution of this work lies in the proposal of a multi-SVM classifier, which refines the test case selection process. Each classifier learns specific problem domains, generating predictions that guide the selection of test cases with unprecedented precision. Experimental results demonstrate that the proposed method achieves remarkable improvements in testing outcomes, including enhanced performance metrics, reduced computation time, and minimized training data requirements. By significantly streamlining the testing process and accurately selecting relevant test cases, this work paves the way for higher quality software updates at a reduced cost.|||Article||||
WEB OF SCIENCE|Lin, Jun-Wei|||Advancing Automated Software Testing Through Test Reuse|2021||||||||||||||Dissertation/Thesis||||
WEB OF SCIENCE|Chen, Zhifei; Jia, Chiheng; Li, Yanhui; Chen, Lin|||Using Dynamic and Static Techniques to Establish Traceability Links Between Production Code and Test Code on Python Projects: A Replication Study|2025|JOURNAL OF SOFTWARE-EVOLUTION AND PROCESS|37|3|e70011|||||10.1002/smr.70011||The relationship between test code and production code, that is, test-to-code traceability, plays an essential role in the verification, reliability, and certification of software systems. Prior work on test-to-code traceability focuses mainly on Java. However, as Python allows more flexible testing styles, it is still unknown whether existing traceability approaches work well on Python projects. In order to address this gap in knowledge, this paper evaluates whether existing traceability approaches can accurately identify test-to-code links in Python projects. We collected seven popular Python projects and carried out an exploratory study at both the method and module levels (involving a total of 3198 test cases). On these projects, we evaluated 15 individual traceability techniques along with cross-level information propagation and four combining resolution strategies. The results reveal that the performance of test-to-code traceability approaches on Python has many differences with Java: (1) most of the existing techniques have poor effectiveness for Python; (2) after augmenting with cross-level information, the recall surprisingly drops; and (3) machine learning based combination approach achieves the best recall but the worst precision. These findings shed light on the best traceability approaches for Python projects, and also provide guidelines for researchers and the Python community.|||Article||||
WEB OF SCIENCE|Yang, Yang; Wang, Weiwei; Li, Zheng; Zhang, Lieshan; Pan, Chaoyue|||Security Development Lifecycle-Based Adaptive Reward Mechanism for Reinforcement Learning in Continuous Integration Testing Optimization|2024|INTERNATIONAL JOURNAL OF SOFTWARE ENGINEERING AND KNOWLEDGE ENGINEERING|34|9||1457|1483|||10.1142/S0218194024500244||Continuous automated testing throughout each cycle can ensure the security of the continuous integration (CI) development lifecycle. Test case prioritization (TCP) is a critical factor in optimizing automated testing, which prioritizes potentially failed test cases and improves the efficiency of automated testing. In CI automated testing, the TCP is a continuous decision-making process that can be solved with reinforcement learning (RL). RL-based CITCP can continuously generate a TCP strategy for each CI development lifecycle, with the reward mechanism as the core. The reward mechanism consists of the reward function and the reward strategy. However, there are new challenges to RL-based CITCP in real-industry CI testing. With high-frequency iteration, the reward function is often calculated with a fixed length of historical information, ignoring the spatial characteristics of the current cycle. Therefore, the dynamic time window (DTW)-based reward function is proposed to perform the reward calculation, which adaptively adjusts the recent historical information range based on the integration cycle. Moreover, with low-failure testing, the reward strategy usually only rewards failure test cases, which creates a sparse reward problem in RL. To address this issue, the similarity-based reward strategy is proposed, which increases the reward objects of some passed test cases, similar to the failure test cases. The DTW-based reward function and the similarity-based reward strategy together constitute the proposed adaptive reward mechanism in RL-based CITCP. To validate the effectiveness of the adaptive reward mechanism, experimental verification is carried out on 13 industrial data sets. The experimental results show that the adaptive reward mechanism can improve the TCP effect, where the average NAPFD is maximally improved by 7.29%, the average Recall is maximally improved by 6.04% and the average TTF is improved by 6.81 positions with a maximum of 63.77.|||Article||||
WEB OF SCIENCE|Tweissi, Adiy; Al Etaiwi, Wael; Al Eisawi, Dalia|||The Accuracy of AI-Based Automatic Proctoring in Online Exams|2022|ELECTRONIC JOURNAL OF E-LEARNING|20|4||419|435|||||This study technically analyses one of the online exam supervision technologies, namely the Artificial Intelligence-based Auto Proctoring (AiAP). This technology has been heavily presented to the academic sectors around the globe. Proctoring technologies are developed to provide oversight and analysis of students' behavior in online exams using AI, and sometimes with the supervision of human proctors to maintain academic integrity. Manual Testing methodology was used to do a software testing on AiAP for verification of any possible incorrect red flags or detections. The study took place in a Middle Eastern university by conducting online exams for 14 different courses, with a total of 244 students. The results were then verified by 5 human proctors in terms of monitoring measurements: screen violation, sound of speech, different faces, multiple faces, and eye movement detection. The proctoring decision was computed by averaging all monitoring measurements and then compared between the human proctors' and the AiAP decisions, to ultimately set the AiAP against a benchmark (human proctoring) and hence to be viable for use. The decision represented the number of violations to the exam conditions, and the result showed a significant difference between Human Decision (average 25.95%) and AiAP Decision (average 35.61%), and the total number of incorrect decisions made by AiAP was 74 out of 244 exam attempts, concluding that AiAP needed some improvements and updates to meet the human level. The researchers provided some technical limitations, privacy concerns, and recommendations to carefully review before deploying and governing such proctoring technologies at institutional level. This paper contributes to the field of educational technology by providing an evidence-based accuracy test on an automatic proctoring software, and the results demand institutional provision to better establish an appropriate online exam experience for higher educational institutions.|||Article||||
WEB OF SCIENCE|Kumar, Sumit; Nitin; Yadav, Mitul|||Finite State GUI Testing with Test Case Prioritization Using Z-BES and GK-GRU|2023|APPLIED SCIENCES-BASEL|13|19|10569|||||10.3390/app131910569||To deliver user-friendly experiences, modern software applications rely heavily on graphical user interfaces (GUIs). However, it is paramount to ensure the quality of these GUIs through effective testing. This paper proposes a novel Finite state testing for GUI with test case prioritization using ZScore-Bald Eagle Search (Z-BES) and Gini Kernel-Gated recurrent unit (GK-GRU) approach to enhance GUI testing accuracy and efficiency. First, historical project data is collected. Subsequently, by utilizing the Z-BES algorithm, test cases are prioritized, aiding in improving GUI testing. Attributes are then extracted from prioritized test cases, which contain crucial details. Additionally, a state transition diagram (STD) is generated to visualize system behavior. The state activity score (SAS) is then computed to quantify state importance using reinforcement learning (RL). Next, GUI components are identified, and their text values are extracted. Similarity scores between GUI text values and test case attributes are computed. Grounded on similarity scores and SAS, a fuzzy algorithm labels the test cases. Data representation is enhanced by word embedding using GS-BERT. Finally, the test case outcomes are predicted by the GK-GRU, validating the GUI performance. The proposed work attains 98% accuracy, precision, recall, f-measure, and sensitivity, and low FPR and FNR error rates of 14.2 and 7.5, demonstrating the reliability of the model. The proposed Z-BES requires only 5587 ms to prioritize the test cases, retaining less time complexity. Meanwhile, the GK-GRU technique requires 38945 ms to train the neurons, thus enhancing the computational efficiency of the system. In conclusion, experimental outcomes demonstrate that, compared with the prevailing approaches, the proposed technique attains superior performance.|||Article||||
WEB OF SCIENCE|Shu, Ting; He, Zhanxiang; Yin, Xuesong; Ding, Zuohua; Zhou, Mengchu|||Model-based diversity-driven learn-to-rank test case prioritization|2024|EXPERT SYSTEMS WITH APPLICATIONS|255||124768|||||10.1016/j.eswa.2024.124768||Model-based Test Case Prioritization utilizing similarity metrics has proved effective in software testing. However, the utility of similarity metrics in it varies with test scenarios, hindering its universal effectiveness and performance optimization. To tackle this problem, we propose a Diversity-driven Learn-to-rank model- based TCP approach, named DLTCP, for optimizing early fault detection performance. Our method first employs the whale optimization algorithm to search for a suitable set of similarity metrics from a pool of existing candidates. This search process determines which metrics should be used. According to each selected metric, test cases are then prioritized. The resulting test case rankings are used as the training data for DLTCP. Finally, the proposed method incorporates random forest to train a ranking model for test case prioritization. As such, it can fuse multiple similarity metrics to improve the TCP performance. We conduct extensive experiments to evaluate our method's performance using the average percentage fault detected (APFD) as metric. The experimental results show that DLTCP achieve an average APFD value of 0.953 for seven classic benchmark models, which is 11.37% higher than that of the state-of-the-art algorithms. It can well select a set of similarity metrics for effective fusion, demonstrating competitive performance in early fault detection.|||Article||||
WEB OF SCIENCE||||AI Trust Audit - A novel solution and process to advance trust in the compliance and risk of AI systems in radiology|2023|||||||||||Radiology AI products have the potential to revolutionise the healthcare industry by improving patient outcomes, reducing errors, and increasing efficiency. However, the adoption of these products has been slow due to concerns over their reliability, robustness, and compliance. The lack of transparency in the development and testing of AI systems has raised questions about their safety and effectiveness. The AI Trust Audit project aims to develop a novel solution to advance trust in the compliance and risk of AI systems auditing, impact assessment, or evaluation, reliability and robustness testing of radiology AI products. This project is essential as radiology AI products are becoming more widely used, and there is a growing need to ensure that they are reliable, trustworthy and have a positive impact on patients and healthcare providers. The proposed solution will be a software-based AI Trust Audit tool, which will use machine learning algorithms to assess the compliance, risk, and reliability of radiology AI products. The tool will perform automated testing and auditing, as well as impact and risk assessments, to identify potential issues with reliability of these products. The tool will be designed to integrate seamlessly with existing radiology workflows and software systems, making it easy for healthcare providers to use and adopt. The impact of this project will be significant for patients, healthcare providers, and the wider healthcare industry. The AI Trust Audit tool will improve patient safety by identifying and addressing potential issues with radiology AI products before they cause harm. It will also provide healthcare providers with greater confidence in the reliability and performance of these products, leading to increased adoption and improved patient outcomes. In addition to the positive impact on patient outcomes, this project will also benefit the UK economy by supporting the development of a new and innovative healthcare technology. Overall, the AI Trust Audit project is a crucial step forward in ensuring the safe and effective use of radiology AI products. By developing a comprehensive and automated tool that addresses the unique challenges and risks of these products, this project has the potential to revolutionise the way radiology AI products are tested, evaluated, and audited.|||Awarded Grant||||
WEB OF SCIENCE|Gorry, Patrick|||Random Generation of Realistic Spatial Data for use in Classroom Assessments|2022||||||||||||||Dissertation/Thesis||||
WEB OF SCIENCE|Aziz, Syed Rashid; Khan, Tamim Ahmed; Nadeem, Aamer|||Exclusive use and evaluation of inheritance metrics viability in software fault prediction an experimental study|2021|PEERJ COMPUTER SCIENCE|||e563|||||10.7717/peerj-cs.563||Software Fault Prediction (SFP) assists in the identification of faulty classes, and software metrics provide us with a mechanism for this purpose. Besides others, metrics addressing inheritance in Object-Oriented (OO) are important as these measure depth, hierarchy, width, and overriding complexity of the software. In this paper, we evaluated the exclusive use, and viability of inheritance metrics in SFP through experiments. We perform a survey of inheritance metrics whose data sets are publicly available, and collected about 40 data sets having inheritance metrics. We cleaned, and filtered them, and captured nine inheritance metrics. After preprocessing, we divided selected data sets into all possible combinations of inheritance metrics, and then we merged similar metrics. We then formed 67 data sets containing only inheritance metrics that have nominal binary class labels. We performed a model building, and validation for Support Vector Machine(SVM). Results of Cross-Entropy, Accuracy, F-Measure, and AUC advocate viability of inheritance metrics in software fault prediction. Furthermore, ic, noc, and dit metrics are helpful in reduction of error entropy rate over the rest of the 67 feature sets.|||Article||||
WEB OF SCIENCE|Sherin, Salman; Muqeet, Asmar; Khan, Muhammad Uzair; Iqbal, Muhammad Zohaib|||QExplore: An exploration strategy for dynamic web applications using guided search|2023|JOURNAL OF SYSTEMS AND SOFTWARE|195||111512|||||10.1016/j.jss.2022.111512||Dynamic exploration approaches play an important role in automating web testing and analysis. They are extensively used to explore the state-space of a web application for achieving complete coverage of the application's functionality. Dynamic exploration approaches support end-to-end automation of testing to verify the correct behavior of a web application. However, existing approaches failed to explore the states behind the web forms and can get stuck in dynamic regions of web applications resulting in poor functionality coverage and diversity. Consequently, existing approaches are regressive in nature and sensitive to small DOM mutations which may not be interesting from a testing perspective. In this paper, we propose a dynamic exploration approach using guided search inspired by Q-learning that systematically explores dynamic web applications requiring less or no prior knowledge about the application. Our approach is implemented in a tool called QExplore and is empirically evaluated with six popular open-source and one real industrial application. The results show that QExplore achieved higher coverage with more diverse DOM than the existing state-of-the-art tools Crawljax and WebExplor. QExplore also results in a greater number of navigational paths, error states and distinct DOM states when compared with the existing tools.(c) 2022 Elsevier Inc. All rights reserved.|||Article||||
WEB OF SCIENCE|Salahirad, Alireza|||Empirical Studies on Automated Software Testing Practices|2022||||||||||||||Dissertation/Thesis||||
WEB OF SCIENCE|Wan, Xiaohui; Li, Tiancheng; Lin, Weibin; Cai, Yi; Zheng, Zheng|||Coverage-guided fuzzing for deep reinforcement learning systems|2024|JOURNAL OF SYSTEMS AND SOFTWARE|210||111963|||||10.1016/j.jss.2024.111963||While the past decade has witnessed a growing demand for employing deep reinforcement learning (DRL) in various domains to solve real -world problems, the reliability of DRL systems has become more of a concern. In particular, DRL agents are often trained on data from a potentially biased distribution over environmental settings, causing the trained agents to fail in certain cases despite high average -case performance. Hence, it is necessary and urgent to adequately test DRL agents to ensure the reliability of practical DRL systems. However, due to the fundamental difference in the programming paradigm and the development process, traditional software testing methodology cannot be applied directly to DRL systems. Given that, we introduce a novel testing framework for DRL systems, aiming to generate diverse test cases that can drive a DRL system to fail. Specifically, we design, implement and evaluate DRLFuzz, which is a coverage -guided fuzzing (CGF) framework for systematically testing DRL systems. Experimental results demonstrate that DRLFuzz can efficiently discover diverse failures in different DRL systems for various benchmark tasks. Compared with a random search baseline, DRLFuzz can generate 60% more failed cases in general. Additionally, the diversity of failed cases generated by DRLFuzz is increased by 4.6% similar to 14.1% in terms of mean pairwise distance (MPD). Furthermore, our experiments also indicate that the failed cases generated by DRLFuzz can be utilized to fine-tune the DRL agent to eliminate the failures resulting from inadequate exploration during training and thus improve the reliability of DRL systems.|||Article||||
WEB OF SCIENCE|Bardakci, Tolgahan; Demeyer, Serge; Beyazit, Mutlu|||Test Amplification for REST APIs: Using Out-of-the-Box Large Language Models|2025|IEEE SOFTWARE|42|4||43|49|||10.1109/MS.2025.3559664||Representational state transfer application programming interfaces (REST APIs) are an indispensable building block in today's cloud-native applications. However, testing REST APIs is challenging because tests must be strong, readable, and exercise the boundary values of the REST API protocol.|||Article||||
WEB OF SCIENCE|Qasaimeh, Malik; Abu Hammour, Rand; Yassein, Muneer Bani; Al-Qassas, Raad S.; Torralbo, Juan Alfonso Lara; Lizcano, David|||Advanced security testing using a cyber-attack forecasting model: A case study of financial institutions|2022|JOURNAL OF SOFTWARE-EVOLUTION AND PROCESS|34|11|e2489|||||10.1002/smr.2489||As the number of cyber-attacks on financial institutions has increased over the past few years, an advanced system that is capable of predicting the target of an attack is essential. Such a system needs to be integrated into the existing detection systems of financial institutions as it provides them with proactive controls with which to halt an attack by predicting patterns. Advanced prediction systems also enhance the software design and security testing of new advanced cyber-security measures by providing new testing scenarios supported by attack forecasting. This present study developed a model that forecasts future network-based cyber-attacks on financial institutions using a deep neural network. The dataset that was used to train and test the model consisted of some of the biggest cyber-attacks on banking institutions over the past three years. This provided insight into new patterns that may end with a cyber-crime. These new attacks were also evaluated to determine behavioral similarities with the nearest known attack or a combination of several existing attacks. The performance of the forecasting model was then evaluated in a real banking environment and provided a forecasting accuracy of 90.36%. As such, financial institutions can use the proposed forecasting model to improve their security testing measures.|||Article||||
WEB OF SCIENCE|Nashaat, Mona; Miller, James|||Refining software defect prediction through attentive neural models for code understanding|2025|JOURNAL OF SYSTEMS AND SOFTWARE|220||112266|||||10.1016/j.jss.2024.112266||Identifying defects through manual software testing is a resource-intensive task in software development. To alleviate this, software defect prediction identifies code segments likely to contain faults using data-driven methods. Traditional techniques rely on static code metrics, which often fail to reflect the deeper syntactic and semantic features of the code. This paper introduces a novel framework that utilizes transformer-based networks with attention mechanisms to predict software defects. The framework encodes input vectors to develop meaningful representations of software modules. A bidirectional transformer encoder is employed to model programming languages, followed by fine-tuning with labeled data to detect defects. The performance of the framework is assessed through experiments across various software projects and compared against baseline techniques. Additionally, statistical hypothesis testing and an ablation study are performed to assess the impact of different parameter choices. The empirical findings indicate that the proposed approach can increase classification accuracy by an average of 15.93% and improve the F1 score by up to 44.26% compared to traditional methods.|||Article||||
WEB OF SCIENCE|Biagiola, Matteo; Tonella, Paolo|||Boundary State Generation for Testing and Improvement of Autonomous Driving Systems|2024|IEEE TRANSACTIONS ON SOFTWARE ENGINEERING|50|8||2040|2053|||10.1109/TSE.2024.3420816||Recent advances in Deep Neural Networks (DNNs) and sensor technologies are enabling autonomous driving systems (ADSs) with an ever-increasing level of autonomy. However, assessing their dependability remains a critical concern. State-of-the-art ADS testing approaches modify the controllable attributes of a simulated driving environment until the ADS misbehaves. In such approaches, environment instances in which the ADS is successful are discarded, despite the possibility that they could contain hidden driving conditions in which the ADS may misbehave. In this paper, we present GenBo (GENerator of BOundary state pairs), a novel test generator for ADS testing. GenBo mutates the driving conditions of the ego vehicle (position, velocity and orientation), collected in a failure-free environment instance, and efficiently generates challenging driving conditions at the behavior boundary (i.e., where the model starts to misbehave) in the same environment instance. We use such boundary conditions to augment the initial training dataset and retrain the DNN model under test. Our evaluation results show that the retrained model has, on average, up to 3x higher success rate on a separate set of evaluation tracks with respect to the original DNN model.|||Article||||
WEB OF SCIENCE|Dola, Swaroopa; Dwyer, Matthew B.; Soffa, Mary Lou|||Input Distribution Coverage: Measuring Feature Interaction Adequacy in Neural Network Testing|2023|ACM TRANSACTIONS ON SOFTWARE ENGINEERING AND METHODOLOGY|32|3|81|||||10.1145/3576040||Testing deep neural networks (DNNs) has garnered great interest in the recent years due to their use in many applications. Black-box test adequacy measures are useful for guiding the testing process in covering the input domain. However, the absence of input specifications makes it challenging to apply black-box test adequacy measures in DNN testing. The Input Distribution Coverage (IDC) framework addresses this challenge by using a variational autoencoder to learn a low dimensional latent representation of the input distribution, and then using that latent space as a coverage domain for testing. IDC applies combinatorial interaction testing on a partitioning of the latent space to measure test adequacy. Empirical evaluation demonstrates that IDC is cost-effective, capable of detecting feature diversity in test inputs, and more sensitive than prior work to test inputs generated using different DNN test generation methods. The findings demonstrate that IDC overcomes several limitations of white-box DNN coverage approaches by discounting coverage from unrealistic inputs and enabling the calculation of test adequacy metrics that capture the feature diversity present in the input space of DNNs.|||Article||||
WEB OF SCIENCE|Shi, Haoxiang; Ai, Jun; Liu, Jingyu; Xu, Jiaxi|||Improving Software Defect Prediction in Noisy Imbalanced Datasets|2023|APPLIED SCIENCES-BASEL|13|18|10466|||||10.3390/app131810466||Software defect prediction is a popular method for optimizing software testing and improving software quality and reliability. However, software defect datasets usually have quality problems, such as class imbalance and data noise. Oversampling by generating the minority class samples is one of the most well-known methods to improving the quality of datasets; however, it often introduces overfitting noise to datasets. To better improve the quality of these datasets, this paper proposes a method called US-PONR, which uses undersampling to remove duplicate samples from version iterations and then uses oversampling through propensity score matching to reduce class imbalance and noise samples in datasets. The effectiveness of this method was validated in a software prediction experiment that involved 24 versions of software data in 11 projects from PROMISE in noisy environments that varied from 0% to 30% noise level. The experiments showed a significant improvement in the quality of datasets pre-processed by US-PONR in noisy imbalanced datasets, especially the noisiest ones, compared with 12 other advanced dataset processing methods. The experiments also demonstrated that the US-PONR method can effectively identify the label noise samples and remove them.|||Article||||
WEB OF SCIENCE|Chi, Po-Wen; Zheng, Yu; Chang, Wei-Yang; Wang, Ming-Hung|||SandboxNet: A Learning-Based Malicious Application Detection Framework in SDN Networks|2022|JOURNAL OF INFORMATION SCIENCE AND ENGINEERING|38|6||1189|1211|||10.6688/JISE.202211_38(6).0006||Software Defined Networking (SDN) is a concept that decouples the control plane and the user plane. So, the network administrator can easily control the network behavior through its own programs. However, the administrator may unconsciously set up some malicious programs on SDN controllers so that the whole network may be under the attacker's control. In this paper, we discuss the malicious software issue on SDN networks. We use the idea of the sandbox to propose a sandbox network called SanboxNet. We emulate a virtual isolated network environment to verify the SDN application functions. With continuous monitoring, we can locate the suspicious SDN applications if the system detects some pre-defined malicious behaviors. We also apply machine learning (ML) techniques to identify unknown malicious applications. Considering the sandbox-evading issue, in our work, we make the emulated networks, and the real-world networks will be indistinguishable to the SDN controller.|||Article||||
WEB OF SCIENCE|Delgado-Licona, Fernando; Abolhasani, Milad|||Research Acceleration in Self-Driving Labs: Technological Roadmap toward Accelerated Materials and Molecular Discovery|2023|ADVANCED INTELLIGENT SYSTEMS|5|4||||||10.1002/aisy.202200331||The urgency of finding solutions to global energy, sustainability, and healthcare challenges has motivated rethinking of the conventional chemistry and material science workflows. Self-driving labs, emerged through integration of disruptive physical and digital technologies, including robotics, additive manufacturing, reaction miniaturization, and artificial intelligence, have the potential to accelerate the pace of materials and molecular discovery by 10-100X. Using autonomous robotic experimentation workflows, self-driving labs enable access to a larger part of the chemical universe and reduce the time-to-solution through an iterative hypothesis formulation, intelligent experiment selection, and automated testing. By providing a data-centric abstraction to the accelerated discovery cycle, in this perspective article, the required hardware and software technological infrastructure to unlock the true potential of self-driving labs is discussed. In particular, process intensification as an accelerator mechanism for reaction modules of self-driving labs and digitalization strategies to further accelerate the discovery cycle in chemical and materials sciences are discussed.|||Article||||
WEB OF SCIENCE|Shin, Seunghoon; Kang, Dongsu|||A Test File Generation Method Based on Generative Adversarial Networks for File Fuzzing|2020|KIISE Transactions on Computing Practices|26|8||384|389|||10.5626/KTCP.2020.26.8.384||It is crucial to discover software vulnerabilities through software testing as there are continuous cases of exploiting software vulnerabilities as a means of initiating cyberattacks. File fuzzing is a method that modifies and executes input files to detect software vulnerabilities. To improve the efficiency of file fuzzing, this paper proposes seed file structure analysis and test file generation based on the deep learning GAN model. To this end, a large number of crashes may be found by applying the GAN model and fuzzing to the files generated by the GAN model.|||research-article||||
WEB OF SCIENCE|Alves, Diogo Rafael Cordeiro|||Modeling of Synthetic Players as an Instrument for Testing Generative Content|2021||||||||||||||Dissertation/Thesis||||
WEB OF SCIENCE|Zhang, Lehuan; Guo, Shikai; Guo, Yi; Li, Hui; Chai, Yu; Chen, Rong; Li, Xiaochen; Jiang, He|||Context-based Transfer Learning for Structuring Fault Localization and Program Repair Automation|2025|ACM TRANSACTIONS ON SOFTWARE ENGINEERING AND METHODOLOGY|34|4|96|||||10.1145/3705302||Automated software debugging plays a crucial role in aiding software developers to swiftly identify and attempt to rectify faults, thereby significantly reducing developers' workload. Previous researches have predominantly relied on simplistic semantic deep learning or statistical analysis methods to locate faulty statements in diverse projects. However, code repositories often consist of lengthy sequences with long-distance dependencies, posing challenges for accurately modeling fault localization using these methods. In addition, the lack of joint reasoning among various faults prevents existing models from deeply capturing fault information. To address these challenges, we propose a method named CodeHealer to achieve accurate fault localization and program repair. CodeHealer comprises three components: a Deep Semantic Information Extraction Component that effectively extracts deep semantic features from suspicious code statements using classifiers based on Jointattention mechanisms; a Suspicious Statement Ranking Component that combines various fault localization features and employs multilayer perceptrons to derive multidimensional vectors of suspicion values; and a Fault Repair Component that, based on ranked suspicious statements generated by fault localization, adopts a top-down approach using multiple classifiers based on Co-teaching mechanisms to select repair templates and generate patches. The experimental results indicate that when applied to fault localization, CodeHealer outperforms the best baseline method with improvements of 11.4%, 2.7%, and 1.6% on Top-1/3/5 metrics, respectively. It also reduces the MFR and MAR by 9.8% and 2.1%, where lower values denote better fault localization effectiveness. Additionally, in automated software debugging, CodeHealer fixes an additional 6 faults compared to the current best method, totaling 53 faults repaired. CCS Concepts: center dot Software and its engineering -> Software testing and debugging;|||Article||||
WEB OF SCIENCE|Pandey, Sushant Kumar; Tripathi, Anil Kumar|||An empirical study toward dealing with noise and class imbalance issues in software defect prediction|2021|SOFT COMPUTING|25|21||13465|13492|||10.1007/s00500-021-06096-3||The quality of the defect datasets is a critical issue in the domain of software defect prediction (SDP). These datasets are obtained through the mining of software repositories. Recent studies claim over the quality of the defect dataset. It is because of inconsistency between bug/clean fix keyword in fault reports and the corresponding link in the change management logs. Class Imbalance (CI) problem is also a big challenging issue in SDP models. The defect prediction method trained using noisy and imbalanced data leads to inconsistent and unsatisfactory results. Combined analysis over noisy instances and CI problem needs to be required. To the best of our knowledge, there are insufficient studies that have been done over such aspects. In this paper, we deal with the impact of noise and CI problem on five baseline SDP models; we manually added the various noise level (0-80%) and identified its impact on the performance of those SDP models. Moreover, we further provide guidelines for the possible range of tolerable noise for baseline models. We have also suggested the SDP model, which has the highest noise tolerable ability and outperforms over other classical methods. The True Positive Rate (TPR) and False Positive Rate (FPR) values of the baseline models reduce between 20-30% after adding 10-40% noisy instances. Similarly, the ROC (Receiver Operating Characteristics) values of SDP models reduce to 40-50%. The suggested model leads to avoid noise between 40-60% as compared to other traditional models.|||Article||||
WEB OF SCIENCE|Alazzam, Iyad; AlSobeh, Anas Mohammad Ramadan; Melhem, Basil Bani|||Enhancing integration testing efficiency through AI-driven combined structural and textual class coupling metric|2024|ONLINE JOURNAL OF COMMUNICATION AND MEDIA TECHNOLOGIES|14|4|e202460|||||10.30935/ojcmt/15524||Integration testing, a critical and resource-intensive phase in the software development lifecycle, can account for up to a high percentage of the total testing cost. Identifying classes with high coupling is crucial for efficient integration testing, as these classes are more susceptible to the impact of maintenance-related changes. This research introduces a novel metric called combined structural and textual class coupling (CSTCC), which harnesses the power of artificial intelligence (AI) techniques to predict and rank the most critical classes in an object-oriented software system. CSTCC integrates structural coupling metrics with latent semantic indexing (LSI)-based textual coupling, providing a comprehensive measure of class coupling. LSI, an information retrieval technique, analyses the semantic relationships between classes based on their textual content, enabling CSTCC to capture both structural and conceptual dependencies, resulting in a more accurate identification of high-risk classes. The effectiveness of the proposed approach is rigorously evaluated using mutation testing on four Java open-source projects, and the results demonstrate that test cases developed based on CSTCC achieve high mutation scores, indicating their ability to detect a significant percentage of integration faults. By focusing testing efforts on high-coupling classes identified by CSTCC, developers can potentially save time and cost during integration testing. The results demonstrate that test cases developed based on CSTCC achieve high mutation scores, ranging from 98% to 100%, indicating their ability to detect a significant percentage of integration faults. Additionally, the approach results in substantial efficiency gains, with a notable reduction in the number of test cases needed, saving up to 33.3% of the testing effort in some cases. By focusing testing efforts on high-coupling classes identified by CSTCC, developers can potentially save time and cost during integration testing. The CSTCC metric provides a novel and effective approach to prioritize testing resources and improve the efficiency of integration testing in object-oriented software systems.|||Article||||
WEB OF SCIENCE||||REU Site: Software and Data Analytics|2021|||||||||||This project will establish a three-year REU site in software and data analytics at East Carolina University (ECU). It will offer a ten-week research program for ten undergraduate students during summer semesters. The faculty-student interaction, as well as interaction among students, will take different forms, including daily Scrum meetings, tutorials, weekly meetings, lectures, seminars, group meetings, and field trips. The REU project will allow a diverse pool of undergraduate students to experience cutting-edge research. Students will gain valuable research skills that will prepare them for their future fields of study, while helping them to develop into self-reliant STEM researchers. Furthermore, their exposure to research will motivate them to continue to graduate studies. Finally, the REU project will provide students with an opportunity to collaborate with their faculty mentors and student peers across the nation after the summer program ends. The sample research projects cover open research topics in software and data analytics. Code Recommendation for Programming Language Learners investigates machine learning techniques for building code recommendation systems aimed at beginning programmers, taking their level of programming knowledge into account. Intelligent Program Update Detection and Automation uses version histories of software systems to understand how code related to uses of a software library (via an Application Programming Interface, or API) evolves, to identify when this evolution needs to occur, and to build transformation scripts to partially or fully automate the changes needed to support a newer API version. Human-Computer Collaborative Dialogue Systems explores techniques for automated regression test case prioritization that utilizes techniques from information retrieval such as term similarity. Link Recovery Systems investigates the use of information retrieval techniques for recovering traceability links between program requirements, bug reports, and project source code. Using Machine Learning to Estimate Software Development Effort explores the use of machine learning techniques to estimate software development effort. Understanding Implicit Extension APIs investigates uses of machine learning for API recommendation, specifically in the context of APIs in dynamic languages that are created implicitly in the code. Machine Learning Algorithms for Biometric Data Analysis uses a combination of machine learning techniques and mobile application usage data (e.g., about swipe gestures) to infer demographic characteristics of app users. Performance Evaluation of Machine Learning Algorithms explores the use of machine learning for prediction, using the example of the next day closing price for crypt-currencies. Students participating in these projects will learn about topics including code recommendation systems, static program analysis, program transformation, classical techniques for classification in machine learning (e.g., k-nearest neighbors), deep learning, information retrieval, software testing, software maintenance, software repository mining, software quality metrics, crypto-currencies, and both theoretical and empirical measurements of algorithm performance. This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.|||Awarded Grant||||
WEB OF SCIENCE|Neelofar, Neelofar; Aleti, Aldeida|||Identifying and Explaining Safety-critical Scenarios for Autonomous Vehicles via Key Features|2024|ACM TRANSACTIONS ON SOFTWARE ENGINEERING AND METHODOLOGY|33|4|94|||||10.1145/3640335||Ensuring the safety of autonomous vehicles (AVs) is of utmost importance, and testing them in simulated environments is a safer option than conducting in-field operational tests. However, generating an exhaustive test suite to identify critical test scenarios is computationally expensive, as the representation of each test is complex and contains various dynamic and static features, such as the AV under test, road participants (vehicles, pedestrians, and static obstacles), environmental factors (weather and light), and the road's structural features (lanes, turns, road speed, etc.). In this article, we present a systematic technique that uses Instance Space Analysis (ISA) to identify the significant features of test scenarios that affect their ability to reveal the unsafe behaviour of AVs. ISA identifies the features that best differentiate safety-critical scenarios from normal driving and visualises the impact of these features on test scenario outcomes (safe/unsafe) in two dimensions. This visualisation helps to identify untested regions of the instance space and provides an indicator of the quality of the test suite in terms of the percentage of feature space covered by testing. To test the predictive ability of the identified features, we train five Machine Learning classifiers to classify test scenarios as safe or unsafe. The high precision, recall, and F1 scores indicate that our proposed approach is effective in predicting the outcome of a test scenario without executing it and can be used for test generation, selection, and prioritisation.|||Article||||
WEB OF SCIENCE|Chang, Shin Woo|||A Study on Test-Driven Development Method with the Aid of Generative AI in Software Engineering|2024|The International Journal of Internet, Broadcasting and Communication|16|4||194|202|||||This study explores the integration of Generative AI into Test-Driven Development (TDD) to efficiently produce code that accurately reflects programmers' requirements in software engineering. Using the Account class as an example, we analyzed the code generation capabilities of leading Generative AI modelsOpenAI's ChatGPT, GitHub's Copilot, and Google's Gemini. Our findings indicate that while Generative AI can automatically generate code, it often fails to capture programmers' intent, potentially leading to functional errors or security vulnerabilities. By applying TDD principles and providing detailed test cases to the Generative AI, we demonstrated that the generated code more closely aligns with the programmer's intentions and successfully passes specified tests. This approach reduces the need for manual code reviews and enhances development efficiency. We propose a development process that combines TDD with Generative AI, leveraging the strengths of both to efficiently produce high-quality software. Future research will focus on extending this approach to more complex systems and exploring automatic test case generation techniques.|||research-article||||
WEB OF SCIENCE|Pandey, Sushant Kumar; Tripathi, Anil Kumar|||BCV-Predictor: A bug count vector predictor of a successive version of the software system|2020|KNOWLEDGE-BASED SYSTEMS|197||105924|||||10.1016/j.knosys.2020.105924||Predicting the number of bugs in a software system intensifies the software quality and turns down the testing effort required in software development. It reduces the overall cost of software development. The evolution of hardware, platform, and user requirements leads to develop the next version of a software system. In this article, we formulate a problem and its novel solution, i.e., we are considering the prediction of the bug count vector of a successive version of a software system. After predicting the bug count vector in the next version of a software, the developer team leader can adequately allocate the developers in respective fault dense modules, in a more faulty dense module, more number of developers required. We have conducted our experiment over seven PROMISE repository datasets of different versions. We build metadata using a concatenation of different versions of the same software system for conducting experiments. We proposed a novel architecture using deep learning called BCV-Predictor. BCV-Predictor predicts the bug count vector of the next version software system; it is trained using metadata. To the best of our knowledge, no such work has been done in these aspects. We also address overfitting and class imbalance problem using random oversampling method and dropout regularization techniques. We conclude that BCV-Predictor is conducive to predicting the bug count vector of the next version of the software. We found five out of seven meta datasets reaches to more than 80% accuracy. In all seven meta datasets, Mean Squared Error (MSE) lies from 0.71 to 4.715, Mean Absolute Error (MAE) lies from 0.22 to 1.679, MSE and MAE over validation set lie between 0.84 to 4.865, and 0.22 to 1.709 respectively. We also compared the performance of BCV-Predictor with eleven baselines techniques and found the proposed approach outperform on most of the meta-datasets. (C) 2020 Published by Elsevier B.V.|||Article||||
WEB OF SCIENCE|Kacker, Raghu N.; Kuhn, D. Richard; Lei, Yu; Simos, Dimitris E.|||Factorials Experiments, Covering Arrays, and Combinatorial Testing|2021|MATHEMATICS IN COMPUTER SCIENCE|15|4||715|739|||10.1007/s11786-021-00502-7||In the twenty-first century, our life will increasingly depend on software-based products and complex interconnected systems. Thus, the quality and security of software-based systems is a world-wide concern. Combinatorial testing is a versatile methodology for finding errors (bugs) and vulnerabilities in software-based systems. This paper offers a review of combinatorial testing. Combinatorial testing (CT) methods evolved from investigations which looked like factorial experiments (FE) with pass/fail outcomes. We will discuss the similarities and differences between FE and CT. Use of CT for detecting errors (bugs) in software-based systems has gained significant interest from the international software testing community. Many successful results have been reported from the use of CT to detect software errors in aerospace, automotive, defense, cybersecurity, electronic medical systems, and financial service industries. Now, combinatorial testing methods are being increasingly used to investigate vulnerabilities in software-based systems. Combinatorial testing could be useful in detecting errors and security vulnerabilities in Internet of Things, Autonomous Systems, and Artificially Intelligent Software.|||Article||||
WEB OF SCIENCE|Naqvi, Muhammad Raza; Iqbal, Muhammad Waseem; Ashraf, Muhammad Usman; Ahmad, Shafiq; Soliman, Ahmed T.; Khurram, Shahzada; Shafiq, Muhammad; Choi, Jin-Ghoo|||Ontology Driven Testing Strategies for IoT Applications|2022|CMC-COMPUTERS MATERIALS & CONTINUA|70|3||5855|5869|||10.32604/cmc.2022.019188||Internet-of-Things (IoT) has attained a major share in embedded software development. The new era of specialized intelligent systems requires adaptation of customized software engineering approaches. Currently, software engineering has merged the development phases with the technologies provided by industrial automation. The improvements are still required in testing phase for the software developed to IoT solutions. This research aims to assist in developing the testing strategies for IoT applications, therein ontology has been adopted as a knowledge representation technique to different software engineering processes. The proposed ontological model renders 101 methodology by using Protege. After completion, the ontology was evaluated in three-dimensional view by the domain experts of software testing, IoT and ontology engineering. Satisfied results of the research are showed in interest of the specialists regarding proposed ontology development and suggestions for improvements. The Proposed reasoning-based ontological model for development of testing strategies in IoT application contributes to increase the general understanding of tests in addition to assisting for the development of testing strategies for different IoT devices.|||Article||||
WEB OF SCIENCE|Shafei, Hassan a.; Tan, Chiu c.|||Enhancing Alexa Skill Testing Through Improved Utterance Discovery|2024|ACM TRANSACTIONS ON INTERNET TECHNOLOGY|24|4|20|||||10.1145/3698200||Extracting skill utterances is a crucial step in testing and evaluating smart speaker skills. Previous works have proposed various techniques for extracting utterances from the skill web page to test and evaluate smart speaker skills. In this article, we evaluate the effectiveness and correctness of different utterance-extracting techniques proposed in previous works. Our evaluation reveals that some techniques can capture incorrect utterances that the skill will not accept as spoken utterances. We also find that all of the proposed techniques would never capture the total utterances supported by skills, and combining these techniques yields the best results in terms of text parsing. To address these limitations, we propose a new technique that combines the strengths of previous techniques and leverages human to interact with a small set of skills to expand the coverage for testing other skills. We evaluate the effectiveness of our technique and demonstrate that it can capture a higher number of utterances supported by skills. We delved into the impact assessment of utterance extraction, aiming to enhance the thoroughness and effectiveness of skill testing. We conducted an impact study on 11 skills to assess the importance of utterance extraction in the context of skills testing. Our findings demonstrate that our technique captures a higher number of utterances compared to previous techniques. Through our evaluation, we provide insights into the significance of discovering more utterances in the testing context, and demonstrate the effectiveness of our proposed technique in capturing more utterances for skill testing and evaluation.|||Article||||
WEB OF SCIENCE|Brutas, Mariel John B.; Fajardo, Arthur L.; Quilloy, Erwin P.; Manuel, Luther John R.; Borja, Adrian A.|||Enhancing Seed Germination Test Classification for Pole Sitao (Vigna unguiculata (L.) Walp.) Using SSD MobileNet and Faster R-CNN Models|2024|APPLIED SCIENCES-BASEL|14|13|5572|||||10.3390/app14135572||The classification of germinated pole sitao (Vigna unguiculata (L.) Walp.) seeds is important in seed germination tests. The automation of this process has been explored for different grain and legume seeds but is only limited to binary classification. This study aimed to develop a classifier system that can recognize three classes: normal, abnormal, and ungerminated. SSD MobileNet and Faster R-CNN models were trained to perform the classification. Both were trained using 1500 images of germinated seeds at fifth- and eighth-day observations. Each class had 500 images. The trained models were evaluated using 150 images per class. The SSD MobileNet model had an accuracy of 0.79 while the Faster R-CNN model had an accuracy of 0.75. The results showed that the average accuracies for the classes were significantly different from one another based on one-way ANOVA at a 95% confidence level with an F-critical value of 3.0159. The SSD MobileNet model outperformed the Faster R-CNN model in classifying pole sitao seeds, with improved precision in identifying abnormal and ungerminated seeds on the fifth day and normal and ungerminated seeds on the eighth day. The results confirm the potential of the SSD MobileNet model as a more reliable classifier in germination tests.|||Article||||
WEB OF SCIENCE|Biagiola, Matteo; Tonella, Paolo|||Testing of Deep Reinforcement Learning Agents with Surrogate Models|2024|ACM TRANSACTIONS ON SOFTWARE ENGINEERING AND METHODOLOGY|33|3|73|||||10.1145/3631970||Deep Reinforcement Learning (DRL) has received a lot of attention from the research community in recent years. As the technology moves away from game playing to practical contexts, such as autonomous vehicles and robotics, it is crucial to evaluate the quality of DRL agents.In this article, we propose a search-based approach to test such agents. Our approach, implemented in a tool called Indago, trains a classifier on failure and non-failure environment (i.e., pass) configurations resulting from the DRL training process. The classifier is used at testing time as a surrogate model for the DRL agent execution in the environment, predicting the extent to which a given environment configuration induces a failure of the DRL agent under test. The failure prediction acts as a fitness function, guiding the generation towards failure environment configurations, while saving computation time by deferring the execution of the DRL agent in the environment to those configurations that are more likely to expose failures.Experimental results show that our search-based approach finds 50% more failures of the DRL agent than state-of-the-art techniques. Moreover, such failures are, on average, 78% more diverse; similarly, the behaviors of the DRL agent induced by failure configurations are 74% more diverse.|||Article||||
WEB OF SCIENCE|Tebes, Guido; Peppino, Denis; Becker, Pablo; Matturro, Gerardo; Solari, Martin; Olsina, Luis|||Analyzing and documenting the systematic review results of software testing ontologies|2020|INFORMATION AND SOFTWARE TECHNOLOGY|123||106298|||||10.1016/j.infsof.2020.106298||Context: Software testing is a complex area since it has a large number of specific methods, processes and strategies, involving a lot of domain concepts. Therefore, it would be valuable to have a conceptualized software testing ontology that explicitly and unambiguously defines the concepts. Consequently, it is important to find out the available evidence in the literature on primary studies for software testing ontologies. In particular, we are looking for research that has a rich ontological coverage that includes Non-Functional Requirements (NFRs) and Functional Requirements (FRs) concepts in conjunction with static and dynamic testing concepts, which can be used in method and process specifications for a family of testing strategies.Objective: The main goal for this secondary study is to identify, evaluate and synthesize the available primary studies on conceptualized software testing ontologies.Method: To conduct this study, we use the Systematic Literature Review (SLR) approach, which follows our enhanced SLR process. We set three research questions. Additionally, to quantitatively evaluate the quality of the selected conceptualized ontologies, we designed a NFRs tree and its associated metrics and indicators.Results: We obtained 12 primary studies documenting conceptualized testing ontologies by using three different retrieval methods. In general, we noted that most of them have a lack of NFRs and static testing terminological coverage. Finally, we observe that none of them is directly linked with FRs and NFRs conceptual components.Conclusion: A general benefit of having the suitable software testing ontology is to minimize the current heterogeneity, ambiguity and incompleteness problems in terms, properties and relationships. We have confirmed that exists heterogeneity, ambiguity, and incompleteness for concepts dealing with testing artifacts, roles, activities, and methods. Moreover, we did not find the suitable ontology for our aim since none of the conceptualized ontologies are directly linked with NFRs and FRs components.|||Review||||
WEB OF SCIENCE|Khan, Bilal; Nadeem, Aamer|||Evaluating the effectiveness of decomposed Halstead Metrics in software fault prediction|2023|PEERJ COMPUTER SCIENCE|9||e1647|||||10.7717/peerj-cs.1647||The occurrence of faults in software systems represents an inevitable predicament. Testing is the most common means to detect such faults; however, exhaustive testing is not feasible for any nontrivial system. Software fault prediction (SFP), which identifies software components that are more prone to errors, seeks to supplement the testing process. Thus, testing efforts can be focused on such modules. Various approaches exist for SFP, with machine learning (ML) emerging as the prevailing methodology. ML-based SFP relies on a wide range of metrics, ranging from file-level and class-level to method-level and even line-level metrics. More granularized metrics are expected to possess a higher degree of micro-level coverage of the code. The Halstead metric suite offers coverage at the line level and has been extensively employed across diverse domains such as fault prediction, quality assessment, and similarity approximation for the past three decades. In this article, we propose to decompose Halstead base metrics and evaluate their fault prediction capability. The Halstead base metrics consist of operators and operands. In the context of the Java language, we partition operators into five distinct categories, i.e., assignment operators, arithmetic operators, logical operators, relational operators, and all other types of operators. Similarly, operands are classified into two classes: constants and variables. For the purpose of empirical evaluation, two experiments were designed. In the first experiment, the Halstead base metrics were used along with McCabe, Lines of Code (LoC), and Halstead-derived metrics as predictors. In the second experiment, decomposed Halstead base metrics were used along with McCabe, LoC, and Halstead-derived metrics. Five public datasets were selected for the experiments. The ML classifiers used included logistic regression, naive Bayes, decision tree, multilayer perceptron, random forest, and support vector machines. The ML classifiers' effectiveness was assessed through metrics such as accuracy, F-measure, and AUC. Accuracy saw an enhancement from 0.82 to 0.97, while F-measure exhibited improvement from 0.81 to 0.99. Correspondingly, the AUC value advanced from 0.79 to 0.99. These findings highlight the superior performance of decomposed Halstead metrics, as opposed to the original Halstead base metrics, in predicting faults across all datasets.|||Article||||
WEB OF SCIENCE|Jiang, Siyu; Zhang, Jiapeng; Guo, Feng; Ouyang, Teng; Li, Jing|||Balanced Adversarial Tight Matching for Cross-Project Defect Prediction|2024|IET SOFTWARE|2024||1561351|||||10.1049/2024/1561351||Cross-project defect prediction (CPDP) is an attractive research area in software testing. It identifies defects in projects with limited labeled data (target projects) by utilizing predictive models from data-rich projects (source projects). Existing CPDP methods based on transfer learning mainly rely on the assumption of a unimodal distribution and consider the case where the feature distribution has one obvious peak. However, in actual situations, the feature distribution of project samples often exhibits multiple peaks that cannot be ignored. It manifests as a multimodal distribution, making it challenging to align distributions between different projects. To address this issue, we propose a balanced adversarial tight-matching model for CPDP. Specifically, this method employs multilinear conditioning to obtain the cross-covariance of both features and classifier predictions, capturing the multimodal distribution of the feature. When reducing the captured multimodal distribution differences, pseudo-labels are needed, but pseudo-labels have uncertainty. Therefore, we additionally add an auxiliary classifier and attempt to generate pseudo-labels using a pseudo-label strategy with less uncertainty. Finally, the feature generator and two classifiers undergo adversarial training to align the multimodal distributions of different projects. This method outperforms the state-of-the-art CPDP model used on the benchmark dataset.|||Article||||
WEB OF SCIENCE|Liu, Xi; Yin, Yongfeng; Li, Haifeng; Chen, Jiabin; Liu, Chang; Wang, Shengli; Yin, Rui|||Intelligent radar software defect classification approach based on the latent Dirichlet allocation topic model|2021|EURASIP JOURNAL ON ADVANCES IN SIGNAL PROCESSING|2021|1|44|||||10.1186/s13634-021-00761-3||Existing software intelligent defect classification approaches do not consider radar characters and prior statistics information. Thus, when applying these appaoraches into radar software testing and validation, the precision rate and recall rate of defect classification are poor and have effect on the reuse effectiveness of software defects. To solve this problem, a new intelligent defect classification approach based on the latent Dirichlet allocation (LDA) topic model is proposed for radar software in this paper. The proposed approach includes the defect text segmentation algorithm based on the dictionary of radar domain, the modified LDA model combining radar software requirement, and the top acquisition and classification approach of radar software defect based on the modified LDA model. The proposed approach is applied on the typical radar software defects to validate the effectiveness and applicability. The application results illustrate that the prediction precison rate and recall rate of the poposed approach are improved up to 15 similar to 20% compared with the other defect classification approaches. Thus, the proposed approach can be applied in the segmentation and classification of radar software defects effectively to improve the identifying adequacy of the defects in radar software.|||Article||||
WEB OF SCIENCE|Chang, Shin Woo|||Utilizing Generative AI for Test Case Generation: Comparative Analysis and Guidelines|2024|The International Journal of Advanced Smart Convergence|13|4||145|154|||||The advancement of generative AI technologies has significantly impacted various domains in software engineering, particularly in automating test case generation. As software systems become increasingly complex, manual test case creation faces limitations in terms of efficiency and coverage. This study analyzes the capabilities and limitations of major generative AI modelsChatGPT, Copilot, and Geminiin generating software test cases. We focus on evaluating their performance in boundary value analysis, exception handling, and property-based testing. Using the ArrayUtils.indexOf() function from the Apache Commons Lang library as the test subject, we conducted experiments to compare the quality and effectiveness of the test cases generated by each model. Our findings indicate that while generative AI can efficiently produce a substantial number of high-quality test cases, there are instances of incorrect test cases and test codes. To address these issues, we propose guidelines for developers to enhance the reliability and consistency of test case generation using generative AI. Future research will explore the application of these models to more complex software systems and further methods to improve their test generation capabilities.|||research-article||||
WEB OF SCIENCE|Singhal, Manoj Kumar; Gunawat, Chhaya|||AI-driven green testing : Optimizing efficiency and sustainability in software testing|2025|JOURNAL OF INFORMATION & OPTIMIZATION SCIENCES|46|4||1347|1356|||10.47974/JIOS-2001||Software has become integral to daily life, continually expanding with increasingly complex features to meet growing expectations. However, managing these complexities- from understanding application dependencies to ensuring reliability through rigorous For organizations, delivering robust and dependable software is crucial for maintaining business success and reputation. Therefore, a significant portion of the software development life cycle is dedicated to testing. Engineers often write thousands of test cases to validate new features and prevent regressions. Despite these efforts, current regression testing methods are inefficient, as they often require developers to run all test cases irrespective of whether the code paths have been altered. This paper proposes an AI-driven approach to optimize regression testing. By analyzing specific trends, the AI identifies and prioritizes the most relevant test cases, thereby reducing execution time and resource consumption. This approach promises to mitigate inefficiencies associated with traditional testing methods, offering a more cost-effective and timely solution for software development cycles.|||Article||||
WEB OF SCIENCE|Ebert, Christof; Nawalramka, Priyanka|||Generative AI for Data Science|2025|IEEE SOFTWARE|42|4||20|24|||10.1109/MS.2025.3562046||Struggling with messy data or incomplete datasets? Trying to find patterns in your static analysis or test results? Generative AI (GAI) is transforming data science by automating data cleaning, generating high-quality synthetic data, and optimizing model training. Learn with our hands-on examples how to enhance data science with GAI to accelerate insights, enhance accuracy, and set up predictive models.-Christof Ebert|||Editorial Material||||
WEB OF SCIENCE|JO, MINSEOK; Chun, Hye-won; Han, Seong-Soo; Jeong, Chang-Sung|||Single Shot Detector for Detecting Clickable Object in Mobile Device Screen|2022|KIPS Transactions on Software and Data Engineering|11|1||29|34|||||We propose a novel network architecture and build dataset for recognizing clickable objects on mobile device screens. The data wascollected based on clickable objects on the mobile device screen that have numerous resolution, and a total of 24,937 annotation datawere subdivided into seven categories: text, edit text, image, button, region, status bar, and navigation bar. We use the DeconvolutionSingle Shot Detector as a baseline, the backbone network with Squeeze-and-Excitation blocks, the Single Shot Detector layer structureto derive inference results and the Feature pyramid networks structure. Also we efficiently extract features by changing the input resolutionof the existing 1:1 ratio of the network to a 1:2 ratio similar to the mobile device screen. As a result of experimenting with the datasetwe have built, the mean average precision was improved by up to 101% compared to baseline.|||research-article||||
WEB OF SCIENCE||||DP210100041|2021|||||||||||Mapping the Effectiveness of Automated Software Testing. This project aims to help software engineers build complex software systems in far more reliable and cost-effective ways. It takes an interdisciplinary approach by applying machine learning techniques to automatically test complex software systems. Expected outcomes include a novel methodology for assessing the strengths and weaknesses of test suites generated by automated software testing techniques and the approaches required for generating high-quality test cases. Such advances are urgently needed to avoid disasters when deploying software systems in the real world.|||Awarded Grant||||
WEB OF SCIENCE|Coppola, Riccardo; Feldt, Robert; Nass, Michel; Alegroth, Emil|||Ranking approaches for similarity-based web element location☆|2025|JOURNAL OF SYSTEMS AND SOFTWARE|222||112286|||||10.1016/j.jss.2024.112286||Context: GUI-based tests for web applications are frequently broken by fragility, i.e. regression tests fail due to changing properties of the web elements. The most influential factor for fragility are the locators used in the scripts, i.e. the means of identifying the elements of the GUI. Objective: We extend a state-of-the-art Multi-Locator solution that considers 14 locators from the DOM model of a web application, and identifies overlapping nodes in the DOM tree (VON-Similo). We augment the approach with standard Machine Learning and Learning to Rank (LTR) approaches to aid the location of web elements. Method: We document an experiment with a ground truth of 1163 web element pairs, taken from different releases of 40 web applications, to compare the robustness of the algorithms to locator weight change, and the performance of LTR approaches in terms of MeanRank and PctAtN. Results: Using LTR algorithms, we obtain a maximum probability of finding the correct target at the first position of 88.4% (lowest 82.57%), and among the first three positions of 94.79% (lowest 91.86%). The best mean rank of the correct candidate is 1.57. Conclusion: The similarity-based approach proved to be highly dependable in the context of web application testing, where a low percentage of matching errors can still be accepted.|||Article||||
WEB OF SCIENCE|Ouedraogo, Wendkuuni C.; Plein, Laura; Kabore, Kader; Habib, Andrew; Klein, Jacques; Lo, David; Bissyande, Tegawende F.|||Enriching automatic test case generation by extracting relevant test inputs from bug reports|2025|EMPIRICAL SOFTWARE ENGINEERING|30|3|85|||||10.1007/s10664-025-10635-z||The quality of software is closely tied to the effectiveness of the tests it undergoes. Manual test writing, though crucial for bug detection, is time-consuming, which has driven significant research into automated test case generation. However, current methods often struggle to generate relevant inputs, limiting the effectiveness of the tests produced. To address this, we introduce BRMiner, a novel approach that leverages Large Language Models (LLMs) in combination with traditional techniques to extract relevant inputs from bug reports, thereby enhancing automated test generation tools. In this study, we evaluate BRMiner using the Defects4J benchmark and test generation tools such as EvoSuite and Randoop. Our results demonstrate that BRMiner achieves a Relevant Input Rate (RIR) of 60.03% and a Relevant Input Extraction Accuracy Rate (RIEAR) of 31.71%, significantly outperforming methods that rely on LLMs alone. The integration of BRMiner's input enhances EvoSuite ability to generate more effective test, leading to increased code coverage, with gains observed in branch, instruction, method, and line coverage across multiple projects. Furthermore, BRMiner facilitated the detection of 58 unique bugs, including those that were missed by traditional baseline approaches. Overall, BRMiner's combination of LLM filtering with traditional input extraction techniques significantly improves the relevance and effectiveness of automated test generation, advancing the detection of bugs and enhancing code coverage, thereby contributing to higher-quality software development.|||Article||||
WEB OF SCIENCE|Zhang, Quanjun; Zhai, Juan; Fang, Chunrong; Liu, Jiawei; Sun, Weisong; Hu, Haichuan; Wang, Qingyu|||Machine Translation Testing via Syntactic Tree Pruning|2024|ACM TRANSACTIONS ON SOFTWARE ENGINEERING AND METHODOLOGY|33|5|125|||||10.1145/3640329||Machine translation systems have been widely adopted in our daily life, making life easier and more convenient. Unfortunately, erroneous translations may result in severe consequences, such as financial losses. This requires to improve the accuracy and the reliability of machine translation systems. However, it is challenging to test machine translation systems because of the complexity and intractability of the underlying neural models. To tackle these challenges, we propose a novel metamorphic testing approach by syntactic tree pruning (STP) to validate machine translation systems. Our key insight is that a pruned sentence should have similar crucial semantics compared with the original sentence. Specifically, STP (1) proposes a core semantics-preserving pruning strategy by basic sentence structures and dependency relations on the level of syntactic tree representation, (2) generates source sentence pairs based on the metamorphic relation, and (3) reports suspicious issues whose translations break the consistency property by a bag-of-words model. We further evaluate STP on two state-of-the-art machine translation systems (i.e., Google Translate and Bing Microsoft Translator) with 1,200 source sentences as inputs. The results show that STP accurately finds 5,073 unique erroneous translations in Google Translate and 5,100 unique erroneous translations in Bing Microsoft Translator (400% more than state-of-the-art techniques), with 64.5% and 65.4% precision, respectively. The reported erroneous translations vary in types and more than 90% of them are not found by state-of-the-art techniques. There are 9,393 erroneous translations unique to STP, which is 711.9% more than state-of-the-art techniques. Moreover, STP is quite effective in detecting translation errors for the original sentences with a recall reaching 74.0%, improving state-of-the-art techniques by 55.1% on average.|||Article||||
WEB OF SCIENCE|Devrani, Shitanshu; Tietze, Daniel; Tietze, Alesia A.|||Automated Microfluidic Platform for High-Throughput Biosensor Development|2025|ADVANCED SENSOR RESEARCH|4|3||||||10.1002/adsr.202400116||Biorecognition elements immobilized into nanopores have transformed point-of-care (POC) diagnostics by converting molecular interactions into electrical and fluorescent signals.This study introduces Bio-Sensei, a high-throughput screening (HTS) microfluidic platform based on nanopore biosensing. Integrating a robotic sampler, electrochemical, and fluorescence setup, Bio-Sensei operates as an Internet of Things (IoT) platform with integrated data analysis. The platform's utility is demonstrated on functionalized with an amino terminal Cu(II)- and Ni(II)-binding (ATCUN) peptide ion track-etched membrane. Automated testing atchieves a significantly higher F-stat value than the critical treshold, while unsupervised clustering reveals optimalnanopores pore size. The biosensordemonstrates remarkable stability, selectivity, and sensitivity with detection limits of 10-6 using fluorescence and 10-15 Musing cyclic voltammetry measurements. Combining these methods enhances machine learning models for Cu2+ concentration prediction, achieving receiver operating characteristic area under the curve values exceeding 95%.|||Article||||
WEB OF SCIENCE||||AMBITION: AI-driven biomedical robotic automation for research continuity|2021|||||||||||Artificial Intelligence (AI) is transforming the world. AI is the core technology of many of the biggest companies in the world, Amazon, Google, Facebook, etc. that effect all our lives. AI is now starting to transform science and technology. Most people in the EU now live better than Kings did in the past: they have better food, medical care, transport, etc. This miracle has been made possible through better technology based on science. To meet the great challenges the 21st century world faces: climate change, food insecurity, disease, etc., we need to make science and technology even more efficient. We propose the AMBITION project to harness the power of AI and laboratory robotics to provide researchers in the UK, and beyond, with continuous, uninterrupted, remote access to AI/robotic augmented biomedical research capabilities. This will enable more robust, efficient and reproducible biomedical research. The UK's life sciences, biotechnological and pharmaceutical industry are world-leading. However, the Covid-19 pandemic has clearly demonstrated the vital importance of biomedical research and the critical need to maintain research continuity at all times. Yet, lockdowns and social distancing pose a severe threat to research continuity, forcing laboratories to shut down, risking loss of years of research. Integrating AI with laboratory automation will also enable the automation of routine parts of scientific theory formation and experimentation. This will enable results to be obtained both more efficiently and faster compared to the state-of-the-art where human scientists must make all the decisions. AMBITION does not aim to replace humans, but empower them by reasoning and data processing capabilities to better support their decision making. Biomedical science is facing a 'reproducibility crisis'. Despite reproducibility being fundamental to science, the reproducibility of few biomedical results is currently tested, and when reproducibility is tested, the results are dismal, with only 10 to 20% of published biomedical research found to be reproducible. Finally, automated laboratories will make scientific results more reproducible, as AI systems describe experiments in more clearly than human scientists, and robots execute experimental protocols more accurately than human scientists. The project will focus on the development of the AI part of the system and iterative testing in real-world laboratory settings employing state-of-the-art robotics equipment. We will initially focus on cancer drug discovery as a first demonstration case, bringing together the power of AI and laboratory robotics. In the medium-term (3-5 years horizon). We plan to extend the approach to clinical patient care, and to provide real-time cancer treatment decision support system for patients in the UK and beyond based on automated testing of hundreds of treatment options on patient-derived tumour material, thereby leading to a reduction in animal experimentation, and giving clinicians an evidence-based, real-time input for their expert treatment decision. In the long-term (5-15 years horizon) we will rollout automated research capabilities and real-time treatment guidance across all of biomedicine, especially fields such as antibiotic treatment/ antimicrobial resistance, inflammatory diseases, etc. In 30 years, autonomous laboratories will transform the health sector. They will lower the costs of laboratory experiments, augment researchers' technical capabilities (making more elaborate and complex tests possible), reduce the risks associated with the presence of humans in the labs (working with hazardous substances, risk of infections), ensure reproducibility, increase accuracy of results, and ensure overall accountability and trust in the process. Autonomous laboratories will speed up and scale up the development of new drugs, remote testing of patients, and will be an enabler for personalised medicine.|||Awarded Grant||||
WEB OF SCIENCE|Zakeri-Nasrabadi, Morteza; Parsa, Saeed|||Learning to predict test effectiveness|2022|INTERNATIONAL JOURNAL OF INTELLIGENT SYSTEMS|37|8||4363|4392|||10.1002/int.22722||The high cost of the test can be dramatically reduced, provided that the coverability as an inherent feature of the code under test is predictable. This article offers a machine learning model to predict the extent to which the test could cover a class in terms of a new metric called Coverageability. The prediction model consists of an ensemble of four regression models. The learning samples consist of feature vectors, where features are source code metrics computed for a class. The samples are labeled by the Coverageability values computed for their corresponding classes. We offer a mathematical model to evaluate test effectiveness in terms of size and coverage of the test suite generated automatically for each class. We extend the size of the feature space by introducing a new approach to define submetrics in terms of existing source code metrics. Using feature importance analysis on the learned prediction models, we sort sources code metrics in the order of their impact on the test effectiveness. As a result of which we found the class strict cyclomatic complexity as the most influential source code metric. Our experiments with our prediction models on a large corpus of Java projects containing about 23,000 classes demonstrate the Mean Absolute Error (MAE) of 0.032, Mean-Squared Error (MSE) of 0.004, and an R-2 score of 0.855. Compared with the state-of-the-art coverage prediction models, our models improve MAE, MSE, and an R-2 score by 5.78%, 2.84%, and 20.71%, respectively.|||Article||||
WEB OF SCIENCE|Bavishi, Rohan Jayesh|||Tools and Techniques for Building Programming Assistants for Data Analysis|2022||||||||||||||Dissertation/Thesis||||
WEB OF SCIENCE|Azzeh, Mohammad; Alqasrawi, Yousef; Elsheikh, Yousef|||A soft computing approach for software defect density prediction|2024|JOURNAL OF SOFTWARE-EVOLUTION AND PROCESS|36|4||||||10.1002/smr.2553||Defect density is an essential software testing and maintenance aspect that determines the quality of software products. It is used as a management factor to distribute limited human resources successfully. The availability of public defect datasets facilitates building defect density prediction models using established static code metrics. Since the data gathered for software modules are often subject to uncertainty, it becomes difficult to deliver accurate and reliable predictions. To alleviate this issue, we propose a new prediction model that integrates gray system theory and fuzzy logic to handle the imprecision in software measurement. We propose a new similarity measure that combines the benefits of fuzzy logic and gray relational analysis. The proposed model was validated against defect density prediction models using public defect datasets. The defect density variable is frequently sparse because of the vast number of none-defected modules in the datasets. Therefore, we also check our proposed model's performance against the sparsity level. The findings reveal that the developed model surpasses other defect density prediction models over the datasets with high and very high sparsity ratios. The ensemble learning techniques are competitive choices to the proposed model when the sparsity ratio is relatively small. On the other hand, the statistical regression models were the most inadequate methods for such problems and datasets. Finally, the proposed model was evaluated against different degrees of uncertainty using a sensitivity analysis procedure. The results showed that our model behaves stably under different degrees of uncertainty.|||Article||||
WEB OF SCIENCE|Shao, Yuanxun; Liu, Bin; Wang, Shihai; Li, Guoqi|||Software defect prediction based on correlation weighted class association rule mining|2020|KNOWLEDGE-BASED SYSTEMS|196||105742|||||10.1016/j.knosys.2020.105742||Software defect prediction based on supervised learning plays a crucial role in guiding software testing for resource allocation. In particular, it is worth noticing that using associative classification with high accuracy and comprehensibility can predict defects. But owing to the imbalance data distribution inherent, it is easy to generate a large number of non-defective class association rules, but the defective class association rules are easily ignored. Furthermore, classical associative classification algorithms mainly measure the interestingness of rules by the occurrence frequency, such as support and confidence, without considering the importance of features, resulting in combinations of the insignificant frequent itemset. This promotes the generation of weighted associative classification. However, the feature weighting based on domain knowledge is subjective and unsuitable for a high dimensional dataset. Hence, we present a novel software defect prediction model based on correlation weighted class association rule mining (CWCAR). It leverages a multi-weighted supports-based framework rather than the traditional support-confidence approach to handle class imbalance and utilizes the correlation-based heuristic approach to assign feature weight. Besides, we also optimize the ranking, pruning and prediction stages based on weighted support. Results show that CWCAR is significantly superior to state-of-the-art classifiers in terms of Balance, MCC, and Gmean. (C) 2020 Elsevier B.V. All rights reserved.|||Article||||
WEB OF SCIENCE|Mazhari, Arash Alex|||ATCAM: Automated Testing and Characterization of Additive Manufacturing|2021||||||||||||||Dissertation/Thesis||||
WEB OF SCIENCE|김주형; 유동연; 이정원|||Evaluation of Model Influence of Training Data according to Neuron Coverage Change|2022|Journal of the Institute of Electronics and Information Engineers|59|5||83|90|||||software testing techniques are largely divided into black box tests and white box tests, and research on black box testing is being conducted more actively due to their difficulty in identifying their internal structure. However, for the explainability of learning results, a white box test is also required because that can observe the internal behavior of the model so research on the generation of test cases using neuron coverage is also being conducted recently. In this paper, neuron coverage is not only applied to learning model test, but also to evaluate the effect of selection of learning data on model performance. 11.25% larger neuron coverage was confirmed when models generated using even feature distribution train dataset then original train dataset. In addition, when the model is re-learned using trainn dataset showing greater neuron coverage, it can be seen that the rate of change in neuron coverage increases from 50% to 379%, and greater change, lower accuracy. Additionally, comparing the previous two datasets with PGD, it can be seen that the change in neuron coverage is low, along with the appearance of PGD side showing accuracy down to 20%. In this regard, by comparing the variance of each neuron value in entire neuron distribution, it can be confirmed that greater variance value, lower the accuracy for deep learning model of the dataset.|||research-article||||
WEB OF SCIENCE|Chen, Yu; Chen, Yuanchao; Wang, Ruipeng; Wang, Taiyan; Ji, Shouling; Shan, Hong; Xu, Dan; Pan, Zulie|||Whiskey: Large-Scale Identification of Mobile Mini-App Session Key Leakage With LLMs|2025|IEEE TRANSACTIONS ON INFORMATION FORENSICS AND SECURITY|20|||5872|5887|||10.1109/TIFS.2025.3575561||Mini-apps, which run on super-apps, have attracted a large number of users due to their lightweight nature and the convenience of supporting the authorized use of super-app user information. Super-apps employ encryption to protect the transmission of sensitive identity information authorized by users to the mini-app, using the session key as the key. However, we have identified a risk of session key leakage, which could be exploited to maliciously manipulate sensitive user identity information, thereby posing a significant threat to user data security. To reveal this damage, we explore potential business scenarios of session key leakage in detail. Nevertheless, the diversity in design among various mini-apps makes automated testing of these business scenarios at a large scale challenging. This diversity is reflected in the inconsistent naming of identical types of controls and the disparate execution orders of controls within the same business scenarios across different mini-apps. To overcome these challenges, we propose Whiskey, which can adaptively and intelligently optimize dynamic testing strategies for mini-apps with diverse designs using large language models to detect session key leakage at scale. We evaluated Whiskey on 157,063 WeChat mini-apps and 10,000 TikTok mini-apps, and found that 15,712 of WeChat mini-apps and 678 of TikTok mini-apps had session key leakage vulnerabilities. Further analysis showed that this leakage could lead to account takeover and promotion abuse attacks. We responsibly reported the detection results to Tencent and the mini-app vendors. At the time of submission, 17 reported issues had been assigned CNVD IDs.|||Article||||
WEB OF SCIENCE|Waqar, Muhammad; Imran; Zaman, Muhammad Atif; Muzammal, Muhammad; Kim, Jungsuk|||Test Suite Prioritization Based on Optimization Approach Using Reinforcement Learning|2022|APPLIED SCIENCES-BASEL|12|13|6772|||||10.3390/app12136772||Regression testing ensures that modified software code changes have not adversely affected existing code modules. The test suite size increases with modification to the software based on the end-user requirements. Regression testing executes the complete test suite after updates in the software. Re-execution of new test cases along with existing test cases is costly. The scientific community has proposed test suite prioritization techniques for selecting and minimizing the test suite to minimize the cost of regression testing. The test suite prioritization goal is to maximize fault detection with minimum test cases. Test suite minimization reduces the test suite size by deleting less critical test cases. In this study, we present a four-fold methodology of test suite prioritization based on reinforcement learning. First, the testers' and users' log datasets are prepared using the proposed interaction recording systems for the android application. Second, the proposed reinforcement learning model is used to predict the highest future reward sequence list from the data collected in the first step. Third, the proposed prioritization algorithm signifies the prioritized test suite. Lastly, the fault seeding approach is used to validate the results from software engineering experts. The proposed reinforcement learning-based test suite optimization model is evaluated through five case study applications. The performance evaluation results show that the proposed mechanism performs better than baseline approaches based on random and t-SANT approaches, proving its importance for regression testing.|||Article||||
WEB OF SCIENCE|Zhou, Yu; Su, Yanqi; Chen, Taolue; Huang, Zhiqiu; Gall, Harald; Panichella, Sebastiano|||User Review-Based Change File Localization for Mobile Applications|2021|IEEE TRANSACTIONS ON SOFTWARE ENGINEERING|47|12||2755|2770|||10.1109/TSE.2020.2967383||In the current mobile app development, novel and emerging DevOps practices (e.g., Continuous Delivery, Integration, and user feedback analysis) and tools are becoming more widespread. For instance, the integration of user feedback (provided in the form of user reviews) in the software release cycle represents a valuable asset for the maintenance and evolution of mobile apps. To fully make use of these assets, it is highly desirable for developers to establish semantic links between the user reviews and the software artefacts to be changed (e.g., source code and documentation), and thus to localize the potential files to change for addressing the user feedback. In this paper, we propose RISING (Review Integration via claSsification, clusterIng, and linkiNG), an automated approach to support the continuous integration of user feedback via classification, clustering, and linking of user reviews. RISING leverages domain-specific constraint information and semi-supervised learning to group user reviews into multiple fine-grained clusters concerning similar users' requests. Then, by combining the textual information from both commit messages and source code, it automatically localizes potential change files to accommodate the users' requests. Our empirical studies demonstrate that the proposed approach outperforms the state-of-the-art baseline work in terms of clustering and localization accuracy, and thus produces more reliable results.|||Review||||
WEB OF SCIENCE|Zaidi, Syed Farhan Alam; Woo, Honguk; Lee, Chan-Gun|||Toward an Effective Bug Triage System Using Transformers to Add New Developers|2022|JOURNAL OF SENSORS|2022||4347004|||||10.1155/2022/4347004||As defects become more widespread in software development and advancement, bug triaging has become imperative for software testing and maintenance. The bug triage process assigns an appropriate developer to a bug report. Many automated and semiautomated systems have been proposed in the last decade, and some recent techniques have provided direction for developing an effective triage system. However, these techniques still require improvement. Another open challenge related to this problem is adding new developers to the existing triage system, which is challenging because the developers have no listed triage history. This paper proposes a transformer-based bug triage system that uses bidirectional encoder representation from transformers (BERT) for word representation. The proposed model can add a new developer to the existing system without building a training model from scratch. To add new developers, we assumed that new developers had a triage history created by a manual triager or human triage manager after learning their skills from the existing developer history. Then, the existing model was fine-tuned to add new developers using the manual triage history. Experiments were conducted using datasets from well-known large-scale open-source projects, such as Eclipse and Mozilla, and top-k accuracy was used as a criterion for assessment. The experimental outcome suggests that the proposed triage system is better than other word-embedding-based triage methods for the bug triage problem. Additionally, the proposed method performs the best for adding new developers to an existing bug triage system without requiring retraining using a whole dataset.|||Article||||
WEB OF SCIENCE|Dilbaz, Adem|||Prediction of Software Project Costs Using Object-Oriented Metrics|2020||||||||||||||Dissertation/Thesis||||
WEB OF SCIENCE|Welten, Sascha; Weber, Sven; Holt, Adrian; Beyan, Oya; Decker, Stefan|||Will it run?-A proof of concept for smoke testing decentralized data analytics experiments|2024|FRONTIERS IN MEDICINE|10||1305415|||||10.3389/fmed.2023.1305415||The growing interest in data-driven medicine, in conjunction with the formation of initiatives such as the European Health Data Space (EHDS) has demonstrated the need for methodologies that are capable of facilitating privacy-preserving data analysis. Distributed Analytics (DA) as an enabler for privacy-preserving analysis across multiple data sources has shown its potential to support data-intensive research. However, the application of DA creates new challenges stemming from its distributed nature, such as identifying single points of failure (SPOFs) in DA tasks before their actual execution. Failing to detect such SPOFs can, for example, result in improper termination of the DA code, necessitating additional efforts from multiple stakeholders to resolve the malfunctions. Moreover, these malfunctions disrupt the seamless conduct of DA and entail several crucial consequences, including technical obstacles to resolve the issues, potential delays in research outcomes, and increased costs. In this study, we address this challenge by introducing a concept based on a method called Smoke Testing, an initial and foundational test run to ensure the operability of the analysis code. We review existing DA platforms and systematically extract six specific Smoke Testing criteria for DA applications. With these criteria in mind, we create an interactive environment called Development Environment for AuTomated and Holistic Smoke Testing of Analysis-Runs (DEATHSTAR), which allows researchers to perform Smoke Tests on their DA experiments. We conduct a user-study with 29 participants to assess our environment and additionally apply it to three real use cases. The results of our evaluation validate its effectiveness, revealing that 96.6% of the analyses created and (Smoke) tested by participants using our approach successfully terminated without any errors. Thus, by incorporating Smoke Testing as a fundamental method, our approach helps identify potential malfunctions early in the development process, ensuring smoother data-driven research within the scope of DA. Through its flexibility and adaptability to diverse real use cases, our solution enables more robust and efficient development of DA experiments, which contributes to their reliability.|||Article||||
WEB OF SCIENCE|Arruda, Filipe; Barros, Flavia; Sampaio, Augusto|||Automation and consistency analysis of test cases written in natural language: An industrial context|2020|SCIENCE OF COMPUTER PROGRAMMING|189||102377|||||10.1016/j.scico.2019.102377||We present here a novel test automation strategy that receives as input a freestyle natural language (NL) test case (consisting of a sequence of test steps) and produces executable test scripts. This strategy relies on a database of previously automated seed test steps, available for reuse. New steps are automated via a capturing process by a tester, without requiring any programming knowledge. Automated tests can be executed by a replay facility. We discuss the reuse improvement, implementation effort, and user feedback regarding the industrial applicability and usability of our capture & replay tool. We then show that restricting the input textual description to obey a proposed Controlled NL (CNL) brings significant advantages: (1) reuse improvement; (2) the possibility of integration with a test generation framework; and (3) definition of consistency notions for test actions and test action sequences, that ensure, respectively, well-formedness of each action and a proper configuration to safely execute a sequence of actions. We formalize these consistency notions in Alloy and use the Alloy Analyzer to carry out the consistency check; the scalability of the analysis is assessed via an evaluation considering a repository with real test cases; the practical context of our work is mobile device testing, involving a partnership with Motorola Mobility, a Lenovo company. (C) 2019 Elsevier B.V. All rights reserved.|||Article; Proceedings Paper||||
WEB OF SCIENCE|Altin, Mahsun; Mutlu, Behcet; Kilinc, Deniz; Cakir, Altan|||Automated Testing for Service-Oriented Architecture: Leveraging Large Language Models for Enhanced Service Composition|2025|IEEE ACCESS|13|||89627|89640|||10.1109/ACCESS.2025.3571994||This article explores the application of Large Language Models (LLMs), including proprietary models such as OpenAI's ChatGPT 4o and ChatGPT 4o-mini, Anthropic's Claude 3.5 Sonnet and Claude 3.7 Sonnet, and Google's Gemini 1.5 Pro, Gemini 2.0 Flash, and Gemini 2.0 Flash-Lite, as well as open-source alternatives including Qwen2.5-14B-Instruct-1M, and commercially accessed models such as DeepSeek R1 and DeepSeek V3, which were tested via APIs despite having open-source variants, to automate validation and verification in Application Programming Interface (API) testing within a Service-Oriented Architecture (SOA). Our system compares internal responses from the Enuygun Web Server against third-party API outputs in both JSON and XML formats, validating critical parameters such as flight prices, baggage allowances, and seat availability. We generated 100 diverse test scenarios across varying complexities (1-4 flight results) by randomly altering request and response parameters. Experimental results show that Google Gemini 2.0 Flash achieved high accuracy (up to 99.98%) with the lowest completion time (85.34 seconds), while Qwen2.5-14B-Instruct-1M exhibited limited capability in processing complex formats. Models such as OpenAI's ChatGPT and Anthropic's Claude Sonnet models also demonstrated strong performance in single-flight validation scenarios, making them suitable for low-latency, high-precision tasks. Our findings indicate that some open-source models can offer promising cost-effective alternatives, though performance significantly varies. This integration of LLMs reduced manual workload, improved test scalability, and enabled real-time validation across large-scale datasets. As LLM technologies mature, we anticipate further advances in automation, accuracy, and efficiency in software validation systems.|||Article||||
WEB OF SCIENCE|Yoon, Hoijin|||Finding Unexpected Test Accuracy by Cross Validation in Machine Learning|2021|INTERNATIONAL JOURNAL OF COMPUTER SCIENCE AND NETWORK SECURITY|21|12||549|555|||10.22937/IJCSNS.2021.21.12.76||Machine Learning(ML) splits data into 3 parts, which are usually 60% for training, 20% for validation, and 20% for testing. It just splits quantitatively instead of selecting each set of data by a criterion, which is very important concept for the adequacy of test data. ML measures a model's accuracy by applying a set of validation data, and revises the model until the validation accuracy reaches on a certain level. After the validation process, the complete model is tested with the set of test data, which are not seen by the model yet. If the set of test data covers the model's attributes well, the test accuracy will be close to the validation accuracy of the model. To make sure that ML's set of test data works adequately, we design an experiment and see if the test accuracy of model is always close to its validation adequacy as expected. The experiment builds 100 different SVM models for each of six data sets published in UCI ML repository. From the test accuracy and its validation accuracy of 600 cases, we find some unexpected cases, where the test accuracy is very different from its validation accuracy. Consequently, it is not always true that ML's set of test data is adequate to assure a model's quality.|||Article||||
WEB OF SCIENCE|Zhong, Ziyuan; Kaiser, Gail; Ray, Baishakhi|||Neural Network Guided Evolutionary Fuzzing for Finding Traffic Violations of Autonomous Vehicles|2023|IEEE TRANSACTIONS ON SOFTWARE ENGINEERING|49|4||1860|1875|||10.1109/TSE.2022.3195640||Self-driving cars and trucks, autonomous vehicles (avs), should not be accepted by regulatory bodies and the public until they have much higher confidence in their safety and reliability - which can most practically and convincingly be achieved by testing. But existing testing methods are inadequate for checking the end-to-end behaviors of av controllers against complex, real-world corner cases involving interactions with multiple independent agents such as pedestrians and human-driven vehicles. While test-driving avs on streets and highways fails to capture many rare events, existing simulation-based testing methods mainly focus on simple scenarios and do not scale well for complex driving situations that require sophisticated awareness of the surroundings. To address these limitations, we propose a new fuzz testing technique, called AutoFuzz, which can leverage widely-used av simulators' API grammars to generate semantically and temporally valid complex driving scenarios (sequences of scenes). To efficiently search for traffic violations-inducing scenarios in a large search space, we propose a constrained neural network (NN) evolutionary search method to optimize AutoFuzz. Evaluation of our prototype on one state-of-the-art learning-based controller, two rule-based controllers, and one industrial-grade controller in five scenarios shows that AutoFuzz efficiently finds hundreds of traffic violationsin high-fidelity simulation environments. For each scenario, AutoFuzz can find on average 10-39% more unique traffic violationsthan the best-performing baseline method. Further, fine-tuning the learning-based controller with the traffic violationsfound by AutoFuzz successfully reduced the traffic violationsfound in the new version of the av controller software.|||Article||||
WEB OF SCIENCE|Nevendra, Meetesh; Singh, Pradeep|||Cross-Project Defect Prediction with Metrics Selection and Balancing Approach|2022|APPLIED COMPUTER SYSTEMS|27|2||137|148|||10.2478/acss-2022-0015||- In software development, defects influence the quality and cost in an undesirable way. Software defect prediction (SDP) is one of the techniques which improves the software quality and testing efficiency by early identification of defects(bug/fault/error). Thus, several experiments have been suggested for defect prediction (DP) techniques. Mainly DP method utilises historical project data for constructing prediction models. SDP performs well within projects until there is an adequate amount of data accessible to train the models. However, if the data are inadequate or limited for the same project, the researchers mainly use Cross-Project Defect Prediction (CPDP). CPDP is a possible alternative option that refers to anticipating defects using prediction models built on historical data from other projects. CPDP is challenging due to its data distribution and domain difference problem. The proposed framework is an effective two-stage approach for CPDP, i.e., model generation and prediction process. In model generation phase, the conglomeration of different pre-processing, including feature selection and class reweights technique, is used to improve the initial data quality. Finally, a fine-tuned efficient bagging and boosting based hybrid ensemble model is developed, which avoids model overfitting/under-fitting and helps enhance the prediction performance. In the prediction process phase, the generated model predicts the historical data from other projects, which has defects or clean. The framework is evaluated using25 software projects obtained from public repositories. The result analysis shows that the proposed model has achieved a 0.71 +/- 0.03 f1-score, which significantly improves the state-of-the-art approaches by 23 % to 60 %.|||Article||||
WEB OF SCIENCE|Taesiri, Mohammad Reza; Macklon, Finlay; Habchi, Sarra; Bezemer, Cor-Paul|||Searching Bug Instances in Gameplay Video Repositories|2024|IEEE TRANSACTIONS ON GAMES|16|3||697|710|||10.1109/TG.2024.3355285||Gameplay videos offer valuable insights into player interactions and game responses, particularly data about game bugs. Despite the abundance of gameplay videos online, extracting useful information remains a challenge. This article introduces a method for searching and extracting relevant videos from extensive video repositories using English text queries. Our approach requires no external information, like video metadata; it solely depends on video content. Leveraging the zero-shot transfer capabilities of the contrastive language-image pretraining model, our approach does not require any data labeling or training. To evaluate our approach, we present the GamePhysics dataset, comprising 26 954 videos from 1873 games that were collected from the GamePhysics section on the Reddit website. Our approach shows promising results in our extensive analysis of simple and compound queries, indicating that our method is useful for detecting objects and events in gameplay videos. Moreover, we assess the effectiveness of our method by analyzing a carefully annotated dataset of 220 gameplay videos. The results of our study demonstrate the potential of our approach for applications, such as the creation of a video search tool tailored to identifying video game bugs, which could greatly benefit quality assurance teams in finding and reproducing bugs.|||Article||||
WEB OF SCIENCE||||POSE: Phase II: An Open Source Ecosystem for Collaborative Rapid Design of Edge AI Hardware Accelerators for Integrated Data Analysis and Discovery|2023|||||||||||This project develops an ecosystem for hls4ml, which is a tool for designing machine learning inference in hardware. Machine learning models written in popular languages (e.g. PyTorch, Keras) are translated by hls4ml into specialty descriptions utilized by digital circuit designers. Hand crafting these system definitions is a process with a high barrier to entry, likely to result in poor quality results, for domain experts (e.g., scientists) without hardware design expertise. This project will innovate and deploy infrastructures and management solutions for support of the developers and users, leading to an extensive, connected, and well-supported ML hardware design automation community bridging hardware experts and domain experts. The project will develop a set of components comprising a support infrastructure for hls4ml. These components include training for users, automated testing and validation procedures for new components contributed to the tool, security validation of developers, creation of review and vetting procedures for quality control of the tool set, and a system for users and developers to report and request features. The ecosystem resulting from this project will manage access to a catalog of pre-designed and validated software packages and Intellectual Property hardware blocks, which can be used for both educational purposes and to build custom machine learning computational systems. The ecosystem will enable application and domain experts from a wide range of disciplines and affiliations (science, health, mobile, academic institutions, government laboratories, industry) to successfully utilize automated design flows to create customized machine learning hardware. This will enhance the productivity and overall ability of the underlying science discovery and technology development efforts, where these systems are deployed. The synergy catalyzed between domain experts and hardware experts will help these communities create powerful co-design methodologies and train the new generation of experts who will be proficient in applying them as part of the future workforce in data-driven disciplines. This collaborative project brings together investigators from Northwestern University, University of Illinois (Urbana-Champaign and Chicago), and Arizona State University. The project���s products and activities will be made available through https://fastmachinelearning.org/hls4ml/ . The project team plans to maintain the project repositories and website for a minimum of 3 years past the completion of this project. This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.|||Awarded Grant||||
WEB OF SCIENCE|Shen, Weijun; Li, Yanhui; Han, Yuanlei; Chen, Lin; Wu, Di; Zhou, Yuming; Xu, Baowen|||Boundary sampling to boost mutation testing for deep learning models|2021|INFORMATION AND SOFTWARE TECHNOLOGY|130||106413|||||10.1016/j.infsof.2020.106413||Context: The prevalent application of Deep Learning (DL) models has raised concerns about their reliability. Due to the data-driven programming paradigm, the quality of test datasets is extremely important to gain accurate assessment of DL models. Recently, researchers have introduced mutation testing into DL testing, which applies mutation operators to generate mutants from DL models, and observes whether the test data can identify mutants to check the quality of test dataset. However, there still exist many factors (e.g., huge labeling efforts and high running cost) hindering the implementation of mutation testing for DL models.Objective: We desire for an approach to selecting a smaller, sensitive, representative and efficient subset of the whole test dataset to promote the current mutation testing (e.g., reduce labeling and running cost) for DL Models.Method: We propose boundary sample selection (BSS), which employs the distance of samples to decision boundary of DL models as the indicator to construct the appropriate subset. To evaluate the performance of BSS, we conduct an extensive empirical study with two widely-used datasets, three popular DL models, and 14 up-to-date DL mutation operators. Results: We observe that (1) The sizes of our subsets generated by BSS are much smaller (about 3%-20% of the whole test set). (2) Under most mutation operators, our subsets are superior (about 9.94-21.63) than the whole test sets in observing mutation effects. (3) Our subsets could replace the whole test sets to a very high degree (higher than 97%) when considering mutation score. (4) The MRR values of our proposed subsets are clearly better (about 2.28-13.19 times higher) than that of the whole test sets.Conclusions: The result shows that BSS can help testers save labelling cost, run mutation testing quickly and identify killed mutants early.|||Article||||
WEB OF SCIENCE|Guzu, Alexandru; Nicolae, Georgian; Cucu, Horia; Burileanu, Corneliu|||Large Language Models for C Test Case Generation: A Comparative Analysis|2025|ELECTRONICS|14|11|2284|||||10.3390/electronics14112284||Software testing is a crucial yet time-consuming aspect of software development. Writing comprehensive unit tests that accurately verify whether a function or an entire program behaves as intended requires considerable effort from developers, particularly when handling numerous edge cases. This study explores how Large Language Models (LLMs) can streamline this process by automatically generating effective unit tests. We evaluate various LLMs on their capability to interpret problem specifications, analyze source code across multiple programming languages, and generate suitable test cases. The effectiveness of these test cases is assessed using the Pass@1 and line coverage metrics. Our findings reveal that LLMs perform significantly better when provided with both the problem description and the corresponding solution code, particularly in the C programming language. Additionally, we observe substantial performance improvements when example test cases are included in the prompt, leading to higher Pass@1 scores and enhanced code coverage, particularly with more advanced LLMs.|||Article||||
WEB OF SCIENCE|Bouchoucha, Rached; Ben Braiek, Houssem; Khomh, Foutse; Bouzidi, Sonia; Zaatour, Rania|||Robustness assessment of hyperspectral image CNNs using metamorphic testing|2023|INFORMATION AND SOFTWARE TECHNOLOGY|162||107281|||||10.1016/j.infsof.2023.107281||Remote sensing has proven its utility in many critical domains, such as medicine, military, and ecology. Recently, we have been witnessing a surge in the adoption of deep learning (DL) techniques by the remote sensing community. DL-based classifiers, such as convolutional neural networks (CNNs), have been reported to achieve impressive predictive performances reaching 99% of accuracy when applied to hyperspectral images (HSIs), a high-dimensional type of remote sensing data. However, these deep learners are known to be highly sensitive to even slight perturbations of their high-dimensional raw inputs. In real-world contexts, concerns can be raised about how robust they really are against corner-case scenarios. When HSI classifiers are applied in safety-critical applications, ensuring an adequate level of robustness is crucial to prevent unexpected system behaviors. Yet, there are few studies dealing with their robustness, nor are RGB-testing methods able to cover the HSI-specific challenges. This led us to propose a systematic testing method to assess the robustness of the CNNs trained to classify HSIs. First, we elaborate domain-specific metamorphic transformations that simulate naturally-occurring distortions of remote sensing HSIs. Then, we leverage metaheuristic search algorithms to optimize the fitness of synthetically-distorted inputs to stress the weaknesses of the on-testing CNN, while remaining in compliance with domain expert requirements, in order to preserve the semantic of the generated inputs. Relying on our metamorphic testing method, we assess the robustness of established and novel CNNs for HSI classification, and demonstrate their failure, on average, in 25% of the produced test cases. Furthermore, we fine-tuned the tested CNNs on training data augmented with these failure-revealing metamorphic transformations. Results show that the fined-tuning successfully fixed at least 90% of the CNN weaknesses, with less than 1% of degradation in the original predictive performance, outperforming the common iterative gradient-based adversarial attack, namely, Projected Gradient Descent (PGD).|||Article||||
WEB OF SCIENCE|Ma, Chunyan; Liu, Shaoying; Fu, Jinglan; Zhang, Tao|||Test Oracle Generation Based on BPNN by Using the Values of Variables at Different Breakpoints for Programs|2021|INTERNATIONAL JOURNAL OF SOFTWARE ENGINEERING AND KNOWLEDGE ENGINEERING|31|10||1469|1494|||10.1142/S0218194021500492||Automatic test oracle generation is a bottleneck in realizing full automation of the entire software testing process. This study proposes a new method for automatically generating a test oracle for a new test input on the basis of several historical test cases by using a backpropagation neural network (BPNN) model. The new method is different from existing test oracle techniques. Specifically, our method has two steps. First, the values of variables are collected as training data when several historical test inputs are used to execute the program at different breakpoints. The test oracles (pass or fail) of these test cases are utilized to classify and label the training data. Second, a new test input is used to execute the program at different breakpoints, where the trained BPNN prediction model automatically generates its test oracle on the basis of the collected values of the variables involved. We conduct an experiment to validate our method. In the experiment, 113 faulty versions of seven types of programs are used as experimental objects. Results show that the average prediction accuracy rate of 74,651 test oracles is 95.8%. Although the failed test cases in the training data account for less than 5%, the overall average recall rate (prediction accuracy of test case execution failure) of all programs is 78.9%. Furthermore, the trained BPNN can reveal not only the impact of the values of variables but also the impact of the logical correspondence between variables in test oracle generation.|||Article||||
WEB OF SCIENCE|Khleel, Nasraldeen Alnor Adam; Nehez, Karoly|||Software defect prediction using a bidirectional LSTM network combined with oversampling techniques|2024|CLUSTER COMPUTING-THE JOURNAL OF NETWORKS SOFTWARE TOOLS AND APPLICATIONS|27|3||3615|3638|||10.1007/s10586-023-04170-z||Software defects are a critical issue in software development that can lead to system failures and cause significant financial losses. Predicting software defects is a vital aspect of ensuring software quality. This can significantly impact both saving time and reducing the overall cost of software testing. During the software defect prediction (SDP) process, automated tools attempt to predict defects in the source codes based on software metrics. Several SDP models have been proposed to identify and prevent defects before they occur. In recent years, recurrent neural network (RNN) techniques have gained attention for their ability to handle sequential data and learn complex patterns. Still, these techniques are not always suitable for predicting software defects due to the problem of imbalanced data. To deal with this problem, this study aims to combine a bidirectional long short-term memory (Bi-LSTM) network with oversampling techniques. To establish the effectiveness and efficiency of the proposed model, the experiments have been conducted on benchmark datasets obtained from the PROMISE repository. The experimental results have been compared and evaluated in terms of accuracy, precision, recall, f-measure, Matthew's correlation coefficient (MCC), the area under the ROC curve (AUC), the area under the precision-recall curve (AUCPR) and mean square error (MSE). The average accuracy of the proposed model on the original and balanced datasets (using random oversampling and SMOTE) was 88%, 94%, And 92%, respectively. The results showed that the proposed Bi-LSTM on the balanced datasets (using random oversampling and SMOTE) improves the average accuracy by 6 and 4% compared to the original datasets. The average F-measure of the proposed model on the original and balanced datasets (using random oversampling and SMOTE) were 51%, 94%, And 92%, respectively. The results showed that the proposed Bi-LSTM on the balanced datasets (using random oversampling and SMOTE) improves the average F-measure by 43 and 41% compared to the original datasets. The experimental results demonstrated that combining the Bi-LSTM network with oversampling techniques positively affects defect prediction performance in datasets with imbalanced class distributions.|||Article||||
WEB OF SCIENCE|Devi, S. V. Gayetri; Ranjith, V. G.; Ramani, P.; Kavitha, A.|||Convolution neural network-AlexNet with gazelle optimization algorithm-based software defect prediction|2025|KNOWLEDGE AND INFORMATION SYSTEMS|67|7||6285|6306|||10.1007/s10115-025-02408-3||Nowadays, the size and complexity of software systems have increased dramatically. Software defects are very challenging to prevent because of these characteristics. Therefore, developers may be able to better allocate their limited resources by predicting the number of defects in software modules automatically. There are various approaches presented for identifying and fixing such problems, but none of these give sufficient results. To address these, this paper proposes convolution neural network-AlexNet with gazelle optimization algorithm-based software defect prediction (SWDP-CNN-AlexNet-GAOA). Here, NASA software defect prediction dataset is used. The feature normalization ensures that all features contribute equally to the model. Without normalization, features with larger numerical values would dominate the learning process. Then, software defects are predicted using convolution neural network (CNN)-AlexNet. Finally, gazelle optimization algorithm (GAOA) is proposed to optimize the parameters of CNN-AlexNet. Simulation proves that the SWDP-CNN-AlexNet-GAOA method outperforms existing models. The proposed SWDP-CNN-AlexNet-GAOA approach attains 3.88%, 5.75%, and 4.94% better accuracy and 6.25%, 5.91%, and 11.28% better F-measure compared with the existing methods, like software defect prediction using enhanced CNN (SWDP-EN-CNN), software defect prediction using hybrid swarm intelligence and deep learning (SWDP-HS-DL), and software defect prediction under ant colony optimization (SWDP-ACO), respectively.|||Article||||
WEB OF SCIENCE|Ooster, Jasper; Tuschen, Laura; Meyer, Bernd T.|||Self-conducted speech audiometry using automatic speech recognition: Simulation results for listeners with hearing loss|2023|COMPUTER SPEECH AND LANGUAGE|78||101447|||||10.1016/j.csl.2022.101447||Speech-in-noise tests are an important tool for assessing hearing impairment, the successful fitting of hearing aids, as well as for research in psychoacoustics. An important drawback of many speech-based tests is the requirement of an expert to be present during the measurement, in order to assess the listener's performance. This drawback may be largely overcome through the use of automatic speech recognition (ASR), which utilizes automatic response logging. However, such an unsupervised system may reduce the accuracy due to the introduction of potential errors. In this study, two different ASR systems are compared for automated testing: A system with a feed-forward deep neural network (DNN) from a previous study (Ooster et al., 2018), as well as a state-of-the-art system utilizing a time-delay neural network (TDNN). The dynamic measurement procedure of the speech intelligibility test was simulated considering the subjects' hearing loss and selecting from real recordings of test participants. The ASR systems' performance is investigated based on responses of 73 listeners, ranging from normal -hearing to severely hearing-impaired as well as read speech from cochlear implant listeners. The feed-forward DNN produced accurate testing results for NH and unaided HI listeners but a decreased measurement accuracy was found in the simulation of the adaptive measurement procedure when considering aided severely HI listeners, recorded in noisy environments with a loudspeaker setup. The TDNN system produces error rates of 0.6% and 3.0% for deletion and insertion errors, respectively. We estimate that the SRT deviation with this system is below 1.38 dB for 95% of the users. This result indicates that a robust unsupervised conduction of the matrix sentence test is possible with a similar accuracy as with a human supervisor even when considering noisy conditions and altered or disordered speech from elderly severely HI listeners and listeners with a CI.|||Article||||
WEB OF SCIENCE|Tang, Yutian; Liu, Zhijie; Zhou, Zhichao; Luo, Xiapu|||ChatGPT vs SBST: A Comparative Assessment of Unit Test Suite Generation|2024|IEEE TRANSACTIONS ON SOFTWARE ENGINEERING|50|6||1340|1359|||10.1109/TSE.2024.3382365||Recent advancements in large language models (LLMs) have demonstrated exceptional success in a wide range of general domain tasks, such as question answering and following instructions. Moreover, LLMs have shown potential in various software engineering applications. In this study, we present a systematic comparison of test suites generated by the ChatGPT LLM and the state-of-the-art SBST tool EvoSuite. Our comparison is based on several critical factors, including correctness, readability, code coverage, and bug detection capability. By highlighting the strengths and weaknesses of LLMs (specifically ChatGPT) in generating unit test cases compared to EvoSuite, this work provides valuable insights into the performance of LLMs in solving software engineering problems. Overall, our findings underscore the potential of LLMs in software engineering and pave the way for further research in this area.|||Article||||
WEB OF SCIENCE|Bansal, Ankita; Jain, Abha; Anand, Abhijeet; Annk, Swatantra|||Proposal of Iterative Genetic Algorithm for Test Suite Generation|2021|INTERNATIONAL JOURNAL OF INFORMATION SYSTEM MODELING AND DESIGN|12|1||111|130|||10.4018/IJISMD.2021010106||Huge and reputed software industries are expected to deliver quality products. However, industry suffers from a loss of approximately $500 billion due to shoddy software quality. The quality of the product in terms of its accuracy, efficiency, and reliability can be revamped through testing by focusing attention on testing the product through effective test case generation and prioritization. The authors have proposed a test-case generation technique based on iterative listener genetic algorithm that generates test cases automatically. The proposed technique uses its adaptive nature and solves the issues like redundant test cases, inefficient test coverage percentage, high execution time, and increased computation complexity by maintaining the diversity of the population which will decrease the redundancy in test cases. The performance of the technique is compared with four existing testcase generation algorithms in terms of computational complexity, execution time, coverage, and it is observed that the proposed technique outperformed.|||Article||||
WEB OF SCIENCE|Guizzo, Giovani; Vergilio, Silvia R.|||A pattern-driven solution for designing multi-objective evolutionary algorithms|2020|NATURAL COMPUTING|19|3||481|494|||10.1007/s11047-018-9677-y||Multi-objective evolutionary algorithms (MOEAs) have been widely studied in the literature, which led to the development of several frameworks and techniques to implement them. Consequently, the reusability, scalability and maintainability became fundamental concerns in the development of such algorithms. To this end, the use of design patterns (DPs) can benefit, ease and improve the design of MOEAs. DPs are reusable solutions for common design problems, which can be applied to almost any context. Despite their advantages to decrease coupling, increase flexibility, and allow an easier design extension, DPs have been underexplored for MOEA design. In order to contribute to this research topic, we propose a pattern-driven solution for the design of MOEAs. The MOEA designed with our solution is compared to another MOEA designed without it. The comparison considered: the Integration and Test Order (ITO) problem and the Traveling Salesman problem (TSP). Obtained results show that the use of this DP-driven solution allows the reuse of MOEA components, without decreasing the quality, in terms of hypervolume. This means that the developer can extend the algorithms to include other components using only object-oriented mechanisms in an easier way, while maintaining the expected results.|||Article||||
WEB OF SCIENCE|Eniser, Hasan Ferit; Sen, Alper|||Virtualization of stateful services via machine learning|2020|SOFTWARE QUALITY JOURNAL|28|1||283|306|||10.1007/s11219-019-09468-z||Today's enterprise software systems are much more complicated than the past. Increasing numbers of dependent applications, heterogeneous technologies, and wide usage of Service-Oriented Architectures (SOA), where numerous services communicate with each other, makes testing of such systems challenging. For testing these software systems, the concept of service virtualization is gaining popularity. Service virtualization is an automated technique to mimic the behavior of a given real service. Services can be classified as stateless or stateful services. Many services are stateful in nature, yet virtualization of stateful services is harder than virtualization of stateless services. In this work, we introduce two novel stateful service virtualization approaches. We employ classification-based and sequence-to-sequence-based machine learning algorithms in developing our solutions. Classification is a supervised learning method where the task is assigning given inputs to corresponding classes. A sequence-to-sequence model is a deep neural network architecture where the input and the output are sequences. We demonstrate the validity of our approaches on three datasets. Our evaluation shows that we obtain 75 % to 81 % accuracy on subject datasets with classification based method. Our deep neural network-based solution achieves even better accuracy results ranging from 89 to 97 % on subject datasets. Our evaluation on training times of the mentioned techniques show that classification based technique significantly outperforms other methods.|||Article||||
WEB OF SCIENCE|Rathore, Santosh S.; Kumar, Sandeep|||An empirical study of ensemble techniques for software fault prediction|2021|APPLIED INTELLIGENCE|51|6||3615|3644|||10.1007/s10489-020-01935-6||Previously, many researchers have performed analysis of various techniques for the software fault prediction (SFP). Oddly, the majority of such studies have shown the limited prediction capability and their performance for given software fault datasets was not persistent. In contrast to this, recently, ensemble techniques based SFP models have shown promising and improved results across different software fault datasets. However, many new as well as improved ensemble techniques have been introduced, which are not explored for SFP. Motivated by this, the paper performs an investigation on ensemble techniques for SFP. We empirically assess the performance of seven ensemble techniques namely, Dagging, Decorate, Grading, MultiBoostAB, RealAdaBoost, Rotation Forest, and Ensemble Selection. We believe that most of these ensemble techniques are not used before for SFP. We conduct a series of experiments on the benchmark fault datasets and use three distinct classification algorithms, namely, naive Bayes, logistic regression, and J48 (decision tree) as base learners to the ensemble techniques. Experimental analysis revealed that rotation forest with J48 as the base learner achieved the highest precision, recall, and G-mean 1 values of 0.995, 0.994, and 0.994, respectively and Decorate achieved the highest AUC value of 0.986. Further, results of statistical tests showed used ensemble techniques demonstrated a statistically significant difference in their performance among the used ones for SFP. Additionally, the cost-benefit analysis showed that SFP models based on used ensemble techniques might be helpful in saving software testing cost and effort for twenty out of twenty-eight used fault datasets.|||Article||||
WEB OF SCIENCE|Rustamov, Fayozbek; Kim, Juhwan; Yu, Jihyeon; Kim, Hyunwook; Yun, Joobeom|||BugMiner: Mining the Hard-to-Reach Software Vulnerabilities through the Target-Oriented Hybrid Fuzzer|2021|ELECTRONICS|10|1|62|||||10.3390/electronics10010062||Greybox Fuzzing is the most reliable and essentially powerful technique for automated software testing. Notwithstanding, a majority of greybox fuzzers are not effective in directed fuzzing, for example, towards complicated patches, as well as towards suspicious and critical sites. To overcome these limitations of greybox fuzzers, Directed Greybox Fuzzing (DGF) approaches were recently proposed. Current DGFs are powerful and efficient approaches that can compete with Coverage-Based Fuzzers. Nevertheless, DGFs neglect to accomplish stability between usefulness and proficiency, and random mutations make it hard to handle complex paths. To alleviate this problem, we propose an innovative methodology, a target-oriented hybrid fuzzing tool that utilizes a fuzzer and dynamic symbolic execution (also referred to as a concolic execution) engine. Our proposed method aims to generate inputs that can quickly reach the target sites in each sequence and trigger potential hard-to-reach vulnerabilities in the program binary. Specifically, to dive deep into the target binary, we designed a proposed technique named BugMiner, and to demonstrate the capability of our implementation, we evaluated it comprehensively on bug hunting and crash reproduction. Evaluation results showed that our proposed implementation could not only trigger hard-to-reach bugs 3.1, 4.3, 2.9, 2.0, 1.8, and 1.9 times faster than Hawkeye, AFLGo, AFL, AFLFast, QSYM, and ParmeSan respectively but also scale to several real-world programs.|||Article||||
WEB OF SCIENCE|Li, Yun; Zhang, Yanmei; Ding, Yanru; Jiang, Shujuan; Yuan, Guan|||A class integration test order generation approach based on Sarsa algorithm|2024|AUTOMATED SOFTWARE ENGINEERING|31|1|7|||||10.1007/s10515-023-00406-9||Class integration test order generation is a key step in integration testing, researching this problem can help find unknown bugs and improve the efficiency of software testing. The challenge of this problem is ordering the classes to be integrated to minimize the cost of required stubs. However, the existing approaches of generating class integration test orders cannot satisfy this requirement well. Considering the excellent performance of reinforcement learning in sequence decision problems, this paper proposes a class integration test order generation approach based on Sarsa algorithm, which is a data-driven model-free reinforcement learning algorithm. This approach takes the stubbing complexity as the indicator to evaluate the stubbing cost and uses it to measure the quality of a class integration test order. The Sarsa algorithm is used to train the agent, and three indicators such as test return, dependency complexity, and the number of cycles are integrated into the design of the reward function to evaluate the merits of the current action. By recording an action path of the agent from its initial state to its termination state, a class integration test order can be obtained. The experimental results on 10 systems show that the class integration test order generation approach based on Sarsa algorithm can generate the class integration test orders with lower stubbing cost.|||Article||||
WEB OF SCIENCE|Anbu, M.|||Improved mayfly optimization deep stacked sparse auto encoder feature selection scorched gradient descent driven dropout XLM learning framework for software defect prediction|2022|CONCURRENCY AND COMPUTATION-PRACTICE & EXPERIENCE|34|25|e7240|||||10.1002/cpe.7240||Software testing is the process of improving software quality by classifying and removing defects in the software development. Previously, several methods were used for software defect prediction, but any one method did not provide sufficient accuracy. To overcome this issue, an improved may fly optimization with deep stacked sparse auto encoder feature selection scorched gradient descent driven dropout extreme learning machine framework (SDP-IMFOFS-GDDDXLMC) is proposed in this article for software defect prediction. Here, an IMFO method is considered for feature selection techniques. In feature selection technique, features are selected, such as PC1, PC4, and MC1 for selecting the probable minimal attribute. Then, GDDDXLMC approach is used to classify buggy and clean software detection. The proposed approach is implemented in MATLAB platform. The performance metrics, such as accuracy, precision, F-measure, sensitivity, specificity, Mathew correlation coefficient (MCC) is examined to examine the performance of the proposed method. The simulation performance of the proposed SDP-IMFOFS-GDDDXLMC method attains higher accuracy 99.75%, 97.85%, 95.13%, 14.89%, 16.34%, 17.89%, and 98.79, higher sensitivity 96.34%, 91.23%, 89.12%, 12.67%, 17.56%, 18.90%, and 87.25% higher specificity 14.89%, 16.89%, 20.67%, 93.67%, 92.37%, 98.47%, and 94.78% compared with the existing methods, like SDP-MLP-PSO, SDP-BPNN-RBFNN, SDP-CNN-RNN-LSTM, SDP-KBN-LIME, SDP-SLDeep-LSTM, SDP-K-PCA-ELM, and SDP-CNN-PHI forest, respectively.|||Article||||
WEB OF SCIENCE|Shi, Yanmei; Yu, Wei; Zhao, Yanxia; Jia, Yungang|||A Web Application Fingerprint Recognition Method Based on Machine Learning|2024|CMES-COMPUTER MODELING IN ENGINEERING & SCIENCES|140|1||887|906|||10.32604/cmes.2024.046140||Web application fingerprint recognition is an effective security technology designed to identify and classify web applications, thereby enhancing the detection of potential threats and attacks. Traditional fingerprint recognition methods, which rely on preannotated feature matching, face inherent limitations due to the ever -evolving nature and diverse landscape of web applications. In response to these challenges, this work proposes an innovative web application fingerprint recognition method founded on clustering techniques. The method involves extensive data collection from the Tranco List, employing adjusted feature selection built upon Wappalyzer and noise reduction through truncated SVD dimensionality reduction. The core of the methodology lies in the application of the unsupervised OPTICS clustering algorithm, eliminating the need for preannotated labels. By transforming web applications into feature vectors and leveraging clustering algorithms, our approach accurately categorizes diverse web applications, providing comprehensive and precise fingerprint recognition. The experimental results, which are obtained on a dataset featuring various web application types, affirm the efficacy of the method, demonstrating its ability to achieve high accuracy and broad coverage. This novel approach not only distinguishes between different web application types effectively but also demonstrates superiority in terms of classification accuracy and coverage, offering a robust solution to the challenges of web application fingerprint recognition.|||Article||||
WEB OF SCIENCE|Leotta, Maurizio; Olianas, Dario; Ricca, Filippo|||A large experimentation to analyze the effects of implementation bugs in machine learning algorithms|2022|FUTURE GENERATION COMPUTER SYSTEMS-THE INTERNATIONAL JOURNAL OF ESCIENCE|133|||184|200|||10.1016/j.future.2022.03.004||In the last years, Machine Learning (ML) has become extremely used in software systems: it is applied in many different contexts such as medicine, bioinformatics, finance, automotive, only to mention a few. One of the main drawbacks recognized in the literature is that there are still no consolidated approaches and strategies to ensure the reliability of the code implementing the underlying ML theoretical algorithms. This fact has potentially a strong impact since many critical software systems rely on ML algorithms for implementing intelligent behaviors, and so on (potentially) unreliable code that could cause, in extreme cases, catastrophic errors: e.g., loss of life due to a wrong diagnosis of an ML-based cancer classifier. Our work aims to understand better the impact that implementation bugs have on the results provided by ML algorithms. Such analysis is fundamental to define novel techniques able to detect bugs in ML-based software systems. Thus, we extensively analyzed thousands of bugs on eight ML algorithms (in particular, four classification algorithms and four clustering ones). The bugs were injected by using an automatic Mutation tool able to mimic realistic errors in the algorithms source code. The empirical study shows that a large amount of the injected bugs are silent since they do not influence the results the eight algorithms provide on the 17 datasets employed in our study; in the remaining cases, the bugs emerge as runtime errors, exceptions, or modified accuracy of the predictions. Moreover, we also discovered that about 1% of the injected bugs are extremely dangerous since they drastically affect the quality of the predictions only in rare cases and with specific datasets increasing the possibility of going unnoticed. The fact that a considerable portion of the bugs does not influence the behavior of the algorithms, on the datasets employed in our study, poses a considerable problem: indeed, among them, several other dangerous silent bugs could be present. They could emerge when the implementations of the algorithms are employed on a novel dataset and with different settings. So the problem of the dangerous silent bugs can potentially be more pervasive than shown in our study. (C) 2022 Elsevier B.V. All rights reserved.|||Article||||
WEB OF SCIENCE|Aditi; Ko, Sang-Ki|||Chain-of-Thought and Chain-of-Verification Prompting for Grammar-based Test Case Generation|2025|Journal of KIISE|52|1||29|34|||||Software testing is an essential but cost-intensive work in the software development process. Automatic test case generation tools are utilized to distinguish between the correct and the incorrect solutions more effectively than manually generating them. Many researchers have recently proposed deep learning-based methods to generate test cases automatically for given logical specifications of problems or programs. In this work, we propose teaching the large language models (LLMs) such as ChatGPT and Google Gemini to generate ‘test case grammars’ from problem specifications, particularly using the chain-of-thought (CoT) prompting. Additionally, we implemented it using the CoT to verify and by providing the details of generalized rules to the LLMs, termed “chain-of-verification” (CoVe). We further evaluate our method with the publicly available dataset, DeepMind CodeContests dataset, which consists of numerous programming problems ranging from beginner to advanced level and is submitted by programming students with test cases for verifying the correctness of programs.|||research-article||||
WEB OF SCIENCE|Joffe, Leonid|||Neural Networks and Search Landscapes for Software Testing|2020||||||||||||||Dissertation/Thesis||||
WEB OF SCIENCE|Intana, Adisak; Tantayakul, Kuljaree; Laosen, Kanjana; Charoenreh, Suraiya|||An Approach of Test Case Generation with Software Requirement Ontology|2023|INTERNATIONAL JOURNAL OF ADVANCED COMPUTER SCIENCE AND APPLICATIONS|14|8||1005|1014|||||Software testing plays an essential role in software development process since it helps to ensure that the developed software product is free from errors and meets the defined specifications before the delivery. As the software specification is mostly written in the form of natural language, this may lead to the ambiguity and misunderstanding by software developers and results in the incorrect test cases to be generated from this unclear specification. Therefore, to solve this problem, this paper presents a novel hybrid approach, Software Requirement Ontologies based Test Case Generation (ReqOntoTestGen) to enhance the reliability of existing software testing techniques. This approach enables a framework that combines ontology engineering with the software test case generation approaches. Controlled Natural Language (CNL) provided by the ROO (Rabbit to OWL Ontologies Authoring) tools is used by the framework to build the software requirement ontology from unstructured functional requirements. This eliminates the inconsistency and ambiguity of requirements before test case generation. The OWL ontology resulted from ontology engineering is then transformed into the XML file of data dictionary. Combination of Equivalence and Classification Tree Method (CCTM) is used to generate test cases from this XML file with the decision tree. This allows us to reduce redundancy of test cases and increase testing coverage. The proposed approach is demonstrated with the developed prototype tool. The contribution of the tool is confirmed by the validation and evaluation result with two real case studies, Library Management System (LMS) and Kidney Failure Diagnosis (KFD) Subsystem, as we expected.|||Article||||
WEB OF SCIENCE|Guo, Zhonghao; Xu, Xinyue; Chen, Xiangxian; Geng, Chenge|||A File-Statement Approach for Bug Localization: Optimizing IRBL and Combination Strategy|2025|IEEE ACCESS|13|||104159|104172|||10.1109/ACCESS.2025.3577608||One of the main objectives of software testing is to locate the position of bugs. Bug localization is generally categorized into statement-level and file-level localization. File-level bug localization is typically performed using information retrieval-based bug localization (IRBL) methods. However, when used alone, file-level bug localization can only identify bugs at the file level and has low accuracy, limiting its practicality. Integrating file-level and statement-level bug localization can produce more precise results. To address these limitations, this study proposes a novel hierarchical bug localization framework that integrates multiple localization techniques across the file and statement levels. First, we present AS_IRBL, an enhanced IRBL method that introduces two innovations: a word-attention component that selectively amplifies the weight of key terms in bug reports, and a complex-word segmentation component that improves semantic matching by decomposing compound identifiers. These enhancements lead to significantly improved file-level localization performance. Second, we introduce C_FF_S, a new cross-level integration strategy that hierarchically combines file-level and statement-level localization results. Unlike prior approaches, C_FF_S uses an activation-based weighting mechanism to adjust statement-level suspicion scores according to file-level confidence, enabling context-aware and more accurate bug localization. Experimental results on the Defects4J benchmark demonstrate the effectiveness of our method: AS_IRBL improves MAP by 30.44% and Einspect@n by 31.89% over baseline IRBL. C_FF_S outperforms existing combination strategies, with MAP, MRR, and Einspect@n increased by 6.08%, 7.31%, and 7.58%, respectively. These results confirm the novelty and practical value of our hierarchical and mechanism-driven approach to multi-level bug localization.|||Article||||
WEB OF SCIENCE|Murakami, Yukasa; Yamasaki, Yuta; Tsunoda, Masateru; Monden, Akito; Tahir, Amjed; Bennin, Kwabena Ebo; Toda, Koji; Nakasai, Keitaro|||The Impact of Defect (Re) Prediction on Software Testing|2025|IEICE TRANSACTIONS ON INFORMATION AND SYSTEMS|E108D|3||175|179|||10.1587/transinf.2024MPL0002||Cross-project defect prediction (CPDP) aims to use data from external projects as historical data may not be available from the same project. In CPDP, deciding on a particular historical project to build a training model can be difficult. To help with this decision, a Bandit Algorithm (BA) based approach has been proposed in prior research to select the most suitable learning project. However, this BA method could lead to the selection of unsuitable data during the early iteration of BA (i.e., early stage of software testing). Selecting an unsuitable model can reduce the prediction accuracy, leading to potential defect overlooking. This study aims to improve the BA method to reduce defects overlooking, especially during the early testing stages. Once all modules have been tested, modules tested in the early stage are re-predicted, and some modules are retested based on there-prediction. To assess the impact of re-prediction and retesting, we applied five kinds of BA methods, using 8, 16, and 32 OSS projects as learning data. The results show that the newly proposed approach steadily reduced the probability of defect overlooking without degradation of prediction accuracy.|||Article||||
WEB OF SCIENCE|Peischl, Bernhard; Tazl, Oliver A.; Wotawa, Franz|||Testing anticipatory systems: A systematic mapping study on the state of the art|2022|JOURNAL OF SYSTEMS AND SOFTWARE|192||111387|||||10.1016/j.jss.2022.111387||Context: Systems exhibiting anticipatory behavior are controlling devices that are influencing decisions critical to business with increasing frequency, but testing such systems has received little attention from the artificial intelligence or software engineering communities. Goal: In this article, we describe research activities being carried out to test anticipatory systems and explore how this research contributes to the body of knowledge. In addition, we review the types of addressed anticipatory applications and point out open issues and trends. Method: This systematic mapping study was conducted to classify and analyze the literature on testing anticipatory systems, enabling us to highlight the most relevant topics and potential gaps in this field. Results: We identified 206 studies that contribute to the testing of systems that exhibit anticipatory behavior. The papers address testing at stages such as context sensing, inferring higher-level concepts from the sensed data, predicting the future context, and intelligent decision-making. We also identified agent testing as a trend, among others. Conclusion: The existing literature on testing anticipatory systems has originated from various research communities, such as those on autonomous agents and quality engineering. Although researchers have recently exhibited increasing interest in testing anticipatory systems, theoretical knowledge about testing such systems is lacking. (c) 2022 The Author(s). Published by Elsevier Inc. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).|||Article||||
WEB OF SCIENCE|Al Salem, Hamad|||Using Grammar Extracted from Sample Input to Generate Effective Fuzzing Files|2021||||||||||||||Dissertation/Thesis||||
WEB OF SCIENCE|Bernal Cardenas, Carlos Eduardo|||On Supporting Android Software Developers and Testers|2021||||||||||||||Dissertation/Thesis||||
WEB OF SCIENCE||||SHF: Medium: Software Engineering for Hardware Errors|2020|||||||||||Silicon technology underlying the growth in computer performance and functionality over the last several decades is now reaching fundamental physical limits. As this happens, computer hardware is becoming increasingly susceptible to errors. Traditional reliability solutions to avoid such errors rely on indiscriminate redundancy, which is too expensive for emerging systems. A promising approach is to rely on software to provide acceptable resiliency to hardware errors at a much lower cost by using selective redundancy only where needed. A key obstacle to practical adoption of software-driven solutions is that some hardware errors may escape the software stack, leading to unacceptable data corruptions. It is therefore critical to develop analysis techniques that can identify software regions that are potentially vulnerable to hardware errors, and low-cost mitigation or hardening techniques that can make such software regions resilient to data corruption. This project is to develop a principled and scalable approach to resiliency analysis and hardening for software. The project is based on two observations. First, resiliency analysis is analogous to the problem of software testing, which seeks to find software bugs. Second, resiliency hardening is analogous to software debugging and repair. The work will leverage methods previously used for software testing and debugging to improve resiliency analysis and hardening for diverse computer architectures. It will (1) explore new testing-based techniques to improve the quality and diversity of test inputs used for resiliency analysis; (2) leverage program-analysis and machine-learning methods to make resiliency analysis faster and more accurate for diverse computer architectures; (3) develop formal specifications, optimization strategies, and machine-learning-based methods to harden software using low-cost checkers; and (4) develop techniques to apply resiliency solutions in an incremental and compositional way. The goal is to make the promise of low-cost software-driven approaches to hardware reliability practical by incorporating resiliency analysis and hardening within a modern software-development workflow. The project offers the opportunity for multidisciplinary training of students in the fields of computer architecture, software testing, program analysis, and machine learning, as well as broadening participation in computing through increased recruitment and retention efforts for women and under-represented minorities. This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.|||Awarded Grant||||
WEB OF SCIENCE|Wang, Junjie; Yang, Ye; Wang, Song; Chen, Chunyang; Wang, Dandan; Wang, Qing|||Context-Aware Personalized Crowdtesting Task Recommendation|2022|IEEE TRANSACTIONS ON SOFTWARE ENGINEERING|48|8||3131|3144|||10.1109/TSE.2021.3081171||Crowdsourced software testing (short for crowdtesting) is a special type of crowdsourcing. It requires that crowdworkers master appropriate skill-sets and commit significant effort for completing a task. Abundant uncertainty may arise during a crowdtesting process due to imperfect information between the task requester and crowdworkers. For example, a worker frequently chooses tasks in an ad hoc manner in crowdtesting context, and an inappropriate task selection may lead to the worker's failing to detect any bugs, and significant testing effort unpaid and wasted. Recent studies have explored methods for supporting task requesters to make informed decisions on task pricing, worker recommendation, and so on. Unfortunately, very few study offers decision making support from the crowdworkers' perspectives. We motivate this study through a pilot study, revealing the large portion (74 percent) of unpaid crowdworkers' effort due to the inappropriate task choice. Drawn from our previous work on context-aware crowdworker recommendations, we advocate a more effective alternative to manual task selection would be to provide contextualized and personalized task recommendation considering the diverse distribution of worker preference and expertise, with objectives to increase their winning chances and to potentially reduce the frequency of unpaid crowd work. This paper proposes a context-aware personalized task recommendation approach PTRec, consisting of a testing context model and a learning-based task recommendation model to aid dynamic worker decision in selecting crowdtesting tasks. The testing context model is constructed in two perspectives, i.e., process context and resource context, to capture the in-process progress-oriented information and crowdworkers' characteristics respectively. Built on top of this context model, the learning-based task recommendation model extracts 60 features automatically, and employs random forest learner to generate dynamic and personalized task recommendation which matches workers' expertise and interest. The evaluation is conducted on 636 crowdtesting tasks involving 2,404 crowdworkers from one of the largest crowdtesting platforms, and results show our approach can achieve an average precision of 82 percent, average recall of 84 percent, and save an estimated average of 81 percent effort originally spent on exploring, significantly outperforming four commonly-used and state-of-the-art baselines. This indicates its potential in recommending proper tasks to workers so as to improve bug detection efficiency and increase their monetary earnings.|||Article||||
WEB OF SCIENCE|Liu, Kui; Kim, Dongsun; Bissyande, Tegawende F.; Yoo, Shin; Le Traon, Yves|||Mining Fix Patterns for FindBugs Violations|2021|IEEE TRANSACTIONS ON SOFTWARE ENGINEERING|47|1||165|188|||10.1109/TSE.2018.2884955||Several static analysis tools, such as Splint or FindBugs, have been proposed to the software development community to help detect security vulnerabilities or bad programming practices. However, the adoption of these tools is hindered by their high false positive rates. If the false positive rate is too high, developers may get acclimated to violation reports from these tools, causing concrete and severe bugs being overlooked. Fortunately, some violations are actually addressed and resolved by developers. We claim that those violations that are recurrently fixed are likely to be true positives, and an automated approach can learn to repair similar unseen violations. However, there is lack of a systematic way to investigate the distributions on existing violations and fixed ones in the wild, that can provide insights into prioritizing violations for developers, and an effective way to mine code and fix patterns which can help developers easily understand the reasons of leading violations and how to fix them. In this paper, we first collect and track a large number of fixed and unfixed violations across revisions of software. The empirical analyses reveal that there are discrepancies in the distributions of violations that are detected and those that are fixed, in terms of occurrences, spread and categories, which can provide insights into prioritizing violations. To automatically identify patterns in violations and their fixes, we propose an approach that utilizes convolutional neural networks to learn features and clustering to regroup similar instances. We then evaluate the usefulness of the identified fix patterns by applying them to unfixed violations. The results show that developers will accept and merge a majority (69/116) of fixes generated from the inferred fix patterns. It is also noteworthy that the yielded patterns are applicable to four real bugs in the Defects4J major benchmark for software testing and automated repair.|||Article||||
WEB OF SCIENCE|Behera, Rajat Kumar; Bala, Pradip Kumar; Jain, Rashmi|||A rule-based automated machine learning approach in the evaluation of recommender engine|2020|BENCHMARKING-AN INTERNATIONAL JOURNAL|27|10||2721|2757|||10.1108/BIJ-01-2020-0051||Purpose Any business that opts to adopt a recommender engine (RE) for various potential benefits must choose from the candidate solutions, by matching to the task of interest and domain. The purpose of this paper is to choose RE that fits best from a set of candidate solutions using rule-based automated machine learning (ML) approach. The objective is to draw trustworthy conclusion, which results in brand building, and establishing a reliable relation with customers and undeniably to grow the business. Design/methodology/approach An experimental quantitative research method was conducted in which the ML model was evaluated with diversified performance metrics and five RE algorithms by combining offline evaluation on historical and simulated movie data set, and the online evaluation on business-alike near-real-time data set to uncover the best-fitting RE. Findings The rule-based automated evaluation of RE has changed the testing landscape, with the removal of longer duration of manual testing and not being comprehensive. It leads to minimal manual effort with high-quality results and can possibly bring a new revolution in the testing practice to start a service line Machine Learning Testing as a service (MLTaaS) and the possibility of integrating with DevOps that can specifically help agile team to ship a fail-safe RE evaluation product targeting SaaS (software as a service) or cloud deployment. Research limitations/implications A small data set was considered for A/B phase study and was captured for ten movies from three theaters operating in a single location in India, and simulation phase study was captured for two movies from three theaters operating from the same location in India. The research was limited to Bollywood and Ollywood movies for A/B phase, and Ollywood movies for simulation phase. Practical implications The best-fitting RE facilitates the business to make personalized recommendations, long-term customer loyalty forecasting, predicting the company's future performance, introducing customers to new products/services and shaping customer's future preferences and behaviors. Originality/value The proposed rule-based ML approach named 2-stage locking evaluation is self-learned, automated by design and largely produces time-bound conclusive result and improved decision-making process. It is the first of a kind to examine the business domain and task of interest. In each stage of the evaluation, low-performer REs are excluded which leads to time-optimized and cost-optimized solution. Additionally, the combination of offline and online evaluation methods offer benefits, such as improved quality with self-learning algorithm, faster time to decision-making by significantly reducing manual efforts with end-to-end test coverage, cognitive aiding for early feedback and unattended evaluation and traceability by identifying the missing test metrics coverage.|||Article||||
WEB OF SCIENCE|Sheoran, Snehlata; Mittal, Neetu; Gelbukh, Alexander|||Artificial bee colony algorithm in data flow testing for optimal test suite generation|2020|INTERNATIONAL JOURNAL OF SYSTEM ASSURANCE ENGINEERING AND MANAGEMENT|11|2||340|349|||10.1007/s13198-019-00862-1||Meta-heuristic Artificial Bee Colony Algorithm finds its applications in the optimization of numerical problems. The intelligent searching behaviour of honey bees forms the base of this algorithm. The Artificial Bee Colony Algorithm is responsible for performing a global search along with a local search. One of the major usage areas of Artificial Bee Colony Algorithm is software testing, such as in structural testing and test suite optimization. The implementation of Artificial Bee Colony Algorithm in the field of data flow testing is still unexplored. In data flow testing, the definition-use paths which are not definition-clear paths are the potential trouble spots. The main aim of this paper is to present a simple and novel algorithm by making use of artificial bee colony algorithm in the field of data flow testing to find out and prioritize the definition-use paths which are not definition-clear paths.|||Article||||
WEB OF SCIENCE|Julian-Iranzo, Pascual; Rigau, German; Saenz-Perez, Fernando; Velasco-Crespo, Pablo|||Conversion of the Spanish WordNet databases into a Prolog-readable format|2025|LANGUAGE RESOURCES AND EVALUATION|59|2||1631|1657|||10.1007/s10579-024-09752-w||WordNet is a lexical database for English that is supplied in a variety of formats, including one compatible with the Prolog programming language. Given the success and usefulness of WordNet, wordnets of other languages have been developed, including Spanish. The Spanish WordNet, like others, does not provide a version compatible with Prolog. This work aims to fill this gap by translating the Multilingual Central Repository (MCR) version of the Spanish WordNet into a Prolog-compatible format. Thanks to this translation, a set of Spanish lexical databases are obtained, which allows access to WordNet information using declarative techniques and the deductive capabilities of the Prolog language. Also, this work facilitates the development of other programs to analyze the obtained information. Remarkably, we have adapted the technique of differential testing, used in software testing, to verify the correctness of this conversion. In addition, to ensure the consistency of the generated Prolog databases, as well as the databases from which we started, a complete series of integrity constraint tests have been carried out. In this way we have discovered some inconsistency problems in the MCR databases that have a reflection in the generated Prolog databases and have been reported to the owners of those databases.|||Article||||
WEB OF SCIENCE|Jiang, Feng; Hu, Qiang; Yang, Zhiyong; Liu, Jinhuan; Du, Junwei|||A neighborhood rough sets-based ensemble method, with application to software fault prediction|2025|EXPERT SYSTEMS WITH APPLICATIONS|264||125919|||||10.1016/j.eswa.2024.125919||Software fault prediction (SFP) aims to detect fault-prone software modules, which is beneficial for allocating software testing resources and improving software quality. Recently, ensemble learning(EL)-based SFP methods have attracted much attention. Although many EL algorithms have been applied to SFP, they are still insufficient to generate multiple accurate and diverse base learners. Therefore, this paper presents a multi-modal EL algorithm (called NRSEL) based on neighborhood rough sets. In NRSEL, the technique of neighborhood approximate reduct (NAR) is used to implement the perturbation of attribute space and the bootstrap sampling technique is used to implement the perturbation of sample space. Asa novel technique for the perturbation of attribute space, NAR stems from the concept of approximate reduct in rough sets. We also consider the application of NRSEL to SFP, and employ a hybrid scheme (called SMOTE-NRSEL) to handle the problem of imbalanced data in SFP. We compare SMOTE-NRSEL with existing EL algorithms using 20 public datasets. Experimental results indicate that SMOTE-NRSEL is effective for SFP. Compared with the baseline algorithms, on average, SMOTE-NRSEL improves the AUC, F1-score, and MCC by 3.09%, 3.18%, and 7.5%, respectively. Moreover, the results of three statistical tests (including the paired t-test, Friedman test, and Nemenyi test) indicate that SMOTE-NRSEL is significantly better than the baseline algorithms inmost cases. This paper shows that NAR is a good choice for the perturbation of attribute space. With the help of NAR and the multi-modal perturbation strategy based on it, SMOTE-NRSEL can generate accurate and diverse base learners. The code is available at https://github.com/jiangfeng0278/NRSEL.|||Article||||
WEB OF SCIENCE|Guo, Shikai; Wang, Jiahui; Xu, Zhihao; Huang, Lin; Li, Hui; Chen, Rong|||Feature transfer learning by reinforcement learning for detecting software defect|2023|SOFTWARE-PRACTICE & EXPERIENCE|53|2||366|389|||10.1002/spe.3152||Software defects, produced inevitably in software projects, seriously affect the efficiency of software testing and maintenance. An appealing solution is the software defect prediction (SDP) that has achieved good performance in many software projects. However, the difference between features and the difference of the same feature between training data and test data may degrade defect prediction performance if such differences violate the model's assumption. To address this issue, we propose a SDP method based on feature transfer learning (FTL), which performs a transformation sequence for each feature in order to map the original features to another feature space. Specifically, FTL first uses the reinforcement learning scheme that automatically learns a strategy for transferring the potential feature knowledge from the training data. Then, we use the learned feature knowledge to inspire the transformation of the test data. The classifier is trained by the transformed training data and predicts defects for transformed test data. We evaluate the validity of FTL on 43 projects from PROMISE and NASA MDP using three classifiers, logistic regression, random forest, and Naive Bayes (NB). Experimental results indicate that FTL is better than the original classifiers and has the best performance on the NB classifier. For PROMISE, after using FTL, the average results of F1-score, AUC, MCC are 0.601, 0.757, and 0.350 respectively, which are 24.9%, 2.6%, and 16.7% higher than the original NB classifier results. The number of projects with improved performance accounts for 83.87%, 83.87%, and 64.52%. Similarly, FTL performs well on NASA MDP. Besides, compared with four feature engineering (FE) methods, FTL achieves an excellent improvement on most projects and the average performance is also better than or close to the FE methods.|||Article||||
WEB OF SCIENCE|Fang, Chunrong; Yu, Shengcheng; Zhang, Quanjun; Li, Xin; Liu, Yulei; Chen, Zhenyu|||Enhanced Crowdsourced Test Report Prioritization via Image-and-Text Semantic Understanding and Feature Integration|2025|IEEE TRANSACTIONS ON SOFTWARE ENGINEERING|51|1||283|304|||10.1109/TSE.2024.3516372||Crowdsourced testing has gained prominence in the field of software testing due to its ability to effectively address the challenges posed by the fragmentation problem in mobile app testing. The inherent openness of crowdsourced testing brings diversity to the testing outcome. However, it also presents challenges for app developers in inspecting a substantial quantity of test reports. To help app developers inspect the bugs in crowdsourced test reports as early as possible, crowdsourced test report prioritization has emerged as an effective technology by establishing a systematic optimal report inspecting sequence. Nevertheless, crowdsourced test reports consist of app screenshots and textual descriptions, but current prioritization approaches mostly rely on textual descriptions, and some may add vectorized image features at the image-as-a-whole level or widget level. They still lack precision in accurately characterizing the distinctive features of crowdsourced test reports. In terms of prioritization strategy, prevailing approaches adopt simple prioritization based on features combined merely using weighted coefficients, without adequately considering the semantics, which may result in biased and ineffective outcomes. In this paper, we propose EncrePrior, an enhanced crowdsourced test report prioritization approach via image-and-text semantic understanding and feature integration. EncrePrior extracts distinctive features from crowdsourced test reports. For app screenshots, EncrePrior considers the structure (i.e., GUI layout) and the contents (i.e., GUI widgets), viewing the app screenshot from the macroscopic and microscopic perspectives, respectively. For textual descriptions, EncrePrior considers the Bug Description and Reproduction Step as the bug context. During the prioritization, we do not directly merge the features with weights to guide the prioritization. Instead, in order to comprehensively consider the semantics, we adopt a prioritize-reprioritize strategy. This practice combines different features together by considering their individual ranks. The reports are first prioritized on four features separately. Then, the ranks on four sequences are used to lexicographically reprioritize the test reports with an integration of features from app screenshots and textual descriptions. Results of an empirical study show that EncrePrior outperforms the representative baseline approach DeepPrior by 15.61% on average, ranging from 2.99% to 63.64% on different apps, and the novelly proposed features and prioritization strategy all contribute to the excellent performance of EncrePrior.|||Article||||
WEB OF SCIENCE|Chhabra, Jitender Kumar|||A hybrid approach based on k-nearest neighbors and decision tree for software fault prediction|2023|KUWAIT JOURNAL OF SCIENCE|50|2||||||10.48129/kjs.18331||Software testing is a very important part of the software development life cycle to develop reliable , bug-free software but it consumes a lot of resources like development time, cost , effort. Researchers have developed many techniques to get prior knowledge of fault-prone modules so that testing time and cost can be reduced. In this research article, a hybrid approach of distance-based pruned classification and regression tree (CART) and k-nearest neighbors is proposed to improve the performance of soft-ware fault prediction. The proposed technique is tested on eleven medium to large scale software fault prediction datasets and performance is compared with decision tree classifier, SVM and its three vari-ations, random forest, KNN, and classification and regression t ree. Four performance metrics are used for comparison purposes that are accuracy, precision, recall, and f1-score. Results show that our pro-posed approach gives better performance for accuracy, precision, and f1-score performance metrics. The second experiment shows a significant amount of running time improvement over the standard k-nearest neighbor algorithm.|||Article||||
WEB OF SCIENCE|Biagiola, Matteo; Tonella, Paolo|||Testing the Plasticity of Reinforcement Learning-based Systems|2022|ACM TRANSACTIONS ON SOFTWARE ENGINEERING AND METHODOLOGY|31|4|80|||||10.1145/3511701||The dataset available for pre-release training of a machine-learning based system is often not representative of all possible execution contexts that the system will encounter in the field. Reinforcement Learning (RL) is a prominent approach among those that support continual learning, i.e., learning continually in the field, in the post-release phase. No study has so far investigated any method to test the plasticity of RL-based systems, i.e., their capability to adapt to an execution context that may deviate from the training one.We propose an approach to test the plasticity of RL-based systems. The output of our approach is a quantification of the adaptation and anti-regression capabilities of the system, obtained by computing the adaptation frontier of the system in a changed environment. We visualize such frontier as an adaptation/anti-regression heatmap in two dimensions, or as a clustered projection when more than two dimensions are involved. In this way, we provide developers with information on the amount of changes that can be accommodated by the continual learning component of the system, which is key to decide if online, in-the-field learning can be safely enabled or not.|||Article||||
WEB OF SCIENCE|Yan, Xiaoyu|||An In-Depth Investigation of Firefox Feature Testability Relating to an Automated Tool|2024||||||||||||||Dissertation/Thesis||||
WEB OF SCIENCE|Lyu, Deyun; Zhang, Zhenya; Arcaini, Paolo; Zhang, Xiao-Yi; Ishikawa, Fuyuki; Zhao, Jianjun|||SPECTACLE: Fault Localisation of AI-Enabled CPS by Exploiting Sequences of DNN Controller Inferences|2025|ACM TRANSACTIONS ON SOFTWARE ENGINEERING AND METHODOLOGY|34|4|110|||||10.1145/3705307||Cyber-physical systems (CPSs) are increasingly adopting deep neural networks (DNNs) as controllers, giving birth to AI-enabled CPSs. Despite their advantages, many concerns arise about the safety of DNN controllers. Numerous efforts have been made to detect system executions that violate safety specifications; however, once a violation is detected, to fix the issue, it is necessary to localise the parameters of the DNN controller responsible for the wrong decisions leading to the violation. This is particularly challenging, as it requires to consider a sequence of control decisions, rather than a single one, preceding the violation. To tackle this problem, we propose SPECTACLE, that can localise the faulty parameters in DNN controllers. SPECTACLE considers the DNN inferences preceding the specification violation and uses forward impact to determine the DNN parameters that are more relevant to the DNN outputs. Then, it identifies which of these parameters are responsible for the specification violation, by adapting classic suspiciousness metrics. Moreover, we propose two versions of SPECTACLE, that consider differently the timestamps that precede the specification violation. We experimentally evaluate the effectiveness of SPECTACLE on 6,067 faulty benchmarks, spanning over different application domains. The results show that SPECTACLE can detect most of the faults.|||Article||||
WEB OF SCIENCE|Guo, An; Feng, Yang; Cheng, Yizhen; Chen, Zhenyu|||Semantic-guided fuzzing for virtual testing of autonomous driving systems|2024|JOURNAL OF SYSTEMS AND SOFTWARE|212||112017|||||10.1016/j.jss.2024.112017||Autonomous driving systems (ADS) have achieved spectacular development and have been utilized in numerous safety -critical tasks. Nonetheless, in spite of their considerable advancement, ADS perception components with high complexity and low interpretability often demonstrate unexpected corner -case behaviors. Several realworld accidents involving self -driving cars even lead to fatalities. Before rolling the autonomous vehicles out to the end -users, it is vital to test and guarantee the safety of ADS. As one of the most critical autonomous driving testing techniques, the prevailing virtual testing depends on the tester using tool -specific languages to code traffic simulation programs correctly. However, this process often requires plenty of effort, and it may fail to capture various rare events from complex driving situations that require sophisticated awareness of the surroundings. In this paper, we design and implement a semantic -guided scene fuzzing framework for autonomous driving systems, namely FuzzScene, based on the metamorphic testing theory. It employs driving scenario description language for scenario representation and equips a tree -based mutation strategy to generate tests with proper oracle information. To improve the testing efficiency and detect misbehaviors under different settings, we propose a unique sampling strategy and construct a testing guidance criterion to optimize FuzzScene. We experiment FuzzScene with multiple steering controllers to evaluate its performance on different tasks. The experiment results show that the semantic transformed driving scenarios generated by FuzzScene efficiently detect hundreds of inconsistent behaviors of ADS. Also, the results confirm that FuzzScene can improve steering precision by retraining with the generated scenes.|||Article||||
WEB OF SCIENCE|ParkSeChan; YEOP, KIM DEOK; Lee, Woo Jin|||UnityPGTA: A Unity Platformer Game Testing Automation Tool Using Reinforcement Learning|2024|Journal of KIISE|51|2||149|156|||||The cost of game testing in the video game industry is significant, accounting for nearly half of the expenses. Research efforts are underway to automate testing processes to reduce testing costs. However, existing research on test automation often involves manual tasks such as script writing, which is costly and labor-intensive. Additionally, implementations using virtual environments like VGDL and GVG-AI pose challenges when applied to real game testing. In this paper, we propose a tool for automating game testing with the aim of system fault detection, focusing on a Unity platformer game. The proposed tool is based on a commercial game engine, autonomously analyzing the game without human intervention to establish an automated game testing environment. We compare and analyze the error detection results of the proposed tool with a random baseline model using open-source games, demonstrating the tool's effectiveness in performing automated game analysis and testing environment setup, ultimately reducing testing costs and improving quality and stability.|||research-article||||
WEB OF SCIENCE|Oriol, Xavier; Teniente, Ernest; Maynou, Marc; Nadal, Sergi|||Generating valid test data through data cloning|2023|FUTURE GENERATION COMPUTER SYSTEMS-THE INTERNATIONAL JOURNAL OF ESCIENCE|144|||179|191|||10.1016/j.future.2023.02.020||One of the most difficult, time-consuming and error-prone tasks during software testing is that of manually generating the data required to properly run the test. This is even harder when we need to generate data of a certain size and such that it satisfies a set of conditions, or business rules, specified over an ontology. To solve this problem, some proposals exist to automatically generate database sample data. However, they are only able to generate data satisfying primary or foreign key constraints but not more complex business rules in the ontology.We propose here a more general solution for generating test data which is able to deal with expressive business rules. Our approach, which is entirely based on the chase algorithm, first generates a small sample of valid test data (by means of an automated reasoner), then clones this sample data, and finally, relates the cloned data with the original data. All the steps are performed iteratively until a valid database of a certain size is obtained. We theoretically prove the correctness of our approach, and experimentally show its practical applicability.(c) 2023 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).|||Article||||
WEB OF SCIENCE|Al-Sharif, Ziad A.; Jeffery, Clinton L.|||AbstractTrace: The Use of Execution Traces to Cluster, Classify, Prioritize, and Optimize a Bloated Test Suite|2024|APPLIED SCIENCES-BASEL|14|23|11168|||||10.3390/app142311168||Due to the incremental and iterative nature of the software testing process, a test suite may become bloated with redundant, overlapping, and similar test cases. This paper aims to optimize a bloated test suite by employing an execution trace that encodes runtime events into a sequence of characters forming a string. A dataset of strings, each of which represents the code coverage and execution behavior of a test case, is analyzed to identify similarities between test cases. This facilitates the de-bloating process by providing a formal mechanism to identify, remove, and reduce extra test cases without compromising software quality. This form of analysis allows for the clustering and classification of test cases based on their code coverage and similarity score. This paper explores three levels of execution traces and evaluates different techniques to measure their similarities. Test cases with the same code coverage should generate the exact string representation of runtime events. Various string similarity metrics are assessed to find the similarity score, which is used to classify, detect, and rank test cases accordingly. Additionally, this paper demonstrates the validity of the approach with two case studies. The first shows how to classify the execution behavior of various test cases, which can provide insight into each test case's internal behavior. The second shows how to identify similar test cases based on their code coverage.|||Article||||
WEB OF SCIENCE|Omar, Ahmed Abdullah|||Development of Water Surface Robot System for Lake Sanitation and Sampling|2022||||||||||||||Dissertation/Thesis||||
WEB OF SCIENCE|Cui, Yuming; Liu, Songyong; Zhou, Da; Zhang, Deyi|||Position tracking and dynamic control of an innovative anchor beam supporting robot|2023|MECHANICS BASED DESIGN OF STRUCTURES AND MACHINES|51|2||721|739|||10.1080/15397734.2020.1853563||Position tracking modeling and automatic control of an innovative anchor beam supporting robot are presented. Specifically, the forward and inverse kinematics model integrated with BP neural network and the mechanical-hydraulic co-simulation model based on ante-valve pressure compensation method are developed and applied. The experimental system is built to verify the models and method. The results show that position tracking precision can reach the sub-centimeter level. The influence of variable load on hydraulic flow control is weakened effectively and the stability and controllability of load sensitive system is improved. The developed model and control approach are valuable for virtual development and automated testing during the commissioning of hydraulic manipulator.|||Article||||
WEB OF SCIENCE|Karun, Shubham Kumar|||Improving the Test Smell-Based Detection of Flaky Tests|2023||||||||||||||Dissertation/Thesis||||
WEB OF SCIENCE|Pan, Rongqi; Ghaleb, Taher A.; Briand, Lionel C.|||LTM: Scalable and Black-Box Similarity-Based Test Suite Minimization Based on Language Models|2024|IEEE TRANSACTIONS ON SOFTWARE ENGINEERING|50|11||3053|3070|||10.1109/TSE.2024.3469582||Test suites tend to grow when software evolves, making it often infeasible to execute all test cases with the allocated testing budgets, especially for large software systems. Test suite minimization (TSM) is employed to improve the efficiency of software testing by removing redundant test cases, thus reducing testing time and resources while maintaining the fault detection capability of the test suite. Most existing TSM approaches rely on code coverage (white-box) or model-based features, which are not always available to test engineers. Recent TSM approaches that rely only on test code (black-box) have been proposed, such as ATM and FAST-R. The former yields higher fault detection rates (FDR) while the latter is faster. To address scalability while retaining a high FDR, we propose LTM (Language model-based Test suite Minimization), a novel, scalable, and black-box similarity-based TSM approach based on large language models (LLMs), which is the first application of LLMs in the context of TSM. To support similarity measurement using test method embeddings, we investigate five different pre-trained language models: CodeBERT, GraphCodeBERT, UniXcoder, StarEncoder, and CodeLlama, on which we compute two similarity measures: Cosine Similarity and Euclidean Distance. Our goal is to find similarity measures that are not only computationally more efficient but can also better guide a Genetic Algorithm (GA), which is used to search for optimal minimized test suites, thus reducing the overall search time. Experimental results show that the best configuration of LTM (UniXcoder/Cosine) outperforms ATM in three aspects: (a) achieving a slightly greater saving rate of testing time ($41.72\%$41.72% versus $41.02\%$41.02%, on average); (b) attaining a significantly higher fault detection rate ($0.84$0.84 versus $0.81$0.81, on average); and, most importantly, (c) minimizing test suites nearly five times faster on average, with higher gains for larger test suites and systems, thus achieving much higher scalability.|||Article||||
WEB OF SCIENCE|Gerstenberger, Joseph|||Action Research Study on Soldier Led Software Development to Reduce Security Vulnerabilities|2022||||||||||||||Dissertation/Thesis||||
WEB OF SCIENCE|Eisty, NasirU.|||Quality Assurance in Research Software|2020||||||||||||||Dissertation/Thesis||||
WEB OF SCIENCE|Nascimento, Nuno|||Safeguard Analyzer: A Fuzz Testing Tool|2024||||||||||||||Dissertation/Thesis||||
WEB OF SCIENCE|Yan, Ming; Chen, Junjie; Zhang, Jie M.; Cao, Xuejie; Yang, Chen; Harman, Mark|||Robustness evaluation of code generation systems via concretizing instructions|2025|INFORMATION AND SOFTWARE TECHNOLOGY|179||107645|||||10.1016/j.infsof.2024.107645||Context: Code generation systems have been extensively developed in recent years to generate source code based on natural language instructions. However, despite their advancements, these systems still robustness issues where even slightly different instructions can result in significantly different code semantics. Robustness is critical for code generation systems, as it can have significant impacts on software development, software quality, and trust in the generated code. Although existing testing techniques for general text text software can detect some robustness issues, they can produce many false positives and are limited effectiveness due to ignoring the characteristics of this kind of systems. Objective: To better evaluate (and further enhance) the robustness of code generation systems, in this we conducted the first exploration by carefully considering the characteristics of code generation systems. Specifically, we propose such a novel technique (called COCO) and perform an extensive study to evaluate robustness of code generation systems with COCO. Method: COCO exploits the usage scenario of code generation systems to make the original programming instruction more concrete by incorporating features known to be present in the original code. A robust system should maintain code semantics for the concretized instruction, and COCO detects robustness inconsistencies when it does not. In the extensive study, we evaluated the robustness of eight advanced code generation systems (including commercial tools Copilot and ChatGPT) with COCO, using two widely-used datasets. Results: Our results demonstrate the effectiveness of COCO. It does not produce any false positive, ensuring the accuracy of robustness evaluation. Additionally, it outperforms the two baselines adopted from general text-to-text software testing, detecting 440.31% and 95.81% more inconsistencies, respectively. Concretized instructions generated by COCO can further help reduce robustness inconsistencies by 21.90% to 60.18% fine-tuning. Conclusions: COCO is effective in detecting robust inconsistencies in code generation systems and significantly outperforms baselines. Additionally, fine-tuning code generation systems with the concretized instructions provided by COCO can largely enhance their robustness.|||Article||||
WEB OF SCIENCE|Sujeetha, R.; Akila, K.|||Improving Coverage and Vulnerability Detection in Smart Contract Testing Using Self-Adaptive Learning GA|2024|IETE JOURNAL OF RESEARCH|70|2||1593|1606|||10.1080/03772063.2023.2280672||In the domain of software testing, the generation of test cases is a critical process for detecting system errors and bugs. However, automated test case generation for smart contracts often encounters challenges related to automation, vulnerability diversity, and coverage. This paper presents a novel method, the self-adaptive learning Genetic Algorithm (self-adaptive learning GA), designed to address these issues. Our research methodology incorporates several construction models, namely the Control Dependence Graph (CDG), Control Flow Graph (CFG), and Application Binary Interface (ABI). Initially, the ABI model provides essential information for generating and executing test cases. The CFG model subsequently visualizes potential execution paths through the functions of smart contracts. Ultimately, the CDG model identifies potential vulnerabilities in smart contracts. Using these models, our method enhances automatic test case generation in smart contracts by improving coverage and reducing execution time. We selected a variety of smart contracts from the Decentralized Finance (DeFi) ecosystem for data collection and comparative analysis. The experimental results show superior performance rates, with an average code coverage rate of 98.1%, a total of 3500 vulnerabilities detected, a vulnerability detection rate of 98.7%, a false positive rate of 1.3%, a recall of 98.2%, precision of 98.8%, a path uniqueness rate of 96.4%, false negative rate of 3.5%, an execution time of 25 s, and test case generation time of 16 s. In conclusion, our proposed approach demonstrates a significant improvement over existing methods for test case generation by providing a promising solution for the robustness of smart contracts and security enhancement in the DeFi ecosystem.|||Article||||
WEB OF SCIENCE|Hribar, Nena; Simic, Goran; Vukadinovic, Simonida; Sprajc, Polona|||Decision-making in sustainable energy transition in Southeastern Europe: probabilistic network-based model|2021|ENERGY SUSTAINABILITY AND SOCIETY|11|1|39|||||10.1186/s13705-021-00315-3||Background Sustainable energy transition of a country is complex and long-term process, which requires decision-making in all stages and at all levels, including a large number of different factors, with different causality. The main objective of this paper is the development of a probabilistic model for decision-making in sustainable energy transition in developing countries of SE Europe. The model will be developed according to the specificities of the countries for which it is intended-SE Europe. These are countries where energy transition is slower and more difficult due to many factors: high degree of uncertainty, low transparency, corruption, investment problems, insufficiently reliable data, lower level of economic development, high level of corruption and untrained human resources. All these factors are making decision-making more challenging and demanding. Methods Research was done by using content analysis, artificial intelligence methods, software development method and testing. The model was developed by using MSBNx-Microsoft Research's Bayesian Network Authoring and Evaluation Tool. Results Due to the large number of insufficiently clear, but interdependent factors, the model is developed on the principle of probabilistic (Bayesian) networks of factors of interest. The paper presents the first model for supporting decision-making in the field of energy sustainability for the region of Southeastern Europe, which is based on the application of Bayesian Networks. Conclusion Testing of the developed model showed certain characteristics, discussed in paper. The application of developed model will make it possible to predict the short-term and long-term consequences that may occur during energy transition by varying these factors. Recommendations are given for further development of the model, based on Bayesian networks.|||Article||||
WEB OF SCIENCE|Stewart, Michael Allen|||Increasing Software Reliability Using Mutation Testing and Machine Learning|2021||||||||||||||Dissertation/Thesis||||
WEB OF SCIENCE||||NSF-CSIRO: RAI4IoE: Responsible AI for Enabling the Internet of Energy|2023|||||||||||The energy sector is going through substantial changes fueled by two key drivers: building a zero-carbon energy sector and the digital transformation of the energy infrastructure. The advances in AI technology and energy as a service market further fuel the convergence of these two drivers, resulting in the emergence of a new field of research in the energy sector ��� the Internet of Energy (IoE). With IoE, renewable distributed energy resources (DERs), such as electric cars, storage batteries, wind turbines and photovoltaics, can be connected and integrated for reliable energy distribution by leveraging advanced 5G-6G networks and AI technology. This allows DER owners as prosumers to participate in the energy market and derive economic incentives. DERs are inherently asset-driven and face equitable challenges (i.e., fair, diverse and inclusive). Without equitable access, privileged individuals, groups and organizations can participate and benefit at the cost of disadvantaged groups. The real-time management of DER resources not only brings out the equity problem to the IoE, it also collects highly sensitive location, time, activity dependent data, which requires to be handled responsibly (e.g., privacy, security and safety), for AI-enhanced predictions, for optimization and prioritization services, and for automated management of flexible resources. This US-Australia joint project plans to develop Equitable and Responsible AI framework, techniques and algorithms for the Internet of Energy, coined as RAI4IoE, aiming to elevate energy poverty by providing secure, privacy-preserving and equitable access to the networks of DERs for every citizen. The outcome of this research will advance the knowledge of responsible AI as the first principle in developing and deploying the IoE systems and services, in facilitating DER integration, promoting deep engagement with prosumers, aggregators and network operators, and enabling flexibility market of renewable energy supply. To facilitate equitable participation of all DER owners and users in the automated flexibility market, AI enabled IOE should be governed by the responsible AI frameworks and guidelines for distributed monitoring, scheduling, management, and consumption of DERs, while exercising and guaranteeing responsible and equitable AI through ensuring AI fairness and safeguarding AI privacy and AI security in an open and continuously evolving IoE ecosystem. This project will develop responsible AI frameworks, algorithms and compliance evaluation methods for the IoE, aiming to elevate energy poverty by providing secure, privacy-preserving and equitable access to the networks of DERs for every citizen. The project will develop innovative solutions along three dimensions. First, it develops an equitable AI framework for ensuring IoE for all, including enabling asset-poor clients to participate in distributed learning of global DER models, and integrating privacy and fairness-aware DER data collection with policy-driven data governance. Second, it develops a suite of responsible AI Algorithms and Models to increase the end-to-end resilience of IoE against disruptive events, including irregular, sparse or corrupted data, biases in data and algorithms, privacy violations, and other fraudulent DER activities. Third, it develops a suite of responsible and equitable AI compliance methods by combining explainable AI with software testing and verification methods. The research findings will lead to new generations of AI-enhanced distributed energy resource management systems. This research will also provide graduate and under-graduate students with diverse backgrounds the unique opportunities to learn responsible AI algorithm development, and the importance of equitable access to DERs from a broad cross-disciplinary perspective. This is a joint project between U.S. and Australian researchers funded by the Collaboration Opportunities in Responsible and Equitable AI under the U.S. NSF and the Australian Commonwealth Scientific and Industrial Research Organization (CSIRO). This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.|||Awarded Grant||||
WEB OF SCIENCE|Qiu, Yiming|||Assisting Cloud System Development With Automated Insight Generation|2025||||||||||||||Dissertation/Thesis||||
WEB OF SCIENCE|Stolic, Predrag; Milosevic, Danijela; Stevic, Zoran; Radovanovic, Ilija|||Ontology Development for Creating Identical Software Environments to Improve Learning Outcomes in Higher Education Institutions|2023|ELECTRONICS|12|14|3057|||||10.3390/electronics12143057||Students engage in remote learning within a diverse computer environment. While virtual machines can address the challenges posed by heterogeneity, there remain unresolved issues, particularly related to the complexity of software management. An imperative is to discover an automated solution that facilitates the creation of consistent software environments for educational purposes. This paper introduces ontology engineering principles as a means to tackle the complexities associated with software management. A suitable ontology is developed using OWL syntax, integrating knowledge pertaining to the required software within a specific academic domain. The practical applicability of this knowledge is enabled through the implementation of dedicated SPARQL queries within a Python program. The effectiveness of the automated solution in achieving identical software environments is verified through testing, conducted in both controlled laboratory settings and by students themselves, thus simulating authentic teaching scenarios. The solution not only adheres to the principles of reusability but can also be adapted or integrated into existing ontologies. Furthermore, it presents an opportunity to create automated and self-adjusting virtual machines, offering significant potential for educational and other domains.|||Article||||
WEB OF SCIENCE|Wen, Junye|||Parallelizing Path Exploration and Optimizing Constraint Solving for Efficient Symbolic Execution|2020||||||||||||||Dissertation/Thesis||||
WEB OF SCIENCE||||NSF Workshop: Towards an Open Source Model for Data and Metadata Standards|2023|||||||||||Recent progress in machine learning and artificial intelligence promises to advance research and understanding across a wide range of fields and activities. In tandem, an increased awareness of the importance of open data for reproducibility and scientific transparency is making inroads in fields that have not traditionally produced large publicly available datasets. Data sharing requirements from publishers and funders, as well as from other stakeholders, have also created pressure to make datasets with research and/or public interest value available through digital repositories. However, to make the best use of existing data, and facilitate the creation of useful future datasets, robust, interoperable and usable standards need to evolve and adapt over time. The open-source development model offers significant potential benefits to the process of standard creation and adaptation. In particular, development and adaptation of standards can take advantage of long-standing socio-technical processes that have been key to managing the development of open-source software, and allow incorporating broad community input into the formulation of these standards. This workshop aims to create interdisciplinary connections across a wide range of research fields, thereby providing fertile ground for exchange of knowledge and the creation of new and broadly useful knowledge about the application of the open-source model to data and metadata standards. Furthermore, the synthesis that will be generated will be useful for policy makers and funders in determining worthwhile avenues for policy and funding investment to best make use of the open-source production and governance principles in support of broad societal goals. By adhering to open-source standards for formal descriptions (e.g., by implementing schemata for standard specification, and/or by implementing automated standard validation), processes such as automated testing and continuous integration, which have been important in the development of open-source software, can be adopted in defining data and metadata standards as well. Similarly, open-source governance provides a range of stakeholders a voice in the development of standards, potentially enabling use-cases and concerns that would not be taken into account in a top-down model of standards development. On the other hand, open-source models also carry unique risks that need to be taken into account. The goal of this workshop is to discuss examples where an open-source model for standards development has had significant impact on the practice within a field. Importantly, the workshop will also discuss cases where this model has not worked in the past, and cases where this model is not a good fit. This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.|||Awarded Grant||||
WEB OF SCIENCE||||REU Site: TaMaLe - Testing and Machine Learning for Context-Driven Systems: Research Experience for Undergraduates|2022|||||||||||TaMaLe (Testing and Machine Learning for Context-Driven Systems), a renewal Research Experience for Undergraduates (REU) Site at University of North Texas, engages 10 undergraduate students for 10 weeks with problems in the context-driven system domain. The students explore research problems to improve the reliability and security of context-driven systems. Context-driven systems, such as mobile apps, face constant streams of input from both users and context changes in their environments. Users interact with apps through touch and speech interfaces. These systems also respond to context events that occur in their environments such as changes to network connection, battery level, screen orientation, and more. The combined explosion of possible user events and context event sequences pose new challenges that require cost effective testing solutions. Students and mentors in this REU program work in small teams to develop and empirically evaluate new software testing techniques for context-driven systems using strategies such as reinforcement learning and combinatorial-based techniques. The project's broader significance and importance are that it trains three diverse cohorts heavily recruited from underrepresented groups. Students gain basic research skills to better prepare them for graduate school, including working with researchers and gaining the ability to formulate research questions, design experiments, critically analyze results, and develop written and oral communication skills. This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.|||Awarded Grant||||
WEB OF SCIENCE||||Project Ignite|2023|||||||||||Project **Ignite** is a new online Certification Programme in Game Quality, providing a professional pathway for entrants into the games industry to develop foundation knowledge and skills in Games Quality Assurance (QA) to a level recognised and endorsed by the industry. QA has evolved from simply finding bugs in a game; from test automation and machine-learning to the 'live service' of games that directly impacts players' experience, QA ultimately increases a game's commercial success. Currently, there is no industry-standard pathway into QA that responds to increasing demand for this ever-evolving skill set. Originated and developed in the UK for a global market by Qualicon; the global leader in Game Quality professional development. **Ignite** is endorsed by leading international studio partners who recognise its potential to professionalise, standardise and future-proof the QA talent pathway. **Ignite** will provide the industry benchmark that identifies, reviews and develops the QA skill set. Ultimately this will stimulate sector growth, accelerate job creation and define best practice to optimise productivity. Responsive to innovation - virtual reality, metaverse and more- **Ignite** will help to future-proof the games industry. Our EDI strategy aims to engage a more diverse demographic, so the industry better represents the game playing population. This project has focused on the content creation of training materials from industry subject matter experts in readiness for a test/launch phase later in 2024.|||Awarded Grant||||
WEB OF SCIENCE|Myllari, Juha; Aalto, Tatu; Nurminen, Jukka K.|||Ladle: a method for unsupervised anomaly detection across log types|2025|AUTOMATED SOFTWARE ENGINEERING|32|2|34|||||10.1007/s10515-025-00504-w||Log files can help detect and diagnose erroneous software behaviour, but their utility is limited by the ability of users and developers to sift through large amounts of text. Unsupervised machine learning tools have been developed to automatically find anomalies in logs, but they are usually not designed for situations where a large number of log streams or log files, each with its own characteristics, need to be analyzed and their anomaly scores compared. We propose Ladle, an accurate unsupervised anomaly detection and localization method that can simultaneously learn the characteristics of hundreds of log types and determine which log entries are the most anomalous across these log types. Ladle uses a sentence transformer (a large language model) to embed short overlapping segments of log files and compares new, potentially anomalous, log segments against a collection of reference data. The result of the comparison is re-centered by subtracting a baseline score indicating how much variation tends to occur in each log type, making anomaly scores comparable across log types. Ladle is designed to adapt to data drift and is updated by adding new reference data without the need to retrain the sentence transformer. We demonstrate the accuracy of Ladle on a real-world dataset consisting of logs produced by an endpoint protection platform test suite. We also compare Ladle's performance on the dataset to that of a state-of-the-art method for single-log anomaly detection, showing that the latter is inadequate for the multi-log task.|||Article||||
WEB OF SCIENCE|Choi, Gyeongtaek; Jeon, Seungho; Cho, Jaeik; Moon, Jongsub|||A Seed Scheduling Method With a Reinforcement Learning for a Coverage Guided Fuzzing|2023|IEEE ACCESS|11|||2048|2057|||10.1109/ACCESS.2022.3233875||Seed scheduling, which determines which seed is input to the fuzzer first and the number of mutated test cases that are generated for the input seed, significantly influences crash detection performance in fuzz testing. Even for the same fuzzer, the performance in terms of detecting crashes that cause program failure varies considerably depending on the seed-scheduling method used. Most existing coverage-guided fuzzers use a heuristic seed-scheduling method. These heuristic methods can't properly determine the seed with a high potential to cause the crash; thus, the fuzzer detects the crash inefficiently. Moreover, the fuzzer's crash detection performance is affected by the characteristics of target programs. To address this problem, we propose a general-purpose reinforced seed-scheduling method that not only improves the crash detection performance of fuzz testing but also remains unaffected by the characteristics of the target program. The fuzzer with the proposed method detected the most crashes in all but one of the target programs in which crashes were detected in the experimental results conducted on various programs, and showed better crash detection efficiency than the comparison targets overall.|||Article||||
WEB OF SCIENCE|Palak; Gulia, Preeti; Gill, Nasib Singh|||An Enhanced Artificial Bee Colony: Naive Bayes Technique for Optimizing Software Testing|2021|INTERNATIONAL JOURNAL OF ADVANCED COMPUTER SCIENCE AND APPLICATIONS|12|2||220|225|||||Software driven technology has become a part of life and the quality of software largely depends on the extent of effective testing performed during various phases of development. A wide range of nature inspired searching techniques are employed over years to automate the testing process and provide promising solutions to elude the infeasibility of exhaustive testing. These techniques use metaheuristics and work by converting the problem space into search space. A subset of optimized solutions is searched that reduces overall time by shortening the testing time. Objective: An enhanced Artificial Bee Colony- Naive Bayes optimizer for test case selection is proposed in this paper. This article also aims to provide brief insights into the emergence of hybrid swarm-inspired techniques over the last two decades. Method: The modified Artificial Bee colony is applied after component selection and further optimization is achieved using Naive Bayes classifier. The proposed technique is implemented and evaluated taking three benchmark programs into consideration. The proposed technique is also compared to other competitive swarm intelligence-based techniques of its class. Results: The experimental results show that the proposed technique outperforms other swarm-inspired techniques in terms of execution time in a given scenario and capable of higher detection of faults with minimal test case selection. Conclusion: The proposed approach is an improvement over existing techniques and helps in huge time and cost saving. It will contribute to the testing society and enhance the overall quality of the software.|||Article||||
WEB OF SCIENCE|Yin, Yuyu; Ruan, Jiajie; Li, Youhuizi; Li, Yu; Pan, Zhijin|||Syntax-based metamorphic relation prediction via the bagging framework|2022|EXPERT SYSTEMS|39|6|e12902|||||10.1111/exsy.12902||Software testing is an indispensable part of the software engineering industry, which guarantees product reliability and safety. Traditional testing approaches face the testing Oracle problem, they are difficult to construct the expected outputs with the increasing of program complexity. As a result, metamorphic testing, which tests the program by examining the relationship between the execution results, is proposed. However, existing manual metamorphic relation construction requires huge effects of domain experts, and automatic methods are unstable and inefficient due to the insufficient software feature mining. Hence, we proposed a multi-dimensional program structure-based metamorphic relation prediction approach, which is composed of feature extraction and prediction model building. In the feature extraction stage, the testing program is converted to multiple intermediate structures (such as control flow graphs and abstract syntax trees) to explore its features. In the prediction model building stage, the extracted feature set is used as the training set, and a novel semi-supervised support vector machine-bagging-K-nearest neighbors algorithm is designed to train the prediction model. Besides, a two-phase hybrid granularity search algorithm is proposed to improve the prediction performance by selecting the optimal number of weak classifiers. Compared with existing approaches, our proposed model can improve the accuracy by around 14%.|||Article||||
WEB OF SCIENCE|Yang, Xingguang; Yu, Huiqun; Fan, Guisheng; Yang, Kang|||DEJIT: A Differential Evolution Algorithm for Effort-Aware Just-in-Time Software Defect Prediction|2021|INTERNATIONAL JOURNAL OF SOFTWARE ENGINEERING AND KNOWLEDGE ENGINEERING|31|3||289|310|||10.1142/S0218194021500108||Software defect prediction is an effective approach to save testing resources and improve software quality, which is widely studied in the field of software engineering. The effort-aware just-in-time software defect prediction (JIT-SDP) aims to identify defective software changes in limited software testing resources. Although many methods have been proposed to solve the JIT-SDP, the effort-aware prediction performance of the existing models still needs to be further improved. To this end, we propose a differential evolution (DE) based supervised method DEJIT to build JIT-SDP models. Specifically, first we propose a metric called density-percentile-average (DPA), which is used as optimization objective on the training set. Then, we use logistic regression (LR) to build a prediction model. To make the LR obtain the maximum DPA on the training set, we use the DE algorithm to determine the coefficients of the LR. The experiment uses defect data sets from six open source projects. We compare the proposed method with state-of-the-art four supervised models and four unsupervised models in cross-validation, cross-project-validation and timewise-cross-validation scenarios. The empirical results demonstrate that the DEJIT method can significantly improve the effort-aware prediction performance in the three evaluation scenarios. Therefore, the DEJIT method is promising for the effort-aware JIT-SDP.|||Article||||
WEB OF SCIENCE|Alsarhan, Qusay Idrees Sarhan|||Methods for Enhancing Software Fault Localization|2023||||||||||||||Dissertation/Thesis||||
WEB OF SCIENCE|Yu, Shengcheng; Fang, Chunrong; Zhang, Quanjun; Cao, Zhihao; Yun, Yexiao; Cao, Zhenfei; Mei, Kai; Chen, Zhenyu|||Mobile App Crowdsourced Test Report Consistency Detection via Deep Image-and-Text Fusion Understanding|2023|IEEE TRANSACTIONS ON SOFTWARE ENGINEERING|49|8||4115|4134|||10.1109/TSE.2023.3285787||Crowdsourced testing, as a distinct testing paradigm, has attracted much attention in software testing, especially in mobile application (app) testing field. Compared with in-house testing, crowdsourced testing shows superiority with the diverse testing environments when faced with the mobile testing fragmentation problem. However, crowdsourced testing also encounters the low-quality test report problem caused by unprofessional crowdworkers involved with different expertise. In order to handle the submitted reports of uneven quality, app developers have to distinguish high-quality reports from low-quality ones to help the bug inspection. One kind of typical low-quality test report is inconsistent test reports, which means the textual descriptions are not focusing on the attached bug-occurring screenshots. According to our empirical survey, only 18.07% crowdsourced test reports are consistent. Inconsistent reports cause waste on mobile app testing. To solve the inconsistency problem, we propose ReCoDe to detect the consistency of crowdsourced test reports via deep image-and-text fusion understanding. ReCoDe is a two-stage approach that first classifies the reports based on textual descriptions into different categories according to the bug feature. In the second stage, ReCoDe has a deep understanding of the GUI image features of the app screenshots and then applies different strategies to handle different types of bugs to detect the consistency of the crowdsourced test reports. We conduct an experiment on a dataset with over 22 k test reports to evaluate ReCoDe, and the results show the effectiveness of ReCoDe in detecting the consistency of crowdsourced test reports. Besides, a user study is conducted to prove the practical value of ReCoDe in effectively helping app developers improve the efficiency of reviewing the crowdsourced test reports.|||Article||||
WEB OF SCIENCE|Gonzalez, Danielle Nicole|||The State of Practice for Security Unit Testing: Towards Data Driven Strategies to Shift Security into Developer's Automated Testing Workflows|2021||||||||||||||Dissertation/Thesis||||
WEB OF SCIENCE|Shao, Yuanxun; Liu, Bin; Wang, Shihai; Xiao, Peng|||A NOVEL TEST CASE PRIORITIZATION METHOD BASED ON PROBLEMS OF NUMERICAL SOFTWARE CODE STATEMENT DEFECT PREDICTION|2020|EKSPLOATACJA I NIEZAWODNOSC-MAINTENANCE AND RELIABILITY|22|3||419|431|||10.17531/ein.2020.3.4||Test case prioritization (TCP) has been considerably utilized to arrange the implementation order of test cases, which contributes to improve the efficiency and resource allocation of software regression testing. Traditional coverage-based TCP techniques, such as statement-level, method/function-level and class-level, only leverages program code coverage to prioritize test cases without considering the probable distribution of defects. However, software defect data tends to be imbalanced following Pareto principle. Instinctively, the more vulnerable the code covered by the test case is, the higher the priority it is. Besides, statement-level coverage is a more fine-grained method than function-level coverage or class-level coverage, which can more accurately formulate test strategies. Therefore, we present a test case prioritization approach based on statement software defect prediction to tame the limitations of current coverage-based techniques in this paper. Statement metrics in the source code are extracted and data pre-processing is implemented to train the defect predictor. And then the defect detection rate of test cases is calculated by combining the prioritization strategy and prediction results. Finally, the prioritization performance is evaluated in terms of average percentage faults detected in four open source datasets. We comprehensively compare the performance of the proposed method under different prioritization strategies and predictors. The experimental results show it is a promising technique to improve the prevailing coverage-based TCP methods by incorporating statement-level defect-proneness. Moreover, it is also concluded that the performance of the additional strategy is better than that of max and total, and the choice of the defect predictor affects the efficiency of the strategy.|||Article||||
WEB OF SCIENCE|Zada, Islam; Alshammari, Abdullah; Mazhar, Ahmad A.; Aldaeej, Abdullah; Qasem, Sultan Noman; Amjad, Kashif; Alkhateeb, Jawad H.|||Enhancing IOT based software defect prediction in analytical data management using war strategy optimization and Kernel ELM|2024|WIRELESS NETWORKS|30|9||7207|7225|||10.1007/s11276-023-03591-3||The existence of software problems in IoT applications caused by insufficient source code, poor design, mistakes, and insufficient testing poses a serious risk to functioning and user expectations. Prior to software deployment, thorough testing and quality assurance methods are crucial to reducing these risks. This study advances the field of IoT-based software quality assessment while also showcasing the viability and benefits of incorporating AI methods into Software Defect Prediction (SDP), particularly the Kernel-based Extreme Learning Machine (KELM) and the War Strategy Optimisation (WSO) algorithm. These efforts are essential to maintain the dependability and performance of IoT applications given the IoT's rising significance in our linked world. The chosen keywords, such as Software defect prediction, IoT, KELM, and WSO, capture the multidimensional nature of this novel technique and serve as an important source of information for upcoming study in this area. One of the main issues that needs to be addressed in order to overcome the difficulties of developing IoT-based software is how time and resource-consuming it is to test the programme in order to ensure its effectiveness. Software Defect Prediction (SDP) assumes a crucial function in this context in locating flaws in software components. Manual defect analysis grows more inefficient and time-consuming as software projects become more complicated. This research introduces a fresh method to SDP by utilising artificial intelligence (AI) to address these issues. The suggested methodology includes the War Strategy Optimisation (WSO) algorithm, which is cleverly used to optimise classifier hyperparameters, together with a Kernel Extreme Learning Machine (KELM) for SDP. The main objective is to improve softw. This innovative combination, grounded in previous studies [1, 2], promises superior capabilities in predicting software defects. Notably, it represents the inaugural endeavor to integrate the WSO algorithm with KELM for SDP, introducing a unique and advanced approach to software quality assessment. The proposed methodology undergoes rigorous evaluation using a diverse set of real-world software project datasets, including the renowned PROMISE dataset and various open-source datasets coded in Java. Performance assessment is conducted through multiple metrics, including Efficiency Accuracy, Reliability, Sensitivity, and F1-score, collectively illuminating the effectiveness of this approach. The outcome of our experiments underscores the potency of the Kernel Extreme Learning Machine coupled with the War Strategy Optimization algorithm in enhancing the accuracy of SDP and consequently elevating defect detection efficiency within software components. Remarkably, our methodology consistently outperforms existing techniques, registering an average increase of over 90% in accuracy across the parameters examined. This promising result underscores the potential of our approach to effectively tackle the challenges associated with IoT-based software development and software defect prediction. In conclusion, this study significantly contributes to the field of IoT-based software quality assessment, introducing an innovative methodology that substantially bolsters accuracy and reliability in SDP.|||Article||||
WEB OF SCIENCE|Al-Najjar, Anees; Rao, Nageswara S. V.; Sankaran, Ramanan; Mukherjee, Debangshu; Roccapriore, Kevin; Ziatdinov, Maxim; Kalinin, Sergei V.|||Design-to-Deployment Continuum Platform for Microscopes and Computing Ecosystems|2025|IEEE TRANSACTIONS ON INDUSTRIAL INFORMATICS|21|5||3645|3654|||10.1109/TII.2025.3528550||Science ecosystems with networked computing systems and physical instruments are increasingly being deployed with a goal to achieve the productivity promised by AI-supported remote automation. In support of these efforts, the virtual infrastructure twins (VITs) have been successfully utilized to develop the orchestration codes for these ecosystems without requiring physical access to expensive instruments, such as electron microscopes. Currently, the utility of such a VIT is severely limited by the computing capacity and capability of the computing system used as its host. Furthermore, codes developed on the VIT typically need to be transferred and refactored for production use, particularly, on high-performance systems with accelerators. In response, we develop a design-to-deployment continuum platform wherein a VIT runs natively on the ecosystem's own computing system, and thereby facilitates the continual in-situ testing and transition of codes for production use. We describe the development and testing of software for remote microscope steering and GPU-based image reconstruction using this platform on a multi-GPU computing system networked to Nion microscopes. We demonstrate a continual transition of steering and reconstruction codes developed under VIT platform to production ecosystem deployment.|||Article||||
WEB OF SCIENCE|Biagiola, Matteo; Stocco, Andrea; Riccio, Vincenzo; Tonella, Paolo|||Two is better than one: digital siblings to improve autonomous driving testing|2024|EMPIRICAL SOFTWARE ENGINEERING|29|4|72|||||10.1007/s10664-024-10458-4||Simulation-based testing represents an important step to ensure the reliability of autonomous driving software. In practice, when companies rely on third-party general-purpose simulators, either for in-house or outsourced testing, the generalizability of testing results to real autonomous vehicles is at stake. In this paper, we enhance simulation-based testing by introducing the notion of digital siblings-a multi-simulator approach that tests a given autonomous vehicle on multiple general-purpose simulators built with different technologies, that operate collectively as an ensemble in the testing process. We exemplify our approach on a case study focused on testing the lane-keeping component of an autonomous vehicle. We use two open-source simulators as digital siblings, and we empirically compare such a multi-simulator approach against a digital twin of a physical scaled autonomous vehicle on a large set of test cases. Our approach requires generating and running test cases for each individual simulator, in the form of sequences of road points. Then, test cases are migrated between simulators, using feature maps to characterize the exercised driving conditions. Finally, the joint predicted failure probability is computed, and a failure is reported only in cases of agreement among the siblings. Our empirical evaluation shows that the ensemble failure predictor by the digital siblings is superior to each individual simulator at predicting the failures of the digital twin. We discuss the findings of our case study and detail how our approach can help researchers interested in automated testing of autonomous driving software.|||Article||||
WEB OF SCIENCE|Swapna, R.; Polala, Niranjan|||MFLion-DMN: Mayfly Lion-optimized deep maxout network for prediction of software development effort|2024|JOURNAL OF SOFTWARE-EVOLUTION AND PROCESS|36|8||||||10.1002/smr.2659||The precise evaluation of predicting software development effort is a serious process in software engineering. The underestimates require more time, which seems to be the negotiation of complete efficient design and complete software testing. Thus, this paper devises a novel model for inspecting the effort taken for the design of software. The Mayfly Lion Optimization (MFLion) algorithm is devised, which ensembles the Mayfly Algorithm (MA) with the Lion Optimization Algorithm (LOA) for precise estimation. The deep maxout network (DMN) is adapted wherein the different weights are produced out of which the most suitable is infused considering the MFLion during model training. The optimal features are selected using recursive feature elimination (RFE) wherein the best features are selected and the remaining irrelevant features are eliminated from the list. The proposed MFLion obtained better performance with the smallest mean magnitude of relative error (MMRE) of 5.909 and the smallest root mean square error (RMSE) of 75.505, respectively. Each technique is produced using a separate database generated using the Promise software engineering repository. The outcomes produced from the assessment of the accuracies of models suggested that the MFLion-DMN is a substitute to forecast software effort, which is extensively devised in engineering platforms.Initially, the input software is acquired from the dataset and the feature selection is performed using the RFE. Then, the software development effort prediction is performed using DMN, which is trained by using the proposed MFLion. The proposed MFLion algorithm is developed by incorporating MA and LOA. The proposed MFLion obtained better performance with the smallest MMRE of 5.909 and the smallest RMSE of 75.505. image|||Article||||
WEB OF SCIENCE|Durmaz, Engin; Tumer, M. Borahan|||Intelligent software debugging: A reinforcement learning approach for detecting the shortest crashing scenarios|2022|EXPERT SYSTEMS WITH APPLICATIONS|198||116722|||||10.1016/j.eswa.2022.116722||The Quality Assurance (QA) team verifies software for months before its release decisions. Nevertheless, some crucial bugs remain undetected in manual testing. These bugs would make the system unusable on field, thus merchant loses money then manufacturer loses its customers. Thus, automatic software testing methods have become inevitable to catch more bugs. To locate and repair bugs with an emphasis on the crash scenarios, we present in this work a reinforcement learning (RL) approach for finding and simplifying the input sequence(s) leading to a system crash or blocking, which represents the goal state of the RL problem. We aim at obtaining the shortest input sequence for the same bug so that developers would analyze agent's actions causing crashes or freeze. We first simplify the given crash scenario using Recursive Delta Debugging (RDD), then we apply RL algorithms to explore a possibly shorter crashing sequence. We approach the exploration of crash scenarios as a RL problem where the agent first attains the goal state of crash/blocking by executing inputs, then shortens the input sequence with the help of the rewarding mechanism. We apply both model-free on-policy and model-based planning-capable RL agents to our problem. Furthermore, we present a novel RL approach, involving Detected Goal Catalyst (DGC), which reduces the time complexity by avoiding grappling with convergence via stopping learning at a small variance and attaining the shortest crash sequence with an algorithm that recursively removes the unrelated actions. Experiments show DGC significantly improves the learning performance of both SARSA and Prioritized Sweeping algorithms on obtaining the shortest path.|||Article||||
WEB OF SCIENCE|Chen, Jianming; Wang, Yawen; Wang, Junjie; Xie, Xiaofei; Wang, Dandan; Wang, Qing; Xu, Fanjiang|||Demo2Test: Transfer Testing of Agent in Competitive Environment with Failure Demonstrations|2025|ACM TRANSACTIONS ON SOFTWARE ENGINEERING AND METHODOLOGY|34|2|46|||||10.1145/3696001||The competitive game between agents exists in many critical applications, such as military unmanned aerial vehicles. It is urgent to test these agents to reduce the significant losses caused by their failures. Existing studies mainly are to construct a testing agent that competes with the target agent to induce its failures. These approaches usually focus on a single task, requiring much more time for multi-task testing. However, if the previously tested tasks (source tasks) and the task to be tested (target task) share similar agents or task objectives, the transferable knowledge in source tasks can potentially increase the effectiveness of testing in the target task. We propose Demo2Test for conducting transfer testing of agents in the competitive environment, i.e., leveraging the demonstrations of failure scenarios from the source task to boost the testing effectiveness in the target task. It trains a testing agent with demonstrations and incorporates the action perturbation at key states to balance the number of revealed failures and their diversity. We conduct experiments in the simulated robotics competitive environments of MuJoCo. The results indicate that Demo2Test outperforms the best-performing baseline with improvements ranging from 22.38% to 87.98%, and 12.69% to 60.98%, in terms of the number and diversity of discovered failure scenarios, respectively.|||Article||||
WEB OF SCIENCE|Chen, Aokun|||Human-Centric Computer Usage Profiling for Continuous Authentication: Feasibility, Challenges, and Applications|2020||||||||||||||Dissertation/Thesis||||
WEB OF SCIENCE||||NSF2020: EAGER: Collaborative Research: Enhancing Employment for Neurodiverse Individuals through Next-Generation, AI-Enabled Assessments of Visuospatial Cognition|2020|||||||||||Each year in the United States, approximately 70,000 new adults on the autism spectrum will seek employment. At the same time, employers in technology, finance, healthcare, and many other critical job sectors seek highly skilled and highly trained individuals to fill specialized positions. With support from the DRK-12 Program in the Division of Research on Learning and the NSF 2026 Fund Program in the Office of Integrated Activities, this research will investigate new tools and methods for matching individual job-seekers on the autism spectrum to employment opportunities that leverage their unique cognitive skills, with a focus on visuospatial cognitive skills. Numerous jobs require strong visuospatial cognitive skills, such as visual inspection and quality control, process monitoring, document review, surveillance, software testing, and data visualization, to name a few. Many people on the autism spectrum show strengths in visuospatial cognitive skills, but these strengths are not fully understood, including how they differ from person to person and how they map onto workplace-relevant capabilities. Understanding visuospatial cognitive skills in individuals on the autism spectrum or other neurodiverse conditions has high potential impact for enhancing the neurodiversity of the workforce by enabling more effective programs for the recruitment, selection, and retention of such candidates in the public and private sectors. This NSF2026 EAGER project enriches the NSF2026 Idea Machine winning entry Harnessing the Human Diversity of Mind. It seeks to develop and evaluate integrated, AI-enabled technologies for measuring a person���s visuospatial cognitive skills in new ways and then using these measurements to predict performance on workplace-relevant tasks. The research conducted during this two-year project will include conducting a large pilot study with individuals on the autism spectrum and neurotypical individuals, in which participants will be given several visuospatial tests, and detailed data about their actions will be recorded using sensors such as eye trackers and cameras. Then, data mining and machine learning techniques will be used to extract meaningful patterns from these rich streams of behavioral data, and analyses will be conducted to examine how these patterns in foundational behaviors map onto individual skills and interests in realistic, workplace-relevant activities. This research will also gather and analyze detailed feedback from industry partners to identify specific job types and sectors that would benefit from recruiting employees who are strong in visuospatial cognitive skills. In addition, this project will involve neurodiverse students and staff in many of its activities, in particular by involving graduate trainees supported by the NSF Research Traineeship in Neurodiversity Inspired Science & Engineering (NISE) and by leveraging the skills of neurodiverse interns at the Frist Center for Autism & Innovation at Vanderbilt University's School of Engineering. This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.|||Awarded Grant||||
WEB OF SCIENCE||||NSF2026: EAGER: Collaborative Research: Enhancing Employment for Neurodiverse Individuals through Next-Generation, AI-Enabled Assessments of Visuospatial Cognition|2020|||||||||||Each year in the United States, approximately 70,000 new adults on the autism spectrum will seek employment. At the same time, employers in technology, finance, healthcare, and many other critical job sectors seek highly skilled and highly trained individuals to fill specialized positions. With support from the DRK-12 Program in the Division of Research on Learning and the NSF 2026 Fund Program in the Office of Integrated Activities, this research will investigate new tools and methods for matching individual job-seekers on the autism spectrum to employment opportunities that leverage their unique cognitive skills, with a focus on visuospatial cognitive skills. Numerous jobs require strong visuospatial cognitive skills, such as visual inspection and quality control, process monitoring, document review, surveillance, software testing, and data visualization, to name a few. Many people on the autism spectrum show strengths in visuospatial cognitive skills, but these strengths are not fully understood, including how they differ from person to person and how they map onto workplace-relevant capabilities. Understanding visuospatial cognitive skills in individuals on the autism spectrum or other neurodiverse conditions has high potential impact for enhancing the neurodiversity of the workforce by enabling more effective programs for the recruitment, selection, and retention of such candidates in the public and private sectors. This NSF2026 EAGER project enriches the NSF2026 Idea Machine winning entry Harnessing the Human Diversity of Mind. It seeks to develop and evaluate integrated, AI-enabled technologies for measuring a person���s visuospatial cognitive skills in new ways and then using these measurements to predict performance on workplace-relevant tasks. The research conducted during this two-year project will include conducting a large pilot study with individuals on the autism spectrum and neurotypical individuals, in which participants will be given several visuospatial tests, and detailed data about their actions will be recorded using sensors such as eye trackers and cameras. Then, data mining and machine learning techniques will be used to extract meaningful patterns from these rich streams of behavioral data, and analyses will be conducted to examine how these patterns in foundational behaviors map onto individual skills and interests in realistic, workplace-relevant activities. This research will also gather and analyze detailed feedback from industry partners to identify specific job types and sectors that would benefit from recruiting employees who are strong in visuospatial cognitive skills. In addition, this project will involve neurodiverse students and staff in many of its activities, in particular by involving graduate trainees supported by the NSF Research Traineeship in Neurodiversity Inspired Science & Engineering (NISE) and by leveraging the skills of neurodiverse interns at the Frist Center for Autism & Innovation at Vanderbilt University's School of Engineering. This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.|||Awarded Grant||||
WEB OF SCIENCE|Caniço, Afonso Manuel Barral|||White-Box Assessment for Programming Education|2024||||||||||||||Dissertation/Thesis||||
WEB OF SCIENCE||||Collaborative Research:SHF:Medium:Bringing Python Up to Speed|2020|||||||||||The Python programming language is among today's most popular computer programming languages and is used to write software in a wide variety of domains, from web services to data analysis to machine learning. Unfortunately, Python?s lightweight and flexible nature -- a major source of its appeal -- can cause significant performance and correctness problems - Python programs can suffer slowdowns as high as 60,000x over optimized code written in traditional programming languages like C and C++, and can require an order-of-magnitude more memory. Python's flexible, ?dynamic? features also make its programs error-prone, with many coding errors only being discovered late in development or after deployment. Python?s frequent use as a glue language -- to integrate and interact with different components written in C or C++ -- exposes many Python programs to the unique dangers of those languages, including susceptibility to memory corruption-based security vulnerabilities. This project aims to remedy these problems by developing new technology for Python in the form of novel performance analysis tools, memory-reduction and speed-improving optimizations (including support for multi-core execution), automated software testing frameworks, and common benchmarks to drive their evaluation. This project will develop (1) performance analysis tools that help Python programmers accurately identify the sources of slowdowns; (2) techniques for automatically identifying code that can be replaced by calls to C/C++ libraries; (3) an approach to unlocking parallelism in Python threads, which currently must execute sequentially due to a global interpreter lock; and (4) automatic techniques to drastically reduce the memory footprints of Python applications. To improve the correctness of Python applications, the project will develop novel automated testing techniques that (1) augment property-based random testing with coverage-guided fuzzing; (2) employ concolic execution for smarter test generation and input minimization; (3) synthesize property-specific generator functions; (4) leverage statistical clustering techniques to reduce duplicated failure-inducing inputs; and (5) leverage parallelism and adaptive scheduling algorithms to increase testing throughput. The project will develop a set of bug benchmarks -- indeed, a novel benchmark-producing methodology -- to evaluate these techniques. The twin threads of performance and correctness are synergistic and complementary: automatic testing drives performance analysis, while performance optimizations (like parallelism) speed automatic testing. This award is co-funded by the Software & Hardware Foundations Program in the Division of Computer & Computing Foundations, and the NSF Office of Advanced Cyberinfrastructure. This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.|||Awarded Grant||||
WEB OF SCIENCE||||Collaborative Research: SHF: Medium: Bringing Python Up to Speed|2020|||||||||||The Python programming language is among today's most popular computer programming languages and is used to write software in a wide variety of domains, from web services to data analysis to machine learning. Unfortunately, Python’s lightweight and flexible nature -- a major source of its appeal -- can cause significant performance and correctness problems - Python programs can suffer slowdowns as high as 60,000x over optimized code written in traditional programming languages like C and C++, and can require an order-of-magnitude more memory. Python's flexible, “dynamic” features also make its programs error-prone, with many coding errors only being discovered late in development or after deployment. Python’s frequent use as a glue language -- to integrate and interact with different components written in C or C++ -- exposes many Python programs to the unique dangers of those languages, including susceptibility to memory corruption-based security vulnerabilities. This project aims to remedy these problems by developing new technology for Python in the form of novel performance analysis tools, memory-reduction and speed-improving optimizations (including support for multi-core execution), automated software testing frameworks, and common benchmarks to drive their evaluation. This project will develop (1) performance analysis tools that help Python programmers accurately identify the sources of slowdowns; (2) techniques for automatically identifying code that can be replaced by calls to C/C++ libraries; (3) an approach to unlocking parallelism in Python threads, which currently must execute sequentially due to a global interpreter lock; and (4) automatic techniques to drastically reduce the memory footprints of Python applications. To improve the correctness of Python applications, the project will develop novel automated testing techniques that (1) augment property-based random testing with coverage-guided fuzzing; (2) employ concolic execution for smarter test generation and input minimization; (3) synthesize property-specific generator functions; (4) leverage statistical clustering techniques to reduce duplicated failure-inducing inputs; and (5) leverage parallelism and adaptive scheduling algorithms to increase testing throughput. The project will develop a set of bug benchmarks -- indeed, a novel benchmark-producing methodology -- to evaluate these techniques. The twin threads of performance and correctness are synergistic and complementary: automatic testing drives performance analysis, while performance optimizations (like parallelism) speed automatic testing. This award is co-funded by the Software & Hardware Foundations Program in the Division of Computer & Computing Foundations, and the NSF Office of Advanced Cyberinfrastructure. This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.|||Awarded Grant||||
WEB OF SCIENCE||||Collaborative Research: SHF: Medium: Bringing Python Up to Speed|2020|||||||||||The Python programming language is among today's most popular computer programming languages and is used to write software in a wide variety of domains, from web services to data analysis to machine learning. Unfortunately, Python?s lightweight and flexible nature -- a major source of its appeal -- can cause significant performance and correctness problems - Python programs can suffer slowdowns as high as 60,000x over optimized code written in traditional programming languages like C and C++, and can require an order-of-magnitude more memory. Python's flexible, ?dynamic? features also make its programs error-prone, with many coding errors only being discovered late in development or after deployment. Python?s frequent use as a glue language -- to integrate and interact with different components written in C or C++ -- exposes many Python programs to the unique dangers of those languages, including susceptibility to memory corruption-based security vulnerabilities. This project aims to remedy these problems by developing new technology for Python in the form of novel performance analysis tools, memory-reduction and speed-improving optimizations (including support for multi-core execution), automated software testing frameworks, and common benchmarks to drive their evaluation. This project will develop (1) performance analysis tools that help Python programmers accurately identify the sources of slowdowns; (2) techniques for automatically identifying code that can be replaced by calls to C/C++ libraries; (3) an approach to unlocking parallelism in Python threads, which currently must execute sequentially due to a global interpreter lock; and (4) automatic techniques to drastically reduce the memory footprints of Python applications. To improve the correctness of Python applications, the project will develop novel automated testing techniques that (1) augment property-based random testing with coverage-guided fuzzing; (2) employ concolic execution for smarter test generation and input minimization; (3) synthesize property-specific generator functions; (4) leverage statistical clustering techniques to reduce duplicated failure-inducing inputs; and (5) leverage parallelism and adaptive scheduling algorithms to increase testing throughput. The project will develop a set of bug benchmarks -- indeed, a novel benchmark-producing methodology -- to evaluate these techniques. The twin threads of performance and correctness are synergistic and complementary: automatic testing drives performance analysis, while performance optimizations (like parallelism) speed automatic testing. This award is co-funded by the Software & Hardware Foundations Program in the Division of Computer & Computing Foundations, and the NSF Office of Advanced Cyberinfrastructure. This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.|||Awarded Grant||||
WEB OF SCIENCE|Li, Ningke; Li, Yuekang; Liu, Yi; Shi, Ling; Wan, Kailong; Wang, Haoyu|||Drowzee: Metamorphic Testing for Fact-Conflicting Hallucination Detection in Large Language Models|2024|PROCEEDINGS OF THE ACM ON PROGRAMMING LANGUAGES-PACMPL|8|OOPSLA2|336|||||10.1145/3689776||Large language models (LLMs) have revolutionized language processing, but face critical challenges with security, privacy, and generating hallucinations - coherent but factually inaccurate outputs. A major issue is fact-conflicting hallucination (FCH), where LLMs produce content contradicting ground truth facts. Addressing FCH is difficult due to two key challenges: 1) Automatically constructing and updating benchmark datasets is hard, as existing methods rely on manually curated static benchmarks that cannot cover the broad, evolving spectrum of FCH cases. 2) Validating the reasoning behind LLM outputs is inherently difficult, especially for complex logical relations. To tackle these challenges, we introduce a novel logic-programming-aided metamorphic testing technique for FCH detection. We develop an extensive and extensible framework that constructs a comprehensive factual knowledge base by crawling sources like Wikipedia, seamlessly integrated into DROWZEE. Using logical reasoning rules, we transform and augment this knowledge into a large set of test cases with ground truth answers. We test LLMs on these cases through template-based prompts, requiring them to provide reasoned answers. To validate their reasoning, we propose two semantic-aware oracles that assess the similarity between the semantic structures of the LLM answers and ground truth. Our approach automatically generates useful test cases and identifies hallucinations across six LLMs within nine domains, with hallucination rates ranging from 24.7% to 59.8%. Key findings include LLMs struggling with temporal concepts, out-of-distribution knowledge, and lack of logical reasoning capabilities. The results show that logic-based test cases generated by DROWZEE effectively trigger and detect hallucinations. To further mitigate the identified FCHs, we explored model editing techniques, which proved effective on a small scale (with edits to fewer than 1000 knowledge pieces). Our findings emphasize the need for continued community efforts to detect and mitigate model hallucinations.|||Article||||
WEB OF SCIENCE|Li, Fuyang; Lu, Wanpeng; Keung, Jacky Wai; Yu, Xiao; Gong, Lina; Li, Juan|||The impact of feature selection techniques on effort-aware defect prediction: An empirical study|2023|IET SOFTWARE|17|2||168|193|||10.1049/sfw2.12099||Effort-Aware Defect Prediction (EADP) methods sort software modules based on the defect density and guide the testing team to inspect the modules with high defect density first. Previous studies indicated that some feature selection methods could improve the performance of Classification-Based Defect Prediction (CBDP) models, and the Correlation-based feature subset selection method with the Best First strategy (CorBF) performed the best. However, the practical benefits of feature selection methods on EADP performance are still unknown, and blindly employing the best-performing CorBF method in CBDP to pre-process the defect datasets may not improve the performance of EADP models but possibly result in performance degradation. To assess the impact of the feature selection techniques on EADP, a total of 24 feature selection methods with 10 classifiers embedded in a state-of-the-art EADP model (CBS+) on the 41 PROMISE defect datasets were examined. We employ six evaluation metrics to assess the performance of EADP models comprehensively. The results show that (1) The impact of the feature selection methods varies in classifiers and datasets. (2) The four wrapper-based feature subset selection methods with forwards search, that is, AdaBoost with Forwards Search, Deep Forest with Forwards Search, Random Forest with Forwards Search, and XGBoost with Forwards Search (XGBF) are better than other methods across the studied classifiers and the used datasets. And XGBF with XGBoost as the embedded classifier in CBS+ performs the best on the datasets. (3) The best-performing CorBF method in CBDP does not perform well on the EADP task. (4) The selected features vary with different feature selection methods and different datasets, and the features noc (number of children), ic (inheritance coupling), cbo (coupling between object classes), and cbm (coupling between methods) are frequently selected by the four wrapper-based feature subset selection methods with forwards search. (5) Using AdaBoost, deep forest, random forest, and XGBoost as the base classifiers embedded in CBS+ can achieve the best performance. In summary, we recommend the software testing team should employ XGBF with XGBoost as the embedded classifier in CBS+ to enhance the EADP performance.|||Article||||
WEB OF SCIENCE|Grano, Giovanni; Palomba, Fabio; Gall, Harald C.|||Lightweight Assessment of Test-Case Effectiveness Using Source-Code-Quality Indicators|2021|IEEE TRANSACTIONS ON SOFTWARE ENGINEERING|47|4||758|774|||10.1109/TSE.2019.2903057||Test cases are crucial to help developers preventing the introduction of software faults. Unfortunately, not all the tests are properly designed or can effectively capture faults in production code. Some measures have been defined to assess test-case effectiveness: the most relevant one is the mutation score, which highlights the quality of a test by generating the so-called mutants, i.e., variations of the production code that make it faulty and that the test is supposed to identify. However, previous studies revealed that mutation analysis is extremely costly and hard to use in practice. The approaches proposed by researchers so far have not been able to provide practical gains in terms of mutation testing efficiency. This leaves the problem of efficiently assessing test-case effectiveness as still open. In this paper, we investigate a novel, orthogonal, and lightweight methodology to assess test-case effectiveness: in particular, we study the feasibility to exploit production and test-code-quality indicators to estimate the mutation score of a test case. We first select a set of 67 factors and study their relation with test-case effectiveness. Then, we devise a mutation score estimation model exploiting such factors and investigate its performance as well as its most relevant features. The key results of the study reveal that our estimation model only based on static features has 86 percent of both F-Measure and AUC-ROC. This means that we can estimate the test-case effectiveness, using source-code-quality indicators, with high accuracy and without executing the tests. As a consequence, we can provide a practical approach that is beyond the typical limitations of current mutation testing techniques.|||Article||||
WEB OF SCIENCE|Yu, Shengcheng; Fang, Chunrong; Li, Xin; Ling, Yuchen; Chen, Zhenyu; Su, Zhendong|||Effective, Platform-Independent GUI Testing via Image Embedding and Reinforcement Learning|2024|ACM TRANSACTIONS ON SOFTWARE ENGINEERING AND METHODOLOGY|33|7|175|||||10.1145/3674728||Software applications (apps) have been playing an increasingly important role in various aspects of society. In particular, mobile apps and web apps are the most prevalent among all applications and are widely used in various industries as well as in people's daily lives. To help ensure mobile and web app quality, many approaches have been introduced to improve app GUI testing via automated exploration, including random testing, model-based testing, learning-based testing, and so on. Despite the extensive effort, existing approaches are still limited in reaching high code coverage, constructing high-quality models, and being generally applicable. Reinforcement learning-based approaches, as a group of representative and advanced approaches for automated GUI exploration testing, are faced with difficult challenges, including effective app state abstraction, reward function design, and so on. Moreover, they heavily depend on the specific execution platforms (i.e., Android or Web), thus leading to poor generalizability and being unable to adapt to different platforms. This work specifically tackles these challenges based on the high-level observation that apps from distinct platforms share commonalities in GUI design. Indeed, we propose PIRLTEST, an effective platform-independent approach for app testing. Specifically, PIRLTEST utilizes computer vision and reinforcement learning techniques in a novel, synergistic manner for automated testing. It extracts the GUI widgets from GUI pages and characterizes the corresponding GUI layouts, embedding the GUI pages as states. The app GUI state combines the macroscopic perspective (app GUI layout) and the microscopic perspective (app GUI widget) and attaches the critical semantic information from GUI images. This enables PIRLTEST to be platform-independent and makes the testing approach generally applicable on different platforms. PIRLTEST explores apps with the guidance of a curiosity-driven strategy, which uses a Q-network to estimate the values of specific state-action pairs to encourage more exploration in uncovered pages without platform dependency. The exploration will be assigned with rewards for all actions, which are designed considering both the app GUI states and the concrete widgets, to help the framework explore more uncovered pages. We conduct an empirical study on 20 mobile apps and 5 web apps, and the results show that PIRLTEST is zero-cost when being adapted to different platforms, and can perform better than the baselines, covering 6.3-41.4% more code on mobile apps and 1.5-51.1% more code on web apps. PIRLTestis capable of detecting 128 unique bugs on mobile and web apps, including 100 bugs that cannot be detected by the baselines.|||Article||||
WEB OF SCIENCE|Atiz, İsmail|||Rulman Yağlama Sistemi Test Otomasyonu ve Arayüzü GeliştirilmesiTest Automation and Interface Development for Bearing Lubrication System|2024||||||||||||||Dissertation/Thesis||||
WEB OF SCIENCE|Huang, Rubing; Cui, Chenhui; Lian, Junlong; Towey, Dave; Sun, Weifeng; Chen, Haibo|||Toward Cost-Effective Adaptive Random Testing: An Approximate Nearest Neighbor Approach|2024|IEEE TRANSACTIONS ON SOFTWARE ENGINEERING|50|5||1182|1214|||10.1109/TSE.2024.3379592||Adaptive Random Testing (ART) enhances the testing effectiveness (including fault-detection capability) of Random Testing (RT) by increasing the diversity of the random test cases throughout the input domain. Many ART algorithms have been investigated such as Fixed-Size-Candidate-Set ART (FSCS) and Restricted Random Testing (RRT), and have been widely used in many practical applications. Despite its popularity, ART suffers from the problem of high computational costs during test-case generation, especially as the number of test cases increases. Although several strategies have been proposed to enhance the ART testing efficiency, such as the forgetting strategy and the $k$k -dimensional tree strategy, these algorithms still face some challenges, including: (1) Although these algorithms can reduce the computation time, their execution costs are still very high, especially when the number of test cases is large; and (2) To achieve low computational costs, they may sacrifice some fault-detection capability. In this paper, we propose an approach based on Approximate Nearest Neighbors (ANNs), called Locality-Sensitive Hashing ART (LSH-ART). When calculating distances among different test inputs, LSH-ART identifies the approximate (not necessarily exact) nearest neighbors for candidates in an efficient way. LSH-ART attempts to balance ART testing effectiveness and efficiency.|||Article||||
WEB OF SCIENCE|Zhao, Yanyang; Wang, Yawen; Zhang, Yuwei; Zhang, Dalin; Gong, Yunzhan; Jin, Dahai|||ST-TLF: Cross-version defect prediction framework based transfer learning|2022|INFORMATION AND SOFTWARE TECHNOLOGY|149||106939|||||10.1016/j.infsof.2022.106939||Context: Cross-version defect prediction (CVDP) is a practical scenario in which defect prediction models are derived from defect data of historical versions to predict potential defects in the current version. Prior research employed defect data of the latest historical version as the training set using the empirical recommended method, ignoring the concept drift between versions, which undermines the accuracy of CVDP.Objective: We customized a Selected Training set and Transfer Learning Framework (ST-TLF) with two objectives: a) to obtain the best training set for the version at hand, proposing an approach to select the training set from the historical data; b) to eliminate the concept drift, designing a transfer strategy for CVDP.Method: To evaluate the performance of ST-TLF, we investigated three research problems, covering the generalization of ST-TLF for multiple classifiers, the accuracy of our training set matching methods, and the performance of ST-TLF in CVDP compared against state-of-the-art approaches.Results: The results reflect that (a) the eight classifiers we examined are all boosted under our ST-TLF, where SVM improves 49.74% considering MCC, as is similar to others; (b) when performing the best training set matching, the accuracy of the method proposed by us is 82.4%, while the experience recommended method is only 41.2%; (c) comparing the 12 control methods, our ST-TLF (with BayesNet), against the best contrast method P15-NB, improves the average MCC by 18.84%.Conclusions: Our framework ST-TLF with various classifiers can work well in CVDP. The training set selection method we proposed can effectively match the best training set for the current version, breaking through the limitation of relying on experience recommendation, which has been ignored in other studies. Also, ST-TLF can efficiently elevate the CVDP performance compared with random forest and 12 control methods.|||Article||||
WEB OF SCIENCE|Ahmed, Bestoun S.; Enoiu, Eduard; Afzal, Wasif; Zamli, Kamal Z.|||An evaluation of Monte Carlo-based hyper-heuristic for interaction testing of industrial embedded software applications|2020|SOFT COMPUTING|24|18||13929|13954|||10.1007/s00500-020-04769-z||Hyper-heuristic is a new methodology for the adaptive hybridization of meta-heuristic algorithms to derive a general algorithm for solving optimization problems. This work focuses on the selection type of hyper-heuristic, called the exponential Monte Carlo with counter (EMCQ). Current implementations rely on the memory-less selection that can be counterproductive as the selected search operator may not (historically) be the best performing operator for the current search instance. Addressing this issue, we propose to integrate the memory into EMCQ for combinatorial t-wise test suite generation using reinforcement learning based on the Q-learning mechanism, called Q-EMCQ. The limited application of combinatorial test generation on industrial programs can impact the use of such techniques as Q-EMCQ. Thus, there is a need to evaluate this kind of approach against relevant industrial software, with a purpose to show the degree of interaction required to cover the code as well as finding faults. We applied Q-EMCQ on 37 real-world industrial programs written in Function Block Diagram (FBD) language, which is used for developing a train control management system at Bombardier Transportation Sweden AB. The results show that Q-EMCQ is an efficient technique for test case generation. Addition- ally, unlike the t-wise test suite generation, which deals with the minimization problem, we have also subjected Q-EMCQ to a maximization problem involving the general module clustering to demonstrate the effectiveness of our approach. The results show the Q-EMCQ is also capable of outperforming the original EMCQ as well as several recent meta/hyper-heuristic including modified choice function, Tabu high-level hyper-heuristic, teaching learning-based optimization, sine cosine algorithm, and symbiotic optimization search in clustering quality within comparable execution time.|||Article||||
WEB OF SCIENCE|Koroglu, Yavuz; Sen, Alper|||Functional test generation from UI test scenarios using reinforcement learning for android applications|2021|SOFTWARE TESTING VERIFICATION & RELIABILITY|31|3|e1752|||||10.1002/stvr.1752||With the ever-growing Android graphical user interface (GUI) application market, there have been many studies on automated test generation for Android GUI applications. These studies successfully demonstrate how to detect fatal exceptions and achieve high coverage with fully automated test generation engines. However, it is unclear how many GUI functions these engines manage to test. The current best practice for the functional testing of Android GUI applications is to design user interface (UI) test scenarios with a non-technical and human-readable language such as Gherkin and implement Java/Kotlin methods for every statement of all the UI test scenarios. Writing tests for UI test scenarios is hard, especially when some scenario statements are high-level and declarative, so it is not clear what actions should the generated test perform. We propose the Fully Automated Reinforcement LEArning-Driven specification-based test generator for Android (FARLEAD-Android). FARLEAD-Android first translates the UI test scenario to a GUI-level formal specification as a linear-time temporal logic (LTL) formula. The LTL formula guides the test generation and acts as a specified test oracle. By dynamically executing the application under test (AUT), and monitoring the LTL formula, FARLEAD-Android learns how to produce a witness for the UI test scenario, using reinforcement learning (RL). Our evaluation shows that FARLEAD-Android is more effective and achieves higher performance in generating tests for UI test scenarios than three known engines: Random, Monkey and QBEa. To the best of our knowledge, FARLEAD-Android is the first fully automated mobile GUI testing engine that uses formal specifications.|||Article||||
WEB OF SCIENCE|Sochor, Hannes; Ferrarotti, Flavio; Kaufmann, Daniela|||Fuzzing-based grammar learning from a minimal set of seed inputs|2024|JOURNAL OF COMPUTER LANGUAGES|78||101252|||||10.1016/j.cola.2023.101252||To be effective, a fuzzer needs to generate inputs that are well formed, so that they are not outright rejected by the Software Under Test (SUT) and can thus detect meaningful bugs. Grammar based fuzzers solve this problem, but they obviously require a grammar of the input language accepted by the SUT. Many times such grammar is unknown. Therefore, different black-and white-box algorithms have been proposed for learning them from SUTs. Black-box algorithms rely only on membership queries, but need access to carefully crafted well formed inputs in order to obtain good results. White-box algorithms require access to the source code and generally produce grammars with higher precision and recall, but at the expense of working only for specific programming languages and libraries. We propose a new algorithm and show through extensive experimentation that it can learn grammars from recursive descendent parsers with consistently high levels of both, recall and precision. Notably, this result was obtained starting with a couple of arbitrary seed inputs and includes evaluations with sophisticated languages such as Java Script Object Notation (JSON). Different to other state of the art white-box approaches, our method does not require sophisticated program analysis techniques such as dynamic tainting or symbolic execution. In fact, the experiments confirm that our method performs extremely well with just a (standard) generic Abstract Syntax Tree (AST) of the parsing program as input. The core of our method uses fuzzing techniques combined with fundamental theoretical results on grammar learning. Compared to other white-box approaches, ours is not tied to specific programming languages and tools, and thus can be easily ported. Regarding performance, we have shown that our algorithm works well in practice and that, under reasonable assumptions, its worst-case complexity is polynomial (with low exponents) w.r.t. time and space requirements.|||Article||||
WEB OF SCIENCE|Al-omari, Sara; Elsheikh, Yousef; Azzeh, Mohammed|||A New Learning to Rank Approach for Software Defect Prediction|2022|INTERNATIONAL JOURNAL OF ADVANCED COMPUTER SCIENCE AND APPLICATIONS|13|8||805|812|||||Software defect prediction is one of the most active research fields in software development. The outcome of defect prediction models provides a list of the most likely defect-prone modules that need a huge effort from quality assurance teams. It can also help project managers to effectively allocate limited resources to validating software products and invest more effort in defect-prone modules. As the size of software projects grows, error prediction models can play an important role in assisting developers and shortening the time it takes to create more reliable software products by ranking software modules based on their defects. Therefore, there is need a learning-to-rank approach that can prioritize and rank defective modules to reduce testing effort, cost, and time. In this paper, a new learning to rank approach was developed to help the QA team rank the most defectprone modules using different regression models. The proposed approach was evaluated on a set of standardized datasets using well-known evaluation measures such as Fault-Percentile Average (FPA), Mean Absolute Error (MAE), Root Mean Square Error (RMSE), and the Cumulative Lift Chart (CLC). Also, our proposed approach was compared with some other regression models that are used for software defect prediction, such as Random Forest (RF), Logistic Regression (LR), Support Vector Regression (SVR), Zero Inflated Regression (ZIR), Zero Inflated Poisson (ZIP), and Negative Polynomial Regression (NPR). Based on the results, the measurement criteria were different than each other as there was a gap in the accuracy obtained for defects prediction due to the nature of the random data, and thus was higher for RF and SVR, as well as FPA achieved better results than MAE and RMSE in this research paper.|||Article||||
WEB OF SCIENCE|Baixo, Ivo Alexandre Pereira|||Vision System Hardware: Simulation and Test Automation|2023||||||||||||||Dissertation/Thesis||||
WEB OF SCIENCE|Dias, Tiago Fontes|||FuzzTheRest - Intelligent Automated Blackbox RESTful Api Fuzzer|2023||||||||||||||Dissertation/Thesis||||
WEB OF SCIENCE|Vedpal; Tanwar, Harish; Chauhan, Naresh; Khanna, Munish|||Test case prioritization using a Hybrid Chaotic Flower-fruit fly optimization algorithm with multiple objectives|2024|MULTIMEDIA TOOLS AND APPLICATIONS|83|10||28395|28418|||10.1007/s11042-023-16606-0||The research aims to resolve the challenges faced in traditional Test Case Prioritization(TCP) techniques and the need to enhance the efficiency of the software testing process.Software development involves test case execution, which tests the changes to the system that requires more resources and time. TCP is the indispensable method, which is established to obtain the goals, such as attaining fast fault detection and a high convergence rate. The code-coverage- methods are the advanced approach employed in the TCP, which is utilized in various prioritization methods to enhance the efficiencyof the method. In this research, the multi-objective- hybrid Chaotic Flower fruit-fly optimization algorithm (Hybrid CFFO) is proposed for the TCP. Instead of using rigid rules or deterministic algorithms, metaheuristic algorithms were created to make intelligent decisions on heuristics and approximations. The foraging behavior of the flower fly and the reproduction characters of the flower are merged which covers a large exploration phase and overcome the local optima. In TCP, being able to quickly explore interesting search space regions and avoid local optima the proposed hybrid Chaotic Flower fruit-fly optimization is essential for producing high-quality solutions. The selection measures used by the optimization algorithm are on the average percentage of combinatorial coverage (APCC) and the Normalized average of the percentage of faults detected (NAPFD), which is designed to develop the multi-objective function. Based on the algorithm, the significance of the test cases is ordered and prioritized. The effectiveness of the proposed methodology is revealed by comparing the proposed multi-objective-based hybrid CFFO method with the conventional methods. From the results obtained, it is proved that the multi-objective-hybrid CFFO method outperforms all the conventional methods in terms of fitness, NAPFD, and APCC. The maximum fitness, NAPFD,and APCC achieved by the proposed methods are 93.1%,92.82%, and 91.1%, respectively for the big fault matrix data.|||Article||||
WEB OF SCIENCE||||NSF ACED: ROOTS: Real-time Optimization Of Transceiver Systems|2023|||||||||||Future wireless systems such as those proposed for the sixth generation of wireless networks (6G) will expand upon our present networking capability and provide for new and emerging services such as augmented/virtual reality, remote surgery, sensing, and imaging of our environment. This will require new wireless circuits and systems that are more precise than those required for previous generations of wireless networks. The goal of this research is to use machine learning to continuously improve the precision and accuracy of wireless circuits and systems. This can enable wireless devices to operate more efficiently and provide more robust wireless connectivity. The proposed investigation will also provide insight into embedding machine learning directly with RF transceiver hardware. This research that is focused on the investigation of CHIPS will result in the design of novel integrated circuit and integration techniques that are promising for 6G. In addition to the scientific outcomes of the investigation, this proposal involves international collaboration between universities in the United States and Taiwan. The educational objectives will cross-train 4 Ph. D. and 4 M.S. students between the partnering universities in both countries. The investigators also plan curriculum development for their undergraduate and graduate courses in circuits and systems design and plan to involve undergraduate students from their courses at earlier stages of their educational development in the research associated with the proposal. The objective of this proposal is to investigate the use of machine learning to continuously calibrate and optimize millimeter wave (mmWave) transceiver hardware. This is warranted because the projections for 6G expand the use of mmWave and near-THz spectrum, which require circuits and systems that can operate flexibly and with better linearity across wider instantaneous bandwidth. Commercially produced transceivers now use 100s-1000s of bits for trimming and calibration; however, many of these trims are only performed at the initial programming of the integrated circuit on automated testing equipment. This creates a large calibration and optimization space that this project will use to investigate continuous background optimizations using a local, efficient neuromorphic compute-in-memory system. As part of the program, highly trimmable digital transmitters will be integrated with a low-power calibration receiver that will be used to estimate transmitter parameters. The outputs of the receiver will be input into a neuromorphic computing accelerator with compute-in-memory (CIM) that will be running calibration/optimization algorithms that control the transmitters trimming and calibration bits. The project has two phases. In the first phase, the transceiver circuits and neuromorphic computing accelerator will be designed separately and characterized. They will be co-packaged for initial investigation of the interface between the systems. In the second phase, the experimental findings from phase one will be used to guide integration in phase two. The phase two demonstration experiment includes a fully integrated system and experiments on system optimizations to improve the system efficiency and linearity. The findings from these experiments will provide relevant information to scale designs for future systems that add complexity including multiple-input, multiple-output systems for wireless beamforming. This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.|||Awarded Grant||||
WEB OF SCIENCE|Bai, Ruxue; Chen, Rongshang; Lei, Xiao; Wu, Keshou|||A Test Report Optimization Method Fusing Reinforcement Learning and Genetic Algorithms|2024|ELECTRONICS|13|21|4281|||||10.3390/electronics13214281||Filtering high-variability and high-severity defect reports from large test report databases is a challenging task in crowdtesting. Traditional optimization algorithms based on clustering and distance techniques have made progress but are limited by initial parameter settings and significantly decrease in efficiency with an increasing number of reports. To address this issue, this paper proposes a method that integrates reinforcement learning with genetic algorithms for crowdsourced testing report optimization, called Reinforcement Learning-based Genetic Algorithm for Crowdsourced Testing Report Optimization (RLGA). Its core goal is to identify distinct, high-severity defect reports from a large set. The method uses genetic algorithms to generate the optimal report selection sequence and adjusts the crossover probability (Pc) and mutation probability (Pm) dynamically with reinforcement learning based on the population's average fitness, best fitness, and diversity. The reinforcement learning component uses a hybrid SARSA and Q-Learning strategy to update the Q-value table, allowing the algorithm to learn quickly in early iterations and expand the search space later to avoid local optima, thereby improving efficiency. To validate the RLGA method, this paper uses four public datasets and compares RLGA with six classic methods. The results indicate that RLGA outperforms BDDIV in terms of execution time and is less sensitive to the total number of test reports. In terms of optimization objectives, the test reports selected by RLGA have higher levels of defect severity and diversity than those selected by the random choice, BDDIV, and TSE methods. Regarding population diversity, RLGA effectively enhances the uniformity and diversity of individuals compared to random initialization. In terms of convergence speed, RLGA is superior to the GA, GA-SARSA, and GA-Q methods.|||Article||||
WEB OF SCIENCE|Negrão, Patrícia Monteiro|||Automated Playtesting in Videogames|2020||||||||||||||Dissertation/Thesis||||
WEB OF SCIENCE|Zhang, Deping; Yang, Zhaohui; Huang, Xiang; Li, Yanhui|||Extensive mutation for testing of word sense disambiguation models|2025|INFORMATION AND SOFTWARE TECHNOLOGY|183||107734|||||10.1016/j.infsof.2025.107734||Context: Word sense disambiguation (WSD) models are extensively utilized in various translation and questionanswering systems. Assessing the WSD capability of these models aids in their improvement and enhances their dependability. Recently, researchers have introduced the concept of mutation to induce WSD errors in machine translation systems to evaluate their WSD ability. Objective: Inspired by the recent research, this study aims to extend types of mutations and check their potential application in testing WSD models to check whether these mutations can effectively provoke WSD errors. Method: We have designed and implemented nine innovative types of mutations focusing on words, phrases, and sentence structure for the sentence in WSD testing. Based on these extensive mutations, we have proposed a WSD testing framework that utilizes large language models to prompt sentence mutations and assess the disambiguation capability of WSD models. Results: In our research, we have conducted experiments using five widely recognized test sets for WSD tasks under five widely used WSD models. The experimental results show that (a) our testing framework can produce correct mutations for nine proposed mutations, and (b) the newly developed mutations have been shown to successfully trigger a substantial number of factual and unique WSD errors. Conclusions: The new types of mutations we designed can effectively be applied in mutation-based WSD testing. This suggests that by exploring more types of mutations, more WSD errors can be triggered.|||Article||||
WEB OF SCIENCE||||Protege: A Knowledge-Engineering Environment for Advancing Biomedical Sciences|2020|||||||||||Project AbstractThe engineering of ontologies that define the entities in an application area and the relationships amongthem has become essential for modern work in biomedicine. Ontologies help both humans andcomputers to manage burgeoning numbers of data. The need to annotate, retrieve, and integrate high-throughput data sets, to process natural language, and to build systems for decision support has set manycommunities of investigators to work building large ontologies.The Protégé system has become an indispensable open-source resource for an enormous internationalcommunity of scientists—supporting the development, maintenance, and use of ontologies and electronicknowledge bases by biomedical investigators everywhere. The number of registered Protégé users hasgrown from 3,500 in 2002 to more than 300,000 users as of this writing. The widespread use ofontologies in biomedicine and the availability of tools, such as Protégé, have taken the biomedical field forwardto a new set of challenges that current technology has not been designed to address: Biomedical ontologieshave grown in size and scope, and their creation, maintenance and quality assurance have become particularlyeffort-intensive and error-prone. In this proposal, we will develop new methods and tools that will significantlyaid biomedical researchers in easily creating and testing biomedical ontologies throughout their lifecycle.Our plan entails four specific aims. First, we will develop methods and tools to allow biomedical scientist toeasily create ontologies directly from their source documents, suchas spreadsheets, tab indented hierarchies,and document outlines. Second, we will provide the methods and tools to allow biomedical scientist to identifypotential “hot spots” in their ontologies that might affect their quality. Third, we will implementacomprehensive, automated testing framework for ontologies that will assist biomedical researchers inperforming ontology and data quality assurance throughout the development cycle. Fourth, we will continue toexpand and support the thriving Protégé user community, as it grows to include new clinicians and biomedicalscientists as they build the ontologies needed to support clinical care, data-driven research, and the elucidationof new discoveries.|||Awarded Grant||||
WEB OF SCIENCE|Zhang, Huimin; Feng, Lei; Li, Zhiwu|||Control of Black-Box Embedded Systems by Integrating Automaton Learning and Supervisory Control Theory of Discrete-Event Systems|2020|IEEE TRANSACTIONS ON AUTOMATION SCIENCE AND ENGINEERING|17|1||361|374|||10.1109/TASE.2019.2929563||The paper presents an approach to the control of black-box embedded systems by integrating automaton learning and supervisory control theory (SCT) of discrete-event systems (DES), where automaton models of both the system and requirements are unavailable or hard to obtain. First, the system is tested against the requirements. If all the requirements are satisfied, no supervisor is needed and the process terminates. Otherwise, a supervisor is synthesized to enforce the system to satisfy the requirements. To apply SCT and automaton learning technologies efficiently, the system is abstracted to be a finite-discrete model. Then, a $C<^>{*}$ learning algorithm is proposed based on the classical $L<^>{*}$ algorithm to infer a Moore automaton describing both the behavior of the system and the conjunctive behavior of the system and the requirements. Subsequently, a supervisor for the system is derived from the learned Moore automaton and patched on the system. Finally, the controlled system is tested again to check the correctness of the supervisor. If the requirements are still not satisfied, a larger Moore automaton is learned and a refined supervisor is synthesized. The whole process iterates until the requirements hold in the controlled system. The effectiveness of the proposed approach is manifested through two realistic case studies. Note to Practitioners-Supervisory control theory of DES can synthesize maximally permissive supervisory controllers to ensure the correctness of software-controlled processes. The application of supervisory control theory relies on automaton models of the plant and specifications; however, the required models are often unavailable and difficult to obtain for black-box embedded systems. Automaton learning is an effective method for inferring models of black-box systems. This paper integrates the two technologies so that the supervisory control theory is applicable to the development of black-box embedded software systems. The proposed approach is implemented in a toolchain that connects automaton learning algorithms, SCT, and testing algorithms via scripts. The obtained supervisor is implemented as a software patch to monitor and control the original system online.|||Article||||
WEB OF SCIENCE|Lino, Adriano Del Pino|||Labder - Virtual Teaching-Learning Laboratory for Relational Databases: An Approach for Automatic Evaluation of ER and SQL Diagrams|2021||||||||||||||Dissertation/Thesis||||
WEB OF SCIENCE||||CSR: Small: Modernizing Dynamic Binary Translation Systems|2024|||||||||||Dynamic binary translation (DBT), used to translate executable code from one instruction set architecture to another, supports a range of essential applications, including architectural simulators, hardware emulators, runtime optimizers, program analysis tools, software testing platforms, and more. However, existing DBT systems have not kept up with the rapid evolution of computer software and hardware. For instance, existing DBT systems suffer from significant execution inefficiencies due to the poor quality of the translated binary code. As a consequence, it becomes increasingly challenging to adopt DBT for many important applications, especially those in emerging domains, e.g., machine learning and graph processing. The goal of this project is to modernize DBT systems through a series of novel innovations. A key insight is that the translation between different computer instruction sets --usually represented in assembly language-- is similar to the translation between different natural languages. Inspired by this insight, this project will invent novel translation approaches to produce high-quality binary code. The innovations developed by this project will improve the performance efficiency of DBT systems when running binary code. Moreover, they will enhance the capability of DBT systems to support important applications. More efficient, more capable, and more powerful DBT systems, as modernized by this project, will not only benefit current DBT applications, but also enable DBT applications in new frontiers, producing long-lasting impacts. The innovative technologies developed in this project will provide insights for the research community to push forward the DBT field. Additionally, this project will assemble a set of well-organized teaching and mentoring activities to promote research experiences for undergraduates and create a more diverse and inclusive educational environment. This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.|||Awarded Grant||||
WEB OF SCIENCE||||CAREER: Enhanced Reliability and Efficiency of Software Regression Testing in the Presence of Flaky Tests|2024|||||||||||Software is usually developed in a continuous development and integration process that incorporates incremental changes leading to successive releases of the software, where each release undergoes rigorous software testing to check whether recent code changes had broken existing functionalities. This process, known as regression testing, is widely used in software development practice. A major problem in the generation of test cases is the presence of flaky tests: tests that non-deterministically pass or fail on the same version of the code. Failures from flaky tests can mislead developers about their recent changes, waste developers��� time, and reduce developers��� trust in software testing. Many software development organizations have reported that flaky tests are one of their biggest problems, because they confound assurance goals. This project aims to improve the reliability and efficiency of regression testing in the presence of flaky tests. It will produce tools that aim to be efficient and effective at resolving the inherent nondeterminism. The work focuses on (1) reducing the cost of flaky-test detection and debugging techniques by predicting important test properties, (2) developing new techniques to predict flakiness-related properties, (3) speeding up and reducing the resources needed by regression testing, (4) developing new techniques to systematically detect flaky tests, and (5) reducing the flakiness in Android user interface testing. The project will also produce curriculum for education and training on the topic of programming in the face of nondeterminism, and will work with industry to transfer technology. The research on flakiness will move from the typical, black-box approaches to a new level for detecting, debugging, and fixing through novel, white-box and learning-based approaches. The approach will use static and dynamic analyses to compute state pollution, which may affect test flakiness based on the test execution order. The work involves combinatorial design theory to improve the efficiency of order-dependent test detection. Special attention will be paid to flaky tests in graphical user interfaces using record-and-replay and test input generation. Test coverage computations, which can be used to predict whether a code change will affect the test's output, will use a machine learning approach. The work will result in tool implementations and large-scale evaluations in open source and proprietary environments. This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.|||Awarded Grant||||
WEB OF SCIENCE|Castro, Miguel Cervera|||Adopting Test Automation at Effizency to Improve Agility and Software Quality|2022||||||||||||||Dissertation/Thesis||||
WEB OF SCIENCE||||POSE: Phase I: Tuitus - A sustainable, inclusive, open ecosystem for Natural Hazards Engineering|2022|||||||||||This project is funded by Pathways to Enable Open-Source Ecosystems (POSE) which seeks to harness the power of open-source development for the creation of new technology solutions to problems of national and societal importance. Natural hazards, such as floods, landslides, earthquakes, tornadoes, and wildfires, threaten more than 57% of the US national infrastructure. Modeling these complex natural hazards pushes the frontiers of high-performance computing, multi-scale modeling, in-situ visualization, big-data analysis, and machine learning. Scientific software codes are often developed in an ad hoc manner by university researchers and graduate students with very little exposure to software development principles and practices. The robustness and open-source nature of these scientific codes are essential for the safety and security of the nation, its people, and the environment. The project establishes the Tuitus Foundation (Latin for ���to protect or care for���), a sustainable, inclusive, open ecosystem of scientific codes for Natural Hazard Engineering (NHE). The project���s novelties are creating a unified interface that supports integration testing, research reproducibility, and workflow provenance in distributed computing environments. The project supports building scalable, automated testing and workflow management for high-performance computing (HPC) environments. The project tackles the social issues around building and sustaining a community by establishing a Governing Board of Directors and supporting community-driven software development in NHE. The project creates an inclusive community by offering guidelines and training for onboarding and supporting new developers through hackathons and Google Summer of Code. By auto-deploying thoroughly tested HPC software to the NSF-funded DesignSafe Cyberinfrastructure, the project impacts the broader community of 6,000 NHE researchers by making robust NHE codes immediately accessible. Open-source codes in NHE will significantly impact the decision-making process and regional-scale risk assessment. The integration of Tuitus Foundation���s HPC Continuous Integration/Continuous Delivery (CI/CD) service with DesignSafe creates a paradigm shift in open-source code delivery in NHE, improving real-world policy decisions during critical natural hazard events. The Tuitus Foundation adopts a holistic approach to address the critical technical challenges in the Open-Source Ecosystem (OSE) by offering a standard Application Programming Interface (API) for HPC and heterogenous hardware architectures and supporting a wide range of applications from HPC, machine learning, database schemas, Jupyter notebooks, and visualizations. This project is the first attempt to integrate HPC-scale CI testing with natural hazard engineering codes for multi-job pipelines. The Tapis framework provides programmable interfaces that enable developers to automate data management and job execution on HPC and cloud resources. Tapis OAuth2 provides a separate security layer for managing user credentials, allowing Tapis to access many different storage and computing resources on behalf of the user. HPC-scale CI/CD with theTapis API enables testing for extreme-scale problems on distributed computing environments and future exascale systems. The project offers workflow provenance in Jupyter notebooks by tracking workflows and packaging runtime environment, thus enhancing research reproducibility. The novel CI developments bring together literate programming and HPC testing to provide the much-needed robustness to improve trustworthiness in engineering decision-making. This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.|||Awarded Grant||||
WEB OF SCIENCE||||CCRI: ENS: Evolving the Defects4J Benchmark and Infrastructure to Enable Sustained Innovation and Reproducibility in Software Engineering Research|2021|||||||||||Software engineering research aims to increase the quality of the software that pervades modern technology. To make significant advances, reproducibility and comparability of empirical results, using realistic artifacts, are essential in many software engineering research areas, including software testing and debugging, program comprehension, software evolution, and machine learning in software engineering. The Defects4J database of real software faults and a supporting infrastructure were developed to support the software engineering research community, in particular to further reproducibility, to enable faster and better completion of downstream research, and to free researchers from the burden of (re-)developing an experiment infrastructure. This project evolves and extends Defects4J, which has been widely adopted by the software engineering research community. It focuses on enabling sustained innovation and reproducibility in software engineering research by making Defects4J more broadly available and meeting the growing interest and feature requests from the software engineering research community. Specifically, this project aims to (1) grow the current set of artifacts in Defects4J, based on community feedback, (2) develop a fully automated framework for mining additional artifacts, (3) future-proof and containerize all artifacts for use with modern compilers and runtime environments, and (4) provide comprehensive tutorials and templates to support researchers and educators. A high degree of automation and structured pathways to community contributions will support sustained growth. Additionally, this project advances scientific knowledge about defect patterns, prediction, and prevention, applicability and limitations of research techniques, and best practices for empirical evaluations. Finally, this project supports software engineering education at the graduate and undergraduate level. The benchmark and infrastructure allow students to reproduce published results, experiment with, and compare, existing tools and techniques, and quickly evaluate new ideas. This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.|||Awarded Grant||||
WEB OF SCIENCE|Wolf, Alex; Palma, Marco Edoardo; Salza, Pasquale; Gall, Harald C.|||Trustworthy Distributed Certification of Program Execution|2025|IEEE TRANSACTIONS ON SOFTWARE ENGINEERING|51|4||1134|1152|||10.1109/TSE.2025.3541810||Verifying the execution of a program is complicated and often limited by the inability to validate the code's correctness. It is a crucial aspect of scientific research, where it is needed to ensure the reproducibility and validity of experimental results. Similarly, in customer software testing, it is difficult for customers to verify that their specific program version was tested or executed at all. Existing state-of-the-art solutions, such as hardware-based approaches, constraint solvers, and verifiable computation systems, do not provide definitive proof of execution, which hinders reliable testing and analysis of program results. In this paper, we propose an innovative approach that combines a prototype programming language called Mona with a certification protocol OCCP to enable the distributed and decentralized re-execution of program segments. Our protocol allows for certification of program segments in a distributed, immutable, and trustworthy system without the need for naive re-execution, resulting in significant improvements in terms of time and computational resources used. We also explore the use of blockchain technology to manage the protocol workflow following other approaches in this space. Our approach offers a promising solution to the challenges of program execution verification and opens up opportunities for further research and development in this area. Our findings demonstrate the efficiency of our approach in reducing the number of program executions by up to 20-fold, while maintaining resilience against various malicious attacks compared to existing state-of-the-art methods, thus improving the efficiency of certifying program executions. Additionally, our approach handles up to 40% malicious workers effectively, showcasing resilience in detecting and mitigating malicious behavior. In the Equivalent Registers Attack scenario, it successfully identifies divergent executions even when register values and results appear identical. Moreover, our findings highlight improvements in time and gas efficiency for longer-running problems (scaled with a multiplier of 1,000) compared to baseline methods. Specifically, adopting an informed step size reduces execution time by up to 43-fold and gas costs by up to 12-fold compared to the baseline. Similarly, the informed step size approach reduces execution time by up to 6-fold and gas costs by up to 26-fold compared to a non-informed variation using a step size of 1,000.|||Article||||
WEB OF SCIENCE|Friande, Francisco Ademar Freitas|||Extending a Hybrid Fuzzer for Smart Contracts with a Test - Suite Diagnosability Metric|2022||||||||||||||Dissertation/Thesis||||
WEB OF SCIENCE|Simões, Inês Raquel Leandro|||Collaborative Development and Testing of Task-Oriented Conversational Agents|2023||||||||||||||Dissertation/Thesis||||
WEB OF SCIENCE|Borgarelli, Andrea; Enea, Constantin; Majumdar, Rupak; Nagendra, Srinidhi|||Reward Augmentation in Reinforcement Learning for Testing Distributed Systems|2024|PROCEEDINGS OF THE ACM ON PROGRAMMING LANGUAGES-PACMPL|8|OOPSLA2|339|||||10.1145/3689779||Bugs in popular distributed protocol implementations have been the source of many downtimes in popular internet services. We describe a randomized testing approach for distributed protocol implementations based on reinforcement learning. Since the natural reward structure is very sparse, the key to successful exploration in reinforcement learning is reward augmentation. We show two different techniques that build on one another. First, we provide a decaying exploration bonus based on the discovery of new states-the reward decays as the same state is visited multiple times. The exploration bonus captures the intuition from coverage-guided fuzzing of prioritizing new coverage points; in contrast to other schemes, we show that taking the maximum of the bonus and the Q-value leads to more effective exploration. Second, we provide waypoints to the algorithm as a sequence of predicates that capture interesting semantic scenarios. Waypoints exploit designer insight about the protocol and guide the exploration to interesting parts of the state space. Our reward structure ensures that new episodes can reliably get to deep interesting states even without execution caching. We have implemented our algorithm in Go. Our evaluation on three large benchmarks (RedisRaft, Etcd, and RSL) shows that our algorithm can significantly outperform baseline approaches in terms of coverage and bug finding.|||Article||||
WEB OF SCIENCE|Jilani, Atif Aftab; Sherin, Salman; Ijaz, Sidra; Iqbal, Muhammad Zohaib; Khan, Muhammad Uzair|||Deriving and evaluating a fault model for testing data science applications|2022|JOURNAL OF SOFTWARE-EVOLUTION AND PROCESS|34|5|e2449|||||10.1002/smr.2449||Data science (DS) applications not only suffer from traditional software faults but may also suffer from data-specific and model-related faults. Fault models play an important role in evaluating and designing tests for testing DS applications. The existing fault models do not consider DS specific faults. In this study, we built a fault model DS applications. We investigate the faults by using diverse approaches: (i) a multi-vocal literature survey of published literature, (ii) semi-structured interviews of industry experts. The Multi-vocal study allows us to synthesize the existing knowledge from researchers and practitioners. Qualitative data from semi-structured interviews provide us with insights into the nature of faults encountered by practitioners. We combine the results of (i) and (ii) to derive a detailed fault model. The developed fault model is further validated through a quantitative survey of industry practitioners, and the respondents were asked to identify the faults from our proposed fault model that they have experienced and classify those faults based on their severity as perceived by practitioners and its frequency. The results show that practitioners consider prediction bias and model decay as the most severe faults while data sampling and splitting faults along with feature engineering faults are the most frequent.|||Article||||
WEB OF SCIENCE|Gonçalves, Luís Filipe Carvalho Martos|||Automatic Generation of Energy Efficient System Tests|2022||||||||||||||Dissertation/Thesis||||
WEB OF SCIENCE|Duarte, Gonçalo Miguel Inácio|||Bio-Inspired Optimization Algorithms for Unit Test Generation|2021||||||||||||||Dissertation/Thesis||||
WEB OF SCIENCE|Rani, S. Alagu; Akila, C.; Raja, S. P.|||Guided Intelligent Hyper-Heuristic Algorithm for Critical Software Application Testing Satisfying Multiple Coverage Criteria|2024|JOURNAL OF CIRCUITS SYSTEMS AND COMPUTERS|33|2|2450029|||||10.1142/S0218126624500294||This paper proposes a novel algorithm that combines symbolic execution and data flow testing to generate test cases satisfying multiple coverage criteria of critical software applications. The coverage criteria considered are data flow coverage as the primary criterion, software safety requirements, and equivalence partitioning as sub-criteria. The characteristics of the subjects used for the study include high-precision floating-point computation and iterative programs. The work proposes an algorithm that aids the tester in automated test data generation, satisfying multiple coverage criteria for critical software. The algorithm adapts itself and selects different heuristics based on program characteristics. The algorithm has an intelligent agent as its decision support system to accomplish this adaptability. Intelligent agent uses the knowledge base to select different low-level heuristics based on the current state of the problem instance during each generation of genetic algorithm execution. The knowledge base mimics the expert's decision in choosing the appropriate heuristics. The algorithm outperforms by accomplishing 100% data flow coverage for all subjects. In contrast, the simple genetic algorithm, random testing and a hyper-heuristic algorithm could accomplish a maximum of 83%, 67% and 76.7%, respectively, for the subject program with high complexity. The proposed algorithm covers other criteria, namely equivalence partition coverage and software safety requirements, with fewer iterations. The results reveal that test cases generated by the proposed algorithm are also effective in fault detection, with 87.2% of mutants killed when compared to a maximum of 76.4% of mutants killed for the complex subject with test cases of other methods.|||Article||||
WEB OF SCIENCE|Sun, Weifeng; Yan, Meng; Liu, Zhongxin; Xia, Xin; Lei, Yan; Lo, David|||Revisiting the Identification of the Co-evolution of Production and Test Code|2023|ACM TRANSACTIONS ON SOFTWARE ENGINEERING AND METHODOLOGY|32|6|152|||||10.1145/3607183||Many software processes advocate that the test code should co-evolve with the production code. Prior work usually studies such co-evolution based on production-test co-evolution samples mined from software repositories. A production-test co-evolution sample refers to a pair of a test code change and a production code change where the test code change triggers or is triggered by the production code change. The quality of the mined samples is critical to the reliability of research conclusions. Existing studies mined production-test co-evolution samples based on the following assumption: if a test class and its associated production class change together in one commit, or a test class changes immediately after the changes of the associated production class within a short time interval, this change pair should be a production-test co-evolution sample. However, the validity of this assumption has never been investigated.To fill this gap, we present an empirical study, investigating the reasons for test code updates occurring after the associated production code changes, and revealing the pervasive existence of noise in the production-test co-evolution samples identified based on the aforementioned assumption by existing works. We define a taxonomy of such noise, including six categories (i.e., adaptive maintenance, perfective maintenance, corrective maintenance, indirectly related production code update, indirectly related test code update, and other reasons). Guided by the empirical findings, we propose CHOSEN (an identifiCation metHod Of production-teSt co-EvolutioN) based on a two-stage strategy. CHOSEN takes a test code change and its associated production code change as input, aiming to determine whether the production-test change pair is a production-test co-evolution sample. Such identified samples are the basis of or are useful for various downstream tasks. We conduct a series of experiments to evaluate our method. Results show that (1) CHOSEN achieves an AUC of 0.931 and an F1-score of 0.928, significantly outperforming existing identification methods, and (2) CHOSEN can help researchers and practitioners draw more accurate conclusions on studies related to the co-evolution of production and test code. For the task of Just-In-Time (JIT) obsolete test code detection, which can help detect whether a piece of test code should be updated when developers modify the production code, the test set constructed by CHOSEN can help measure the detection method's performance more accurately, only leading to 0.76% of average error compared with ground truth. In addition, the dataset constructed by CHOSEN can be used to train a better obsolete test code detection model, of which the average improvements on accuracy, precision, recall, and F1-score are 12.00%, 17.35%, 8.75%, and 13.50% respectively.|||Article||||
WEB OF SCIENCE||||CyberCorps(R): Scholarship for Service (Renewal): An Interdisciplinary Cybersecurity Program with Technical and Managerial Paths|2023|||||||||||Security training has become the foundation of societal resilience, often necessary for organizational effectiveness. The State University of New York at Buffalo (UB) is a designated National Center of Academic Excellence (CAE) in cybersecurity education and a CAE in cybersecurity research (CAE-R). UB will leverage this security foundation by participating in the CyberCorps(R): Scholarship for Service (SFS) program to prepare highly qualified cybersecurity professionals to enter the federal workforce. This project builds on a successful program and develops a comprehensive cybersecurity curriculum based on security best practices, experiential learning, and applied research. It will develop authentic pathways to cybersecurity by expanding the program's scope to include undergraduate students and by recruiting students for graduate studies. This project also plans to inspire middle and high school students to become security problem solvers and security professionals. The project will provide scholars with an enhanced, interdisciplinary cybersecurity experience by engaging faculty from computer science, engineering and management sciences with support from mathematics and law at UB. This project will continue to develop and sustain a successful, broad cybersecurity program by building on existing research on ransomware, blockchain technology, and information authenticity. The project will train 24 students in four cohorts in both technical and managerial paths. A minor in cybersecurity will be offered for undergraduate students and an advanced certificate for graduate students specializing in cybersecurity. UB will leverage the state-of-the-art resources in Buffalo's Regional Computer Forensics Lab (RCFL) to offer 15 high-level experience-based courses. These courses include Software Testing, Blockchain Application Development, Systems Security, Network Security, Privacy, Ethics, and an integrative Information Assurance course that will prepare students for industry certification. The project team will actively engage underrepresented groups through the local Minority Management Society, the SUNY Louis Stokes Alliance for Minority Participation program, and the Women in Management and Engineering and Science groups to recruit students and conduct cybersecurity awareness workshops in Buffalo. Partnerships with local industries will allow educational opportunities and talent development in the emerging domains of artificial intelligence, analytics, and blockchain technology. These stakeholder engagement opportunities will broaden the impact of the project���s cybersecurity efforts within the community. This project is supported by the CyberCorps�� Scholarship for Service (SFS) program, which funds proposals establishing or continuing scholarship programs in cybersecurity and aligns with the U.S. National Cyber Strategy to develop a superior cybersecurity workforce. Following graduation, scholarship recipients are required to work in cybersecurity for a federal, state, local, or tribal Government organization for the same duration as their scholarship support.������ This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.|||Awarded Grant||||
WEB OF SCIENCE||||FAI: Measuring and Mitigating Biases in Generic Image Representations|2021|||||||||||Visual recognition is a remarkable task performed by the human brain. Computational methods trained to emulate this capability rely on observing millions of examples of visual input paired with human annotations. These computational methods have made great progress and are being increasingly adopted in many user-facing applications such as image search, automated image tagging, semi-autonomous navigation systems, smart virtual assistants, etc. However, the underlying visual recognition models in these systems often produce errors by associating sensitive variables of societal significance with their predictions. The goal of this project is to measure and mitigate such errors in a systematic fashion. For example, if a method is able to recognize images of scenes such as 'classroom', the goal of this project is to ensure that such predictions are obtained based on cues such as the presence of a whiteboard, chairs, desks, and other elements typically needed for a space to function as a classroom and not based on incidental elements such as the characteristics or attributes of people present in the classroom. To this end, this project aims to make it easier to determine to what extent methods for computational visual recognition rely on spurious associations with incidental elements. This project will provide a study of societal biases present in current methods and models for computational visual recognition that are widely used as a source of generic visual representations. The developed methods will be based on solid foundations drawn from both the machine learning, computer vision, and software testing communities. The project introduces association tests to probe models trained under a variety of conditions to systematically disentangle the biases introduced during generic visual representation learning. The project will be 1) developing a general assessment methodology to measure various types of biases in generic visual representation learning, 2) proposing methods to diminish the impact of these biases in existing generic visual representation extraction models, and 3) measuring the impact of these biases on some key downstream tasks. These three research aims will be complemented by a comprehensive evaluation plan and broadening participation activities. This research effort will bring novel insights into the sources of biases in the predictions of computer vision models and methodologies to make informed decisions about the risks in the deployment of such models. This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.|||Awarded Grant||||
WEB OF SCIENCE||||FAI: Measuring and Mitigating Biases in Generic Image Representations|2021|||||||||||Visual recognition is a remarkable task performed by the human brain. Computational methods trained to emulate this capability rely on observing millions of examples of visual input paired with human annotations. These computational methods have made great progress and are being increasingly adopted in many user-facing applications such as image search, automated image tagging, semi-autonomous navigation systems, smart virtual assistants, etc. However, the underlying visual recognition models in these systems often produce errors by associating sensitive variables of societal significance with their predictions. The goal of this project is to measure and mitigate such errors in a systematic fashion. For example, if a method is able to recognize images of scenes such as 'classroom', the goal of this project is to ensure that such predictions are obtained based on cues such as the presence of a whiteboard, chairs, desks, and other elements typically needed for a space to function as a classroom and not based on incidental elements such as the characteristics or attributes of people present in the classroom. To this end, this project aims to make it easier to determine to what extent methods for computational visual recognition rely on spurious associations with incidental elements. This project will provide a study of societal biases present in current methods and models for computational visual recognition that are widely used as a source of generic visual representations. The developed methods will be based on solid foundations drawn from both the machine learning, computer vision, and software testing communities. The project introduces association tests to probe models trained under a variety of conditions to systematically disentangle the biases introduced during generic visual representation learning. The project will be 1) developing a general assessment methodology to measure various types of biases in generic visual representation learning, 2) proposing methods to diminish the impact of these biases in existing generic visual representation extraction models, and 3) measuring the impact of these biases on some key downstream tasks. These three research aims will be complemented by a comprehensive evaluation plan and broadening participation activities. This research effort will bring novel insights into the sources of biases in the predictions of computer vision models and methodologies to make informed decisions about the risks in the deployment of such models. This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.|||Awarded Grant||||
WEB OF SCIENCE|Peng, Xi; Jia, Peng; Fan, Ximing; Liu, Jiayong|||ENZZ: Effective N-gram coverage assisted fuzzing with nearest neighboring branch estimation|2025|INFORMATION AND SOFTWARE TECHNOLOGY|177||107582|||||10.1016/j.infsof.2024.107582||Fuzzing is a highly effective approach for identifying software bugs and vulnerabilities. Among the various techniques employed, coverage-guided fuzzing stands out as particularly valuable, relying on tracing code coverage information. N-gram coverage is a coverage metric in gray-box fuzz testing, where the value of N determines the sensitivity of the coverage. Block and edge coverage can be represented as 0-gram and 1-gram, respectively. The value of N can range from 0 to infinity. However, the specific methodology for selecting the appropriate value of N is still an area yet to be explored. This paper proposes an estimation method based on the nearest branch. We initially explained the role of N-gram in the execution paths of programs and elucidated the objective of selecting the value of N, which aims to cover the closest neighboring branches. Subsequently, based on this objective, we proposed a method for calculating N based on the closest neighboring branch and estimated N at the function level. Finally, in this paper, we designed a scheduling mechanism using Adversarial Multi-Armed Bandit model that automatically selects either the seeds generated by N-gram or the original queue seeds for fuzz testing. We implement our approach in ENZZ based on AFL and compare it with other N-gram coverage fuzzers and the state-of-the-art path coverage-assisted fuzzer PathAFL. We find that ENZZ outperforms other N-gram fuzzers and PathAFL by achieving an average improvement of 5.57% and 4.38% on edge coverage, and it improves the efficiency of path-to-edge discovery by 31.5% and 26.1%, respectively, on 12 Google FuzzBench programs. It also finds more bugs than other N-gram fuzzers and three more real-world bugs than PathAFL.|||Article||||
WEB OF SCIENCE|Shafei, Hassan A.|||Testing Privacy and Security of Voice Interface Applications in the IoT Era|2024||||||||||||||Dissertation/Thesis||||
WEB OF SCIENCE||||CAREER: Behavior-Driven Testing of Big Data Exploration Tools|2022|||||||||||This award is funded in whole or in part under the American Rescue Plan Act of 2021 (Public Law 117-2). Companies, governments, and institutions all over the world use massive datasets to make many decisions that impact our daily lives, such as how climate change is addressed, who is protected from COVID-19, or which investments to prioritize to maximize a company���s growth. However, big data is only valuable when it can provide useful insights, which analysts often seek to extract from data visualizations. Much like mastering a new recipe, it takes effort and skill to process data and design effective visualizations, and analysts are increasingly turning to computational tools to support their efforts to visualize massive data and process it into a form suitable for consumption. However, evaluating these tools is challenging, both because they are used for a wide variety of problems and by a wide variety of people, and standard tool benchmarks are unequipped to handle these variations. The vision for this project is to develop better ways to evaluate tools as they are used in the wild; if we can automate the way we evaluate data exploration tools, then we can automatically test new tools as soon as they are created, tune them to real workloads, and help analysts be more efficient and effective at generating insights. To this end, the research team will develop automated testing software that can determine: (1) whether a data exploration tool is capable of helping someone achieve the particular goals they have in exploring their data; and (2) what problems these tools and evaluation methods may introduce to the data exploration process. The team will also work with leading visualization researchers and software companies to fine-tune the software and maximize its impact, and develop new programs to help students learn fundamental visualization and research skills. To make the envisioned software feasible, the research objective of this project is to formally specify an analyst���s goals in exploring a dataset, and to measure whether a given system helps or hinders an analyst���s ability to achieve these specified data exploration goals. During data exploration, analysts visually and interactively query their data to help their organization make informed decisions. The research will be conducted in three phases. Phase 1 will theoretically and programmatically define a person���s exploration intent at different granularities (e.g., goals, sub-tasks, interaction patterns). Phase 2 will integrate foundational theory in HCI with AI path planning methods to generate a valid sequence of user interactions that achieve a programmatically defined intent. Phase 3 will extend the models from Phase 2 to develop customizable performance testing software that can simulate how people alternate between goal-directed interactions (i.e., following a planned sequence) and open-ended interactions (i.e., exploring alternative analyses). The research team will implement the framework as an open source platform so others can use the findings to evaluate their own systems and data exploration use cases. This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.|||Awarded Grant||||
WEB OF SCIENCE|Santos, Carlos Francisco Fernandes|||Evolutionary Robustness Testing of Rest Services|2022||||||||||||||Dissertation/Thesis||||
WEB OF SCIENCE||||AF: Small: Lower Bounds in Complexity Theory Via Algorithms|2021|||||||||||Computers have transformed nearly every aspect of life, by automating and assisting in helping people work more efficiently. But while researchers know much about what computers can do, there is still comparatively little known about what computers cannot do. This phenomenon is the problem of proving complexity lower bounds. Lower bounds are among the great scientific mysteries of our time: there are many mathematical conjectures and beliefs about lower bounds---indeed, the security of the Internet and cryptography relies on such conjectures being true---but concrete results are few. The major goal of this project is to leverage humanity's vast knowledge of computer algorithms to prove new lower bounds: put another way, the goal is to use the power of computers to prove limitations on them. A secondary goal is to study the scientific consequences of these connections. It is hard to overestimate the potential impact---societal, scientific, and otherwise---of a theoretical framework which would lead to a fine-grained understanding of what computers can and cannot do. Another goal of the project is to bring complexity research closer to real-world computing, and to introduce practitioners to aspects of complexity that will impact their work. A final goal is educational outreach, through online forums dedicated to learning computer science and collaboration with the media on communicating theoretical computer science to the public. To give one example of a lower bound, a central question in computer science is the famous P versus NP open problem, which is about the difficulty of combinatorial problems which admit short solutions. Such problems can always be solved via brute force, trying all possible solutions. Can brute force always be replaced with a cleverer search method? This question is a major one; no satisfactory answers are known, and concrete answers seem far away. The conventional wisdom is that in general, brute force cannot be entirely avoided, but it is still mathematically possible that most natural search problems can be solved extremely rapidly, without any brute force. The mathematical theory is hampered by negative results showing that most known proof methods are incapable of proving strong lower bounds. A primary objective of this project is to help discover and develop new ways of thinking that will demystify lower bounds, and elucidate the limits and possibilities of computing. The major hypothesis of this project is that an algorithmic perspective on lower bounds is the key: for example, an earlier project led by the same research team shows that algorithms for the circuit-satisfiability problem (which slightly beat brute force search) imply circuit-complexity lower bounds. Other algorithmic problems, such as estimating the acceptance probability of a circuit without using randomness, and finding bad inputs which prove that a piece of code does not correctly compute a function, also turn out to be useful for proving lower bounds. The potential scientific applications are vast, ranging from logical circuit design, to network algorithms, to improved hardware and software testing, to better nearest-neighbor search (with its own applications in computer vision, DNA sequencing, and machine learning), and to cryptography and security. This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.|||Awarded Grant||||
WEB OF SCIENCE||||Discovery of input/output Casual relations in Software Systems|2020|||||||||||Despite digital technologies have notably revolutionized daily life, security and privacy concerns have emerged alongside. The complexity of their tasks has made automated systems ever more difficult to understand, causing a progressive loss of confidence, especially in critical scenarios involving sensitive data. Current interpretability methods tackle the opacity problem only from partial perspectives: suited to specific systems, highlighting statistical correlations, or providing too technical explanations. Our research places in the Causal Discovery area and aims thus to answer the critical question why did a system make that decision? lifting the analysis to higher levels of abstraction. We propose a novel General Causal Explanation Method for testing the behavioural logic of software systems on large-scale, serving a dual purpose: provide human-understandable explanations of the reasons why an automated procedure comes to the outcome in terms of input categories that directly affect it; assess whether a system's decision logic violates predefined software specifications. We leverage on Information Theory and a Lattice structure of partitions defined on the input space of the systems under test (SUT), treated as black-box: we only require access to input/output (I/O) interfaces. We develop an algorithm that investigates I/O causal relationships by performing Conditional Independence Testing via Conditional Mutual Information (CMI). The idea is look for the smallest subset of input variables (input part) that when altered cause a change in the output (or given output part). An elimination strategy is used to build explanations, excluding input variables with null CMI. The three core pillars of our research are summarized below: 1) Information-Theory grounded General Causal Explanation Framework: evaluation of the methodology in different application areas. We show the versatility of our method in testing software and properties of different nature. We start focusing on Machine Learning-based predictive systems involving sensitive input categories, Programs implementing security policies and Image recognition systems. After dealing with Fairness, Information leakage and misclassification in black-box scenarios, we'll introduce a fourth white-box case study. With the growing number of studies focused on testing Social Network platforms, we find interesting to adopt our explanation methodology to model simulated social interactions by leveraging on causal reasoning. 2) Enhance Software Testing Performance adding Statistical Guarantee. We aim to improve our Test Set and information-theoretic measurements' quality by providing our testing approach with statistical guarantee. We investigate existing statistical methods used for estimating Mutual Information looking for the most suitable in the context of our study, that comes with a good statistical confidence level. This would allow to: provide more rigorous findings, argue that the detected influential and non-influential parts are correct with a high-level confidence; release our findings from approximations and test suite size. 3) Generalise Causal Analysis with Directed Information (DI). We discuss the link between Granger Causality and DI Theory showing that DI algebraic structure, simplified to our scenarios, aligns with CMI. Expand our generalised approach using DI becomes thus a compelling direction for our research, especially w.r.t. more complex scenarios where the direction of the I/O relationship is ambiguous. An interesting application context is given by interactive programs (webpages, editors) where the information can flow in different directions, given the existence of multiple users interacting with the program simultaneously. We expect to deliver a broad range of contributions both to users and developers, enabling informed usage of critical software systems, detecting and mitigating threats to fairness and security, and enhancing the overall q|||Awarded Grant||||
WEB OF SCIENCE||||SHF:Small:Closing the Specification Gap with Logic and Linguistics|2022|||||||||||Recent years have seen dramatic advances in the ability to exploit formal or semi-formal specifications of software behavior for finding software bugs or building confidence in software correctness. However, these specifications are typically given in the form of logical formulae (for formal verification) or additional code (for typical software testing), while the original description of expected behavior is typically written in natural language such as English prose. Currently, these (semi)formal specifications are manually translated from natural language, leaving significant opportunities for misunderstandings or mistakes during translation, which can lead to validating that software satisfies useless or actively incorrect properties. The manual nature of the translation means it is difficult to audit after the fact. This project pursues new approaches to connecting natural language specifications of software behavior, at the level of single sentences, to the (semi)formal specifications currently accepted by many varieties of software quality tools, including property-based testing frameworks, proof assistants, and various tools using temporal logic specifications. The project's novelties are connecting natural and formal specifications using techniques drawn from the linguistics literature, which are modular (making them possible to extend or locally repair) and evidence-producing (making it possible to audit the translation for understanding or debugging translation errors); innovating on the structure of word knowledge used by the system to allow high degrees of direct reuse across different semi-formal specification forms; and improving techniques for linguistic lexicon inference by using information about the datatypes involved. These are all difficult to attain with mainstream machine learning techniques, against which the project will compare. The project will produce new techniques for translating English sentences into property-based tests for testing, proof assistant specifications for formal proofs of correctness, and multiple temporal logics for both correctness proofs and automated bug finding; and the project will implement them in an open source tool. The project's impacts are expected to be tools for connecting English descriptions of behavior to the formal descriptions used by software quality experts (improving requirement tracing, communication between software experts and non-technical clients, and education), extensive validation of classic linguistic theories in an important domain application, and cross-pollination of techniques and applications between computational linguistics and software quality research. Additionally, the project is expected to improve confidence in individual pieces of software whose specifications are studied by this project. The project takes categorial grammars as its key building block, an approach to compositional semantics of natural language that has been extensively vetted by linguists to cover a wide variety of subtle grammatical phenomena in many natural languages from different language families. Categorial grammars are therefore expected to impose no a priori restrictions on sentence structure or grammatical flexibility, unlike prior approaches to relating formal and natural specifications. Categorial grammars have also been used to parse natural language into enough various logics addressing varied linguistic phenomena (such as time and/or place in addition to current facts) that they can also target all of the specification forms of interest to the project. Key novel insights for the project are the ability to share lexical entries of the grammar across different logics by transporting the semantics of a word in a given logic into semantics targeting other logics, and focusing on a family of specifications that can be deeply embedded in one highly-expressive logic (dependent type theory) to improve sharing, as well as benefiting from and experimentally validating linguistics research positing that such logics are more appropriate representations of natural language meaning. The project will produce a publicly-available prototype system for relating English to property-based tests, proof assistant specifications in dependent type theory, and temporal logics. The project will also produce tools for symbolically learning the grammatical roles and semantics of words that are specific to a project or problem domain, from only a few examples. The framework will be adaptable by others to target other specification logics. This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.|||Awarded Grant||||
SCIENCE DIRECT|Natraj NA,Sundaravadivazhagan B,Pethururaj C,Bhavani S|||AI-driven testing for cloud-native architectures: From implementation challenges to integrated platforms|2025|||||||||10.1016/bs.adcom.2025.07.006|http://dx.doi.org/10.1016/bs.adcom.2025.07.006;https://www.sciencedirect.com/science/article/pii/S0065245825001160|"Software testing is a critical component of the software development lifecycle, ensuring quality and reliability across increasingly complex systems. As cloud-native architectures and microservices proliferate, traditional testing methodologies face significant limitations in coverage, maintenance, and defect detection. These methods struggle particularly with modern architectures like microservices, containerized applications, and event-driven systems that characterize cloud-native environments. This research explores the transformative potential of artificial intelligence in addressing these challenges, while critically examining the obstacles that must be overcome for successful implementation. The integration of AI into testing processes offers remarkable opportunities to improve test coverage, efficiency, and adaptability through automated test case generation, defect prediction, and self-healing test scripts. However, several significant challenges must be addressed: data quality concerns affecting model accuracy, the ""black box"" problem limiting transparency and trustworthiness, and practical implementation difficulties in enterprise and mission-critical environments. We provide a detailed analysis of these challenges, with particular focus on testing cloud-native services, process-aware systems, event-driven architectures, and people-centric applications. This chapter presents both theoretical frameworks and practical strategies for implementing AI-driven testing in modern software architectures. We examine approaches for enhancing data quality, improving explainability in AI models, and streamlining integration with existing enterprise testing frameworks. The research will prove valuable for both researchers exploring AI applications in testing and practitioners implementing AI-driven testing solutions in cloud-native environments. By addressing these challenges strategically, organizations can harness AI’s full potential to develop more robust, efficient, and adaptive testing processes, ultimately delivering higher-quality software products to end-users at accelerated speeds."|Artificial intelligence, Software testing, Test automation, Cloud-native architecture, Explainable AI, Machine learning, Quality assurance, Data quality, Black box problem, Microservices testing||||||
SCIENCE DIRECT|Karathanasopoulos N,Hadjidoukas P|||Deep learning based automated fracture identification in material characterization experiments|2024||60|||||102402||10.1016/j.aei.2024.102402|http://dx.doi.org/10.1016/j.aei.2024.102402;https://www.sciencedirect.com/science/article/pii/S1474034624000508|In the current work, the automated fracture identification in material testing experiments is investigated through deep learning convolutional neural network (CNN) techniques. Three widely employed material characterization experiments are considered, namely uniaxial tensile, punch, and shear experiments. Initially, the surface crack identification performance of well-known, minorly modified CNN architectures is investigated in the context of transfer learning. In particular, the transfer learning performance of VGG, ResNet, and Inception CNN architectures is analyzed. It is found that moderate-size filters and deeper rather than wider network architectures yield significantly higher validation accuracies in all cases, with validation scores that approach and exceed 95% accuracies. Moreover, low computational cost models that can run on minimal storage and computing power devices and deliver superior performance for all experimental testing setups are identified through greedy network searches. Thereupon, CNN deep learning architectures that allow for validation accuracies above 99% are reported, delimiting low-performing model counterparts. Moreover, CNN-based deep learning «all-in-one» material fracture models are elaborated, furnishing automated, computer vision-based fracture characterization techniques. Furthermore, feature map insights are provided, highlighting the salient-feature identification potential of the networks, while the automated crack localization and profile characterization are demonstrated through Local Interpretable Model-agnostic Explanations (LIME) machine learning (ML) methods and image subset creation techniques. The results are expected to serve as a basis for material testing automation with the support of deep learning techniques, providing reliable analysis methods in labor-intensive engineering tasks.|Automation, Convolutional Neural Networks, Transfer learning, Deep Learning, Materials, Fracture||||||
SCIENCE DIRECT|Huang H,Hao Z|||Chapter 3 - Application of intelligent algorithms in the field of software testing|2024|||||||123-142||10.1016/B978-0-443-21758-6.00001-2|http://dx.doi.org/10.1016/B978-0-443-21758-6.00001-2;https://www.sciencedirect.com/science/article/pii/B9780443217586000012|This chapter introduces the application of intelligent algorithms for software engineering, that is, the automated test case generation method, in fog computing, natural language processing (NLP), and other problems. Specifically, Section 3.1 introduces the application of intelligent algorithms based on test-case-relationship matrix in the programs of fog computing. Section 3.2 introduces the application of intelligent algorithms based on a dynamic scatter search strategy in the program of NLP.|Test case generation, relationship matrix, scatter search strategy, fog computing, natural language processing||||||
SCIENCE DIRECT|Watfa M,Bykovski A,Jafar K|||Testing automation adoption influencers in construction using light deep learning|2022||141|||||104448||10.1016/j.autcon.2022.104448|http://dx.doi.org/10.1016/j.autcon.2022.104448;https://www.sciencedirect.com/science/article/pii/S0926580522003211|Technology adoption is pivotal for the productivity growth in construction industry. This research paper attempts to fill this gap by addressing the following research objectives. First, the predictor factors stimulating project managers' adoption of construction automation innovations are rigorously analyzed using a mixed approach combining a systematic literature review, a knowledgeable panel, and a survey questionnaire. Secondly, the study implements a light deep learning model to track the progress of reinforcing bar placements by verifying completed rebar ties. By linking the progress of the bar to a single binary condition, the number of classes needed to train the neural network drops to only two resulting in a light CNN with a recall rate of 89.2% and precision rate of 95.7%. This model can be implemented on a low power GPU, making it more cost efficient and simpler to adopt on site. A similar approach can be used on other critical activities in construction. This approach can aid inspections, quality control, in combination with drones or robotic systems. The proposed system integrates the most important factors of a successful adoption by providing a proof of concept with potential use cases in construction sites.|Automation, Machine learning, Predictors, Construction management||||||
SCIENCE DIRECT|Javaid M,Haleem A,Singh RP,Khan S,Khan IH|||Unlocking the opportunities through ChatGPT Tool towards ameliorating the education system|2023||3|2||||100115||10.1016/j.tbench.2023.100115|http://dx.doi.org/10.1016/j.tbench.2023.100115;https://www.sciencedirect.com/science/article/pii/S2772485923000327|Artificial Intelligence (AI)-based ChatGPT developed by OpenAI is now widely accepted in several fields, including education. Students can learn about ideas and theories by using this technology while generating content with it. ChatGPT is built on State of the Art (SOA), like Deep Learning (DL), Natural Language Processing (NLP), and Machine Learning (ML), an extrapolation of a class of ML-NLP models known as Large Language Model (LLMs). It may be used to automate test and assignment grading, giving instructors more time to concentrate on instruction. This technology can be utilised to customise learning for kids, enabling them to focus more intently on the subject matter and critical thinking ChatGPT is an excellent tool for language lessons since it can translate text from one language to another. It may provide lists of vocabulary terms and meanings, assisting students in developing their language proficiency with resources. Personalised learning opportunities are one of ChatGPT’s significant applications in the classroom. This might include creating educational resources and content tailored to a student’s unique interests, skills, and learning goals. This paper discusses the need for ChatGPT and the significant features of ChatGPT in the education system. Further, it identifies and discusses the significant applications of ChatGPT in education. Using ChatGPT, educators may design lessons and instructional materials specific to each student’s requirements and skills based on current trends. Students may work at their speed and concentrate on the areas where they need the most support, resulting in a more effective and efficient learning environment. Both instructors and students may profit significantly from using ChatGPT in the classroom. Instructors may save time on numerous duties by using this technology. In future, ChatGPT will become a powerful tool for enhancing students’ and teachers’ experience.|Artificial Intelligence, ChatGPT, Education, Students, Teaching, Learning||||||
SCIENCE DIRECT|Chen H,Wang X,Zhang F|||AI enabled launch vehicles: Next potential disruptive technology after reusability|2025|||||||103756||10.1016/j.cja.2025.103756|http://dx.doi.org/10.1016/j.cja.2025.103756;https://www.sciencedirect.com/science/article/pii/S1000936125003620|In the era of global space industry’s rapid expansion, reusable launch technology has the advantage of cost reduction, but makes launch frequency and flight reliability remain critical. This study proposes that Artificial Intelligence (AI) would be the potential disruptive technology to solve these challenges. AI enables transformative capabilities for launch vehicles which are pointed out in four domains: Agile launch operations enabling automate testing, fault diagnosis, and decision-making for targeting hour-level launch cycles and minute-level fault resolution; high-reliability flight enabling real-time autonomous fault diagnosis, mission replanning, and fault-tolerant control within seconds during anomalies, potentially improving reliability by 1-2 orders of magnitude; rapid maintenance enabling real-time health monitoring and lifespan prediction for swift re-launch decisions; efficient space traffic management enabling predict/resolve orbital conflicts amid growing congestion from satellites and debris. The key challenges for AI applications are analyzed as well, including multi-system coupling, uncertain failure modes and narrow flight corridors, limited sensor data, and massive heterogeneous data processing. Finally, the study also proposes that AI promises substantial efficiency gains in launch vehicle design, manufacturing, and testing through multidisciplinary optimization and reduced reliance on physical testing.|Launch vehicle, Artificial intelligence, Launch preparation, Flight reliability, Rapid maintenance, Safety operation & control||||||
SCIENCE DIRECT|Chandler C,Holmlund TB,Foltz PW,Cohen AS,Elvevåg B|||Extending the usefulness of the verbal memory test: The promise of machine learning|2021||297|||||113743||10.1016/j.psychres.2021.113743|http://dx.doi.org/10.1016/j.psychres.2021.113743;https://www.sciencedirect.com/science/article/pii/S0165178121000408|The evaluation of verbal memory is a core component of neuropsychological assessment in a wide range of clinical and research settings. Leveraging story recall to assay neurocognitive function could be made more useful if it were possible to administer frequently (i.e., would allow for the collection of more patient data over time) and automatically assess the recalls with machine learning methods. In the present study, we evaluated a novel story recall test with 24 parallel forms that was deployed using smart devices in 94 psychiatric inpatients and 80 nonpatient adults. Machine learning and vector-based natural language processing methods were employed to automate test scoring, and performance using these methods was evaluated in their incremental validity, criterion validity (i.e., convergence with trained human raters), and parallel forms reliability. Our results suggest moderate to high consistency across the parallel forms, high convergence with human raters (r values 0.89), and high incremental validity for discriminating between groups. While much work remains, the present findings are critical for implementing an automated, neuropsychological test deployable using remote technologies across multiple and frequent administrations.|Machine learning, Natural language processing, Verbal memory test, Criteria||||||
SCIENCE DIRECT|Moshantaf A,Wesemann M,Beinlich S,Junkes H,Schumann J,Alkan B,Kube P,Marshall CP,Pfister N,Trunschke A|||Advancing catalysis research through FAIR data principles implemented in a local data infrastructure – a case study of an automated test reactor††Electronic supplementary information (ESI) available. See DOI: https://doi.org/10.1039/d4cy00693c|2024||14|21||||6186-6197||10.1039/d4cy00693c|http://dx.doi.org/10.1039/d4cy00693c;https://www.sciencedirect.com/science/article/pii/S204447532400529X|Findable, accessible, interoperable, and reusable (FAIR) data is currently emerging as an indispensable element in the advancement of science and requires the development of new methods for data acquisition, storage and sharing. This is becoming even more critical as the increasing application of artificial intelligence demands significantly higher data quality in terms of reliability, reproducibility and consistency of datasets. This paper presents methods for the digital and automatic acquisition and storage of data and metadata in catalysis experiments based on open-source software solutions. The successful implementation of a digitalization concept, which includes working according to machine-readable standard operating procedures (SOPs) is outlined using a reactor for catalytic tests that has been automated with the open source software tool EPICS (Experimental Physics and Industrial Control System). The process of data acquisition, standardized analysis, upload to a database and generation of relationships between database entries is fully automated. Application programming interfaces (APIs) have been developed to enable data exchange within the local data infrastructure and beyond to overarching repositories, paving the way for autonomous catalyst discovery and machine learning applications.|||||||
SCIENCE DIRECT|Takerngsaksiri W,Charakorn R,Tantithamthavorn C,Li YF|||Pytester: Deep reinforcement learning for text-to-testcase generation|2025||224|||||112381||10.1016/j.jss.2025.112381|http://dx.doi.org/10.1016/j.jss.2025.112381;https://www.sciencedirect.com/science/article/pii/S0164121225000494|Test-driven development (TDD) is a widely-employed software development practice that mandates writing test cases based on a textual description before writing the actual code. While writing test cases is the centerpiece of TDD, it is time-consuming, expensive, and often shunned by developers. To address these issues associated with TDD, automated test case generation approaches have recently been investigated. Such approaches take source code as input, but not the textual description. Therefore, existing work does not fully support true TDD, as actual code is required to generate test cases. In addition, current deep learning-based test case generation approaches are trained with one learning objective, i.e., to generate test cases that are exactly matched with the ground-truth test cases. However, such approaches may limit the model’s ability to generate different yet correct test cases. In this paper, we introduce PyTester, a Text-to-Testcase generation approach that can automatically generate syntactically correct, executable, complete, and effective test cases while being aligned with a given textual description. We evaluate PyTester on the public APPS benchmark dataset, and the results show that our Deep RL approach enables PyTester, a small language model, to outperform much larger language models like GPT3.5, StarCoder, and InCoder. Our findings suggest that future research could consider improving small over large LMs for better resource efficiency by integrating the SE domain knowledge into the design of reinforcement learning architecture.|Text-to-testcase generation, Deep reinforcement learning||||||
SCIENCE DIRECT|Alagarsamy S,Tantithamthavorn C,Aleti A|||A3Test: Assertion-Augmented Automated Test case generation|2024||176|||||107565||10.1016/j.infsof.2024.107565|http://dx.doi.org/10.1016/j.infsof.2024.107565;https://www.sciencedirect.com/science/article/pii/S0950584924001708|Context: Test case generation is a critical yet challenging task in software development. Recently, AthenaTest – a Deep Learning (DL) approach for generating unit test cases has been proposed. However, our revisiting study reveals that AthenaTest can generate less than one-fifth of the test cases correctly, due to a lack of assertion knowledge and test signature verification. Objective: This paper introduces A3Test, a novel DL-based approach to the generation of test cases, enhanced with assertion knowledge and a mechanism to verify consistency of the name and signatures of the tests. A3Test aims to adapt domain knowledge from assertion generation to test case generation. Method: A3Test employs domain adaptation principles and introduces a verification approach to name consistency and test signatures. We evaluate its effectiveness using 5,278 focal methods from the Defects4j dataset. Results: Our findings indicate that A3Test outperforms AthenaTest and ChatUniTest. A3Test generates 2.16% to 395.43% more correct test cases, achieves 2.17% to 34.29% higher method coverage, and 25.64% higher line coverage. A3Test achieves 2.13% to 12.20% higher branch coverage, 2.22% to 12.20% higher mutation scores, and 2.44% to 55.56% more correct assertions compared to both ChatUniTest and AthenaTest respectively for one iteration. When generating multiple test cases per method A3Test still shows improvements and comparable efficacy to ChatUnitTest. A survey of developers reveals that the majority of the participants 70.51% agree that test cases generated by A3Test are more readable than those generated by EvoSuite. Conclusions: A3Test significantly enhances test case generation through its incorporation of assertion knowledge and test signature verification, contributing to the generation of correct test cases.|Test case generation, Deep learning||||||
SCIENCE DIRECT|Tahvili S,Hatvani L|||Chapter One - Introduction|2022|||||||3-6||10.1016/B978-0-32-391913-5.00012-9|http://dx.doi.org/10.1016/B978-0-32-391913-5.00012-9;https://www.sciencedirect.com/science/article/pii/B9780323919135000129|This book provides several artificial intelligence approaches for optimizing the testing process from an engineering perspective, where the objective is to design a system that optimizes a set of metrics subject to constraints. The lack of available data is one of the obstacles to implementing artificial intelligence in the daily use industry. Therefore, in this book, we provide several industrial use cases collected from two large companies in Sweden: Ericsson AB and Alstom Sweden AB. Moreover, applying the proposed artificial intelligence-based solutions in this book to both telecommunication use cases at Ericsson AB and safety-critical system cases at Alstom Sweden AB can help us overcome the problem of feasibility and generalizability. The conducted case studies in this book cover industrial data-gathering, utilizing different artificial intelligence and machine learning models, and also how we can deal with small datasets. However, large datasets might cause other problems for the usage of advanced machine learning models. Inaccurate data, noises, and duplicates are some of the issues that we faced during our research. In this regard, this book provides several strategies to deal with large datasets in industries as well. The topics covered in this book include decision-making, optimization under uncertainty, data preparation and feature engineering, dimensionality reduction for high-dimensional data, semantic and syntactic analysis, dealing with imbalanced datasets, cluster and classification analysis, understanding data with visualization, artificial intelligence platforms, and benefits of utilizing artificial intelligence in the software testing process.|software testing, artificial intelligence, machine learning, deep learning, natural language processing, intelligent decision-making, optimization||||||
SCIENCE DIRECT|Tahvili S,Hatvani L|||Chapter Five - Application of vectorized test artifacts|2022|||||||107-160||10.1016/B978-0-32-391913-5.00016-6|http://dx.doi.org/10.1016/B978-0-32-391913-5.00016-6;https://www.sciencedirect.com/science/article/pii/B9780323919135000166|This chapter provides comprehensive guidelines for conducting several industrial case studies at various levels of software testing. Several pipelines are provided for employing artificial intelligence and machine learning techniques. A step-by-step guide is provided for empirical evaluation of the obtained results. Several industrial test optimization applications for the proposed solutions in this book are provided in this chapter. All the mentioned concepts in this book are exemplified by several industrial use cases in this chapter.|industrial case studies, test optimization, applications, machine learning||||||
SCIENCE DIRECT|Ahmed BS,Zamli KZ,Lim CP|||Application of Particle Swarm Optimization to uniform and variable strength covering array construction|2012||12|4||||1330-1347||10.1016/j.asoc.2011.11.029|http://dx.doi.org/10.1016/j.asoc.2011.11.029;https://www.sciencedirect.com/science/article/pii/S1568494611004716|Recently, researchers have started to explore the use of Artificial Intelligence (AI)-based algorithms as t-way (where t indicates the interaction strength) testing strategies. Many AI-based strategies have been developed, such as Ant Colony, Simulated Annealing, Genetic Algorithm, and Tabu Search. Although useful, most existing AI-based t-way testing strategies adopt complex search processes and require heavy computations. For this reason, existing AI-based t-way testing strategies have been confined to small interaction strengths (i.e., t≤3) and small test configurations. Recent studies demonstrate the need to go up to t=6 in order to capture most faults. In this paper, we demonstrate the effectiveness of our proposed Particle Swarm-based t-way Test Generator (PSTG) for generating uniform and variable strength covering arrays. Unlike other existing AI-based t-way testing strategies, the lightweight computation of the particle swarm search process enables PSTG to support high interaction strengths of up to t=6. The performance of our proposed PSTG is evaluated using several sets of benchmark experiments. Comparatively, PSTG consistently outperforms its AI counterparts and other existing testing strategies as far as the size of the array is concerned. Furthermore, our case study demonstrates the usefulness of PSTG for facilitating fault detection owing to interactions of the input components.|Software testing, -way testing, Variable strength interaction, Artificial Intelligence, Particle Swarm Optimization||||||
SCIENCE DIRECT|Dick S,Meeks A,Last M,Bunke H,Kandel A|||Data mining in software metrics databases|2004||145|1||||81-110||10.1016/j.fss.2003.10.006|http://dx.doi.org/10.1016/j.fss.2003.10.006;https://www.sciencedirect.com/science/article/pii/S016501140300438X|We investigate the use of data mining for the analysis of software metric databases, and some of the issues in this application domain. Software metrics are collected at various phases of the software development process, in order to monitor and control the quality of a software product. However, software quality control is complicated by the complex relationship between these metrics and the attributes of a software development process. Data mining has been proposed as a potential technology for supporting and enhancing our understanding of software metrics and their relationship to software quality. In this paper, we use fuzzy clustering to investigate three datasets of software metrics, along with the larger issue of whether supervised or unsupervised learning is more appropriate for software engineering problems. While our findings generally confirm the known linear relationship between metrics and change rates, some interesting behaviors are noted. In addition, our results partly contradict earlier studies that only used correlation analysis to investigate these datasets. These results illustrate how intelligent technologies can augment traditional statistical inference in software quality control.|Software reliability, Software testing, Artificial intelligence, Machine learning, Data mining, Fuzzy clustering||||||
SCIENCE DIRECT|Hänsch S,Evdokimov I,Schlegel F,Lucas D|||A workflow for the sustainable development of closure models for bubbly flows|2021||244|||||116807||10.1016/j.ces.2021.116807|http://dx.doi.org/10.1016/j.ces.2021.116807;https://www.sciencedirect.com/science/article/pii/S0009250921003729|Many years of research in developing closure models for polydisperse bubbly flows have produced a plethora of empirical and semi-empirical models. The continuous development and analysis of such models requires their constant validation with the steadily increasing number of validation cases in the literature. In this paper we present a pipeline for the fully-automated analysis of OpenFOAM simulations using the Snakemake workflow management system. The pipeline is applied to an extensive collection of well-established validation cases for bubbly flows and allows the fast and efficient production of large amounts of results that are summarized in well-structured reports. An optional post-processing step introduces a fuzzy logic controller developed for the detailed analysis of these results by quantifying the agreement of the simulation with the available experimental data. It is demonstrated how such quantification enables the systematic evaluation of new closure models and contributes to a more sustainable model development.|Baseline, Bubbly flow, OpenFOAM, Workflow, Artificial intelligence||||||
SCIENCE DIRECT|Gianola DS,della Ventura NM,Balbus GH,Ziemke P,Echlin MP,Begley MR|||Advances and opportunities in high-throughput small-scale mechanical testing|2023||27|4||||101090||10.1016/j.cossms.2023.101090|http://dx.doi.org/10.1016/j.cossms.2023.101090;https://www.sciencedirect.com/science/article/pii/S1359028623000359|The quest for novel materials used in technologies demanding extreme performance has been accelerated by advances in computational materials screening, additive manufacturing routes, and characterization probes. Despite tremendous progress, the pace of adoption of new materials has still not met the promise of global initiatives in materials discovery. This challenge is particularly acute for structural materials with thermomechanical and environmental demands whose performance depends on microstructure as well as material composition. In this prospective article, we review advances in high-throughput mechanical testing, and the associated specimen fabrication, materials characterization, and modeling tasks that show promise for acceleration of the materials development cycle. We identify a critical need to develop rapid testing and characterization strategies that faithfully reproduce design-relevant properties and circumvent the time and expense of conventional high fidelity testing. We identify small-scale mechanical testing workflows that can incorporate real-time decision making based on feedback from multimodal characterization and computational modeling. These workflows will require site-specific specimen fabrication procedures that are agnostic to the synthesis route and have the ability to modulate microstructure and defect characteristics. We close our review by conceptualizing a fully integrated high-throughput testing platform that addresses the speed-fidelity tradeoff in pursuit of a design-relevant suite of properties for new materials.|Mechanical testing, High-throughput, Small-scale testing, Automation, Fidelity, Down-selection, Machine learning, In situ, Laser ablation||||||
SCIENCE DIRECT|de Oliveira JP,J.A. Bastos-Filho C,Oliveira SC|||Non-invasive embedded system hardware/firmware anomaly detection based on the electric current signature|2022||51|||||101519||10.1016/j.aei.2021.101519|http://dx.doi.org/10.1016/j.aei.2021.101519;https://www.sciencedirect.com/science/article/pii/S1474034621002676|Quality control is a critical aspect of the modern electronic circuit industry. In addition to being a pre-requisite to proper functioning, circuit quality is closely related to safety, security, and economic issues. Quality control has been reached through system testing. Meanwhile, device miniaturization and multilayer Printed Circuit Boards have increased the electronic circuit test complexity considerably. Hence, traditional test processes based on manual inspections have become outdated and inefficient. More recently, the concept of Advanced Manufacturing or Industry 4.0 has enabled the manufacturing of customized products, tailored to the changing customers’ demands. This scenario points out additional requirements for electronic system testing: it demands a high degree of flexibility in production processes, short design and manufacturing cycles, and cost control. Thus, there is a demand for circuit testing systems that present effectiveness and accessibility without placing numerous test points. This work is focused on automated test solutions based on machine learning, which are becoming popular with advances in computational tools. We present a new testing approach that uses autoencoders to detect firmware or hardware anomalies based on the electric current signature. We built a test set-up using an embedded system development board to evaluate the proposed approach. We implemented six firmware versions that can run independently on the test board – one of them is considered anomaly-free. In order to obtain a reference frame to our results, two other classification techniques (a computer vision algorithm and a random forest classification model) were employed to detect anomalies on the same development board. The outcomes of the experiments demonstrated that the proposed test method is highly effective. For several test scenarios, the correct detection rate was above 99%. Test results showed that autoencoder and random forest approaches are effective. However, random forests require all data classes to be trained. Training an autoencoder, on the other hand, only requires the reference (anomaly-free) class.|Anomaly detection, Embedded systems test, Autoencoders, Deep learning, Random forest||||||
SCIENCE DIRECT|Wang J,Zhang C|||Software reliability prediction using a deep learning model based on the RNN encoder–decoder|2018||170|||||73-82||10.1016/j.ress.2017.10.019|http://dx.doi.org/10.1016/j.ress.2017.10.019;https://www.sciencedirect.com/science/article/pii/S0951832017303538|Different software reliability models, such as parameter and non-parameter models, have been developed in the past four decades to assess software reliability in the software testing process. Although these models can effectively assess software reliability in certain testing scenarios, no single model can accurately predict the fault number in software in all testing conditions. In particular, modern software is developed with more sizes and functions, and assessing software reliability is a remarkably difficult task. The recently developed deep learning model, called deep neural network (NN) model, has suitable prediction performance. This deep learning model not only deepens the layer levels but can also adapt to capture the training characteristics. A comprehensive, in-depth study and feature excavation ultimately shows the model can have suitable prediction performance. This study utilizes a deep learning model based on the recurrent NN (RNN) encoder–decoder to predict the number of faults in software and assess software reliability. Experimental results show that the proposed model has better prediction performance compared with other parameter and NN models.|Deep learning model based on RNN encoder–decoder, Model comparison, Neural network models, Parameter models, Software reliability||||||
SCIENCE DIRECT|Batarseh FA,Yang R|||Chapter 9 - A Deployment Life Cycle Model for Agricultural Data Systems Using Kansei Engineering and Association Rules|2018|||||||141-159||10.1016/B978-0-12-812443-7.00009-0|http://dx.doi.org/10.1016/B978-0-12-812443-7.00009-0;https://www.sciencedirect.com/science/article/pii/B9780128124437000090|The early promise of artificial intelligence that was sought by many is now partially drifting toward data science and big data analytics. Software engineers have been increasingly overwhelmed by the amounts of data available to them during development, but their main quandary is that they are unable to draw solid conclusions from that data without proper analytics. As a result of the recent evolution of software engineering, analytics have been directly applied to solve different challenges of the software development life cycle. Rarely however, have analytics been applied directly for deployment or user acceptance. This chapter introduces a life cycle model that uses the power of data analytics (i.e., association rules and Kansei) to guide a federal team through software testing, deployment, and user acceptance. The model is evaluated through an agricultural data system and is deployed to federal employees; experimental results are collected and presented.|Association rules, Data analytics, Federal analyst, Kansei engineering, Software testing, System deployment, User adoption||||||
SCIENCE DIRECT|Vengattaraman T,Abiramy S,Dhavachelvan P,Baskaran R|||An application perspective evaluation of multi-agent system in versatile environments|2011||38|3||||1405-1416||10.1016/j.eswa.2010.07.047|http://dx.doi.org/10.1016/j.eswa.2010.07.047;https://www.sciencedirect.com/science/article/pii/S0957417410006755|Multi-agent systems (MAS) based computing is the most appropriate paradigm for the problem domain, where data, control, expertise or resources are distributed and also it is interesting to the user only if the technologies address the issues of interest to the user. The MAS has the hypothesis that the agent based computing offers better approach to manage the complex systems and process. They are large-scale systems and collaborate with one another to achieve their functions in a highly modular and flexible way. In this point of view, the work presented in this paper is an enhanced attempt to validate the MAS based on application perspective. As a test-bed, a distributed MAS for software testing is constructed such that to provide a hybrid testing environment based on variety of agents, which possibly incorporate several testing techniques. The developed framework is validated on two perspectives namely, efficiency of the application domain, i.e. software testing using MAS and efficiency of the proposed framework. The validation of the later case has been carried out on two conditions: regular working environment and exceptional working environment. The second type of validation provided the guidelines for implementing proper exception handling mechanism in the enhanced MAS, which is being developed for software testing Purpose.|Testing and debugging, Distributed artificial intelligence, Multi-agent systems, Exception handling, Metrics-performance measures, Model validation and analysis||||||
SCIENCE DIRECT|Cai G,Su Q,Hu Z|||Binary searching iterative algorithm for generating test cases to cover paths|2021||113|||||107910||10.1016/j.asoc.2021.107910|http://dx.doi.org/10.1016/j.asoc.2021.107910;https://www.sciencedirect.com/science/article/pii/S1568494621008322|Similar paths are usually covered by similar test cases, which is one of the characteristics of automated test case generation for path coverage. Based on this characteristic, this paper proposes a novel search-based algorithm for generating test cases to satisfy path coverage criterion, called binary searching iterative algorithm. The proposed algorithm first selects an uncovered path as a target path, which is most similar to the path covered by a discovered test case. Then it performs a binary search in both the left and right regions of each element of the discovered test case under the guidance of a fitness function for the target path. Binary searching iterative algorithm can quickly find undiscovered test case covering the target path because of making full use of the characteristic of automated test case generation for path coverage. Experimental studies on six fog computing benchmark programs and six natural language processing benchmark programs show that the proposed algorithm can achieve the highest path coverage for all the twelve benchmark programs, and the average number of test cases obtained by the proposed algorithm is significantly less than those obtained by a number of state-of-the-art algorithms for eleven out of the twelve benchmark programs. Moreover, binary searching iterative algorithm is more appropriate for ALBD-based fitness function than BD-based fitness function.|Automated test case generation, Binary searching iterative algorithm, Dimensional relevance of test cases, Path coverage||||||
SCIENCE DIRECT|Gonzalez-Hernandez L|||New bounds for mixed covering arrays in t-way testing with uniform strength|2015||59|||||17-32||10.1016/j.infsof.2014.10.009|http://dx.doi.org/10.1016/j.infsof.2014.10.009;https://www.sciencedirect.com/science/article/pii/S0950584914002377|Context Combinatorial testing (CT) can increase the effectiveness of software testing by ensuring that all t-way input combinations are covered in a test suite. When software components have different input cardinalities, CT uses a mixed covering array (MCA) to represent the test suite. This study proposes a new methodology for constructing MCAs of t∈2-6 by using Mixed-Tabu Search (MiTS) as the construction strategy. Objective The objective of this study is to significantly improve the best bounds of MCAs of t∈2-6 with uniform strength. Method The proposed solution incorporates a new procedure for efficient parameter tuning where statistical testing is used to identify the setting values that significantly affect the performance of MiTS. For validation purposes, we used a robust benchmark that comprised a set of 35 instances of real cases and a set of 95 academic instances, which represented the best bounds reported previously. Result The experimental results showed that our MiTS-based methodology improved 93 bounds and matched 36 of them. The Wilcoxon signed-rank test demonstrated that our MiTS-based methodology significantly enhanced the best bounds of MCAs compared with those reported previously with 95% confidence. Conclusion MCAs for t-way testing with a good solution quality (in terms of test size), which involves artificial intelligence-based strategies, may be obtained by following a well-established methodology during the construction process.|Combinatorial testing, Metaheuristic, Mixed covering array, Parameter tuning, Software testing||||||
SCIENCE DIRECT|Lee W,Cho S,Chu P,Vu H,Helal S,Song W,Jeong YS,Cho K|||Automatic agent generation for IoT-based smart house simulator|2016||209|||||14-24||10.1016/j.neucom.2015.04.130|http://dx.doi.org/10.1016/j.neucom.2015.04.130;https://www.sciencedirect.com/science/article/pii/S092523121630580X|In order to evaluate the quality of Internet of Things (IoT) environments in smart houses, large datasets containing interactions between people and ubiquitous environments are essential for hardware and software testing. Both testing and simulation require a substantial amount of time and volunteer resources. Consequently, the ability to simulate these ubiquitous environments has recently increased in importance. In order to create an easy-to-use simulator for designing ubiquitous environments, we propose a simulator and autonomous agent generator that simulates human activity in smart houses. The simulator provides a three-dimensional (3D) graphical user interface (GUI) that enables spatial configuration, along with virtual sensors that simulate actual sensors. In addition, the simulator provides an artificial intelligence agent that automatically interacts with virtual smart houses using a motivation-driven behavior planning method. The virtual sensors are designed to detect the states of the smart house and its living agents. The sensed datasets simulate long-term interaction results for ubiquitous computing researchers, reducing the testing costs associated with smart house architecture evaluation.|Virtual environment, Autonomous agent, Ubiquitous computing, GUI tool, Behavior planning||||||
SCIENCE DIRECT|Avritzer A,Britto R,Trubiani C,Camilli M,Janes A,Russo B,van Hoorn A,Heinrich R,Rapp M,Henß J,Chalawadi RK|||Scalability testing automation using multivariate characterization and detection of software performance antipatterns|2022||193|||||111446||10.1016/j.jss.2022.111446|http://dx.doi.org/10.1016/j.jss.2022.111446;https://www.sciencedirect.com/science/article/pii/S016412122200142X|Context: Software Performance Antipatterns (SPAs) research has focused on algorithms for their characterization, detection, and solution. Existing algorithms are based on the analysis of runtime behavior to detect trends on several monitored variables, such as system response time and CPU utilization. However, the lack of computationally efficient methods currently limits their integration into modern agile practices to detect SPAs in large scale systems. Objective: In this paper, we extended our previously proposed approach for the automated SPA characterization and detection designed to support continuous integration/delivery/deployment (CI/CDD) pipelines, with the goal of addressing the lack of computationally efficient algorithms. Method: We introduce a machine learning-based approach to improve the detection of SPA and interpretation of approach’s results. The approach is complemented with a simulation-based methodology to analyze different architectural alternatives and measure the precision and recall of our approach. Our approach includes SPA statistical characterization using a multivariate analysis of load testing experimental results to identify the services that have the largest impact on system scalability. Results: To show the effectiveness of our approach, we have applied it to a large complex telecom system at Ericsson. We have built a simulation model of the Ericsson system and we have evaluated the introduced methodology by using simulation-based SPA injection. For this system, we are able to automatically identify the top five services that represent scalability choke points. We applied two machine learning algorithms for the automated detection of SPA. Conclusion: We contributed to the state-of-the-art by introducing a novel approach to support computationally efficient SPA characterization and detection that has been applied to a large complex system using performance testing data. We have compared the computational efficiency of the proposed approach with state-of-the-art heuristics. We have found that the approach introduced in this paper grows linearly, which is a significant improvement over existing techniques.|Software Performance Antipatterns, Characterization, Detection, Multivariate analysis||||||
SCIENCE DIRECT|Ahmed BS,Zamli KZ|||A variable strength interaction test suites generation strategy using Particle Swarm Optimization|2011||84|12||||2171-2185||10.1016/j.jss.2011.06.004|http://dx.doi.org/10.1016/j.jss.2011.06.004;https://www.sciencedirect.com/science/article/pii/S0164121211001464|This paper highlights a novel strategy for generating variable-strength (VS) interaction test suites, called VS Particle Swarm Test Generator (VS-PSTG). As the name suggests, VS-PSTG adopts Particle Swarm Optimization to ensure optimal test size reduction. To determine its efficiency in terms of the size of the generated test suite, VS-PSTG was subjected to well-known benchmark configurations. Comparative results indicate that VS-PSTG gives competitive results as compared to existing strategies. An empirical case study was conducted on a non-trivial software system to show the applicability of the strategy and to determine the effectiveness of the generated test suites to detect faults.|Software testing, Variable-strength interaction, Artificial intelligence, Particle Swarm Optimization, Search-based Software Testing||||||
SCIENCE DIRECT|Balera JM,de Santiago Júnior VA|||A systematic mapping addressing Hyper-Heuristics within Search-based Software Testing|2019||114|||||176-189||10.1016/j.infsof.2019.06.012|http://dx.doi.org/10.1016/j.infsof.2019.06.012;https://www.sciencedirect.com/science/article/pii/S0950584919301430|Context Search-based Software Testing (SBST) is a research field where testing a software product is formulated as an optimization problem. It is an active sub-area of Search-based Software Engineering (SBSE) where many studies have been published and some reviews have been carried out. The majority of studies in SBST has been adopted meta-heuristics while hyper-heuristics have a long way to go. Moreover, there is still a lack of studies to perceive the state-of-the-art of the use of hyper-heuristics within SBST. Objective The objective of this work is to investigate the adoption of hyper-heuristics for Software Testing highlighting the current efforts and identifying new research directions. Method A Systematic mapping study was carried out with 5 research questions considering papers published up to may/2019, and 4 different bases. The research questions aims to find out, among other things, what are the hyper-heuristics used in the context of Software Testing, for what problems hyper-heuristics have been applied, and what are the objective functions in the scope of Software Testing. Results A total of 734 studies were found via the search strings and 164 articles were related to Software Testing. However, from these, only 26 papers were actually in accordance with the scope of this research and 3 more papers were considered due to snowballing or expert’s suggestion, totalizing 29 selected papers. Few different problems and application domains where hyper-heuristics have been considered were identified. Conclusion Differently from other communities (Operational Research, Artificial Intelligence), SBST has little explored the benefits of hyper-heuristics which include generalization and less difficulty in parameterization. Hence, it is important to further investigate this area in order to alleviate the effort of practitioners to use such an approach in their testing activities.|Search-based Software Testing, Hyper-heuristics, Systematic Mapping, Evolutionary Algorithms, Genetic Algorithms, Meta-heuristics||||||
SCIENCE DIRECT|Gondra I|||Applying machine learning to software fault-proneness prediction|2008||81|2||||186-195||10.1016/j.jss.2007.05.035|http://dx.doi.org/10.1016/j.jss.2007.05.035;https://www.sciencedirect.com/science/article/pii/S0164121207001240|The importance of software testing to quality assurance cannot be overemphasized. The estimation of a module’s fault-proneness is important for minimizing cost and improving the effectiveness of the software testing process. Unfortunately, no general technique for estimating software fault-proneness is available. The observed correlation between some software metrics and fault-proneness has resulted in a variety of predictive models based on multiple metrics. Much work has concentrated on how to select the software metrics that are most likely to indicate fault-proneness. In this paper, we propose the use of machine learning for this purpose. Specifically, given historical data on software metric values and number of reported errors, an Artificial Neural Network (ANN) is trained. Then, in order to determine the importance of each software metric in predicting fault-proneness, a sensitivity analysis is performed on the trained ANN. The software metrics that are deemed to be the most critical are then used as the basis of an ANN-based predictive model of a continuous measure of fault-proneness. We also view fault-proneness prediction as a binary classification task (i.e., a module can either contain errors or be error-free) and use Support Vector Machines (SVM) as a state-of-the-art classification method. We perform a comparative experimental study of the effectiveness of ANNs and SVMs on a data set obtained from NASA’s Metrics Data Program data repository.|Software testing, Software metrics, Fault-proneness, Machine learning, Neural network, Sensitivity analysis, Support vector machine||||||
SCIENCE DIRECT|Jaensch F,Kübler K,Schwarz E,Verl A|||Test-Driven Reward Function for Reinforcement Learning: A Contribution towards Applicable Machine Learning Algorithms for Production Systems|2022||112|||||103-108||10.1016/j.procir.2022.09.043|http://dx.doi.org/10.1016/j.procir.2022.09.043;https://www.sciencedirect.com/science/article/pii/S2212827122011970|Reinforcement Learning algorithms find more and more application in fields where complex tasks need to be solved. The automation of production systems is one of those fields. Normally, programming a control system defines the automation strategy. Previous contributions by the authors have shown that a so-called agent can learn automation strategies for production systems using a Reinforcement Learning setup. However, the development of the reward function for the agent can be challenging and needs Reinforcement Learning domain knowledge. This paper introduces a novel approach in combining Test-Driven Development with Reinforcement Learning in order to solve the problem of a suitable reward function. In the presented approach predefined test cases are used to derive rewards for the agent. The use of an automated test framework allows for continuous learning sequences until all test cases are passed. An application example of a robot cell is used to demonstrate the novel approach and verify its suitability and usability. The first application shows promising results for further examination towards more application scenarios.|Virtual Commissioning Simulation, Test-Driven Development, Reinforcement Learning||||||
SCIENCE DIRECT|Gove R,Faytong J|||Chapter 4 - Machine Learning and Event-Based Software Testing: Classifiers for Identifying Infeasible GUI Event Sequences|2012||86|||||109-135||10.1016/B978-0-12-396535-6.00004-1|http://dx.doi.org/10.1016/B978-0-12-396535-6.00004-1;https://www.sciencedirect.com/science/article/pii/B9780123965356000041|Machine learning is a technique not widely used in software testing even though the broader field of software engineering has used machine learning to solve many problems. In this chapter we present an overview of machine learning approaches for many problems in software testing, including test suite reduction, regression testing, and faulty statement identification. We also present our work using machine learning to augment automatic model-based test case generation for graphical user interfaces (GUIs). A model of the GUI is used to generate test cases, which are event sequences, to be executed on the system under test. Such models may not completely represent the GUI, and therefore may allow infeasible test cases to be generated that violate constraints in the GUI. We use two different machine learning techniques (support vector machines and grammar induction) to identify infeasible test cases (i.e., test requirements that cannot be satisfied). We demonstrate that these techniques are robust across different-length test cases and different GUI constraints.|Event-based testing, GUI testing, Grammar induction, Machine learning, Model-based testing, Software testing, Support vector machines||||||
SCIENCE DIRECT|Rafael Lenz A,Pozo A,Regina Vergilio S|||Linking software testing results with a machine learning approach|2013||26|5||||1631-1640||10.1016/j.engappai.2013.01.008|http://dx.doi.org/10.1016/j.engappai.2013.01.008;https://www.sciencedirect.com/science/article/pii/S0952197613000183|Software testing techniques and criteria are considered complementary since they can reveal different kinds of faults and test distinct aspects of the program. The functional criteria, such as Category Partition, are difficult to be automated and are usually manually applied. Structural and fault-based criteria generally provide measures to evaluate test sets. The existing supporting tools produce a lot of information including: input and produced output, structural coverage, mutation score, faults revealed, etc. However, such information is not linked to functional aspects of the software. In this work, we present an approach based on machine learning techniques to link test results from the application of different testing techniques. The approach groups test data into similar functional clusters. After this, according to the tester's goals, it generates classifiers (rules) that have different uses, including selection and prioritization of test cases. The paper also presents results from experimental evaluations and illustrates such uses.|Machine learning, Software testing, Test coverage criteria||||||
SCIENCE DIRECT|Podryabinkin EV,Shapeev AV|||Active learning of linearly parametrized interatomic potentials|2017||140|||||171-180||10.1016/j.commatsci.2017.08.031|http://dx.doi.org/10.1016/j.commatsci.2017.08.031;https://www.sciencedirect.com/science/article/pii/S0927025617304536|This paper introduces an active learning approach to the fitting of machine learning interatomic potentials. Our approach is based on the D-optimality criterion for selecting atomic configurations on which the potential is fitted. It is shown that the proposed active learning approach is highly efficient in training potentials on the fly, ensuring that no extrapolation is attempted and leading to a completely reliable atomistic simulation without any significant decrease in accuracy. We apply our approach to molecular dynamics and structure relaxation, and we argue that it can be applied, in principle, to any other type of atomistic simulation. The software, test cases, and examples of usage are published at http://gitlab.skoltech.ru/shapeev/mlip/.|Interatomic potential, Active learning, Learning on the fly, Machine learning, Atomistic simulation, Moment tensor potentials||||||
SCIENCE DIRECT|Cross JH,Chang KH,Homer Carlisle W,Brown DB|||Expert system assisted test data generation for software branch coverage|1991||6|4||||279-295||10.1016/0169-023X(91)90035-V|http://dx.doi.org/10.1016/0169-023X(91)90035-V;https://www.sciencedirect.com/science/article/pii/0169023X9190035V|With the increased production of complex software systems, verification and validation (V & V) has evolved into a set of activities that span the entire software life cycle. Among these various activities, software testing plays a major role in V&V. Conventional software testing methods generally require considerable manual effort which can generate only a limited number of test cases before the amount of time expended becomes unacceptably large. In this paper, we present a new approach to generating test cases based on artificial intelligence methods. By analyzing the branch coverage of previous test cases, an expert system is able to generate new test cases which provide additional coverage. Heuristic rules are used to modify previous test cases in order to achieve the desired branch coverage. This approach to software testing has the potential for greatly reducing the overall costs associated with branch coverage testing.|Artificial intelligence, expert systems, knowledge-based systems, software engineering, software testing, test data generation||||||
SCIENCE DIRECT|Zakeri-Nasrabadi M,Parsa S,Jafari S|||Measuring and improving software testability at the design level|2024||174|||||107511||10.1016/j.infsof.2024.107511|http://dx.doi.org/10.1016/j.infsof.2024.107511;https://www.sciencedirect.com/science/article/pii/S0950584924001162|Context The quality of software systems is significantly influenced by design testability, an aspect often overlooked during the initial phases of software development. The implementation may deviate from its design, resulting in decreased testability at the integration and unit levels. Objective The objective of this study is to automatically identify low-testable parts in object-orientated design and enhance them by refactoring to design patterns. The impact of various design metrics mainly coupling (e.g., fan-in and fan-out) and inheritance (e.g., depth of inheritance tree and number of subclasses) metrics on design testability is measured to select the most appropriate refactoring candidates. Method The methodology involves creating a machine learning model for design testability prediction using a large dataset of Java classes, followed by developing an automated refactoring tool. The design classes are vectorized by ten design metrics and labeled with testability scores calculated from a mathematical model. The model computes testability based on code coverage and test suite size of classes that have already been tested via automatic tools. A voting regressor model is trained to predict the design testability of any class diagram based on these design metrics. The proposed refactoring tool for dependency injection and factory method is applied to various open-source Java projects, and its impact on design testability is assessed. Results The proposed design testability model demonstrates its effectiveness by satisfactorily predicting design testability, as indicated by a mean squared error of 0.04 and an R2 score of 0.53. The automated refactoring tool has been successfully evaluated on six open-source Java projects, revealing an enhancement in design testability by up to 19.11 %. Conclusion The proposed automated approach offers software developers the means to continuously evaluate and enhance design testability throughout the entire software development life cycle, mitigating the risk of testability issues stemming from design-to-implementation discrepancies.|Software testability, Design for testability, Object-oriented design, Class diagram, Automated refactoring, Design patterns||||||
SCIENCE DIRECT|Carvalho G,Falcão D,Barros F,Sampaio A,Mota A,Motta L,Blackburn M|||NAT2TESTSCR: Test case generation from natural language requirements based on SCR specifications|2014||95|||||275-297||10.1016/j.scico.2014.06.007|http://dx.doi.org/10.1016/j.scico.2014.06.007;https://www.sciencedirect.com/science/article/pii/S0167642314002858|Formal models are increasingly being used as input for automated test generation strategies. Software Cost Reduction (SCR), for example, was designed to detect and correct errors during the requirements phase, also allowing test generation. However, the syntax of SCR and other formalisms are not trivial for non-experts. In this work, we present a strategy for test case generation from natural language requirements that uses SCR as an intermediate and hidden formalism. To minimize textual ambiguity, requirements are written according to a controlled natural language. Syntactically valid requirements are mapped into their semantic representation using case frames, from which SCR specifications are derived. These specifications are then used by the T-VEC tool to generate tests cases. Our strategy was evaluated in four different domains: (i) a vending machine (toy example); (ii) a control system for safety injection in a nuclear power plant (publicly available), (iii) one example provided by our industrial partner Embraer; and (iv) the turn indicator system of Mercedes vehicles (publicly available). As a baseline we considered random testing, and, in general, our strategy outperformed it in terms of performance and mutant-based strength analysis.|Requirements, Test generation, Natural language processing, Software cost reduction, SCR||||||
SCIENCE DIRECT|Sagarna R,Mendiburu A,Inza I,Lozano JA|||Assisting in search heuristics selection through multidimensional supervised classification: A case study on software testing|2014||258|||||122-139||10.1016/j.ins.2013.09.050|http://dx.doi.org/10.1016/j.ins.2013.09.050;https://www.sciencedirect.com/science/article/pii/S0020025513007196|A fundamental question in the field of approximation algorithms, for a given problem instance, is the selection of the best (or a suitable) algorithm with regard to some performance criteria. A practical strategy for facing this problem is the application of machine learning techniques. However, limited support has been given in the literature to the case of more than one performance criteria, which is the natural scenario for approximation algorithms. We propose multidimensional Bayesian network (mBN) classifiers as a relatively simple, yet well-principled, approach for helping to solve this problem. Precisely, we relax the algorithm selection decision problem into the elucidation of the nondominated subset of algorithms, which contains the best. This formulation can be used in different ways to elucidate the main problem, each of which can be tackled with an mBN classifier. Namely, we deal with two of them: the prediction of the whole nondominated set and whether an algorithm is nondominated or not. We illustrate the feasibility of the approach for real-life scenarios with a case study in the context of Search Based Software Test Data Generation (SBSTDG). A set of five SBSTDG generators is considered and the aim is to assist a hypothetical test engineer in elucidating good generators to fulfil the branch testing of a given programme.|Algorithm selection, Multidimensional classification, Dominance relation, Search based software testing||||||
SCIENCE DIRECT|Singh A,Bhatia R,Singhrova A|||Taxonomy of machine learning algorithms in software fault prediction using object oriented metrics|2018||132|||||993-1001||10.1016/j.procs.2018.05.115|http://dx.doi.org/10.1016/j.procs.2018.05.115;https://www.sciencedirect.com/science/article/pii/S1877050918308470|Prediction of Fault proneness of a software component is the compelling field of investigations in software testing arena. Software coupling plays a vital role in assessing the software quality through fault prediction and complexity measures. Various fault prediction models, have used the object oriented metrics for the predicting and localizing the faults. Many of these metrics have direct influence on the quality of software. More over prior knowledge of the fault proneness of a component may significantly reduce the testing effort and time. The measures of object oriented features like inheritance, polymorphism and encapsulation etc may be used to estimate fault proneness. Many researchers have investigated the usage of object oriented metrics in the software fault prediction. In this study we present taxonomy of usage these metrics in the fault prediction. We also present the analysis of machine learning techniques in fault prediction.|Software fault prediction, Object Oriented Testing, Object Oriented Coupling, software faults prediction, machine learning||||||
SCIENCE DIRECT|Arora I,Tetarwal V,Saha A|||Open Issues in Software Defect Prediction|2015||46|||||906-912||10.1016/j.procs.2015.02.161|http://dx.doi.org/10.1016/j.procs.2015.02.161;https://www.sciencedirect.com/science/article/pii/S1877050915002252|Software Defect Prediction (SDP) is one of the most assisting activities of the Testing Phase of SDLC. It identifies the modules that are defect prone and require extensive testing. This way, the testing resources can be used efficiently without violating the constraints. Though SDP is very helpful in testing, it's not always easy to predict the defective modules. There are various issues that hinder the smooth performance as well as use of the Defect Prediction models. In this report, we have distinguished some of the major issues of SDP and studied what has been done so far to address them.|data mining, defect prediction, machine learning, software quality, software testing||||||
SCIENCE DIRECT|Oepen S,Flickinger DP|||Towards systematic grammar profiling.Test suite technology 10 years after|1998||12|4||||411-435||10.1006/csla.1998.0105|http://dx.doi.org/10.1006/csla.1998.0105;https://www.sciencedirect.com/science/article/pii/S088523089890105X|An experiment with recent test suite and grammar (engineering) resources is outlined: a criticial assessment of the EU-fundedtsnlp(Test Suites for Natural Language Processing) package as a diagnostic and benchmarking facility for a distributed (multi-site) large-scalehpsggrammar engineering effort. This paper argues for a generalized, systematic, and fully automated testing and diagnosis facility as an integral part of the linguistic engineering cycle and gives a practical assessment of existing resources; both a flexible methodology and tools for competence and performance profiling are presented. By comparison to earlier evaluation work as reflected in the Hewlett-Packard test suite data, released exactly 10 years beforetsnlp, it is judged where test-suite-based evaluation has improved (and where not) over time.|||||||
SCIENCE DIRECT|Gharleghi R,Adikari D,Ellenberger K,Ooi SY,Ellis C,Chen CM,Gao R,He Y,Hussain R,Lee CY,Li J,Ma J,Nie Z,Oliveira B,Qi Y,Skandarani Y,Vilaça JL,Wang X,Yang S,Sowmya A,Beier S|||Automated segmentation of normal and diseased coronary arteries – The ASOCA challenge|2022||97|||||102049||10.1016/j.compmedimag.2022.102049|http://dx.doi.org/10.1016/j.compmedimag.2022.102049;https://www.sciencedirect.com/science/article/pii/S0895611122000222|Cardiovascular disease is a major cause of death worldwide. Computed Tomography Coronary Angiography (CTCA) is a non-invasive method used to evaluate coronary artery disease, as well as evaluating and reconstructing heart and coronary vessel structures. Reconstructed models have a wide array of for educational, training and research applications such as the study of diseased and non-diseased coronary anatomy, machine learning based disease risk prediction and in-silico and in-vitro testing of medical devices. However, coronary arteries are difficult to image due to their small size, location, and movement, causing poor resolution and artefacts. Segmentation of coronary arteries has traditionally focused on semi-automatic methods where a human expert guides the algorithm and corrects errors, which severely limits large-scale applications and integration within clinical systems. International challenges aiming to overcome this barrier have focussed on specific tasks such as centreline extraction, stenosis quantification, and segmentation of specific artery segments only. Here we present the results of the first challenge to develop fully automatic segmentation methods of full coronary artery trees and establish the first large standardized dataset of normal and diseased arteries. This forms a new automated segmentation benchmark allowing the automated processing of CTCAs directly relevant for large-scale and personalized clinical applications.|Coronary arteries, Image segmentation, Machine learning||||||
SCIENCE DIRECT|König A,Linz N,Baykara E,Tröger J,Ritchie C,Saunders S,Teipel S,Köhler S,Sánchez-Benavides G,Grau-Rivera O,Gispert JD,Palmqvist S,Tideman P,Hansson O|||The Journal of Prevention of Alzheimer's Disease|2023||10|2||||314-321||10.14283/jpad.2023.11|http://dx.doi.org/10.14283/jpad.2023.11;https://www.sciencedirect.com/science/article/pii/S2274580724002395|Background Speech impairments are an early feature of Alzheimer's disease (AD) and consequently, analysing speech performance is a promising new digital biomarker for AD screening. Future clinical AD trials on disease modifying drugs will require a shift to very early identification of individuals at risk of dementia. Hence, digital markers of language and speech may offer a method for screening of at-risk populations that are at the earliest stages of AD, eventually in combination with advanced machine learning. To this end, we developed a screening battery consisting of speech-based neurocognitive tests. The automated test performs a remote primary screening using a simple telephone. Objectives PROSPECT-AD aims to validate speech biomarkers for identification of individuals with early signs of AD and monitor their longitudinal course through access to well-phenotyped cohorts. Design PROSPECT-AD leverages ongoing cohorts such as EPAD (UK), DESCRIBE and DELCODE (Germany), and BioFINDER Primary Care (Sweden) and Beta-AARC (Spain) by adding a collection of speech data over the telephone to existing longitudinal follow-ups. Participants at risk of dementia are recruited from existing parent cohorts across Europe to form an AD ‘probability-spectrum', i.e., individuals with a low risk to high risk of developing AD dementia. The characterization of cognition, biomarker and risk factor (genetic and environmental) status of each research participants over time combined with audio recordings of speech samples will provide a well-phenotyped population for comparing novel speech markers with current gold standard biomarkers and cognitive scores. Participants N= 1000 participants aged 50 or older will be included in total, with a clinical dementia rating scale (CDR) score of 0 or 0.5. The study protocol is planned to run according to sites between 12 and 18 months. Measurements The speech protocol includes the following neurocognitive tests which will be administered remotely: Word List [Memory Function], Verbal Fluency [Executive Functions] and spontaneous free speech [Psychological and/ or behavioral symptoms]. Speech features on the linguistic and paralinguistic level will be extracted from the recordings and compared to data from CSF and blood biomarkers, neuroimaging, neuropsychological evaluations, genetic profiles, and family history. Primary candidate marker from speech will be a combination of most significant features in comparison to biomarkers as reference measure. Machine learning and computational techniques will be employed to identify the most significant speech biomarkers that could represent an early indicator of AD pathology. Furthermore, based on the analysis of speech performances, models will be trained to predict cognitive decline and disease progression across the AD continuum. Conclusion The outcome of PROSPECT-AD may support AD drug development research as well as primary or tertiary prevention of dementia by providing a validated tool using a remote approach for identifying individuals at risk of dementia and monitoring individuals over time, either in a screening context or in clinical trials.|Dementia, Alzheimer's disease, screening, cognitive assessment, speech biomarker, phone-based, machine learning||||||
SCIENCE DIRECT|Shao Y,Liu B,Wang S,Li G|||Expert Systems with Applications|2018||114|||||237-254||10.1016/j.eswa.2018.07.042|http://dx.doi.org/10.1016/j.eswa.2018.07.042;https://www.sciencedirect.com/science/article/pii/S0957417418304664|To ensure the rational allocation of software testing resources and reduce costs, software defect prediction has drawn notable attention to many “white-box” and “black-box” classification algorithms. Although there have been lots of studies on using software product metrics to identify defect-prone modules, defect prediction algorithms are still worth exploring. For instance, it is not easy to directly implement the Apriori algorithm to classify defect-prone modules across a skewed dataset. Therefore, we propose a novel supervised approach for software defect prediction based on atomic class-association rule mining (ACAR). It holds the characteristics of only one feature of the antecedent and a unique class label of the consequent, which is a specific kind of association rules that explores the relationship between attributes and categories. It holds the characteristics of only one feature of the antecedent and a unique class label of the consequent, which is a specific kind of association rules that explores the relationship between attributes and categories. Such association patterns can provide meaningful knowledge that can be easily understood by software engineers. A new software defect prediction model infrastructure based on association rules is employed to improve the prediction of defect-prone modules, which is divided into data preprocessing, rule model building and performance evaluation. Moreover, ACAR can achieve a satisfactory classification performance compared with other seven benchmark learners (the extension of classification based on associations (CBA2), Support Vector Machine, Naive Bayesian, Decision Tree, OneR, K-nearest Neighbors and RIPPER) on NASA MDP and PROMISE datasets. In light of software defect associative prediction, a comparative experiment between ACAR and CBA2 is discussed in details. It is demonstrated that ACAR is better than CBA2 in terms of AUC, G-mean, Balance, and understandability. In addition, the average AUC of ACAR is increased by 2.9% compared with CBA2, which can reach 81.1%.|Software defect prediction, Data mining, Association rules, Apriori, Machine learning||||||
SCIENCE DIRECT|Gongora AE,Snapp KL,Pang R,Tiano TM,Reyes KG,Whiting E,Lawton TJ,Morgan EF,Brown KA|||Matter|2022||5|9||||2829-2846||10.1016/j.matt.2022.06.051|http://dx.doi.org/10.1016/j.matt.2022.06.051;https://www.sciencedirect.com/science/article/pii/S2590238522003460|Summary Like many specialty applications, the pace of designing structures for impact protection is limited by its reliance on specialized testing. Here, we develop a transfer learning approach to determine how more widely available quasi-static testing can be used to predict impact protection. We first extensively test a parametric family of lattices in both impact and quasi-static domains and train a model that predicts impact performance to within 8% using only quasi-static measurements. Next, we test the transferability of this model using a distinct family of lattices and find that performance rank was well predicted even for structures whose behavior extrapolated beyond the training set. Finally, we combine 812 quasi-static and 141 impact tests to train a model that predicts absolute impact performance of novel lattices with 18% error. These results highlight a path for accelerating design for specialty applications and that transferrable mechanical insight can be obtained in a data-driven manner.|impact protection, transfer learning, automated experimentation, structured matter, additive manufacturing, lattice design, machine learning||||||
SCIENCE DIRECT|Esfandyari S,Rafe V|||Information and Software Technology|2018||94|||||165-185||10.1016/j.infsof.2017.10.007|http://dx.doi.org/10.1016/j.infsof.2017.10.007;https://www.sciencedirect.com/science/article/pii/S0950584917300897|Context To improve the quality and correctness of a software product it is necessary to test different aspects of the software system. Among different approaches for software testing, combinatorial testing along with covering array is a proper testing method. The most challenging problem in combinatorial testing strategies like t-way, is the combinatorial explosion which considers all combinations of input parameters. Many evolutionary and meta-heuristic strategies have been proposed to address and mitigate this problem. Objective Genetic Algorithm (GA) is an evolutionary search-based technique that has been used in t-way interaction testing by different approaches. Although useful, all of these approaches can produce test suite with small interaction strengths (i.e. t ≤ 6). Additionally, most of them suffer from expensive computations. Even though there are other strategies which use different meta-heuristic algorithms to solve these problems, in this paper, we propose an efficient uniform and variable t-way minimal test suite generation approach to address these problems using GA, called Genetic Strategy (GS). Method By changing the bit structure and accessing test cases quickly, GS improves performance of the fitness function. These adjustments and reduction of the complexities of GA in the proposed GS decreases the test suite size and increases the speed of test suite generation up tot=20. Results To evaluate the efficiency and performance of the proposed GS, various experiments are performed on different set of benchmarks. Experimental results show that not only GS supports higher interaction strengths in comparison with the existing GA-based strategies, but also its supported interaction strength is higher than most of other AI-based and computational-based strategies. Conclusion Furthermore, experimental results show that GS can compete against the existing (both AI-based and computational-based) strategies in terms of efficiency and performance in most of the case studies.|Genetic algorithm, -way testing, Combinatorial testing, Covering array generation||||||
SCIENCE DIRECT|Liu H,Zhu J,Zhong J,Qiao S,Zhang L,Li J,Hu B,Ma S,Peng H|||Biomedical Signal Processing and Control|2025||110|||||108070||10.1016/j.bspc.2025.108070|http://dx.doi.org/10.1016/j.bspc.2025.108070;https://www.sciencedirect.com/science/article/pii/S1746809425005816|The comorbidity between Generalized Anxiety Disorder (GAD) and Major Depressive Disorder (MDD) is notably high, underscoring the need for nuanced diagnostic tools to differentiate between the two. Despite the rich clinical landscape, automated tests for discerning MDD from GAD remain underdeveloped, with existing disparities in brain function between the disorders yet to be fully elucidated. Functional Near-Infrared Spectroscopy (fNIRS), a promising neuroimaging modality, holds the potential to bridge this gap by supplementing clinical interviews and mental status examinations. This study engaged 113 participants, including 39 individuals clinically diagnosed with GAD, 35 healthy controls (HCs), and 39 individuals clinically diagnosed with MDD, collecting resting-state fNIRS data over three minutes from each subject. Measurements of brain oxygenated hemoglobin (HbO) and deoxygenated hemoglobin (HbR) were captured using a 22-channel continuous wave fNIRS device to investigate resting state brain dynamics. In a departure from conventional machine learning methodologies, which often suffer from lower accuracy and the need for manual feature selection, this research introduces a pioneering transfer learning strategy. The raw fNIRS time series data were transformed into images via the Gramian Angular Summation Field method, facilitating the subsequent classification task through the application of three distinct neural networks: EfficientNet, MobileNet, and ResNet. Given the significant influence of resting-state data length on functional connectivity outcomes, a methodical approach utilizing a 30-second step size was employed to identify the optimal time scale for functional connectivity analysis. This approach leveraged the average accuracy across the three models as a guiding criterion, ultimately selecting data durations that maximized classification accuracy for functional connectivity exploration. Moreover, this study proposes a novel data processing technique, Temporal Compression by Averaging (TCA), designed to enhance data stability and conserve computational resources. Data processed through TCA demonstrated robust performance in classification tasks, with an optimal duration of 150 s identified for the resting-state data. This duration achieved an average accuracy rate of 90.42% across the networks, peaking at 93.82%. Functional connectivity analyses conducted on this optimized data subset revealed distinct connectivity patterns in patient groups relative to HCs. Notably, GAD patients exhibited increased functional connectivity strength in the MFG.R and ORBsup.R regions compared to MDD patients, highlighting the intricate neural underpinnings of these disorders. These insights affirm the potential of fNIRS as a valuable adjunct in the clinical diagnosis of comorbid MDD and GAD, showcasing the transformative impact of transfer learning methodologies in advancing fNIRS research.|Functional near-infrared spectroscopy (fNIRS), Major depressive disorder (MDD), Generalized anxiety disorder (GAD), Transfer learning, Functional connectivity||||||
SCIENCE DIRECT|Serdar Biçer M,Diri B|||Applied Soft Computing|2016||49|||||1078-1084||10.1016/j.asoc.2016.05.038|http://dx.doi.org/10.1016/j.asoc.2016.05.038;https://www.sciencedirect.com/science/article/pii/S1568494616302484|Testing is a crucial activity in software development. However exhaustive testing of a given software is impossible in practice because projects have serious time and budget limitations. Therefore, software testing teams need guidance about which modules they should focus on. Defect prediction techniques are useful for this situation because they let testers to identify and focus on defect prone parts of software. These techniques are essential for software teams, because they help teams to efficiently allocate their precious resources in testing phase. Software defect prediction has been an active research area in recent years. Researchers in this field have been using different types of metrics in their prediction models. However, value of extracting static code metrics for style sheet languages has been ignored until now. User experience is a very important part of web applications and its mostly provided using Cascading Style Sheets (CSS). In this research, our aim is to improve defect prediction performance for web applications by utilizing metrics generated from CSS code. We generated datasets from four open source web applications to conduct our experiments. Defect prediction is then performed using three different well-known machine learning algorithms. The results revealed that static code metrics based defect prediction techniques can be performed effectively to improve quality of CSS code in web applications. Therefore we recommend utilizing domain-specific characteristics of applications in defect prediction as they result in significantly high prediction performance with low costs.|Defect prediction, Software Metrics, Software quality, Web sites||||||
SCIENCE DIRECT|Amin A,Grunske L,Colman A|||Journal of Systems and Software|2013||86|7||||1923-1932||10.1016/j.jss.2013.03.045|http://dx.doi.org/10.1016/j.jss.2013.03.045;https://www.sciencedirect.com/science/article/pii/S0164121213000617|Reliability is the key factor for software system quality. Several models have been introduced to estimate and predict reliability based on results of software testing activities. Software Reliability Growth Models (SRGMs) are considered the most commonly used to achieve this goal. Over the past decades, many researchers have discussed SRGMs’ assumptions, applicability, and predictability. They have concluded that SRGMs have many shortcomings related to their unrealistic assumptions, environment-dependent applicability, and questionable predictability. Several approaches based on non-parametric statistics, Bayesian networks, and machine learning methods have been proposed in the literature. Based on their theoretical nature, however, they cannot completely address the SRGMs’ limitations. Consequently, addressing these shortcomings is still a very crucial task in order to provide reliable software systems. This paper presents a well-established prediction approach based on time series ARIMA (Autoregressive Integrated Moving Average) modeling as an alternative solution to address the SRGMs’ limitations and provide more accurate reliability prediction. Using real-life data sets on software failures, the accuracy of the proposed approach is evaluated and compared to popular existing approaches.|Reliability prediction, Software Reliability Growth Models, Time series ARIMA models||||||
SCIENCE DIRECT|Boucher A,Badri M|||Information and Software Technology|2018||96|||||38-67||10.1016/j.infsof.2017.11.005|http://dx.doi.org/10.1016/j.infsof.2017.11.005;https://www.sciencedirect.com/science/article/pii/S0950584916303135|Context: Nowadays, fault-proneness prediction is an important field of software engineering. It can be used by developers and testers to prioritize tests. This would allow a better allocation of resources, reducing testing time and costs, and improving the effectiveness of software testing. Non-supervised fault-proneness prediction models, especially thresholds-based models, can easily be automated and give valuable insights to developers and testers on the classification performed. Objective: In this paper, we investigated three thresholds calculation techniques that can be used for fault-proneness prediction: ROC Curves, VARL (Value of an Acceptable Risk Level) and Alves rankings. We compared the performance of these techniques with the performance of four machine learning and two clustering based models. Method: Threshold values were calculated on a total of twelve different public datasets: eleven from the PROMISE Repository and another based on the Eclipse project. Thresholds-based models were then constructed using each thresholds calculation technique investigated. For comparison, results were also computed for supervised machine learning and clustering based models. Inter-dataset experimentation between different systems and versions of a same system was performed. Results: Results show that ROC Curves is the best performing method among the three thresholds calculation methods investigated, closely followed by Alves Rankings. VARL method didn’t give valuable results for most of the datasets investigated and was easily outperformed by the two other methods. Results also show that thresholds-based models using ROC Curves outperformed machine learning and clustering based models. Conclusion: The best of the three thresholds calculation techniques for fault-proneness prediction is ROC Curves, but Alves Rankings is a good choice too. In fact, the advantage of Alves Rankings over ROC Curves technique is that it is completely unsupervised and can therefore give pertinent threshold values when fault data is not available.|Metrics thresholds, Class-level metrics, Object-oriented metrics, Faults, Fault-proneness prediction, Machine learning, Clustering, Cross-validation, Code quality, Object-oriented programming||||||
SCIENCE DIRECT|Zakeri-Nasrabadi M,Parsa S|||Applied Soft Computing|2022||129|||||109562||10.1016/j.asoc.2022.109562|http://dx.doi.org/10.1016/j.asoc.2022.109562;https://www.sciencedirect.com/science/article/pii/S1568494622006263|Unlike most other software quality attributes, testability cannot be evaluated solely based on the characteristics of the source code. The effectiveness of the test suite and the budget assigned to the test highly impact the testability of the code under test. The size of a test suite determines the test effort and cost, while the coverage measure indicates the test effectiveness. Therefore, testability can be measured based on the coverage and number of test cases provided by a test suite, considering the test budget. This paper offers a new equation to estimate testability regarding the size and coverage of a given test suite. The equation has been used to label 23,000 classes belonging to 110 Java projects with their testability measure. The labeled classes were vectorized using 262 metrics. The labeled vectors were fed into a family of supervised machine learning algorithms, regression, to predict testability in terms of the source code metrics. Regression models predicted testability with an R2 of 0.68 and a mean squared error of 0.03, suitable in practice. Fifteen software metrics highly affecting testability prediction were identified using a feature importance analysis technique on the learned model. The proposed models have improved mean absolute error by 38% due to utilizing new criteria, metrics, and data compared with the relevant study on predicting branch coverage as a test criterion. As an application of testability prediction, it is demonstrated that automated refactoring of 42 smelly Java classes targeted at improving the 15 influential software metrics could elevate their testability by an average of 86.87%.|Software testability, Software metrics, Automated refactoring, Static and dynamic analysis, Machine learning||||||
SCIENCE DIRECT|Chen L,Fang B,Shang Z,Tang Y|||Information and Software Technology|2015||62|||||67-77||10.1016/j.infsof.2015.01.014|http://dx.doi.org/10.1016/j.infsof.2015.01.014;https://www.sciencedirect.com/science/article/pii/S0950584915000348|Context Software defect prediction has been widely studied based on various machine-learning algorithms. Previous studies usually focus on within-company defects prediction (WCDP), but lack of training data in the early stages of software testing limits the efficiency of WCDP in practice. Thus, recent research has largely examined the cross-company defects prediction (CCDP) as an alternative solution. Objective However, the gap of different distributions between cross-company (CC) data and within-company (WC) data usually makes it difficult to build a high-quality CCDP model. In this paper, a novel algorithm named Double Transfer Boosting (DTB) is introduced to narrow this gap and improve the performance of CCDP by reducing negative samples in CC data. Method The proposed DTB model integrates two levels of data transfer: first, the data gravitation method reshapes the whole distribution of CC data to fit WC data. Second, the transfer boosting method employs a small ratio of labeled WC data to eliminate negative instances in CC data. Results The empirical evaluation was conducted based on 15 publicly available datasets. CCDP experiment results indicated that the proposed model achieved better overall performance than compared CCDP models. DTB was also compared to WCDP in two different situations. Statistical analysis suggested that DTB performed significantly better than WCDP models trained by limited samples and produced comparable results to WCDP with sufficient training data. Conclusions DTB reforms the distribution of CC data from different levels to improve the performance of CCDP, and experimental results and analysis demonstrate that it could be an effective model for early software defects detection.|Cross-company defects prediction, Software fault prediction, Transfer learning||||||
SCIENCE DIRECT|Ma Y,Luo G,Zeng X,Chen A|||Information and Software Technology|2012||54|3||||248-256||10.1016/j.infsof.2011.09.007|http://dx.doi.org/10.1016/j.infsof.2011.09.007;https://www.sciencedirect.com/science/article/pii/S0950584911001996|Context Software defect prediction studies usually built models using within-company data, but very few focused on the prediction models trained with cross-company data. It is difficult to employ these models which are built on the within-company data in practice, because of the lack of these local data repositories. Recently, transfer learning has attracted more and more attention for building classifier in target domain using the data from related source domain. It is very useful in cases when distributions of training and test instances differ, but is it appropriate for cross-company software defect prediction? Objective In this paper, we consider the cross-company defect prediction scenario where source and target data are drawn from different companies. In order to harness cross company data, we try to exploit the transfer learning method to build faster and highly effective prediction model. Method Unlike the prior works selecting training data which are similar from the test data, we proposed a novel algorithm called Transfer Naive Bayes (TNB), by using the information of all the proper features in training data. Our solution estimates the distribution of the test data, and transfers cross-company data information into the weights of the training data. On these weighted data, the defect prediction model is built. Results This article presents a theoretical analysis for the comparative methods, and shows the experiment results on the data sets from different organizations. It indicates that TNB is more accurate in terms of AUC (The area under the receiver operating characteristic curve), within less runtime than the state of the art methods. Conclusion It is concluded that when there are too few local training data to train good classifiers, the useful knowledge from different-distribution training data on feature level may help. We are optimistic that our transfer learning method can guide optimal resource allocation strategies, which may reduce software testing cost and increase effectiveness of software testing process.|Machine learning, Software defect prediction, Transfer learning, Naive Bayes, Different distribution||||||
SCIENCE DIRECT|Stolberg MA,Lopez J,Cawthern SD,Herzog-Arbeitman A,Kwon HK,Schweigert D,Anapolosky A,Storey BD,Johnson JA,Shao-Horn Y|||Matter|2025||8|6||||102129||10.1016/j.matt.2025.102129|http://dx.doi.org/10.1016/j.matt.2025.102129;https://www.sciencedirect.com/science/article/pii/S2590238525001729|Summary Lithium-ion batteries aid decarbonization by enabling electric vehicles and renewable energy generation, but these applications put increasing demands on the energy density, safety, and cost of batteries. Polymer electrolytes could improve battery safety but currently do not have sufficient ionic conductivity for ambient operation. To address this challenge, we developed a high-throughput platform to increase the speed and scale of polymer electrolyte research, enabling the acquisition of data for over 60 samples per researcher hour. We utilized automated formulation and characterization operations, including electrochemical impedance spectroscopy with in situ thickness measurements, to perform a comparison of lithium and sodium salts in poly(ethylene oxide). Our study provides a high-quality, unified reference dataset for the community and greatly expands available data for sodium-based electrolytes. Secondly, our large dataset allows us to find that the local minima in glass transition temperature that corresponds to maximum ionic conductivity is a colligative property independent of either anion or cation chemistry.|polymer electrolyte, high-throughput, ionic conductivity, data-driven materials||||||
SCIENCE DIRECT|Miholca DL,Czibula G,Czibula IG|||Information Sciences|2018||441|||||152-170||10.1016/j.ins.2018.02.027|http://dx.doi.org/10.1016/j.ins.2018.02.027;https://www.sciencedirect.com/science/article/pii/S0020025518301154|The growing complexity of software projects requires increasing consideration of their analysis and testing. Identifying defective software entities is essential for software quality assurance and it also improves activities related to software testing. In this study, we developed a novel supervised classification method called HyGRAR for software defect prediction. HyGRAR is a non-linear hybrid model that combines gradual relational association rule mining and artificial neural networks to discriminate between defective and non-defective software entities. Experiments performed based on 10 open-source data sets demonstrated the excellent performance of the HYGRAR classifier. HyGRAR performed better than most of the previously proposed approaches for software defect prediction in performance evaluations using the same data sets.|Artificial neural network, Gradual relational association rule, Machine learning, Software defect prediction||||||
SCIENCE DIRECT|Laviron A,Gourlaouen V,Hamadache C,Hiver C,Kiener J,Peyré J,Tatischeff V|||Nuclear Instruments and Methods in Physics Research Section A: Accelerators, Spectrometers, Detectors and Associated Equipment|2021||1007|||||165379||10.1016/j.nima.2021.165379|http://dx.doi.org/10.1016/j.nima.2021.165379;https://www.sciencedirect.com/science/article/pii/S0168900221003636|For the next generation of MeV range gamma-ray telescopes, position sensitive calorimeters based on a monolithic scintillator coupled to a pixelated photodetector could be an important building block. In this paper, we present the optimization of the position reconstruction algorithms using machine learning, for a detector based on a 51×51×10mm3 CeBr3 crystal. For that purpose, we used an automated test bench and collimated radioactive sources to generate experimental data of known energy and position by irradiating the detector with gamma rays. We found in these data different gamma-ray interaction morphologies for which position reconstruction algorithms perform differently, and we developed an algorithm to automatically classify them. We also conducted an extensive optimization of the artificial neural networks that perform the 3D position reconstruction using the Keras Python library with Theano backend. We found that at 662keV, 90% of events have a morphology that facilitates position reconstruction. The optimized position reconstruction algorithms give for those events a rms error in the plane of the detector of 1.8mm on each axis. The rms error in the depth of the crystal is found to be 2mm.|gamma-ray astronomy, Compton imaging, Artificial neural network, Scintillating calorimeter, Cerium bromide, Position reconstruction, Spatial resolution||||||
SCIENCE DIRECT|Czibula G,Czibula IG,Marian Z|||Applied Soft Computing|2018||65|||||517-530||10.1016/j.asoc.2018.01.042|http://dx.doi.org/10.1016/j.asoc.2018.01.042;https://www.sciencedirect.com/science/article/pii/S1568494618300486|Within the software testing domain, determining the order in which classes are tested in integration testing is an important problem called class integration test order identification (CITO). This problem is useful in integration testing, as it contributes to reducing the time needed for testing a software system and refers to the process of identifying an optimal order in which the application classes should be combined and tested as a group. This paper introduces a novel approach based on reinforcement learning for class integration test order optimization in the context of integration testing. The experimental evaluation is performed on four synthetic examples and on six existing software systems often used in the literature for this problem. The results obtained are analyzed and compared to similar related work from the literature, highlighting the potential of the current proposal. The proposed reinforcement learning based approach outperforms most methods existing in the software engineering literature for optimizing the test order for class-based integration. Moreover, it is general, and can be easily extended for optimizing the order in which software components should be tested during component integration testing of a software system.|Integration testing, Class integration test order identification, Machine learning, Reinforcement learning||||||
SCIENCE DIRECT|Taneja D,Singh R,Singh A,Malik H|||Procedia Computer Science|2020||167|||||2221-2228||10.1016/j.procs.2020.03.274|http://dx.doi.org/10.1016/j.procs.2020.03.274;https://www.sciencedirect.com/science/article/pii/S1877050920307407|Software maintenance is the costliest phase of software life cycle and it consumes almost 70 percent of resources of development process. Software testing involves the examining the built software with the intension to find the defects in it. Exhaustive testing of the software for all possible test cases is not feasible as may take infinitely large amount of time and may consume large number of other resources. Researchers in the field of the software testing are exploring the different possibilities to reduce the required number of test cases to test given software. In case of an object oriented (OO) software, the complexities like inheritance, coupling and cohesion, make the software modules more prone to the faults. This problem gets augmented in case of very large software systems. Many researchers have solved the problem of test case minimization from the different perspectives like requirements coverage; statement coverage and risk coverage. But negligible research has been done of the basis of security metrics coverage. In this paper, a technique has been presented for minimization of test cases for the OO systems. The research reported in the paper has considered security as a perspective for test cases evaluation and minimization. Publically available data sets pertaining to open source software Camel 1.6.1 have been used for the evaluation of proposed methodology. Linear Regression (LR) model for the bugs present in the data and various object oriented metrics for security have been developed. The proposed model dissects the given metrics sets into effective and non-effective metrics. Effective metrics are then utilized for giving weights to the test cases, further with the help of weights obtained the test suite is minimized. The performance results of proposed approach are encouraging.|Object oriented metrics, Test Case Minimization, machine learning, object oriented testing||||||
